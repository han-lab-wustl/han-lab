{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31095e6-def7-4715-b424-13830d204d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTraining Data is a N*T*n tensor, N is the number of samples, T is the interval,\\nn is number of neurons.\\nTraining Data is a N*1*1 tensor, N is the number of samples, 1*1 represents the\\noutput dimension, which is the position of last time point.\\nTesting Data is a N'*T*n tensor.\\nTesting label is a N*1*1 tensor.\\nE.g.,\\nTrainingData = create_subsequences(np.transpose(X, TimeInterval))\\nTrainingLabel = Y[TimeInterval-1:].reshape(-1,1)\\nX is dFF, Y is corresponding position.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Training Data is a N*T*n tensor, N is the number of samples, T is the interval,\n",
    "n is number of neurons.\n",
    "Training Data is a N*1*1 tensor, N is the number of samples, 1*1 represents the\n",
    "output dimension, which is the position of last time point.\n",
    "Testing Data is a N'*T*n tensor.\n",
    "Testing label is a N*1*1 tensor.\n",
    "E.g.,\n",
    "TrainingData = create_subsequences(np.transpose(X, TimeInterval))\n",
    "TrainingLabel = Y[TimeInterval-1:].reshape(-1,1)\n",
    "X is dFF, Y is corresponding position.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5af50423-b76f-4e59-a724-3db6f6fee61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import scipy, pandas as pd, random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 256, \n",
    "        output_dim = 1, \n",
    "        num_layers = 2):\n",
    "        # hidden_dim = height of network\n",
    "        # layers = wifth of network\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Initialize the LSTM, Hidden Layer, and Output Layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                dropout = 0.0, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Forward propagate the LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "def create_subsequences(time_series, subsequence_length=20):\n",
    "    num_subsequences = len(time_series) - subsequence_length + 1\n",
    "    subsequences = [time_series[i:i+subsequence_length] for i in range(num_subsequences)]\n",
    "    return np.array(subsequences)\n",
    "\n",
    "class CreateTimeSeriesData(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29889763-e36c-4fe3-a06e-92993d7618ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw data\n",
    "with open(\"Z:\\dcts_com_opto_inference.p\", \"rb\") as fp: #unpickle\n",
    "        dcts = pickle.load(fp)\n",
    "conddf = pd.read_csv(r\"Z:\\condition_df\\conddf_neural_com_inference.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2d63a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\analysis\\fmats\\e218\\days\\e218_day035_plane0_Fall.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('name_date_vr', 'O'), ('ROE', 'O'), ('lickThreshold', 'O'), ('reward', 'O'), ('time', 'O'), ('lick', 'O'), ('ypos', 'O'), ('lickVoltage', 'O'), ('trialNum', 'O'), ('timeROE', 'O'), ('optoTrigger', 'O'), ('changeRewLoc', 'O'), ('pressedKeys', 'O'), ('world', 'O'), ('imageSync', 'O'), ('scalingFACTOR', 'O'), ('wOff', 'O'), ('settings', 'O')]\n",
      "0.6666666666666666\n",
      "6.666666666666666\n"
     ]
    }
   ],
   "source": [
    "dd=4\n",
    "animal = conddf.animals.values[dd]\n",
    "day = conddf.days.values[dd]\n",
    "savepth = rf'Z:\\models_lstm_all_cells_no_rew'   \n",
    "testpth = glob.glob(os.path.join(savepth, f'model_dd{dd:02d}*_{animal}_day{day}*'), recursive=True)\n",
    "dct = dcts[dd]\n",
    "params_pth = rf\"Y:\\analysis\\fmats\\{animal}\\days\\{animal}_day{day:03d}_plane0_Fall.mat\"\n",
    "print(params_pth)\n",
    "fall = scipy.io.loadmat(params_pth, variable_names=['dFF', 'forwardvel', 'ybinned', 'iscell',\n",
    "                            'trialnum', 'bordercells', 'changeRewLoc', 'licks', 'VR'])\n",
    "VR = fall['VR'][0][0]\n",
    "print(VR.dtype)\n",
    "gainf = VR[15][0][0]\n",
    "print(gainf)\n",
    "print(VR[17][0][0][4][0][0])\n",
    "    # gainf = VR[14][0][0]\n",
    "    # rewsize = VR[16][0][0][4][0][0]/gainf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d706cd70-567b-4dfe-a185-adb96ce06eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\analysis\\fmats\\e218\\days\\e218_day044_plane0_Fall.mat\n",
      "(9361, 859)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7382.5313\n",
      "Validation Loss: 8001.3311\n",
      "Epoch [21/3000], Loss: 6246.7324\n",
      "Validation Loss: 6791.0223\n",
      "Epoch [41/3000], Loss: 5995.6915\n",
      "Validation Loss: 6526.2552\n",
      "Epoch [61/3000], Loss: 5788.6340\n",
      "Validation Loss: 6312.3642\n",
      "Epoch [81/3000], Loss: 5607.4048\n",
      "Validation Loss: 6115.3774\n",
      "Epoch [101/3000], Loss: 5417.0054\n",
      "Validation Loss: 5929.2074\n",
      "Epoch [121/3000], Loss: 5260.8977\n",
      "Validation Loss: 5751.5136\n",
      "Epoch [141/3000], Loss: 5083.1036\n",
      "Validation Loss: 5581.4743\n",
      "Epoch [161/3000], Loss: 4950.6935\n",
      "Validation Loss: 5418.3169\n",
      "Epoch [181/3000], Loss: 4793.3418\n",
      "Validation Loss: 5262.0108\n",
      "Epoch [201/3000], Loss: 4667.0665\n",
      "Validation Loss: 5112.3281\n",
      "Epoch [221/3000], Loss: 4526.2545\n",
      "Validation Loss: 4969.0112\n",
      "Epoch [241/3000], Loss: 4406.8986\n",
      "Validation Loss: 4832.1353\n",
      "Epoch [261/3000], Loss: 4260.7670\n",
      "Validation Loss: 4701.7425\n",
      "Epoch [281/3000], Loss: 4168.9103\n",
      "Validation Loss: 4577.7845\n",
      "Epoch [301/3000], Loss: 4054.5992\n",
      "Validation Loss: 4459.9038\n",
      "Epoch [321/3000], Loss: 3962.9939\n",
      "Validation Loss: 4348.4133\n",
      "Epoch [341/3000], Loss: 3848.7986\n",
      "Validation Loss: 4243.1802\n",
      "Epoch [361/3000], Loss: 3766.9061\n",
      "Validation Loss: 4144.2586\n",
      "Epoch [381/3000], Loss: 3681.7993\n",
      "Validation Loss: 4051.4503\n",
      "Epoch [401/3000], Loss: 3601.0606\n",
      "Validation Loss: 3964.9353\n",
      "Epoch [421/3000], Loss: 3531.0134\n",
      "Validation Loss: 3884.4434\n",
      "Epoch [441/3000], Loss: 3469.3747\n",
      "Validation Loss: 3810.0850\n",
      "Epoch [461/3000], Loss: 2812.5414\n",
      "Validation Loss: 3407.6424\n",
      "Epoch [481/3000], Loss: 2637.0853\n",
      "Validation Loss: 3295.3708\n",
      "Epoch [501/3000], Loss: 2517.7260\n",
      "Validation Loss: 3176.3145\n",
      "Epoch [521/3000], Loss: 2399.6811\n",
      "Validation Loss: 3086.7339\n",
      "Epoch [541/3000], Loss: 2296.7338\n",
      "Validation Loss: 3000.4552\n",
      "Epoch [561/3000], Loss: 2197.8496\n",
      "Validation Loss: 2927.5373\n",
      "Epoch [581/3000], Loss: 2103.1712\n",
      "Validation Loss: 2829.2259\n",
      "Epoch [601/3000], Loss: 1997.4666\n",
      "Validation Loss: 2708.2745\n",
      "Epoch [621/3000], Loss: 1913.3379\n",
      "Validation Loss: 2680.8026\n",
      "Epoch [641/3000], Loss: 1825.4769\n",
      "Validation Loss: 2603.1456\n",
      "Epoch [661/3000], Loss: 1739.1580\n",
      "Validation Loss: 2543.5042\n",
      "Epoch [681/3000], Loss: 1655.7506\n",
      "Validation Loss: 2489.7029\n",
      "Epoch [701/3000], Loss: 1578.8617\n",
      "Validation Loss: 2429.2054\n",
      "Epoch [721/3000], Loss: 1500.7136\n",
      "Validation Loss: 2381.8167\n",
      "Epoch [741/3000], Loss: 1428.8702\n",
      "Validation Loss: 2332.5297\n",
      "Epoch [761/3000], Loss: 1353.5259\n",
      "Validation Loss: 2276.2653\n",
      "Epoch [781/3000], Loss: 1282.6836\n",
      "Validation Loss: 2244.3174\n",
      "Epoch [801/3000], Loss: 1214.4873\n",
      "Validation Loss: 2194.4216\n",
      "Epoch [821/3000], Loss: 1156.3044\n",
      "Validation Loss: 2153.1640\n",
      "Epoch [841/3000], Loss: 1091.9703\n",
      "Validation Loss: 2106.7438\n",
      "Epoch [861/3000], Loss: 1031.4960\n",
      "Validation Loss: 2070.6046\n",
      "Epoch [881/3000], Loss: 972.2979\n",
      "Validation Loss: 2035.7740\n",
      "Epoch [901/3000], Loss: 913.3333\n",
      "Validation Loss: 2010.8010\n",
      "Epoch [921/3000], Loss: 887.4405\n",
      "Validation Loss: 2266.5524\n",
      "Epoch [941/3000], Loss: 815.4154\n",
      "Validation Loss: 1884.7948\n",
      "Epoch [961/3000], Loss: 772.5092\n",
      "Validation Loss: 1865.7603\n",
      "Epoch [981/3000], Loss: 723.9533\n",
      "Validation Loss: 1852.7808\n",
      "Epoch [1001/3000], Loss: 682.9011\n",
      "Validation Loss: 1831.9069\n",
      "Epoch [1021/3000], Loss: 640.9769\n",
      "Validation Loss: 1817.3715\n",
      "Epoch [1041/3000], Loss: 600.9465\n",
      "Validation Loss: 1813.2857\n",
      "Epoch [1061/3000], Loss: 562.4628\n",
      "Validation Loss: 1798.6614\n",
      "Epoch [1081/3000], Loss: 525.8190\n",
      "Validation Loss: 1769.4943\n",
      "Epoch [1101/3000], Loss: 489.1964\n",
      "Validation Loss: 1755.4665\n",
      "Epoch [1121/3000], Loss: 457.2117\n",
      "Validation Loss: 1736.6345\n",
      "Epoch [1141/3000], Loss: 426.8447\n",
      "Validation Loss: 1737.9235\n",
      "Epoch [1161/3000], Loss: 406.8063\n",
      "Validation Loss: 1692.6931\n",
      "Epoch [1181/3000], Loss: 370.4568\n",
      "Validation Loss: 1707.7493\n",
      "Epoch [1201/3000], Loss: 343.6449\n",
      "Validation Loss: 1698.8505\n",
      "Epoch [1221/3000], Loss: 319.0257\n",
      "Validation Loss: 1692.4688\n",
      "Epoch [1241/3000], Loss: 293.5493\n",
      "Validation Loss: 1686.1831\n",
      "Epoch [1261/3000], Loss: 271.9971\n",
      "Validation Loss: 1691.9725\n",
      "Epoch [1281/3000], Loss: 249.5572\n",
      "Validation Loss: 1704.1374\n",
      "Epoch [1301/3000], Loss: 231.0034\n",
      "Validation Loss: 1711.8738\n",
      "Epoch [1321/3000], Loss: 211.6895\n",
      "Validation Loss: 1718.4200\n",
      "Epoch [1341/3000], Loss: 194.9623\n",
      "Validation Loss: 1743.6777\n",
      "Epoch [1361/3000], Loss: 177.9310\n",
      "Validation Loss: 1759.7862\n",
      "Epoch [1381/3000], Loss: 162.6709\n",
      "Validation Loss: 1766.1613\n",
      "Epoch [1401/3000], Loss: 147.9977\n",
      "Validation Loss: 1810.5652\n",
      "Epoch [1421/3000], Loss: 135.1104\n",
      "Validation Loss: 1736.7786\n",
      "Epoch [1441/3000], Loss: 122.2404\n",
      "Validation Loss: 1767.3934\n",
      "Epoch [1461/3000], Loss: 110.3325\n",
      "Validation Loss: 1775.1587\n",
      "Epoch [1481/3000], Loss: 100.3219\n",
      "Validation Loss: 1792.0696\n",
      "Epoch [1501/3000], Loss: 89.9331\n",
      "Validation Loss: 1814.7577\n",
      "Epoch [1521/3000], Loss: 80.6589\n",
      "Validation Loss: 1823.5934\n",
      "Epoch [1541/3000], Loss: 71.1488\n",
      "Validation Loss: 1843.4875\n",
      "Epoch [1561/3000], Loss: 63.8491\n",
      "Validation Loss: 1858.1771\n",
      "Epoch [1581/3000], Loss: 56.2943\n",
      "Validation Loss: 1870.6739\n",
      "Epoch [1601/3000], Loss: 49.7209\n",
      "Validation Loss: 1901.8022\n",
      "Epoch [1621/3000], Loss: 43.5482\n",
      "Validation Loss: 1924.9834\n",
      "Epoch [1641/3000], Loss: 38.1149\n",
      "Validation Loss: 1914.5250\n",
      "Epoch [1661/3000], Loss: 41.9950\n",
      "Validation Loss: 1768.7047\n",
      "Epoch [1681/3000], Loss: 28.7015\n",
      "Validation Loss: 1876.1680\n",
      "Epoch [1701/3000], Loss: 24.6948\n",
      "Validation Loss: 1899.9259\n",
      "Epoch [1721/3000], Loss: 21.0495\n",
      "Validation Loss: 1923.9936\n",
      "Epoch [1741/3000], Loss: 17.8900\n",
      "Validation Loss: 1946.4604\n",
      "Epoch [1761/3000], Loss: 15.1897\n",
      "Validation Loss: 1960.4421\n",
      "Epoch [1781/3000], Loss: 12.5707\n",
      "Validation Loss: 1988.1851\n",
      "Epoch [1801/3000], Loss: 10.2299\n",
      "Validation Loss: 1995.7685\n",
      "Epoch [1821/3000], Loss: 8.2464\n",
      "Validation Loss: 2001.2273\n",
      "Epoch [1841/3000], Loss: 6.6174\n",
      "Validation Loss: 2009.2710\n",
      "Epoch [1861/3000], Loss: 5.2909\n",
      "Validation Loss: 2024.4342\n",
      "Epoch [1881/3000], Loss: 4.0013\n",
      "Validation Loss: 2016.9692\n",
      "Epoch [1901/3000], Loss: 3.0514\n",
      "Validation Loss: 2031.0036\n",
      "Epoch [1921/3000], Loss: 2.3113\n",
      "Validation Loss: 2024.3523\n",
      "Epoch [1941/3000], Loss: 1.6779\n",
      "Validation Loss: 2018.6397\n",
      "Epoch [1961/3000], Loss: 1.1965\n",
      "Validation Loss: 1994.8589\n",
      "Epoch [1981/3000], Loss: 0.8382\n",
      "Validation Loss: 1967.1605\n",
      "Epoch [2001/3000], Loss: 0.5819\n",
      "Validation Loss: 1983.1831\n",
      "Epoch [2021/3000], Loss: 0.3765\n",
      "Validation Loss: 1974.8823\n",
      "Epoch [2041/3000], Loss: 0.2560\n",
      "Validation Loss: 1974.7182\n",
      "Epoch [2061/3000], Loss: 0.1715\n",
      "Validation Loss: 1979.9144\n",
      "Epoch [2081/3000], Loss: 0.1266\n",
      "Validation Loss: 1954.1219\n",
      "Epoch [2101/3000], Loss: 0.0884\n",
      "Validation Loss: 1965.5939\n",
      "Epoch [2121/3000], Loss: 0.0835\n",
      "Validation Loss: 1964.7547\n",
      "Epoch [2141/3000], Loss: 0.0579\n",
      "Validation Loss: 1956.1210\n",
      "Epoch [2161/3000], Loss: 0.0542\n",
      "Validation Loss: 1955.1806\n",
      "Epoch [2181/3000], Loss: 0.0517\n",
      "Validation Loss: 1948.7011\n",
      "Epoch [2201/3000], Loss: 0.0461\n",
      "Validation Loss: 1947.5825\n",
      "Epoch [2221/3000], Loss: 0.0407\n",
      "Validation Loss: 1935.0868\n",
      "Epoch [2241/3000], Loss: 0.0387\n",
      "Validation Loss: 1940.5857\n",
      "Epoch [2261/3000], Loss: 0.0344\n",
      "Validation Loss: 1946.4512\n",
      "Epoch [2281/3000], Loss: 0.0340\n",
      "Validation Loss: 1933.5644\n",
      "Epoch [2301/3000], Loss: 0.0335\n",
      "Validation Loss: 1912.4323\n",
      "Epoch [2321/3000], Loss: 0.0392\n",
      "Validation Loss: 1923.6818\n",
      "Epoch [2341/3000], Loss: 0.0430\n",
      "Validation Loss: 1916.7522\n",
      "Epoch [2361/3000], Loss: 0.0285\n",
      "Validation Loss: 1917.7971\n",
      "Epoch [2381/3000], Loss: 0.0190\n",
      "Validation Loss: 1899.4249\n",
      "Epoch [2401/3000], Loss: 0.0237\n",
      "Validation Loss: 1913.5118\n",
      "Epoch [2421/3000], Loss: 0.0225\n",
      "Validation Loss: 1917.8655\n",
      "Epoch [2441/3000], Loss: 0.0198\n",
      "Validation Loss: 1916.4215\n",
      "Epoch [2461/3000], Loss: 0.0440\n",
      "Validation Loss: 1916.5054\n",
      "Epoch [2481/3000], Loss: 0.0199\n",
      "Validation Loss: 1904.1892\n",
      "Epoch [2501/3000], Loss: 0.0209\n",
      "Validation Loss: 1903.3927\n",
      "Epoch [2521/3000], Loss: 0.0159\n",
      "Validation Loss: 1903.9935\n",
      "Epoch [2541/3000], Loss: 0.0227\n",
      "Validation Loss: 1900.8174\n",
      "Epoch [2561/3000], Loss: 0.0407\n",
      "Validation Loss: 1886.2503\n",
      "Epoch [2581/3000], Loss: 0.0167\n",
      "Validation Loss: 1906.1210\n",
      "Epoch [2601/3000], Loss: 0.0181\n",
      "Validation Loss: 1896.8494\n",
      "Epoch [2621/3000], Loss: 0.0292\n",
      "Validation Loss: 1902.0876\n",
      "Epoch [2641/3000], Loss: 0.0173\n",
      "Validation Loss: 1894.9895\n",
      "Epoch [2661/3000], Loss: 0.0114\n",
      "Validation Loss: 1891.6975\n",
      "Epoch [2681/3000], Loss: 0.0155\n",
      "Validation Loss: 1894.6428\n",
      "Epoch [2701/3000], Loss: 0.0193\n",
      "Validation Loss: 1880.3879\n",
      "Epoch [2721/3000], Loss: 0.0108\n",
      "Validation Loss: 1893.6396\n",
      "Epoch [2741/3000], Loss: 0.0111\n",
      "Validation Loss: 1888.7239\n",
      "Epoch [2761/3000], Loss: 0.0298\n",
      "Validation Loss: 1878.9498\n",
      "Epoch [2781/3000], Loss: 0.0145\n",
      "Validation Loss: 1885.1467\n",
      "Epoch [2801/3000], Loss: 0.0173\n",
      "Validation Loss: 1884.1665\n",
      "Epoch [2821/3000], Loss: 0.0143\n",
      "Validation Loss: 1886.7853\n",
      "Epoch [2841/3000], Loss: 0.0132\n",
      "Validation Loss: 1884.9653\n",
      "Epoch [2861/3000], Loss: 1.3886\n",
      "Validation Loss: 1649.1933\n",
      "Epoch [2881/3000], Loss: 0.0828\n",
      "Validation Loss: 1731.2708\n",
      "Epoch [2901/3000], Loss: 0.0380\n",
      "Validation Loss: 1743.0057\n",
      "Epoch [2921/3000], Loss: 0.0220\n",
      "Validation Loss: 1751.0056\n",
      "Epoch [2941/3000], Loss: 0.0147\n",
      "Validation Loss: 1759.2704\n",
      "Epoch [2961/3000], Loss: 0.0111\n",
      "Validation Loss: 1765.3280\n",
      "Epoch [2981/3000], Loss: 0.0090\n",
      "Validation Loss: 1770.7714\n",
      "Y:\\analysis\\fmats\\e218\\days\\e218_day047_plane0_Fall.mat\n",
      "(6944, 691)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8537.8887\n",
      "Validation Loss: 8237.5420\n",
      "Epoch [21/3000], Loss: 7298.7031\n",
      "Validation Loss: 7041.4401\n",
      "Epoch [41/3000], Loss: 7055.6855\n",
      "Validation Loss: 6803.1898\n",
      "Epoch [61/3000], Loss: 6850.2297\n",
      "Validation Loss: 6616.4832\n",
      "Epoch [81/3000], Loss: 6692.6897\n",
      "Validation Loss: 6452.1072\n",
      "Epoch [101/3000], Loss: 6532.1862\n",
      "Validation Loss: 6296.9526\n",
      "Epoch [121/3000], Loss: 6374.7635\n",
      "Validation Loss: 6148.2600\n",
      "Epoch [141/3000], Loss: 6222.0487\n",
      "Validation Loss: 6001.1619\n",
      "Epoch [161/3000], Loss: 6076.8978\n",
      "Validation Loss: 5858.5293\n",
      "Epoch [181/3000], Loss: 5932.8181\n",
      "Validation Loss: 5721.9247\n",
      "Epoch [201/3000], Loss: 5794.6850\n",
      "Validation Loss: 5589.6296\n",
      "Epoch [221/3000], Loss: 5657.3337\n",
      "Validation Loss: 5461.2924\n",
      "Epoch [241/3000], Loss: 5531.0133\n",
      "Validation Loss: 5336.8017\n",
      "Epoch [261/3000], Loss: 5405.4382\n",
      "Validation Loss: 5216.0879\n",
      "Epoch [281/3000], Loss: 5283.8901\n",
      "Validation Loss: 5099.1099\n",
      "Epoch [301/3000], Loss: 5154.7806\n",
      "Validation Loss: 4985.7366\n",
      "Epoch [321/3000], Loss: 5040.3148\n",
      "Validation Loss: 4875.9643\n",
      "Epoch [341/3000], Loss: 4934.7684\n",
      "Validation Loss: 4769.9153\n",
      "Epoch [361/3000], Loss: 4820.8154\n",
      "Validation Loss: 4667.3685\n",
      "Epoch [381/3000], Loss: 4723.9405\n",
      "Validation Loss: 4568.4283\n",
      "Epoch [401/3000], Loss: 4616.9405\n",
      "Validation Loss: 4473.0652\n",
      "Epoch [421/3000], Loss: 4518.2674\n",
      "Validation Loss: 4381.2461\n",
      "Epoch [441/3000], Loss: 4427.3495\n",
      "Validation Loss: 4293.0438\n",
      "Epoch [461/3000], Loss: 4338.5328\n",
      "Validation Loss: 4208.3232\n",
      "Epoch [481/3000], Loss: 4255.0559\n",
      "Validation Loss: 4127.1481\n",
      "Epoch [501/3000], Loss: 4166.4825\n",
      "Validation Loss: 4049.4523\n",
      "Epoch [521/3000], Loss: 4087.5890\n",
      "Validation Loss: 3975.2981\n",
      "Epoch [541/3000], Loss: 4015.4564\n",
      "Validation Loss: 3904.5751\n",
      "Epoch [561/3000], Loss: 3943.6362\n",
      "Validation Loss: 3836.0847\n",
      "Epoch [581/3000], Loss: 3870.5122\n",
      "Validation Loss: 3772.0477\n",
      "Epoch [601/3000], Loss: 3783.6449\n",
      "Validation Loss: 3682.0926\n",
      "Epoch [621/3000], Loss: 3082.4386\n",
      "Validation Loss: 3127.8228\n",
      "Epoch [641/3000], Loss: 2953.8603\n",
      "Validation Loss: 3064.9302\n",
      "Epoch [661/3000], Loss: 2851.3627\n",
      "Validation Loss: 2963.4069\n",
      "Epoch [681/3000], Loss: 2745.9625\n",
      "Validation Loss: 2867.8539\n",
      "Epoch [701/3000], Loss: 2652.5214\n",
      "Validation Loss: 2788.0238\n",
      "Epoch [721/3000], Loss: 2555.9251\n",
      "Validation Loss: 2699.7416\n",
      "Epoch [741/3000], Loss: 2468.9735\n",
      "Validation Loss: 2628.5052\n",
      "Epoch [761/3000], Loss: 2381.8497\n",
      "Validation Loss: 2539.3282\n",
      "Epoch [781/3000], Loss: 2299.0644\n",
      "Validation Loss: 2467.2190\n",
      "Epoch [801/3000], Loss: 2216.6802\n",
      "Validation Loss: 2390.9568\n",
      "Epoch [821/3000], Loss: 2136.1946\n",
      "Validation Loss: 2324.7319\n",
      "Epoch [841/3000], Loss: 2056.9688\n",
      "Validation Loss: 2252.6041\n",
      "Epoch [861/3000], Loss: 1979.7267\n",
      "Validation Loss: 2183.5789\n",
      "Epoch [881/3000], Loss: 1904.5959\n",
      "Validation Loss: 2126.9984\n",
      "Epoch [901/3000], Loss: 1833.2469\n",
      "Validation Loss: 2065.4654\n",
      "Epoch [921/3000], Loss: 1765.3231\n",
      "Validation Loss: 2039.3603\n",
      "Epoch [941/3000], Loss: 1694.3255\n",
      "Validation Loss: 1968.6796\n",
      "Epoch [961/3000], Loss: 1628.6517\n",
      "Validation Loss: 1910.7166\n",
      "Epoch [981/3000], Loss: 1560.0139\n",
      "Validation Loss: 1857.2886\n",
      "Epoch [1001/3000], Loss: 1501.9649\n",
      "Validation Loss: 1809.6245\n",
      "Epoch [1021/3000], Loss: 1438.7424\n",
      "Validation Loss: 1772.5408\n",
      "Epoch [1041/3000], Loss: 1380.1488\n",
      "Validation Loss: 1721.7779\n",
      "Epoch [1061/3000], Loss: 1325.8461\n",
      "Validation Loss: 1674.9178\n",
      "Epoch [1081/3000], Loss: 1267.7956\n",
      "Validation Loss: 1632.1548\n",
      "Epoch [1101/3000], Loss: 1214.6761\n",
      "Validation Loss: 1601.9161\n",
      "Epoch [1121/3000], Loss: 1159.2662\n",
      "Validation Loss: 1544.2462\n",
      "Epoch [1141/3000], Loss: 1111.2192\n",
      "Validation Loss: 1500.2616\n",
      "Epoch [1161/3000], Loss: 1063.8852\n",
      "Validation Loss: 1446.0304\n",
      "Epoch [1181/3000], Loss: 1015.7702\n",
      "Validation Loss: 1411.5818\n",
      "Epoch [1201/3000], Loss: 967.1907\n",
      "Validation Loss: 1368.6592\n",
      "Epoch [1221/3000], Loss: 926.3211\n",
      "Validation Loss: 1331.0968\n",
      "Epoch [1241/3000], Loss: 880.7408\n",
      "Validation Loss: 1296.8293\n",
      "Epoch [1261/3000], Loss: 838.8858\n",
      "Validation Loss: 1269.0315\n",
      "Epoch [1281/3000], Loss: 800.6983\n",
      "Validation Loss: 1250.6942\n",
      "Epoch [1301/3000], Loss: 762.1436\n",
      "Validation Loss: 1224.7482\n",
      "Epoch [1321/3000], Loss: 724.1765\n",
      "Validation Loss: 1197.1850\n",
      "Epoch [1341/3000], Loss: 687.7328\n",
      "Validation Loss: 1173.0321\n",
      "Epoch [1361/3000], Loss: 654.2844\n",
      "Validation Loss: 1140.8629\n",
      "Epoch [1381/3000], Loss: 621.4469\n",
      "Validation Loss: 1117.0136\n",
      "Epoch [1401/3000], Loss: 589.0472\n",
      "Validation Loss: 1102.7402\n",
      "Epoch [1421/3000], Loss: 558.7430\n",
      "Validation Loss: 1075.8025\n",
      "Epoch [1441/3000], Loss: 530.0190\n",
      "Validation Loss: 1064.5142\n",
      "Epoch [1461/3000], Loss: 501.5574\n",
      "Validation Loss: 1043.1445\n",
      "Epoch [1481/3000], Loss: 473.0176\n",
      "Validation Loss: 1020.5069\n",
      "Epoch [1501/3000], Loss: 448.4063\n",
      "Validation Loss: 1004.1314\n",
      "Epoch [1521/3000], Loss: 423.0733\n",
      "Validation Loss: 983.1161\n",
      "Epoch [1541/3000], Loss: 398.0372\n",
      "Validation Loss: 962.1841\n",
      "Epoch [1561/3000], Loss: 374.4579\n",
      "Validation Loss: 934.4466\n",
      "Epoch [1581/3000], Loss: 353.6017\n",
      "Validation Loss: 920.6621\n",
      "Epoch [1601/3000], Loss: 333.5544\n",
      "Validation Loss: 900.9468\n",
      "Epoch [1621/3000], Loss: 311.1119\n",
      "Validation Loss: 895.1431\n",
      "Epoch [1641/3000], Loss: 294.2331\n",
      "Validation Loss: 868.2679\n",
      "Epoch [1661/3000], Loss: 277.1068\n",
      "Validation Loss: 858.1401\n",
      "Epoch [1681/3000], Loss: 259.4580\n",
      "Validation Loss: 837.3190\n",
      "Epoch [1701/3000], Loss: 243.1031\n",
      "Validation Loss: 822.4346\n",
      "Epoch [1721/3000], Loss: 227.9258\n",
      "Validation Loss: 815.2385\n",
      "Epoch [1741/3000], Loss: 213.0505\n",
      "Validation Loss: 805.7323\n",
      "Epoch [1761/3000], Loss: 199.0257\n",
      "Validation Loss: 801.5633\n",
      "Epoch [1781/3000], Loss: 185.8108\n",
      "Validation Loss: 788.3064\n",
      "Epoch [1801/3000], Loss: 174.4426\n",
      "Validation Loss: 781.0402\n",
      "Epoch [1821/3000], Loss: 162.9434\n",
      "Validation Loss: 776.0206\n",
      "Epoch [1841/3000], Loss: 151.6567\n",
      "Validation Loss: 766.3755\n",
      "Epoch [1861/3000], Loss: 141.7790\n",
      "Validation Loss: 761.4347\n",
      "Epoch [1881/3000], Loss: 132.1445\n",
      "Validation Loss: 753.7015\n",
      "Epoch [1901/3000], Loss: 122.5630\n",
      "Validation Loss: 781.1270\n",
      "Epoch [1921/3000], Loss: 111.9236\n",
      "Validation Loss: 811.6787\n",
      "Epoch [1941/3000], Loss: 104.3822\n",
      "Validation Loss: 807.7906\n",
      "Epoch [1961/3000], Loss: 96.8559\n",
      "Validation Loss: 804.1779\n",
      "Epoch [1981/3000], Loss: 89.8873\n",
      "Validation Loss: 797.4477\n",
      "Epoch [2001/3000], Loss: 83.4288\n",
      "Validation Loss: 789.8046\n",
      "Epoch [2021/3000], Loss: 77.0985\n",
      "Validation Loss: 787.4819\n",
      "Epoch [2041/3000], Loss: 71.1552\n",
      "Validation Loss: 782.1264\n",
      "Epoch [2061/3000], Loss: 65.2574\n",
      "Validation Loss: 773.7723\n",
      "Epoch [2081/3000], Loss: 59.7349\n",
      "Validation Loss: 770.1012\n",
      "Epoch [2101/3000], Loss: 55.0471\n",
      "Validation Loss: 762.8696\n",
      "Epoch [2121/3000], Loss: 50.4154\n",
      "Validation Loss: 756.7758\n",
      "Epoch [2141/3000], Loss: 45.8001\n",
      "Validation Loss: 749.6243\n",
      "Epoch [2161/3000], Loss: 41.4700\n",
      "Validation Loss: 748.6086\n",
      "Epoch [2181/3000], Loss: 37.3864\n",
      "Validation Loss: 744.9035\n",
      "Epoch [2201/3000], Loss: 33.6465\n",
      "Validation Loss: 744.9207\n",
      "Epoch [2221/3000], Loss: 30.1061\n",
      "Validation Loss: 740.4051\n",
      "Epoch [2241/3000], Loss: 26.6241\n",
      "Validation Loss: 738.0512\n",
      "Epoch [2261/3000], Loss: 23.6612\n",
      "Validation Loss: 738.4071\n",
      "Epoch [2281/3000], Loss: 20.9542\n",
      "Validation Loss: 735.8479\n",
      "Epoch [2301/3000], Loss: 18.4250\n",
      "Validation Loss: 726.4932\n",
      "Epoch [2321/3000], Loss: 16.0014\n",
      "Validation Loss: 729.2502\n",
      "Epoch [2341/3000], Loss: 14.0622\n",
      "Validation Loss: 722.4255\n",
      "Epoch [2361/3000], Loss: 12.1886\n",
      "Validation Loss: 721.5545\n",
      "Epoch [2381/3000], Loss: 10.5194\n",
      "Validation Loss: 721.2873\n",
      "Epoch [2401/3000], Loss: 9.0259\n",
      "Validation Loss: 710.4488\n",
      "Epoch [2421/3000], Loss: 7.5891\n",
      "Validation Loss: 712.9426\n",
      "Epoch [2441/3000], Loss: 6.4499\n",
      "Validation Loss: 718.3198\n",
      "Epoch [2461/3000], Loss: 5.3113\n",
      "Validation Loss: 713.7878\n",
      "Epoch [2481/3000], Loss: 4.4759\n",
      "Validation Loss: 710.4363\n",
      "Epoch [2501/3000], Loss: 3.6661\n",
      "Validation Loss: 717.7623\n",
      "Epoch [2521/3000], Loss: 2.9716\n",
      "Validation Loss: 716.6276\n",
      "Epoch [2541/3000], Loss: 2.3845\n",
      "Validation Loss: 715.3741\n",
      "Epoch [2561/3000], Loss: 1.8741\n",
      "Validation Loss: 714.8443\n",
      "Epoch [2581/3000], Loss: 1.4621\n",
      "Validation Loss: 719.6521\n",
      "Epoch [2601/3000], Loss: 1.1188\n",
      "Validation Loss: 712.9172\n",
      "Epoch [2621/3000], Loss: 0.8445\n",
      "Validation Loss: 711.1939\n",
      "Epoch [2641/3000], Loss: 0.6260\n",
      "Validation Loss: 708.3816\n",
      "Epoch [2661/3000], Loss: 0.4459\n",
      "Validation Loss: 703.7174\n",
      "Epoch [2681/3000], Loss: 0.3076\n",
      "Validation Loss: 703.0470\n",
      "Epoch [2701/3000], Loss: 0.2174\n",
      "Validation Loss: 702.2569\n",
      "Epoch [2721/3000], Loss: 0.1379\n",
      "Validation Loss: 706.2643\n",
      "Epoch [2741/3000], Loss: 0.0889\n",
      "Validation Loss: 704.7538\n",
      "Epoch [2761/3000], Loss: 0.0606\n",
      "Validation Loss: 703.3867\n",
      "Epoch [2781/3000], Loss: 0.0411\n",
      "Validation Loss: 699.4256\n",
      "Epoch [2801/3000], Loss: 0.0370\n",
      "Validation Loss: 700.7524\n",
      "Epoch [2821/3000], Loss: 0.0309\n",
      "Validation Loss: 699.2101\n",
      "Epoch [2841/3000], Loss: 0.0254\n",
      "Validation Loss: 696.6526\n",
      "Epoch [2861/3000], Loss: 0.0174\n",
      "Validation Loss: 699.4851\n",
      "Epoch [2881/3000], Loss: 0.0223\n",
      "Validation Loss: 695.8310\n",
      "Epoch [2901/3000], Loss: 0.0150\n",
      "Validation Loss: 696.0025\n",
      "Epoch [2921/3000], Loss: 0.0175\n",
      "Validation Loss: 696.2586\n",
      "Epoch [2941/3000], Loss: 0.0128\n",
      "Validation Loss: 699.1498\n",
      "Epoch [2961/3000], Loss: 0.0212\n",
      "Validation Loss: 700.2919\n",
      "Epoch [2981/3000], Loss: 0.0142\n",
      "Validation Loss: 697.6656\n",
      "Y:\\analysis\\fmats\\e218\\days\\e218_day048_plane0_Fall.mat\n",
      "(7631, 855)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6130.9995\n",
      "Validation Loss: 6696.0183\n",
      "Epoch [21/3000], Loss: 5179.5225\n",
      "Validation Loss: 5606.3246\n",
      "Epoch [41/3000], Loss: 4973.1689\n",
      "Validation Loss: 5379.9717\n",
      "Epoch [61/3000], Loss: 4834.0295\n",
      "Validation Loss: 5210.8476\n",
      "Epoch [81/3000], Loss: 4675.1918\n",
      "Validation Loss: 5056.9237\n",
      "Epoch [101/3000], Loss: 4557.8871\n",
      "Validation Loss: 4912.4910\n",
      "Epoch [121/3000], Loss: 4433.9582\n",
      "Validation Loss: 4774.8377\n",
      "Epoch [141/3000], Loss: 4308.6612\n",
      "Validation Loss: 4642.8955\n",
      "Epoch [161/3000], Loss: 4228.5406\n",
      "Validation Loss: 4515.9357\n",
      "Epoch [181/3000], Loss: 4123.7331\n",
      "Validation Loss: 4393.5619\n",
      "Epoch [201/3000], Loss: 4006.5818\n",
      "Validation Loss: 4274.6444\n",
      "Epoch [221/3000], Loss: 3937.1576\n",
      "Validation Loss: 4159.8815\n",
      "Epoch [241/3000], Loss: 3855.4335\n",
      "Validation Loss: 4050.1998\n",
      "Epoch [261/3000], Loss: 3757.0129\n",
      "Validation Loss: 3944.7909\n",
      "Epoch [281/3000], Loss: 3662.8323\n",
      "Validation Loss: 3843.7327\n",
      "Epoch [301/3000], Loss: 3602.1619\n",
      "Validation Loss: 3746.6821\n",
      "Epoch [321/3000], Loss: 3199.9216\n",
      "Validation Loss: 3472.0014\n",
      "Epoch [341/3000], Loss: 3100.0557\n",
      "Validation Loss: 3367.0971\n",
      "Epoch [361/3000], Loss: 2948.0932\n",
      "Validation Loss: 3264.7864\n",
      "Epoch [381/3000], Loss: 2848.4030\n",
      "Validation Loss: 3167.3654\n",
      "Epoch [401/3000], Loss: 2751.2934\n",
      "Validation Loss: 3075.4483\n",
      "Epoch [421/3000], Loss: 2649.6997\n",
      "Validation Loss: 2967.1474\n",
      "Epoch [441/3000], Loss: 2588.6103\n",
      "Validation Loss: 2870.4382\n",
      "Epoch [461/3000], Loss: 2479.2804\n",
      "Validation Loss: 2776.2341\n",
      "Epoch [481/3000], Loss: 2386.0519\n",
      "Validation Loss: 2695.7665\n",
      "Epoch [501/3000], Loss: 2294.9432\n",
      "Validation Loss: 2604.2305\n",
      "Epoch [521/3000], Loss: 2219.6139\n",
      "Validation Loss: 2517.8813\n",
      "Epoch [541/3000], Loss: 2140.5545\n",
      "Validation Loss: 2437.9548\n",
      "Epoch [561/3000], Loss: 2067.3974\n",
      "Validation Loss: 2351.0206\n",
      "Epoch [581/3000], Loss: 1980.6240\n",
      "Validation Loss: 2303.4357\n",
      "Epoch [601/3000], Loss: 1909.7770\n",
      "Validation Loss: 2233.1372\n",
      "Epoch [621/3000], Loss: 1844.8187\n",
      "Validation Loss: 2161.6731\n",
      "Epoch [641/3000], Loss: 1767.4938\n",
      "Validation Loss: 2089.2610\n",
      "Epoch [661/3000], Loss: 1700.5846\n",
      "Validation Loss: 2017.6069\n",
      "Epoch [681/3000], Loss: 1635.6084\n",
      "Validation Loss: 1949.0499\n",
      "Epoch [701/3000], Loss: 1568.5662\n",
      "Validation Loss: 1882.8856\n",
      "Epoch [721/3000], Loss: 1506.4931\n",
      "Validation Loss: 1825.0186\n",
      "Epoch [741/3000], Loss: 1434.4301\n",
      "Validation Loss: 1763.5671\n",
      "Epoch [761/3000], Loss: 1383.2031\n",
      "Validation Loss: 1706.0655\n",
      "Epoch [781/3000], Loss: 1337.5377\n",
      "Validation Loss: 1652.6786\n",
      "Epoch [801/3000], Loss: 1280.0148\n",
      "Validation Loss: 1604.4409\n",
      "Epoch [821/3000], Loss: 1226.7423\n",
      "Validation Loss: 1543.6325\n",
      "Epoch [841/3000], Loss: 1179.0623\n",
      "Validation Loss: 1510.2754\n",
      "Epoch [861/3000], Loss: 1112.2584\n",
      "Validation Loss: 1435.1221\n",
      "Epoch [881/3000], Loss: 1075.6732\n",
      "Validation Loss: 1386.1301\n",
      "Epoch [901/3000], Loss: 1023.9783\n",
      "Validation Loss: 1359.1823\n",
      "Epoch [921/3000], Loss: 980.0484\n",
      "Validation Loss: 1319.2495\n",
      "Epoch [941/3000], Loss: 946.0041\n",
      "Validation Loss: 1280.4977\n",
      "Epoch [961/3000], Loss: 902.6284\n",
      "Validation Loss: 1243.4202\n",
      "Epoch [981/3000], Loss: 858.4427\n",
      "Validation Loss: 1206.2547\n",
      "Epoch [1001/3000], Loss: 817.5066\n",
      "Validation Loss: 1168.4078\n",
      "Epoch [1021/3000], Loss: 783.5293\n",
      "Validation Loss: 1130.6318\n",
      "Epoch [1041/3000], Loss: 748.0227\n",
      "Validation Loss: 1096.3040\n",
      "Epoch [1061/3000], Loss: 712.7554\n",
      "Validation Loss: 1060.7446\n",
      "Epoch [1081/3000], Loss: 685.3989\n",
      "Validation Loss: 1024.6693\n",
      "Epoch [1101/3000], Loss: 645.5553\n",
      "Validation Loss: 998.0888\n",
      "Epoch [1121/3000], Loss: 618.4204\n",
      "Validation Loss: 969.2684\n",
      "Epoch [1141/3000], Loss: 593.3121\n",
      "Validation Loss: 951.2862\n",
      "Epoch [1161/3000], Loss: 566.7763\n",
      "Validation Loss: 929.0967\n",
      "Epoch [1181/3000], Loss: 537.9719\n",
      "Validation Loss: 897.3174\n",
      "Epoch [1201/3000], Loss: 513.0435\n",
      "Validation Loss: 876.3537\n",
      "Epoch [1221/3000], Loss: 486.3272\n",
      "Validation Loss: 859.4268\n",
      "Epoch [1241/3000], Loss: 459.8388\n",
      "Validation Loss: 830.0035\n",
      "Epoch [1261/3000], Loss: 442.3553\n",
      "Validation Loss: 813.9315\n",
      "Epoch [1281/3000], Loss: 416.8788\n",
      "Validation Loss: 794.5921\n",
      "Epoch [1301/3000], Loss: 396.5441\n",
      "Validation Loss: 781.6668\n",
      "Epoch [1321/3000], Loss: 380.1107\n",
      "Validation Loss: 765.4767\n",
      "Epoch [1341/3000], Loss: 359.0160\n",
      "Validation Loss: 751.0145\n",
      "Epoch [1361/3000], Loss: 339.6670\n",
      "Validation Loss: 722.1451\n",
      "Epoch [1381/3000], Loss: 324.9277\n",
      "Validation Loss: 716.9943\n",
      "Epoch [1401/3000], Loss: 310.2384\n",
      "Validation Loss: 701.7560\n",
      "Epoch [1421/3000], Loss: 292.1751\n",
      "Validation Loss: 689.8786\n",
      "Epoch [1441/3000], Loss: 278.6877\n",
      "Validation Loss: 675.8620\n",
      "Epoch [1461/3000], Loss: 261.3406\n",
      "Validation Loss: 672.0069\n",
      "Epoch [1481/3000], Loss: 246.1280\n",
      "Validation Loss: 655.0506\n",
      "Epoch [1501/3000], Loss: 234.8855\n",
      "Validation Loss: 644.3604\n",
      "Epoch [1521/3000], Loss: 224.1046\n",
      "Validation Loss: 624.3269\n",
      "Epoch [1541/3000], Loss: 209.4026\n",
      "Validation Loss: 627.0908\n",
      "Epoch [1561/3000], Loss: 198.4509\n",
      "Validation Loss: 605.1142\n",
      "Epoch [1581/3000], Loss: 183.4389\n",
      "Validation Loss: 593.7256\n",
      "Epoch [1601/3000], Loss: 169.3110\n",
      "Validation Loss: 583.7214\n",
      "Epoch [1621/3000], Loss: 161.3858\n",
      "Validation Loss: 569.5294\n",
      "Epoch [1641/3000], Loss: 151.8127\n",
      "Validation Loss: 567.8480\n",
      "Epoch [1661/3000], Loss: 142.1100\n",
      "Validation Loss: 555.2646\n",
      "Epoch [1681/3000], Loss: 133.8905\n",
      "Validation Loss: 544.0556\n",
      "Epoch [1701/3000], Loss: 122.7989\n",
      "Validation Loss: 538.9275\n",
      "Epoch [1721/3000], Loss: 113.6846\n",
      "Validation Loss: 528.9905\n",
      "Epoch [1741/3000], Loss: 107.6145\n",
      "Validation Loss: 530.5797\n",
      "Epoch [1761/3000], Loss: 99.4118\n",
      "Validation Loss: 523.0413\n",
      "Epoch [1781/3000], Loss: 92.6135\n",
      "Validation Loss: 526.9089\n",
      "Epoch [1801/3000], Loss: 85.1595\n",
      "Validation Loss: 519.6040\n",
      "Epoch [1821/3000], Loss: 79.6584\n",
      "Validation Loss: 516.7767\n",
      "Epoch [1841/3000], Loss: 71.5075\n",
      "Validation Loss: 515.2848\n",
      "Epoch [1861/3000], Loss: 66.4488\n",
      "Validation Loss: 513.5106\n",
      "Epoch [1881/3000], Loss: 61.8328\n",
      "Validation Loss: 511.4139\n",
      "Epoch [1901/3000], Loss: 55.1772\n",
      "Validation Loss: 505.3314\n",
      "Epoch [1921/3000], Loss: 51.0633\n",
      "Validation Loss: 504.0326\n",
      "Epoch [1941/3000], Loss: 46.2944\n",
      "Validation Loss: 497.0457\n",
      "Epoch [1961/3000], Loss: 42.0654\n",
      "Validation Loss: 495.9114\n",
      "Epoch [1981/3000], Loss: 38.1045\n",
      "Validation Loss: 497.4473\n",
      "Epoch [2001/3000], Loss: 34.6144\n",
      "Validation Loss: 498.6643\n",
      "Epoch [2021/3000], Loss: 31.1237\n",
      "Validation Loss: 499.5625\n",
      "Epoch [2041/3000], Loss: 27.7435\n",
      "Validation Loss: 497.0786\n",
      "Epoch [2061/3000], Loss: 24.6396\n",
      "Validation Loss: 496.5262\n",
      "Epoch [2081/3000], Loss: 21.7744\n",
      "Validation Loss: 492.9767\n",
      "Epoch [2101/3000], Loss: 19.5246\n",
      "Validation Loss: 492.7032\n",
      "Epoch [2121/3000], Loss: 17.4150\n",
      "Validation Loss: 488.6693\n",
      "Epoch [2141/3000], Loss: 15.1902\n",
      "Validation Loss: 490.1888\n",
      "Epoch [2161/3000], Loss: 13.0200\n",
      "Validation Loss: 498.0016\n",
      "Epoch [2181/3000], Loss: 11.5261\n",
      "Validation Loss: 503.8389\n",
      "Epoch [2201/3000], Loss: 9.9365\n",
      "Validation Loss: 497.4262\n",
      "Epoch [2221/3000], Loss: 8.5515\n",
      "Validation Loss: 489.5289\n",
      "Epoch [2241/3000], Loss: 7.2988\n",
      "Validation Loss: 479.6306\n",
      "Epoch [2261/3000], Loss: 5.9721\n",
      "Validation Loss: 482.5398\n",
      "Epoch [2281/3000], Loss: 4.9897\n",
      "Validation Loss: 477.9030\n",
      "Epoch [2301/3000], Loss: 4.2140\n",
      "Validation Loss: 483.0226\n",
      "Epoch [2321/3000], Loss: 3.3921\n",
      "Validation Loss: 474.2220\n",
      "Epoch [2341/3000], Loss: 2.7950\n",
      "Validation Loss: 476.6440\n",
      "Epoch [2361/3000], Loss: 2.1874\n",
      "Validation Loss: 473.7558\n",
      "Epoch [2381/3000], Loss: 1.7363\n",
      "Validation Loss: 472.0091\n",
      "Epoch [2401/3000], Loss: 1.3119\n",
      "Validation Loss: 479.0820\n",
      "Epoch [2421/3000], Loss: 0.9649\n",
      "Validation Loss: 474.1067\n",
      "Epoch [2441/3000], Loss: 0.7294\n",
      "Validation Loss: 474.0320\n",
      "Epoch [2461/3000], Loss: 0.5122\n",
      "Validation Loss: 474.2165\n",
      "Epoch [2481/3000], Loss: 0.3386\n",
      "Validation Loss: 475.3214\n",
      "Epoch [2501/3000], Loss: 0.2352\n",
      "Validation Loss: 472.4823\n",
      "Epoch [2521/3000], Loss: 0.1514\n",
      "Validation Loss: 479.6159\n",
      "Epoch [2541/3000], Loss: 0.0914\n",
      "Validation Loss: 476.6297\n",
      "Epoch [2561/3000], Loss: 0.0547\n",
      "Validation Loss: 481.9556\n",
      "Epoch [2581/3000], Loss: 0.0329\n",
      "Validation Loss: 481.3232\n",
      "Epoch [2601/3000], Loss: 0.0218\n",
      "Validation Loss: 483.0788\n",
      "Epoch [2621/3000], Loss: 0.0161\n",
      "Validation Loss: 482.8517\n",
      "Epoch [2641/3000], Loss: 0.0134\n",
      "Validation Loss: 483.6676\n",
      "Epoch [2661/3000], Loss: 0.0119\n",
      "Validation Loss: 484.5771\n",
      "Epoch [2681/3000], Loss: 0.0151\n",
      "Validation Loss: 487.5341\n",
      "Epoch [2701/3000], Loss: 0.0104\n",
      "Validation Loss: 486.9095\n",
      "Epoch [2721/3000], Loss: 0.0082\n",
      "Validation Loss: 487.3035\n",
      "Epoch [2741/3000], Loss: 0.0076\n",
      "Validation Loss: 489.2027\n",
      "Epoch [2761/3000], Loss: 0.0101\n",
      "Validation Loss: 489.2098\n",
      "Epoch [2781/3000], Loss: 0.0068\n",
      "Validation Loss: 491.2610\n",
      "Epoch [2801/3000], Loss: 0.0070\n",
      "Validation Loss: 487.7289\n",
      "Epoch [2821/3000], Loss: 0.0114\n",
      "Validation Loss: 488.0891\n",
      "Epoch [2841/3000], Loss: 0.0135\n",
      "Validation Loss: 485.9260\n",
      "Epoch [2861/3000], Loss: 0.0064\n",
      "Validation Loss: 490.7742\n",
      "Epoch [2881/3000], Loss: 0.0076\n",
      "Validation Loss: 490.4348\n",
      "Epoch [2901/3000], Loss: 0.0059\n",
      "Validation Loss: 492.4466\n",
      "Epoch [2921/3000], Loss: 0.0069\n",
      "Validation Loss: 492.2487\n",
      "Epoch [2941/3000], Loss: 0.0094\n",
      "Validation Loss: 490.1437\n",
      "Epoch [2961/3000], Loss: 0.0050\n",
      "Validation Loss: 493.1305\n",
      "Epoch [2981/3000], Loss: 0.0044\n",
      "Validation Loss: 490.7149\n",
      "Y:\\analysis\\fmats\\e218\\days\\e218_day049_plane0_Fall.mat\n",
      "(7216, 757)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8465.3409\n",
      "Validation Loss: 7875.5040\n",
      "Epoch [21/3000], Loss: 7194.1254\n",
      "Validation Loss: 6687.6338\n",
      "Epoch [41/3000], Loss: 6938.2807\n",
      "Validation Loss: 6445.1625\n",
      "Epoch [61/3000], Loss: 6742.9193\n",
      "Validation Loss: 6262.8526\n",
      "Epoch [81/3000], Loss: 6563.0935\n",
      "Validation Loss: 6097.1909\n",
      "Epoch [101/3000], Loss: 6388.7061\n",
      "Validation Loss: 5940.8255\n",
      "Epoch [121/3000], Loss: 6245.2062\n",
      "Validation Loss: 5791.0465\n",
      "Epoch [141/3000], Loss: 6081.5278\n",
      "Validation Loss: 5646.8265\n",
      "Epoch [161/3000], Loss: 5926.4252\n",
      "Validation Loss: 5507.4268\n",
      "Epoch [181/3000], Loss: 5784.9476\n",
      "Validation Loss: 5372.5494\n",
      "Epoch [201/3000], Loss: 5642.2103\n",
      "Validation Loss: 5241.9646\n",
      "Epoch [221/3000], Loss: 5503.0309\n",
      "Validation Loss: 5115.4096\n",
      "Epoch [241/3000], Loss: 5369.1374\n",
      "Validation Loss: 4992.9556\n",
      "Epoch [261/3000], Loss: 5238.9811\n",
      "Validation Loss: 4874.4713\n",
      "Epoch [281/3000], Loss: 5109.4177\n",
      "Validation Loss: 4760.0161\n",
      "Epoch [301/3000], Loss: 4999.3821\n",
      "Validation Loss: 4649.4652\n",
      "Epoch [321/3000], Loss: 4874.1715\n",
      "Validation Loss: 4542.7469\n",
      "Epoch [341/3000], Loss: 4760.3053\n",
      "Validation Loss: 4440.0583\n",
      "Epoch [361/3000], Loss: 4650.2893\n",
      "Validation Loss: 4341.1511\n",
      "Epoch [381/3000], Loss: 4537.7222\n",
      "Validation Loss: 4246.1137\n",
      "Epoch [401/3000], Loss: 4131.9098\n",
      "Validation Loss: 3831.8078\n",
      "Epoch [421/3000], Loss: 3976.2859\n",
      "Validation Loss: 3694.0615\n",
      "Epoch [441/3000], Loss: 3839.6721\n",
      "Validation Loss: 3582.4379\n",
      "Epoch [461/3000], Loss: 3712.4024\n",
      "Validation Loss: 3466.9251\n",
      "Epoch [481/3000], Loss: 3594.3233\n",
      "Validation Loss: 3353.5421\n",
      "Epoch [501/3000], Loss: 3472.8798\n",
      "Validation Loss: 3243.3045\n",
      "Epoch [521/3000], Loss: 3362.3231\n",
      "Validation Loss: 3137.0707\n",
      "Epoch [541/3000], Loss: 3251.2643\n",
      "Validation Loss: 3032.0173\n",
      "Epoch [561/3000], Loss: 3138.6712\n",
      "Validation Loss: 2931.3581\n",
      "Epoch [581/3000], Loss: 3035.9226\n",
      "Validation Loss: 2827.3945\n",
      "Epoch [601/3000], Loss: 2927.2006\n",
      "Validation Loss: 2731.3657\n",
      "Epoch [621/3000], Loss: 2825.8942\n",
      "Validation Loss: 2642.9900\n",
      "Epoch [641/3000], Loss: 2728.3189\n",
      "Validation Loss: 2538.5171\n",
      "Epoch [661/3000], Loss: 2631.6595\n",
      "Validation Loss: 2464.7367\n",
      "Epoch [681/3000], Loss: 2526.1197\n",
      "Validation Loss: 2379.5845\n",
      "Epoch [701/3000], Loss: 2435.5735\n",
      "Validation Loss: 2298.1662\n",
      "Epoch [721/3000], Loss: 2352.4534\n",
      "Validation Loss: 2218.8657\n",
      "Epoch [741/3000], Loss: 2267.6369\n",
      "Validation Loss: 2139.7485\n",
      "Epoch [761/3000], Loss: 2172.6644\n",
      "Validation Loss: 2061.3078\n",
      "Epoch [781/3000], Loss: 2096.3769\n",
      "Validation Loss: 1989.2005\n",
      "Epoch [801/3000], Loss: 2014.4881\n",
      "Validation Loss: 1915.2609\n",
      "Epoch [821/3000], Loss: 1935.3787\n",
      "Validation Loss: 1846.6241\n",
      "Epoch [841/3000], Loss: 1855.8060\n",
      "Validation Loss: 1781.6870\n",
      "Epoch [861/3000], Loss: 1783.0973\n",
      "Validation Loss: 1717.0786\n",
      "Epoch [881/3000], Loss: 1709.3001\n",
      "Validation Loss: 1658.9100\n",
      "Epoch [901/3000], Loss: 1636.4370\n",
      "Validation Loss: 1595.5343\n",
      "Epoch [921/3000], Loss: 1570.5727\n",
      "Validation Loss: 1535.3600\n",
      "Epoch [941/3000], Loss: 1505.9279\n",
      "Validation Loss: 1475.0780\n",
      "Epoch [961/3000], Loss: 1439.9002\n",
      "Validation Loss: 1416.0350\n",
      "Epoch [981/3000], Loss: 1377.9986\n",
      "Validation Loss: 1358.0858\n",
      "Epoch [1001/3000], Loss: 1313.4282\n",
      "Validation Loss: 1302.7780\n",
      "Epoch [1021/3000], Loss: 1257.4950\n",
      "Validation Loss: 1253.4728\n",
      "Epoch [1041/3000], Loss: 1200.3743\n",
      "Validation Loss: 1203.7798\n",
      "Epoch [1061/3000], Loss: 1145.9599\n",
      "Validation Loss: 1156.9233\n",
      "Epoch [1081/3000], Loss: 1093.9782\n",
      "Validation Loss: 1114.2088\n",
      "Epoch [1101/3000], Loss: 1042.2442\n",
      "Validation Loss: 1069.6070\n",
      "Epoch [1121/3000], Loss: 991.5404\n",
      "Validation Loss: 1027.9714\n",
      "Epoch [1141/3000], Loss: 943.6216\n",
      "Validation Loss: 985.4577\n",
      "Epoch [1161/3000], Loss: 896.5506\n",
      "Validation Loss: 944.8339\n",
      "Epoch [1181/3000], Loss: 851.9069\n",
      "Validation Loss: 913.6236\n",
      "Epoch [1201/3000], Loss: 809.4357\n",
      "Validation Loss: 874.2626\n",
      "Epoch [1221/3000], Loss: 766.2375\n",
      "Validation Loss: 839.3796\n",
      "Epoch [1241/3000], Loss: 728.2662\n",
      "Validation Loss: 828.5277\n",
      "Epoch [1261/3000], Loss: 690.8757\n",
      "Validation Loss: 793.8159\n",
      "Epoch [1281/3000], Loss: 654.3801\n",
      "Validation Loss: 761.0851\n",
      "Epoch [1301/3000], Loss: 617.7360\n",
      "Validation Loss: 732.5625\n",
      "Epoch [1321/3000], Loss: 583.0269\n",
      "Validation Loss: 707.8934\n",
      "Epoch [1341/3000], Loss: 554.6243\n",
      "Validation Loss: 739.7817\n",
      "Epoch [1361/3000], Loss: 519.2428\n",
      "Validation Loss: 700.3736\n",
      "Epoch [1381/3000], Loss: 489.7852\n",
      "Validation Loss: 666.4285\n",
      "Epoch [1401/3000], Loss: 461.4715\n",
      "Validation Loss: 639.8042\n",
      "Epoch [1421/3000], Loss: 433.4110\n",
      "Validation Loss: 616.7841\n",
      "Epoch [1441/3000], Loss: 407.3099\n",
      "Validation Loss: 594.3167\n",
      "Epoch [1461/3000], Loss: 383.0612\n",
      "Validation Loss: 572.5536\n",
      "Epoch [1481/3000], Loss: 358.5171\n",
      "Validation Loss: 553.8885\n",
      "Epoch [1501/3000], Loss: 337.0991\n",
      "Validation Loss: 535.3086\n",
      "Epoch [1521/3000], Loss: 315.7381\n",
      "Validation Loss: 514.6858\n",
      "Epoch [1541/3000], Loss: 297.7046\n",
      "Validation Loss: 501.1972\n",
      "Epoch [1561/3000], Loss: 276.6965\n",
      "Validation Loss: 486.3982\n",
      "Epoch [1581/3000], Loss: 259.2109\n",
      "Validation Loss: 479.7448\n",
      "Epoch [1601/3000], Loss: 264.9151\n",
      "Validation Loss: 474.0117\n",
      "Epoch [1621/3000], Loss: 228.4886\n",
      "Validation Loss: 472.5054\n",
      "Epoch [1641/3000], Loss: 212.1649\n",
      "Validation Loss: 456.1197\n",
      "Epoch [1661/3000], Loss: 198.3716\n",
      "Validation Loss: 440.9482\n",
      "Epoch [1681/3000], Loss: 184.9658\n",
      "Validation Loss: 430.4448\n",
      "Epoch [1701/3000], Loss: 173.3399\n",
      "Validation Loss: 421.1563\n",
      "Epoch [1721/3000], Loss: 162.3580\n",
      "Validation Loss: 410.6653\n",
      "Epoch [1741/3000], Loss: 150.6751\n",
      "Validation Loss: 397.7661\n",
      "Epoch [1761/3000], Loss: 140.5862\n",
      "Validation Loss: 394.0152\n",
      "Epoch [1781/3000], Loss: 132.1683\n",
      "Validation Loss: 384.4489\n",
      "Epoch [1801/3000], Loss: 122.3435\n",
      "Validation Loss: 379.1229\n",
      "Epoch [1821/3000], Loss: 114.8154\n",
      "Validation Loss: 366.1803\n",
      "Epoch [1841/3000], Loss: 106.8707\n",
      "Validation Loss: 357.6990\n",
      "Epoch [1861/3000], Loss: 98.6828\n",
      "Validation Loss: 348.6433\n",
      "Epoch [1881/3000], Loss: 92.0214\n",
      "Validation Loss: 338.5088\n",
      "Epoch [1901/3000], Loss: 85.4457\n",
      "Validation Loss: 330.2899\n",
      "Epoch [1921/3000], Loss: 79.2447\n",
      "Validation Loss: 327.7732\n",
      "Epoch [1941/3000], Loss: 72.5741\n",
      "Validation Loss: 322.6097\n",
      "Epoch [1961/3000], Loss: 66.3595\n",
      "Validation Loss: 322.1047\n",
      "Epoch [1981/3000], Loss: 61.0571\n",
      "Validation Loss: 323.6544\n",
      "Epoch [2001/3000], Loss: 55.8762\n",
      "Validation Loss: 321.8447\n",
      "Epoch [2021/3000], Loss: 50.8262\n",
      "Validation Loss: 321.3695\n",
      "Epoch [2041/3000], Loss: 45.9980\n",
      "Validation Loss: 318.7452\n",
      "Epoch [2061/3000], Loss: 41.8484\n",
      "Validation Loss: 314.4644\n",
      "Epoch [2081/3000], Loss: 37.6906\n",
      "Validation Loss: 311.2472\n",
      "Epoch [2101/3000], Loss: 33.9181\n",
      "Validation Loss: 307.4102\n",
      "Epoch [2121/3000], Loss: 30.5213\n",
      "Validation Loss: 303.1226\n",
      "Epoch [2141/3000], Loss: 27.2205\n",
      "Validation Loss: 301.5266\n",
      "Epoch [2161/3000], Loss: 24.2675\n",
      "Validation Loss: 300.4218\n",
      "Epoch [2181/3000], Loss: 21.5153\n",
      "Validation Loss: 299.2792\n",
      "Epoch [2201/3000], Loss: 19.0630\n",
      "Validation Loss: 298.5308\n",
      "Epoch [2221/3000], Loss: 16.7447\n",
      "Validation Loss: 298.4438\n",
      "Epoch [2241/3000], Loss: 14.5685\n",
      "Validation Loss: 299.8470\n",
      "Epoch [2261/3000], Loss: 12.6171\n",
      "Validation Loss: 298.6418\n",
      "Epoch [2281/3000], Loss: 10.9505\n",
      "Validation Loss: 298.4921\n",
      "Epoch [2301/3000], Loss: 9.4302\n",
      "Validation Loss: 298.6293\n",
      "Epoch [2321/3000], Loss: 7.9968\n",
      "Validation Loss: 299.7807\n",
      "Epoch [2341/3000], Loss: 6.7999\n",
      "Validation Loss: 295.8218\n",
      "Epoch [2361/3000], Loss: 5.6755\n",
      "Validation Loss: 296.1900\n",
      "Epoch [2381/3000], Loss: 4.6366\n",
      "Validation Loss: 298.9618\n",
      "Epoch [2401/3000], Loss: 3.8348\n",
      "Validation Loss: 299.1135\n",
      "Epoch [2421/3000], Loss: 3.0999\n",
      "Validation Loss: 294.5433\n",
      "Epoch [2441/3000], Loss: 2.4645\n",
      "Validation Loss: 295.6184\n",
      "Epoch [2461/3000], Loss: 1.9289\n",
      "Validation Loss: 297.3417\n",
      "Epoch [2481/3000], Loss: 1.4771\n",
      "Validation Loss: 297.2469\n",
      "Epoch [2501/3000], Loss: 1.1210\n",
      "Validation Loss: 296.2874\n",
      "Epoch [2521/3000], Loss: 0.8272\n",
      "Validation Loss: 294.7014\n",
      "Epoch [2541/3000], Loss: 0.5827\n",
      "Validation Loss: 295.0777\n",
      "Epoch [2561/3000], Loss: 0.4168\n",
      "Validation Loss: 294.1292\n",
      "Epoch [2581/3000], Loss: 0.2822\n",
      "Validation Loss: 291.2319\n",
      "Epoch [2601/3000], Loss: 0.1793\n",
      "Validation Loss: 293.5683\n",
      "Epoch [2621/3000], Loss: 0.1120\n",
      "Validation Loss: 294.2630\n",
      "Epoch [2641/3000], Loss: 0.0694\n",
      "Validation Loss: 293.5975\n",
      "Epoch [2661/3000], Loss: 0.0440\n",
      "Validation Loss: 293.5283\n",
      "Epoch [2681/3000], Loss: 0.0278\n",
      "Validation Loss: 290.9068\n",
      "Epoch [2701/3000], Loss: 0.0180\n",
      "Validation Loss: 290.4485\n",
      "Epoch [2721/3000], Loss: 0.0147\n",
      "Validation Loss: 290.0050\n",
      "Epoch [2741/3000], Loss: 0.0174\n",
      "Validation Loss: 288.7748\n",
      "Epoch [2761/3000], Loss: 0.0124\n",
      "Validation Loss: 289.0106\n",
      "Epoch [2781/3000], Loss: 0.0110\n",
      "Validation Loss: 289.8085\n",
      "Epoch [2801/3000], Loss: 0.0171\n",
      "Validation Loss: 288.7679\n",
      "Epoch [2821/3000], Loss: 0.0137\n",
      "Validation Loss: 288.0648\n",
      "Epoch [2841/3000], Loss: 0.0101\n",
      "Validation Loss: 287.5058\n",
      "Epoch [2861/3000], Loss: 0.0095\n",
      "Validation Loss: 286.7144\n",
      "Epoch [2881/3000], Loss: 0.0085\n",
      "Validation Loss: 285.4555\n",
      "Epoch [2901/3000], Loss: 0.0085\n",
      "Validation Loss: 284.8679\n",
      "Epoch [2921/3000], Loss: 0.0090\n",
      "Validation Loss: 284.1893\n",
      "Epoch [2941/3000], Loss: 0.0076\n",
      "Validation Loss: 284.2760\n",
      "Epoch [2961/3000], Loss: 0.0064\n",
      "Validation Loss: 285.5054\n",
      "Epoch [2981/3000], Loss: 0.0070\n",
      "Validation Loss: 283.9580\n",
      "Y:\\analysis\\fmats\\e218\\days\\e218_day050_plane0_Fall.mat\n",
      "(6453, 642)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9419.5377\n",
      "Validation Loss: 8312.5010\n",
      "Epoch [21/3000], Loss: 8080.9462\n",
      "Validation Loss: 7081.5364\n",
      "Epoch [41/3000], Loss: 7800.0352\n",
      "Validation Loss: 6833.6818\n",
      "Epoch [61/3000], Loss: 7601.7359\n",
      "Validation Loss: 6656.6972\n",
      "Epoch [81/3000], Loss: 7426.6547\n",
      "Validation Loss: 6496.8336\n",
      "Epoch [101/3000], Loss: 7246.3236\n",
      "Validation Loss: 6345.9316\n",
      "Epoch [121/3000], Loss: 7081.8699\n",
      "Validation Loss: 6201.3904\n",
      "Epoch [141/3000], Loss: 6941.0381\n",
      "Validation Loss: 6061.6616\n",
      "Epoch [161/3000], Loss: 6781.6660\n",
      "Validation Loss: 5926.1919\n",
      "Epoch [181/3000], Loss: 6636.7476\n",
      "Validation Loss: 5794.5750\n",
      "Epoch [201/3000], Loss: 6482.5629\n",
      "Validation Loss: 5666.5317\n",
      "Epoch [221/3000], Loss: 6346.1217\n",
      "Validation Loss: 5541.9274\n",
      "Epoch [241/3000], Loss: 6191.6379\n",
      "Validation Loss: 5420.6770\n",
      "Epoch [261/3000], Loss: 6069.2618\n",
      "Validation Loss: 5302.6679\n",
      "Epoch [281/3000], Loss: 5936.9357\n",
      "Validation Loss: 5187.8320\n",
      "Epoch [301/3000], Loss: 5799.9833\n",
      "Validation Loss: 5076.2374\n",
      "Epoch [321/3000], Loss: 5684.9452\n",
      "Validation Loss: 4967.8105\n",
      "Epoch [341/3000], Loss: 5567.5738\n",
      "Validation Loss: 4862.4896\n",
      "Epoch [361/3000], Loss: 5440.2839\n",
      "Validation Loss: 4760.2745\n",
      "Epoch [381/3000], Loss: 5326.0430\n",
      "Validation Loss: 4661.2404\n",
      "Epoch [401/3000], Loss: 5214.5332\n",
      "Validation Loss: 4565.3378\n",
      "Epoch [421/3000], Loss: 5095.7785\n",
      "Validation Loss: 4472.4686\n",
      "Epoch [441/3000], Loss: 4988.0075\n",
      "Validation Loss: 4382.6990\n",
      "Epoch [461/3000], Loss: 4885.5879\n",
      "Validation Loss: 4296.0624\n",
      "Epoch [481/3000], Loss: 4789.7514\n",
      "Validation Loss: 4212.4993\n",
      "Epoch [501/3000], Loss: 4694.5641\n",
      "Validation Loss: 4131.9918\n",
      "Epoch [521/3000], Loss: 4600.2069\n",
      "Validation Loss: 4054.5404\n",
      "Epoch [541/3000], Loss: 4505.9836\n",
      "Validation Loss: 3980.0833\n",
      "Epoch [561/3000], Loss: 4409.0907\n",
      "Validation Loss: 3908.6916\n",
      "Epoch [581/3000], Loss: 4333.9769\n",
      "Validation Loss: 3840.3508\n",
      "Epoch [601/3000], Loss: 4248.9236\n",
      "Validation Loss: 3775.0389\n",
      "Epoch [621/3000], Loss: 4171.3686\n",
      "Validation Loss: 3712.7805\n",
      "Epoch [641/3000], Loss: 4100.9673\n",
      "Validation Loss: 3653.4128\n",
      "Epoch [661/3000], Loss: 4022.1356\n",
      "Validation Loss: 3597.1092\n",
      "Epoch [681/3000], Loss: 3945.0629\n",
      "Validation Loss: 3543.7814\n",
      "Epoch [701/3000], Loss: 3885.5230\n",
      "Validation Loss: 3493.3952\n",
      "Epoch [721/3000], Loss: 3817.6573\n",
      "Validation Loss: 3435.5704\n",
      "Epoch [741/3000], Loss: 3068.7976\n",
      "Validation Loss: 2710.4223\n",
      "Epoch [761/3000], Loss: 2951.5742\n",
      "Validation Loss: 2621.2286\n",
      "Epoch [781/3000], Loss: 2843.3281\n",
      "Validation Loss: 2547.4745\n",
      "Epoch [801/3000], Loss: 2738.9563\n",
      "Validation Loss: 2472.1786\n",
      "Epoch [821/3000], Loss: 2654.9853\n",
      "Validation Loss: 2396.1990\n",
      "Epoch [841/3000], Loss: 2564.4539\n",
      "Validation Loss: 2319.6313\n",
      "Epoch [861/3000], Loss: 2477.0486\n",
      "Validation Loss: 2245.8890\n",
      "Epoch [881/3000], Loss: 2391.4395\n",
      "Validation Loss: 2173.6970\n",
      "Epoch [901/3000], Loss: 2310.3964\n",
      "Validation Loss: 2107.0960\n",
      "Epoch [921/3000], Loss: 2221.5373\n",
      "Validation Loss: 2039.6803\n",
      "Epoch [941/3000], Loss: 2151.0215\n",
      "Validation Loss: 1976.2856\n",
      "Epoch [961/3000], Loss: 2073.8504\n",
      "Validation Loss: 1913.2092\n",
      "Epoch [981/3000], Loss: 1999.6101\n",
      "Validation Loss: 1855.6938\n",
      "Epoch [1001/3000], Loss: 1926.7637\n",
      "Validation Loss: 1791.5982\n",
      "Epoch [1021/3000], Loss: 1856.0757\n",
      "Validation Loss: 1731.0785\n",
      "Epoch [1041/3000], Loss: 1787.1199\n",
      "Validation Loss: 1679.2363\n",
      "Epoch [1061/3000], Loss: 1720.2995\n",
      "Validation Loss: 1618.8472\n",
      "Epoch [1081/3000], Loss: 1654.4451\n",
      "Validation Loss: 1562.4751\n",
      "Epoch [1101/3000], Loss: 1597.6025\n",
      "Validation Loss: 1513.0204\n",
      "Epoch [1121/3000], Loss: 1532.1784\n",
      "Validation Loss: 1459.8942\n",
      "Epoch [1141/3000], Loss: 1465.4154\n",
      "Validation Loss: 1415.6274\n",
      "Epoch [1161/3000], Loss: 1409.1647\n",
      "Validation Loss: 1370.9312\n",
      "Epoch [1181/3000], Loss: 1352.9734\n",
      "Validation Loss: 1318.3482\n",
      "Epoch [1201/3000], Loss: 1296.2442\n",
      "Validation Loss: 1291.3179\n",
      "Epoch [1221/3000], Loss: 1245.5092\n",
      "Validation Loss: 1248.3468\n",
      "Epoch [1241/3000], Loss: 1194.5675\n",
      "Validation Loss: 1206.0052\n",
      "Epoch [1261/3000], Loss: 1137.4673\n",
      "Validation Loss: 1165.6160\n",
      "Epoch [1281/3000], Loss: 1090.9360\n",
      "Validation Loss: 1125.7568\n",
      "Epoch [1301/3000], Loss: 1046.5528\n",
      "Validation Loss: 1087.9819\n",
      "Epoch [1321/3000], Loss: 997.2647\n",
      "Validation Loss: 1052.3856\n",
      "Epoch [1341/3000], Loss: 951.7484\n",
      "Validation Loss: 1014.1669\n",
      "Epoch [1361/3000], Loss: 905.9839\n",
      "Validation Loss: 975.3645\n",
      "Epoch [1381/3000], Loss: 869.5360\n",
      "Validation Loss: 940.2621\n",
      "Epoch [1401/3000], Loss: 827.6619\n",
      "Validation Loss: 905.7987\n",
      "Epoch [1421/3000], Loss: 788.4674\n",
      "Validation Loss: 873.7925\n",
      "Epoch [1441/3000], Loss: 750.4943\n",
      "Validation Loss: 840.1668\n",
      "Epoch [1461/3000], Loss: 714.7161\n",
      "Validation Loss: 811.6642\n",
      "Epoch [1481/3000], Loss: 677.2593\n",
      "Validation Loss: 790.5452\n",
      "Epoch [1501/3000], Loss: 644.4363\n",
      "Validation Loss: 763.0193\n",
      "Epoch [1521/3000], Loss: 612.3630\n",
      "Validation Loss: 737.8666\n",
      "Epoch [1541/3000], Loss: 580.7455\n",
      "Validation Loss: 716.4590\n",
      "Epoch [1561/3000], Loss: 548.9008\n",
      "Validation Loss: 700.3381\n",
      "Epoch [1581/3000], Loss: 520.2310\n",
      "Validation Loss: 674.5547\n",
      "Epoch [1601/3000], Loss: 492.2370\n",
      "Validation Loss: 653.3019\n",
      "Epoch [1621/3000], Loss: 465.4223\n",
      "Validation Loss: 625.8648\n",
      "Epoch [1641/3000], Loss: 438.2891\n",
      "Validation Loss: 618.4401\n",
      "Epoch [1661/3000], Loss: 415.7349\n",
      "Validation Loss: 606.2134\n",
      "Epoch [1681/3000], Loss: 389.3275\n",
      "Validation Loss: 587.7511\n",
      "Epoch [1701/3000], Loss: 367.9683\n",
      "Validation Loss: 584.2706\n",
      "Epoch [1721/3000], Loss: 347.1791\n",
      "Validation Loss: 559.9546\n",
      "Epoch [1741/3000], Loss: 325.0291\n",
      "Validation Loss: 548.6438\n",
      "Epoch [1761/3000], Loss: 306.0657\n",
      "Validation Loss: 537.5022\n",
      "Epoch [1781/3000], Loss: 286.4217\n",
      "Validation Loss: 522.1489\n",
      "Epoch [1801/3000], Loss: 268.8017\n",
      "Validation Loss: 510.3194\n",
      "Epoch [1821/3000], Loss: 252.0295\n",
      "Validation Loss: 499.2100\n",
      "Epoch [1841/3000], Loss: 236.5308\n",
      "Validation Loss: 492.7726\n",
      "Epoch [1861/3000], Loss: 221.1607\n",
      "Validation Loss: 477.2141\n",
      "Epoch [1881/3000], Loss: 206.9298\n",
      "Validation Loss: 478.3639\n",
      "Epoch [1901/3000], Loss: 193.4759\n",
      "Validation Loss: 458.7733\n",
      "Epoch [1921/3000], Loss: 180.4294\n",
      "Validation Loss: 448.6567\n",
      "Epoch [1941/3000], Loss: 167.7390\n",
      "Validation Loss: 440.4899\n",
      "Epoch [1961/3000], Loss: 156.1759\n",
      "Validation Loss: 434.7332\n",
      "Epoch [1981/3000], Loss: 146.4431\n",
      "Validation Loss: 428.7872\n",
      "Epoch [2001/3000], Loss: 136.1492\n",
      "Validation Loss: 422.7776\n",
      "Epoch [2021/3000], Loss: 127.1829\n",
      "Validation Loss: 413.4204\n",
      "Epoch [2041/3000], Loss: 117.3669\n",
      "Validation Loss: 405.9799\n",
      "Epoch [2061/3000], Loss: 109.6295\n",
      "Validation Loss: 404.1727\n",
      "Epoch [2081/3000], Loss: 101.5836\n",
      "Validation Loss: 399.7656\n",
      "Epoch [2101/3000], Loss: 94.6595\n",
      "Validation Loss: 395.2904\n",
      "Epoch [2121/3000], Loss: 87.9592\n",
      "Validation Loss: 393.4535\n",
      "Epoch [2141/3000], Loss: 81.4244\n",
      "Validation Loss: 392.5665\n",
      "Epoch [2161/3000], Loss: 75.1246\n",
      "Validation Loss: 386.2525\n",
      "Epoch [2181/3000], Loss: 69.9630\n",
      "Validation Loss: 381.2327\n",
      "Epoch [2201/3000], Loss: 64.4877\n",
      "Validation Loss: 380.1320\n",
      "Epoch [2221/3000], Loss: 59.9220\n",
      "Validation Loss: 377.8415\n",
      "Epoch [2241/3000], Loss: 55.0757\n",
      "Validation Loss: 371.2666\n",
      "Epoch [2261/3000], Loss: 50.0336\n",
      "Validation Loss: 368.1461\n",
      "Epoch [2281/3000], Loss: 46.8544\n",
      "Validation Loss: 369.4729\n",
      "Epoch [2301/3000], Loss: 42.6664\n",
      "Validation Loss: 364.1402\n",
      "Epoch [2321/3000], Loss: 38.6577\n",
      "Validation Loss: 363.6796\n",
      "Epoch [2341/3000], Loss: 34.8301\n",
      "Validation Loss: 360.7560\n",
      "Epoch [2361/3000], Loss: 31.7865\n",
      "Validation Loss: 362.3272\n",
      "Epoch [2381/3000], Loss: 28.5438\n",
      "Validation Loss: 354.8006\n",
      "Epoch [2401/3000], Loss: 25.6679\n",
      "Validation Loss: 356.2438\n",
      "Epoch [2421/3000], Loss: 23.0896\n",
      "Validation Loss: 353.9349\n",
      "Epoch [2441/3000], Loss: 20.5254\n",
      "Validation Loss: 347.5479\n",
      "Epoch [2461/3000], Loss: 18.2356\n",
      "Validation Loss: 350.5836\n",
      "Epoch [2481/3000], Loss: 16.1309\n",
      "Validation Loss: 347.6431\n",
      "Epoch [2501/3000], Loss: 14.2400\n",
      "Validation Loss: 347.3141\n",
      "Epoch [2521/3000], Loss: 12.3879\n",
      "Validation Loss: 345.5907\n",
      "Epoch [2541/3000], Loss: 10.9525\n",
      "Validation Loss: 346.4793\n",
      "Epoch [2561/3000], Loss: 9.5762\n",
      "Validation Loss: 344.6805\n",
      "Epoch [2581/3000], Loss: 8.2824\n",
      "Validation Loss: 345.9090\n",
      "Epoch [2601/3000], Loss: 7.0811\n",
      "Validation Loss: 345.8358\n",
      "Epoch [2621/3000], Loss: 6.1775\n",
      "Validation Loss: 344.1409\n",
      "Epoch [2641/3000], Loss: 5.3198\n",
      "Validation Loss: 343.9826\n",
      "Epoch [2661/3000], Loss: 4.5045\n",
      "Validation Loss: 343.2673\n",
      "Epoch [2681/3000], Loss: 3.7792\n",
      "Validation Loss: 341.3050\n",
      "Epoch [2701/3000], Loss: 3.1566\n",
      "Validation Loss: 341.8999\n",
      "Epoch [2721/3000], Loss: 2.6158\n",
      "Validation Loss: 342.9786\n",
      "Epoch [2741/3000], Loss: 2.1333\n",
      "Validation Loss: 340.2231\n",
      "Epoch [2761/3000], Loss: 1.6794\n",
      "Validation Loss: 339.5289\n",
      "Epoch [2781/3000], Loss: 1.3688\n",
      "Validation Loss: 340.1977\n",
      "Epoch [2801/3000], Loss: 1.0774\n",
      "Validation Loss: 338.5600\n",
      "Epoch [2821/3000], Loss: 0.8357\n",
      "Validation Loss: 340.6398\n",
      "Epoch [2841/3000], Loss: 0.6332\n",
      "Validation Loss: 339.0378\n",
      "Epoch [2861/3000], Loss: 0.4676\n",
      "Validation Loss: 338.6192\n",
      "Epoch [2881/3000], Loss: 0.3444\n",
      "Validation Loss: 338.6757\n",
      "Epoch [2901/3000], Loss: 0.2410\n",
      "Validation Loss: 338.0838\n",
      "Epoch [2921/3000], Loss: 0.1792\n",
      "Validation Loss: 339.9893\n",
      "Epoch [2941/3000], Loss: 0.1105\n",
      "Validation Loss: 340.3209\n",
      "Epoch [2961/3000], Loss: 0.0774\n",
      "Validation Loss: 342.2919\n",
      "Epoch [2981/3000], Loss: 0.0511\n",
      "Validation Loss: 340.7806\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day007_plane0_Fall.mat\n",
      "(4801, 648)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7756.5213\n",
      "Validation Loss: 6397.6674\n",
      "Epoch [21/3000], Loss: 6825.8076\n",
      "Validation Loss: 5547.0985\n",
      "Epoch [41/3000], Loss: 6561.5827\n",
      "Validation Loss: 5337.5373\n",
      "Epoch [61/3000], Loss: 6487.9836\n",
      "Validation Loss: 5219.4684\n",
      "Epoch [81/3000], Loss: 6301.5483\n",
      "Validation Loss: 5112.1352\n",
      "Epoch [101/3000], Loss: 6196.2697\n",
      "Validation Loss: 5018.2948\n",
      "Epoch [121/3000], Loss: 6089.8608\n",
      "Validation Loss: 4930.0215\n",
      "Epoch [141/3000], Loss: 6029.6157\n",
      "Validation Loss: 4845.6770\n",
      "Epoch [161/3000], Loss: 5935.9733\n",
      "Validation Loss: 4764.3512\n",
      "Epoch [181/3000], Loss: 5815.5467\n",
      "Validation Loss: 4685.5764\n",
      "Epoch [201/3000], Loss: 5773.5488\n",
      "Validation Loss: 4608.8873\n",
      "Epoch [221/3000], Loss: 5646.2705\n",
      "Validation Loss: 4534.3855\n",
      "Epoch [241/3000], Loss: 5607.2300\n",
      "Validation Loss: 4460.2858\n",
      "Epoch [261/3000], Loss: 5475.8621\n",
      "Validation Loss: 4388.9227\n",
      "Epoch [281/3000], Loss: 5408.6683\n",
      "Validation Loss: 4319.4099\n",
      "Epoch [301/3000], Loss: 5322.5237\n",
      "Validation Loss: 4251.6658\n",
      "Epoch [321/3000], Loss: 5263.3934\n",
      "Validation Loss: 4184.5583\n",
      "Epoch [341/3000], Loss: 5175.6604\n",
      "Validation Loss: 4119.8379\n",
      "Epoch [361/3000], Loss: 5078.0027\n",
      "Validation Loss: 4056.8670\n",
      "Epoch [381/3000], Loss: 4983.9706\n",
      "Validation Loss: 3995.5677\n",
      "Epoch [401/3000], Loss: 4949.8105\n",
      "Validation Loss: 3935.8301\n",
      "Epoch [421/3000], Loss: 4896.8318\n",
      "Validation Loss: 3877.8226\n",
      "Epoch [441/3000], Loss: 4811.9677\n",
      "Validation Loss: 3821.3686\n",
      "Epoch [461/3000], Loss: 4744.5135\n",
      "Validation Loss: 3766.4262\n",
      "Epoch [481/3000], Loss: 4688.7088\n",
      "Validation Loss: 3713.0864\n",
      "Epoch [501/3000], Loss: 4647.4770\n",
      "Validation Loss: 3661.3822\n",
      "Epoch [521/3000], Loss: 4559.7454\n",
      "Validation Loss: 3611.2391\n",
      "Epoch [541/3000], Loss: 4502.9630\n",
      "Validation Loss: 3562.5967\n",
      "Epoch [561/3000], Loss: 4453.1131\n",
      "Validation Loss: 3515.5288\n",
      "Epoch [581/3000], Loss: 4378.9607\n",
      "Validation Loss: 3470.0096\n",
      "Epoch [601/3000], Loss: 4311.6443\n",
      "Validation Loss: 3426.1314\n",
      "Epoch [621/3000], Loss: 4236.9610\n",
      "Validation Loss: 3383.7488\n",
      "Epoch [641/3000], Loss: 4225.6950\n",
      "Validation Loss: 3342.8765\n",
      "Epoch [661/3000], Loss: 4162.4238\n",
      "Validation Loss: 3303.5530\n",
      "Epoch [681/3000], Loss: 4115.8412\n",
      "Validation Loss: 3265.7454\n",
      "Epoch [701/3000], Loss: 4091.8861\n",
      "Validation Loss: 3229.4094\n",
      "Epoch [721/3000], Loss: 4021.6398\n",
      "Validation Loss: 3194.5990\n",
      "Epoch [741/3000], Loss: 3970.6015\n",
      "Validation Loss: 3161.3496\n",
      "Epoch [761/3000], Loss: 3954.8976\n",
      "Validation Loss: 3129.6147\n",
      "Epoch [781/3000], Loss: 3929.9222\n",
      "Validation Loss: 3099.4079\n",
      "Epoch [801/3000], Loss: 3848.7525\n",
      "Validation Loss: 3070.6139\n",
      "Epoch [821/3000], Loss: 3811.3011\n",
      "Validation Loss: 3043.3437\n",
      "Epoch [841/3000], Loss: 3786.7138\n",
      "Validation Loss: 3017.4990\n",
      "Epoch [861/3000], Loss: 3748.3115\n",
      "Validation Loss: 2993.0677\n",
      "Epoch [881/3000], Loss: 3730.9320\n",
      "Validation Loss: 2970.1154\n",
      "Epoch [901/3000], Loss: 3653.4138\n",
      "Validation Loss: 2948.5722\n",
      "Epoch [921/3000], Loss: 3651.7459\n",
      "Validation Loss: 2928.5562\n",
      "Epoch [941/3000], Loss: 3619.9618\n",
      "Validation Loss: 2909.9421\n",
      "Epoch [961/3000], Loss: 3569.1342\n",
      "Validation Loss: 2892.6270\n",
      "Epoch [981/3000], Loss: 3573.3256\n",
      "Validation Loss: 2876.7802\n",
      "Epoch [1001/3000], Loss: 3542.9264\n",
      "Validation Loss: 2862.2599\n",
      "Epoch [1021/3000], Loss: 3524.5098\n",
      "Validation Loss: 2849.0761\n",
      "Epoch [1041/3000], Loss: 3515.4363\n",
      "Validation Loss: 2837.2161\n",
      "Epoch [1061/3000], Loss: 3486.9517\n",
      "Validation Loss: 2826.6281\n",
      "Epoch [1081/3000], Loss: 3439.1842\n",
      "Validation Loss: 2817.3765\n",
      "Epoch [1101/3000], Loss: 3441.2856\n",
      "Validation Loss: 2809.3064\n",
      "Epoch [1121/3000], Loss: 3419.4658\n",
      "Validation Loss: 2802.4798\n",
      "Epoch [1141/3000], Loss: 3417.1952\n",
      "Validation Loss: 2796.8154\n",
      "Epoch [1161/3000], Loss: 3394.3870\n",
      "Validation Loss: 2792.2787\n",
      "Epoch [1181/3000], Loss: 3363.8131\n",
      "Validation Loss: 2788.8431\n",
      "Epoch [1201/3000], Loss: 3363.5012\n",
      "Validation Loss: 2786.4243\n",
      "Epoch [1221/3000], Loss: 3365.9907\n",
      "Validation Loss: 2784.9993\n",
      "Epoch [1241/3000], Loss: 3351.6770\n",
      "Validation Loss: 2784.4851\n",
      "Epoch [1261/3000], Loss: 3342.0266\n",
      "Validation Loss: 2784.8258\n",
      "Epoch [1281/3000], Loss: 3343.5607\n",
      "Validation Loss: 2785.9368\n",
      "Epoch [1301/3000], Loss: 3323.3942\n",
      "Validation Loss: 2787.7106\n",
      "Epoch [1321/3000], Loss: 3325.6818\n",
      "Validation Loss: 2790.0585\n",
      "Epoch [1341/3000], Loss: 3327.6899\n",
      "Validation Loss: 2792.8463\n",
      "Epoch [1361/3000], Loss: 2793.6347\n",
      "Validation Loss: 2346.5145\n",
      "Epoch [1381/3000], Loss: 1971.9262\n",
      "Validation Loss: 2010.0095\n",
      "Epoch [1401/3000], Loss: 1883.2808\n",
      "Validation Loss: 1935.4006\n",
      "Epoch [1421/3000], Loss: 1794.2898\n",
      "Validation Loss: 1907.7665\n",
      "Epoch [1441/3000], Loss: 1748.8714\n",
      "Validation Loss: 1866.6726\n",
      "Epoch [1461/3000], Loss: 1695.0667\n",
      "Validation Loss: 1819.8091\n",
      "Epoch [1481/3000], Loss: 1646.8813\n",
      "Validation Loss: 1792.5116\n",
      "Epoch [1501/3000], Loss: 1594.7958\n",
      "Validation Loss: 1755.6675\n",
      "Epoch [1521/3000], Loss: 1570.2278\n",
      "Validation Loss: 1730.6160\n",
      "Epoch [1541/3000], Loss: 1518.1681\n",
      "Validation Loss: 1699.1038\n",
      "Epoch [1561/3000], Loss: 1475.0671\n",
      "Validation Loss: 1662.2666\n",
      "Epoch [1581/3000], Loss: 1443.2790\n",
      "Validation Loss: 1636.0951\n",
      "Epoch [1601/3000], Loss: 1408.2664\n",
      "Validation Loss: 1600.9643\n",
      "Epoch [1621/3000], Loss: 1356.3697\n",
      "Validation Loss: 1571.2001\n",
      "Epoch [1641/3000], Loss: 1334.8417\n",
      "Validation Loss: 1545.5882\n",
      "Epoch [1661/3000], Loss: 1296.7264\n",
      "Validation Loss: 1519.3245\n",
      "Epoch [1681/3000], Loss: 1279.3769\n",
      "Validation Loss: 1497.3629\n",
      "Epoch [1701/3000], Loss: 1228.6257\n",
      "Validation Loss: 1476.2174\n",
      "Epoch [1721/3000], Loss: 1200.0309\n",
      "Validation Loss: 1455.9136\n",
      "Epoch [1741/3000], Loss: 1163.5582\n",
      "Validation Loss: 1438.4081\n",
      "Epoch [1761/3000], Loss: 1132.2388\n",
      "Validation Loss: 1416.7042\n",
      "Epoch [1781/3000], Loss: 1100.0208\n",
      "Validation Loss: 1399.5332\n",
      "Epoch [1801/3000], Loss: 1074.5244\n",
      "Validation Loss: 1379.6755\n",
      "Epoch [1821/3000], Loss: 1046.9583\n",
      "Validation Loss: 1354.9419\n",
      "Epoch [1841/3000], Loss: 1004.6029\n",
      "Validation Loss: 1343.1945\n",
      "Epoch [1861/3000], Loss: 985.4930\n",
      "Validation Loss: 1325.6839\n",
      "Epoch [1881/3000], Loss: 955.4887\n",
      "Validation Loss: 1307.9587\n",
      "Epoch [1901/3000], Loss: 932.5265\n",
      "Validation Loss: 1292.2398\n",
      "Epoch [1921/3000], Loss: 894.0257\n",
      "Validation Loss: 1274.5003\n",
      "Epoch [1941/3000], Loss: 883.3720\n",
      "Validation Loss: 1260.0515\n",
      "Epoch [1961/3000], Loss: 859.4483\n",
      "Validation Loss: 1245.4116\n",
      "Epoch [1981/3000], Loss: 821.0433\n",
      "Validation Loss: 1239.4923\n",
      "Epoch [2001/3000], Loss: 797.2579\n",
      "Validation Loss: 1224.4138\n",
      "Epoch [2021/3000], Loss: 771.5354\n",
      "Validation Loss: 1214.6979\n",
      "Epoch [2041/3000], Loss: 759.7246\n",
      "Validation Loss: 1204.6418\n",
      "Epoch [2061/3000], Loss: 732.1126\n",
      "Validation Loss: 1195.1112\n",
      "Epoch [2081/3000], Loss: 717.0032\n",
      "Validation Loss: 1188.2052\n",
      "Epoch [2101/3000], Loss: 692.5438\n",
      "Validation Loss: 1188.1723\n",
      "Epoch [2121/3000], Loss: 671.9067\n",
      "Validation Loss: 1188.8125\n",
      "Epoch [2141/3000], Loss: 650.2725\n",
      "Validation Loss: 1186.8938\n",
      "Epoch [2161/3000], Loss: 630.2838\n",
      "Validation Loss: 1177.2731\n",
      "Epoch [2181/3000], Loss: 608.9157\n",
      "Validation Loss: 1174.3735\n",
      "Epoch [2201/3000], Loss: 593.7500\n",
      "Validation Loss: 1168.8891\n",
      "Epoch [2221/3000], Loss: 562.0249\n",
      "Validation Loss: 1169.6478\n",
      "Epoch [2241/3000], Loss: 553.5125\n",
      "Validation Loss: 1160.7618\n",
      "Epoch [2261/3000], Loss: 536.9489\n",
      "Validation Loss: 1160.3950\n",
      "Epoch [2281/3000], Loss: 513.1478\n",
      "Validation Loss: 1156.2713\n",
      "Epoch [2301/3000], Loss: 496.9887\n",
      "Validation Loss: 1151.0652\n",
      "Epoch [2321/3000], Loss: 485.9312\n",
      "Validation Loss: 1157.0324\n",
      "Epoch [2341/3000], Loss: 464.8500\n",
      "Validation Loss: 1154.8642\n",
      "Epoch [2361/3000], Loss: 446.4152\n",
      "Validation Loss: 1153.4062\n",
      "Epoch [2381/3000], Loss: 440.5076\n",
      "Validation Loss: 1151.3174\n",
      "Epoch [2401/3000], Loss: 413.8799\n",
      "Validation Loss: 1152.4885\n",
      "Epoch [2421/3000], Loss: 402.4939\n",
      "Validation Loss: 1149.5727\n",
      "Epoch [2441/3000], Loss: 385.9598\n",
      "Validation Loss: 1138.2433\n",
      "Epoch [2461/3000], Loss: 373.6692\n",
      "Validation Loss: 1140.2718\n",
      "Epoch [2481/3000], Loss: 364.0668\n",
      "Validation Loss: 1140.6686\n",
      "Epoch [2501/3000], Loss: 346.0736\n",
      "Validation Loss: 1138.3034\n",
      "Epoch [2521/3000], Loss: 335.7639\n",
      "Validation Loss: 1141.7618\n",
      "Epoch [2541/3000], Loss: 325.0155\n",
      "Validation Loss: 1136.7981\n",
      "Epoch [2561/3000], Loss: 311.6291\n",
      "Validation Loss: 1137.9935\n",
      "Epoch [2581/3000], Loss: 297.8605\n",
      "Validation Loss: 1134.2037\n",
      "Epoch [2601/3000], Loss: 286.4007\n",
      "Validation Loss: 1133.5483\n",
      "Epoch [2621/3000], Loss: 274.7809\n",
      "Validation Loss: 1126.6487\n",
      "Epoch [2641/3000], Loss: 266.7878\n",
      "Validation Loss: 1127.3437\n",
      "Epoch [2661/3000], Loss: 254.7159\n",
      "Validation Loss: 1123.7383\n",
      "Epoch [2681/3000], Loss: 242.0477\n",
      "Validation Loss: 1112.2089\n",
      "Epoch [2701/3000], Loss: 232.9756\n",
      "Validation Loss: 1112.5572\n",
      "Epoch [2721/3000], Loss: 224.0789\n",
      "Validation Loss: 1108.4146\n",
      "Epoch [2741/3000], Loss: 214.5691\n",
      "Validation Loss: 1105.0382\n",
      "Epoch [2761/3000], Loss: 206.3448\n",
      "Validation Loss: 1103.3641\n",
      "Epoch [2781/3000], Loss: 196.5296\n",
      "Validation Loss: 1103.3314\n",
      "Epoch [2801/3000], Loss: 188.1445\n",
      "Validation Loss: 1100.8516\n",
      "Epoch [2821/3000], Loss: 177.4337\n",
      "Validation Loss: 1101.3360\n",
      "Epoch [2841/3000], Loss: 170.5780\n",
      "Validation Loss: 1100.4964\n",
      "Epoch [2861/3000], Loss: 165.4842\n",
      "Validation Loss: 1097.5458\n",
      "Epoch [2881/3000], Loss: 156.5300\n",
      "Validation Loss: 1090.0768\n",
      "Epoch [2901/3000], Loss: 146.9653\n",
      "Validation Loss: 1089.1843\n",
      "Epoch [2921/3000], Loss: 140.9585\n",
      "Validation Loss: 1092.6931\n",
      "Epoch [2941/3000], Loss: 135.3525\n",
      "Validation Loss: 1086.2210\n",
      "Epoch [2961/3000], Loss: 127.3800\n",
      "Validation Loss: 1091.7680\n",
      "Epoch [2981/3000], Loss: 120.4291\n",
      "Validation Loss: 1097.1837\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day008_plane0_Fall.mat\n",
      "(7726, 1152)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 10442.2489\n",
      "Validation Loss: 7048.2203\n",
      "Epoch [21/3000], Loss: 9018.0519\n",
      "Validation Loss: 5986.1526\n",
      "Epoch [41/3000], Loss: 8722.5556\n",
      "Validation Loss: 5774.0417\n",
      "Epoch [61/3000], Loss: 8484.1913\n",
      "Validation Loss: 5612.6184\n",
      "Epoch [81/3000], Loss: 8298.4605\n",
      "Validation Loss: 5461.3237\n",
      "Epoch [101/3000], Loss: 8091.6236\n",
      "Validation Loss: 5321.6804\n",
      "Epoch [121/3000], Loss: 7888.0640\n",
      "Validation Loss: 5189.3368\n",
      "Epoch [141/3000], Loss: 7708.1502\n",
      "Validation Loss: 5062.7768\n",
      "Epoch [161/3000], Loss: 7539.6758\n",
      "Validation Loss: 4941.3480\n",
      "Epoch [181/3000], Loss: 7356.9782\n",
      "Validation Loss: 4824.7537\n",
      "Epoch [201/3000], Loss: 7201.3333\n",
      "Validation Loss: 4712.8619\n",
      "Epoch [221/3000], Loss: 7039.1882\n",
      "Validation Loss: 4605.5350\n",
      "Epoch [241/3000], Loss: 6865.3291\n",
      "Validation Loss: 4502.7790\n",
      "Epoch [261/3000], Loss: 6714.3479\n",
      "Validation Loss: 4404.4885\n",
      "Epoch [281/3000], Loss: 6563.3187\n",
      "Validation Loss: 4310.6812\n",
      "Epoch [301/3000], Loss: 6411.5228\n",
      "Validation Loss: 4221.2109\n",
      "Epoch [321/3000], Loss: 6280.2034\n",
      "Validation Loss: 4134.8687\n",
      "Epoch [341/3000], Loss: 6140.8831\n",
      "Validation Loss: 4053.8518\n",
      "Epoch [361/3000], Loss: 6011.0287\n",
      "Validation Loss: 3977.3799\n",
      "Epoch [381/3000], Loss: 5879.9833\n",
      "Validation Loss: 3905.3222\n",
      "Epoch [401/3000], Loss: 5753.5446\n",
      "Validation Loss: 3837.6124\n",
      "Epoch [421/3000], Loss: 5637.1233\n",
      "Validation Loss: 3774.2360\n",
      "Epoch [441/3000], Loss: 5527.3023\n",
      "Validation Loss: 3715.2259\n",
      "Epoch [461/3000], Loss: 5411.0766\n",
      "Validation Loss: 3660.5175\n",
      "Epoch [481/3000], Loss: 5305.8792\n",
      "Validation Loss: 3610.0961\n",
      "Epoch [501/3000], Loss: 5210.1036\n",
      "Validation Loss: 3563.9549\n",
      "Epoch [521/3000], Loss: 5102.8696\n",
      "Validation Loss: 3522.0386\n",
      "Epoch [541/3000], Loss: 5006.7546\n",
      "Validation Loss: 3484.3458\n",
      "Epoch [561/3000], Loss: 4924.8516\n",
      "Validation Loss: 3450.8029\n",
      "Epoch [581/3000], Loss: 4848.0321\n",
      "Validation Loss: 3421.4225\n",
      "Epoch [601/3000], Loss: 4763.9338\n",
      "Validation Loss: 3396.0981\n",
      "Epoch [621/3000], Loss: 4570.0400\n",
      "Validation Loss: 3207.0013\n",
      "Epoch [641/3000], Loss: 3761.5470\n",
      "Validation Loss: 2595.6792\n",
      "Epoch [661/3000], Loss: 3594.8324\n",
      "Validation Loss: 2514.9514\n",
      "Epoch [681/3000], Loss: 3466.9084\n",
      "Validation Loss: 2424.3958\n",
      "Epoch [701/3000], Loss: 3334.6637\n",
      "Validation Loss: 2362.3009\n",
      "Epoch [721/3000], Loss: 3215.2134\n",
      "Validation Loss: 2337.2838\n",
      "Epoch [741/3000], Loss: 3103.1911\n",
      "Validation Loss: 2314.0828\n",
      "Epoch [761/3000], Loss: 2986.4582\n",
      "Validation Loss: 2264.1493\n",
      "Epoch [781/3000], Loss: 2880.3756\n",
      "Validation Loss: 2206.8063\n",
      "Epoch [801/3000], Loss: 2774.0141\n",
      "Validation Loss: 2149.4906\n",
      "Epoch [821/3000], Loss: 2677.9239\n",
      "Validation Loss: 2102.9656\n",
      "Epoch [841/3000], Loss: 2574.0081\n",
      "Validation Loss: 2049.9422\n",
      "Epoch [861/3000], Loss: 2477.8609\n",
      "Validation Loss: 2008.2991\n",
      "Epoch [881/3000], Loss: 2382.7408\n",
      "Validation Loss: 1963.9123\n",
      "Epoch [901/3000], Loss: 2287.9988\n",
      "Validation Loss: 1913.0203\n",
      "Epoch [921/3000], Loss: 2201.6064\n",
      "Validation Loss: 1864.4630\n",
      "Epoch [941/3000], Loss: 2115.2983\n",
      "Validation Loss: 1836.4849\n",
      "Epoch [961/3000], Loss: 2028.5816\n",
      "Validation Loss: 1789.0298\n",
      "Epoch [981/3000], Loss: 1945.0147\n",
      "Validation Loss: 1737.8536\n",
      "Epoch [1001/3000], Loss: 1864.5763\n",
      "Validation Loss: 1735.9848\n",
      "Epoch [1021/3000], Loss: 1784.5917\n",
      "Validation Loss: 1698.9914\n",
      "Epoch [1041/3000], Loss: 1712.3664\n",
      "Validation Loss: 1667.8722\n",
      "Epoch [1061/3000], Loss: 1636.3967\n",
      "Validation Loss: 1635.9472\n",
      "Epoch [1081/3000], Loss: 1565.0080\n",
      "Validation Loss: 1604.5725\n",
      "Epoch [1101/3000], Loss: 1491.8316\n",
      "Validation Loss: 1577.4495\n",
      "Epoch [1121/3000], Loss: 1425.7571\n",
      "Validation Loss: 1562.3953\n",
      "Epoch [1141/3000], Loss: 1357.8790\n",
      "Validation Loss: 1540.0289\n",
      "Epoch [1161/3000], Loss: 1296.9297\n",
      "Validation Loss: 1520.7087\n",
      "Epoch [1181/3000], Loss: 1235.5850\n",
      "Validation Loss: 1497.2897\n",
      "Epoch [1201/3000], Loss: 1171.6093\n",
      "Validation Loss: 1481.4238\n",
      "Epoch [1221/3000], Loss: 1114.5568\n",
      "Validation Loss: 1467.1820\n",
      "Epoch [1241/3000], Loss: 1058.9413\n",
      "Validation Loss: 1470.1608\n",
      "Epoch [1261/3000], Loss: 1002.1287\n",
      "Validation Loss: 1452.6879\n",
      "Epoch [1281/3000], Loss: 951.3602\n",
      "Validation Loss: 1409.4438\n",
      "Epoch [1301/3000], Loss: 899.5829\n",
      "Validation Loss: 1401.4416\n",
      "Epoch [1321/3000], Loss: 851.1864\n",
      "Validation Loss: 1398.0044\n",
      "Epoch [1341/3000], Loss: 803.3174\n",
      "Validation Loss: 1391.7113\n",
      "Epoch [1361/3000], Loss: 757.7749\n",
      "Validation Loss: 1395.1426\n",
      "Epoch [1381/3000], Loss: 714.5480\n",
      "Validation Loss: 1396.0166\n",
      "Epoch [1401/3000], Loss: 673.8083\n",
      "Validation Loss: 1408.2275\n",
      "Epoch [1421/3000], Loss: 631.5311\n",
      "Validation Loss: 1412.5846\n",
      "Epoch [1441/3000], Loss: 592.8893\n",
      "Validation Loss: 1406.4078\n",
      "Epoch [1461/3000], Loss: 555.9577\n",
      "Validation Loss: 1407.1713\n",
      "Epoch [1481/3000], Loss: 520.1903\n",
      "Validation Loss: 1410.1740\n",
      "Epoch [1501/3000], Loss: 486.1487\n",
      "Validation Loss: 1421.0739\n",
      "Epoch [1521/3000], Loss: 453.3240\n",
      "Validation Loss: 1415.4737\n",
      "Epoch [1541/3000], Loss: 421.8563\n",
      "Validation Loss: 1405.3885\n",
      "Epoch [1561/3000], Loss: 392.0338\n",
      "Validation Loss: 1410.8488\n",
      "Epoch [1581/3000], Loss: 364.1388\n",
      "Validation Loss: 1412.1947\n",
      "Epoch [1601/3000], Loss: 336.5727\n",
      "Validation Loss: 1419.8409\n",
      "Epoch [1621/3000], Loss: 311.3636\n",
      "Validation Loss: 1420.2494\n",
      "Epoch [1641/3000], Loss: 285.3728\n",
      "Validation Loss: 1424.5780\n",
      "Epoch [1661/3000], Loss: 261.8451\n",
      "Validation Loss: 1416.8288\n",
      "Epoch [1681/3000], Loss: 240.4110\n",
      "Validation Loss: 1421.5116\n",
      "Epoch [1701/3000], Loss: 219.9716\n",
      "Validation Loss: 1425.1263\n",
      "Epoch [1721/3000], Loss: 199.7008\n",
      "Validation Loss: 1419.4075\n",
      "Epoch [1741/3000], Loss: 181.1115\n",
      "Validation Loss: 1450.6185\n",
      "Epoch [1761/3000], Loss: 163.7192\n",
      "Validation Loss: 1431.8330\n",
      "Epoch [1781/3000], Loss: 147.1433\n",
      "Validation Loss: 1424.8704\n",
      "Epoch [1801/3000], Loss: 131.7431\n",
      "Validation Loss: 1441.8999\n",
      "Epoch [1821/3000], Loss: 117.5767\n",
      "Validation Loss: 1455.0245\n",
      "Epoch [1841/3000], Loss: 104.7363\n",
      "Validation Loss: 1457.9144\n",
      "Epoch [1861/3000], Loss: 92.5177\n",
      "Validation Loss: 1453.2811\n",
      "Epoch [1881/3000], Loss: 81.4303\n",
      "Validation Loss: 1467.6110\n",
      "Epoch [1901/3000], Loss: 71.7111\n",
      "Validation Loss: 1474.5976\n",
      "Epoch [1921/3000], Loss: 62.7333\n",
      "Validation Loss: 1489.2379\n",
      "Epoch [1941/3000], Loss: 55.0112\n",
      "Validation Loss: 1478.4491\n",
      "Epoch [1961/3000], Loss: 48.1278\n",
      "Validation Loss: 1499.2315\n",
      "Epoch [1981/3000], Loss: 42.1318\n",
      "Validation Loss: 1469.5527\n",
      "Epoch [2001/3000], Loss: 37.3478\n",
      "Validation Loss: 1427.8735\n",
      "Epoch [2021/3000], Loss: 32.8925\n",
      "Validation Loss: 1459.1600\n",
      "Epoch [2041/3000], Loss: 29.4030\n",
      "Validation Loss: 1433.2409\n",
      "Epoch [2061/3000], Loss: 25.2899\n",
      "Validation Loss: 1442.6824\n",
      "Epoch [2081/3000], Loss: 21.6012\n",
      "Validation Loss: 1470.3046\n",
      "Epoch [2101/3000], Loss: 18.1000\n",
      "Validation Loss: 1482.6746\n",
      "Epoch [2121/3000], Loss: 15.2925\n",
      "Validation Loss: 1449.9595\n",
      "Epoch [2141/3000], Loss: 12.6813\n",
      "Validation Loss: 1495.7870\n",
      "Epoch [2161/3000], Loss: 10.4676\n",
      "Validation Loss: 1476.1154\n",
      "Epoch [2181/3000], Loss: 8.5884\n",
      "Validation Loss: 1510.3787\n",
      "Epoch [2201/3000], Loss: 6.9508\n",
      "Validation Loss: 1540.1509\n",
      "Epoch [2221/3000], Loss: 5.5676\n",
      "Validation Loss: 1447.1856\n",
      "Epoch [2241/3000], Loss: 4.3082\n",
      "Validation Loss: 1546.0534\n",
      "Epoch [2261/3000], Loss: 3.2921\n",
      "Validation Loss: 1559.8318\n",
      "Epoch [2281/3000], Loss: 2.4863\n",
      "Validation Loss: 1560.2621\n",
      "Epoch [2301/3000], Loss: 1.8180\n",
      "Validation Loss: 1577.7280\n",
      "Epoch [2321/3000], Loss: 1.3195\n",
      "Validation Loss: 1544.0436\n",
      "Epoch [2341/3000], Loss: 0.9428\n",
      "Validation Loss: 1557.2303\n",
      "Epoch [2361/3000], Loss: 0.6691\n",
      "Validation Loss: 1549.4463\n",
      "Epoch [2381/3000], Loss: 0.5023\n",
      "Validation Loss: 1578.9701\n",
      "Epoch [2401/3000], Loss: 0.3646\n",
      "Validation Loss: 1554.9105\n",
      "Epoch [2421/3000], Loss: 0.2506\n",
      "Validation Loss: 1560.5653\n",
      "Epoch [2441/3000], Loss: 0.1832\n",
      "Validation Loss: 1549.9800\n",
      "Epoch [2461/3000], Loss: 0.1239\n",
      "Validation Loss: 1564.7717\n",
      "Epoch [2481/3000], Loss: 0.0841\n",
      "Validation Loss: 1571.1425\n",
      "Epoch [2501/3000], Loss: 0.0589\n",
      "Validation Loss: 1566.9549\n",
      "Epoch [2521/3000], Loss: 0.0510\n",
      "Validation Loss: 1569.6495\n",
      "Epoch [2541/3000], Loss: 0.0342\n",
      "Validation Loss: 1581.2428\n",
      "Epoch [2561/3000], Loss: 0.0375\n",
      "Validation Loss: 1555.9429\n",
      "Epoch [2581/3000], Loss: 0.0248\n",
      "Validation Loss: 1570.1104\n",
      "Epoch [2601/3000], Loss: 0.0484\n",
      "Validation Loss: 1552.7803\n",
      "Epoch [2621/3000], Loss: 0.0233\n",
      "Validation Loss: 1575.2031\n",
      "Epoch [2641/3000], Loss: 0.0627\n",
      "Validation Loss: 1548.9201\n",
      "Epoch [2661/3000], Loss: 0.0162\n",
      "Validation Loss: 1559.7103\n",
      "Epoch [2681/3000], Loss: 0.0191\n",
      "Validation Loss: 1530.0206\n",
      "Epoch [2701/3000], Loss: 0.0670\n",
      "Validation Loss: 1506.7381\n",
      "Epoch [2721/3000], Loss: 0.0119\n",
      "Validation Loss: 1552.9786\n",
      "Epoch [2741/3000], Loss: 0.0165\n",
      "Validation Loss: 1537.1188\n",
      "Epoch [2761/3000], Loss: 0.0114\n",
      "Validation Loss: 1541.4401\n",
      "Epoch [2781/3000], Loss: 0.0164\n",
      "Validation Loss: 1542.5216\n",
      "Epoch [2801/3000], Loss: 0.0124\n",
      "Validation Loss: 1539.2660\n",
      "Epoch [2821/3000], Loss: 0.0108\n",
      "Validation Loss: 1554.0428\n",
      "Epoch [2841/3000], Loss: 0.0167\n",
      "Validation Loss: 1540.5927\n",
      "Epoch [2861/3000], Loss: 0.0092\n",
      "Validation Loss: 1538.9871\n",
      "Epoch [2881/3000], Loss: 0.0160\n",
      "Validation Loss: 1539.8945\n",
      "Epoch [2901/3000], Loss: 0.0162\n",
      "Validation Loss: 1534.9558\n",
      "Epoch [2921/3000], Loss: 0.0108\n",
      "Validation Loss: 1535.3657\n",
      "Epoch [2941/3000], Loss: 0.0082\n",
      "Validation Loss: 1531.2259\n",
      "Epoch [2961/3000], Loss: 0.0104\n",
      "Validation Loss: 1537.9291\n",
      "Epoch [2981/3000], Loss: 0.0135\n",
      "Validation Loss: 1554.7072\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day009_plane0_Fall.mat\n",
      "(9199, 926)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8155.6190\n",
      "Validation Loss: 6305.8883\n",
      "Epoch [21/3000], Loss: 6901.0814\n",
      "Validation Loss: 5239.8207\n",
      "Epoch [41/3000], Loss: 6655.3370\n",
      "Validation Loss: 5030.1599\n",
      "Epoch [61/3000], Loss: 6439.9456\n",
      "Validation Loss: 4857.3687\n",
      "Epoch [81/3000], Loss: 6235.3914\n",
      "Validation Loss: 4700.3439\n",
      "Epoch [101/3000], Loss: 6045.2773\n",
      "Validation Loss: 4553.0434\n",
      "Epoch [121/3000], Loss: 5870.6537\n",
      "Validation Loss: 4413.6021\n",
      "Epoch [141/3000], Loss: 5725.1915\n",
      "Validation Loss: 4280.9876\n",
      "Epoch [161/3000], Loss: 5573.7164\n",
      "Validation Loss: 4155.0017\n",
      "Epoch [181/3000], Loss: 5393.7768\n",
      "Validation Loss: 4034.6918\n",
      "Epoch [201/3000], Loss: 5268.2034\n",
      "Validation Loss: 3920.0282\n",
      "Epoch [221/3000], Loss: 5105.6152\n",
      "Validation Loss: 3811.9737\n",
      "Epoch [241/3000], Loss: 4984.5531\n",
      "Validation Loss: 3710.0741\n",
      "Epoch [261/3000], Loss: 4847.6591\n",
      "Validation Loss: 3614.1498\n",
      "Epoch [281/3000], Loss: 4730.7728\n",
      "Validation Loss: 3524.3125\n",
      "Epoch [301/3000], Loss: 4615.7583\n",
      "Validation Loss: 3440.3417\n",
      "Epoch [321/3000], Loss: 4493.1052\n",
      "Validation Loss: 3362.2720\n",
      "Epoch [341/3000], Loss: 4381.6789\n",
      "Validation Loss: 3289.9993\n",
      "Epoch [361/3000], Loss: 4294.6679\n",
      "Validation Loss: 3223.5499\n",
      "Epoch [381/3000], Loss: 4195.6097\n",
      "Validation Loss: 3162.9523\n",
      "Epoch [401/3000], Loss: 4123.4681\n",
      "Validation Loss: 3107.9374\n",
      "Epoch [421/3000], Loss: 4046.0266\n",
      "Validation Loss: 3058.5984\n",
      "Epoch [441/3000], Loss: 3980.9273\n",
      "Validation Loss: 3014.8127\n",
      "Epoch [461/3000], Loss: 3251.4522\n",
      "Validation Loss: 2479.7258\n",
      "Epoch [481/3000], Loss: 3049.1079\n",
      "Validation Loss: 2418.8218\n",
      "Epoch [501/3000], Loss: 2897.1907\n",
      "Validation Loss: 2359.0776\n",
      "Epoch [521/3000], Loss: 2779.0386\n",
      "Validation Loss: 2131.9433\n",
      "Epoch [541/3000], Loss: 2640.6792\n",
      "Validation Loss: 2233.7220\n",
      "Epoch [561/3000], Loss: 2533.9916\n",
      "Validation Loss: 2169.1380\n",
      "Epoch [581/3000], Loss: 2419.0993\n",
      "Validation Loss: 2092.9759\n",
      "Epoch [601/3000], Loss: 2321.4805\n",
      "Validation Loss: 2013.7679\n",
      "Epoch [621/3000], Loss: 2229.0677\n",
      "Validation Loss: 1930.6004\n",
      "Epoch [641/3000], Loss: 2136.3244\n",
      "Validation Loss: 1856.5796\n",
      "Epoch [661/3000], Loss: 2029.2328\n",
      "Validation Loss: 1792.0230\n",
      "Epoch [681/3000], Loss: 1931.4389\n",
      "Validation Loss: 1723.6251\n",
      "Epoch [701/3000], Loss: 1845.6143\n",
      "Validation Loss: 1653.5664\n",
      "Epoch [721/3000], Loss: 1756.0636\n",
      "Validation Loss: 1606.2123\n",
      "Epoch [741/3000], Loss: 1675.5494\n",
      "Validation Loss: 1596.1976\n",
      "Epoch [761/3000], Loss: 1589.5335\n",
      "Validation Loss: 1538.0543\n",
      "Epoch [781/3000], Loss: 1512.5231\n",
      "Validation Loss: 1486.8074\n",
      "Epoch [801/3000], Loss: 1443.8511\n",
      "Validation Loss: 1432.7300\n",
      "Epoch [821/3000], Loss: 1359.7663\n",
      "Validation Loss: 1372.9028\n",
      "Epoch [841/3000], Loss: 1293.0668\n",
      "Validation Loss: 1349.2686\n",
      "Epoch [861/3000], Loss: 1226.3939\n",
      "Validation Loss: 1430.0405\n",
      "Epoch [881/3000], Loss: 1158.0338\n",
      "Validation Loss: 1274.9074\n",
      "Epoch [901/3000], Loss: 1102.5672\n",
      "Validation Loss: 1236.5370\n",
      "Epoch [921/3000], Loss: 1039.7357\n",
      "Validation Loss: 1274.7863\n",
      "Epoch [941/3000], Loss: 988.2030\n",
      "Validation Loss: 1236.8088\n",
      "Epoch [961/3000], Loss: 931.5314\n",
      "Validation Loss: 1204.9953\n",
      "Epoch [981/3000], Loss: 874.8544\n",
      "Validation Loss: 1163.7457\n",
      "Epoch [1001/3000], Loss: 830.8849\n",
      "Validation Loss: 1151.1360\n",
      "Epoch [1021/3000], Loss: 786.2843\n",
      "Validation Loss: 1108.5106\n",
      "Epoch [1041/3000], Loss: 738.3025\n",
      "Validation Loss: 1087.5542\n",
      "Epoch [1061/3000], Loss: 692.4850\n",
      "Validation Loss: 1058.0867\n",
      "Epoch [1081/3000], Loss: 646.6875\n",
      "Validation Loss: 1033.0113\n",
      "Epoch [1101/3000], Loss: 614.2971\n",
      "Validation Loss: 1002.3727\n",
      "Epoch [1121/3000], Loss: 571.9992\n",
      "Validation Loss: 986.9460\n",
      "Epoch [1141/3000], Loss: 532.8697\n",
      "Validation Loss: 973.2311\n",
      "Epoch [1161/3000], Loss: 501.2985\n",
      "Validation Loss: 944.1838\n",
      "Epoch [1181/3000], Loss: 466.2194\n",
      "Validation Loss: 926.6013\n",
      "Epoch [1201/3000], Loss: 431.9476\n",
      "Validation Loss: 924.5539\n",
      "Epoch [1221/3000], Loss: 406.4372\n",
      "Validation Loss: 884.2983\n",
      "Epoch [1241/3000], Loss: 377.4288\n",
      "Validation Loss: 938.6790\n",
      "Epoch [1261/3000], Loss: 352.4194\n",
      "Validation Loss: 914.0347\n",
      "Epoch [1281/3000], Loss: 323.5272\n",
      "Validation Loss: 898.7920\n",
      "Epoch [1301/3000], Loss: 302.1441\n",
      "Validation Loss: 887.1323\n",
      "Epoch [1321/3000], Loss: 278.7656\n",
      "Validation Loss: 874.3816\n",
      "Epoch [1341/3000], Loss: 253.4086\n",
      "Validation Loss: 858.6372\n",
      "Epoch [1361/3000], Loss: 235.1889\n",
      "Validation Loss: 845.7714\n",
      "Epoch [1381/3000], Loss: 215.2458\n",
      "Validation Loss: 839.8825\n",
      "Epoch [1401/3000], Loss: 198.0476\n",
      "Validation Loss: 830.7970\n",
      "Epoch [1421/3000], Loss: 179.5296\n",
      "Validation Loss: 826.3436\n",
      "Epoch [1441/3000], Loss: 164.8195\n",
      "Validation Loss: 821.5158\n",
      "Epoch [1461/3000], Loss: 149.3214\n",
      "Validation Loss: 816.0544\n",
      "Epoch [1481/3000], Loss: 134.9837\n",
      "Validation Loss: 812.6227\n",
      "Epoch [1501/3000], Loss: 121.3515\n",
      "Validation Loss: 798.1335\n",
      "Epoch [1521/3000], Loss: 110.0075\n",
      "Validation Loss: 811.3901\n",
      "Epoch [1541/3000], Loss: 99.1338\n",
      "Validation Loss: 799.9915\n",
      "Epoch [1561/3000], Loss: 87.8023\n",
      "Validation Loss: 788.9953\n",
      "Epoch [1581/3000], Loss: 78.5110\n",
      "Validation Loss: 780.2593\n",
      "Epoch [1601/3000], Loss: 69.3914\n",
      "Validation Loss: 774.6441\n",
      "Epoch [1621/3000], Loss: 61.5610\n",
      "Validation Loss: 765.1532\n",
      "Epoch [1641/3000], Loss: 54.4496\n",
      "Validation Loss: 754.8950\n",
      "Epoch [1661/3000], Loss: 47.0896\n",
      "Validation Loss: 746.9930\n",
      "Epoch [1681/3000], Loss: 40.6073\n",
      "Validation Loss: 741.7106\n",
      "Epoch [1701/3000], Loss: 35.4701\n",
      "Validation Loss: 732.0383\n",
      "Epoch [1721/3000], Loss: 30.0602\n",
      "Validation Loss: 723.2829\n",
      "Epoch [1741/3000], Loss: 25.6923\n",
      "Validation Loss: 718.5927\n",
      "Epoch [1761/3000], Loss: 21.9200\n",
      "Validation Loss: 714.2044\n",
      "Epoch [1781/3000], Loss: 18.2933\n",
      "Validation Loss: 712.9089\n",
      "Epoch [1801/3000], Loss: 15.3419\n",
      "Validation Loss: 707.2440\n",
      "Epoch [1821/3000], Loss: 12.4827\n",
      "Validation Loss: 706.0579\n",
      "Epoch [1841/3000], Loss: 10.1959\n",
      "Validation Loss: 702.8172\n",
      "Epoch [1861/3000], Loss: 8.1762\n",
      "Validation Loss: 706.0679\n",
      "Epoch [1881/3000], Loss: 6.5148\n",
      "Validation Loss: 709.7865\n",
      "Epoch [1901/3000], Loss: 4.9735\n",
      "Validation Loss: 713.9715\n",
      "Epoch [1921/3000], Loss: 4.0533\n",
      "Validation Loss: 743.2061\n",
      "Epoch [1941/3000], Loss: 3.1873\n",
      "Validation Loss: 740.3742\n",
      "Epoch [1961/3000], Loss: 2.4545\n",
      "Validation Loss: 739.4134\n",
      "Epoch [1981/3000], Loss: 1.8491\n",
      "Validation Loss: 737.9004\n",
      "Epoch [2001/3000], Loss: 1.3881\n",
      "Validation Loss: 736.0876\n",
      "Epoch [2021/3000], Loss: 1.0055\n",
      "Validation Loss: 735.9342\n",
      "Epoch [2041/3000], Loss: 0.7247\n",
      "Validation Loss: 736.7096\n",
      "Epoch [2061/3000], Loss: 0.5128\n",
      "Validation Loss: 738.3809\n",
      "Epoch [2081/3000], Loss: 0.3551\n",
      "Validation Loss: 740.6776\n",
      "Epoch [2101/3000], Loss: 0.2189\n",
      "Validation Loss: 741.3241\n",
      "Epoch [2121/3000], Loss: 0.1363\n",
      "Validation Loss: 743.1399\n",
      "Epoch [2141/3000], Loss: 0.0844\n",
      "Validation Loss: 744.5533\n",
      "Epoch [2161/3000], Loss: 0.0648\n",
      "Validation Loss: 746.3050\n",
      "Epoch [2181/3000], Loss: 0.0489\n",
      "Validation Loss: 746.2065\n",
      "Epoch [2201/3000], Loss: 0.0385\n",
      "Validation Loss: 745.4384\n",
      "Epoch [2221/3000], Loss: 0.0310\n",
      "Validation Loss: 747.1166\n",
      "Epoch [2241/3000], Loss: 0.0337\n",
      "Validation Loss: 746.6712\n",
      "Epoch [2261/3000], Loss: 0.0275\n",
      "Validation Loss: 749.3865\n",
      "Epoch [2281/3000], Loss: 0.0315\n",
      "Validation Loss: 749.4080\n",
      "Epoch [2301/3000], Loss: 0.0238\n",
      "Validation Loss: 750.5637\n",
      "Epoch [2321/3000], Loss: 0.0223\n",
      "Validation Loss: 750.3604\n",
      "Epoch [2341/3000], Loss: 0.0232\n",
      "Validation Loss: 751.1397\n",
      "Epoch [2361/3000], Loss: 0.0213\n",
      "Validation Loss: 753.4667\n",
      "Epoch [2381/3000], Loss: 0.0196\n",
      "Validation Loss: 749.8383\n",
      "Epoch [2401/3000], Loss: 0.0158\n",
      "Validation Loss: 750.7438\n",
      "Epoch [2421/3000], Loss: 0.0150\n",
      "Validation Loss: 751.8380\n",
      "Epoch [2441/3000], Loss: 0.0185\n",
      "Validation Loss: 750.7612\n",
      "Epoch [2461/3000], Loss: 0.0120\n",
      "Validation Loss: 751.8060\n",
      "Epoch [2481/3000], Loss: 0.0122\n",
      "Validation Loss: 751.9260\n",
      "Epoch [2501/3000], Loss: 0.0135\n",
      "Validation Loss: 751.0475\n",
      "Epoch [2521/3000], Loss: 0.0109\n",
      "Validation Loss: 752.6493\n",
      "Epoch [2541/3000], Loss: 0.0106\n",
      "Validation Loss: 753.8119\n",
      "Epoch [2561/3000], Loss: 0.0131\n",
      "Validation Loss: 752.6357\n",
      "Epoch [2581/3000], Loss: 0.0158\n",
      "Validation Loss: 752.2664\n",
      "Epoch [2601/3000], Loss: 0.0214\n",
      "Validation Loss: 751.1920\n",
      "Epoch [2621/3000], Loss: 0.0089\n",
      "Validation Loss: 752.7214\n",
      "Epoch [2641/3000], Loss: 0.0085\n",
      "Validation Loss: 754.1137\n",
      "Epoch [2661/3000], Loss: 0.0077\n",
      "Validation Loss: 753.1575\n",
      "Epoch [2681/3000], Loss: 0.0103\n",
      "Validation Loss: 754.0114\n",
      "Epoch [2701/3000], Loss: 0.0127\n",
      "Validation Loss: 753.3341\n",
      "Epoch [2721/3000], Loss: 0.0091\n",
      "Validation Loss: 755.7311\n",
      "Epoch [2741/3000], Loss: 0.0068\n",
      "Validation Loss: 754.0705\n",
      "Epoch [2761/3000], Loss: 0.0072\n",
      "Validation Loss: 754.6175\n",
      "Epoch [2781/3000], Loss: 0.0106\n",
      "Validation Loss: 755.7515\n",
      "Epoch [2801/3000], Loss: 0.0067\n",
      "Validation Loss: 754.0290\n",
      "Epoch [2821/3000], Loss: 0.0070\n",
      "Validation Loss: 753.5107\n",
      "Epoch [2841/3000], Loss: 0.0061\n",
      "Validation Loss: 755.2085\n",
      "Epoch [2861/3000], Loss: 0.0062\n",
      "Validation Loss: 754.7764\n",
      "Epoch [2881/3000], Loss: 0.0070\n",
      "Validation Loss: 753.2356\n",
      "Epoch [2901/3000], Loss: 0.0083\n",
      "Validation Loss: 755.8552\n",
      "Epoch [2921/3000], Loss: 0.0050\n",
      "Validation Loss: 755.0200\n",
      "Epoch [2941/3000], Loss: 0.0057\n",
      "Validation Loss: 754.5658\n",
      "Epoch [2961/3000], Loss: 0.0105\n",
      "Validation Loss: 756.4224\n",
      "Epoch [2981/3000], Loss: 0.0107\n",
      "Validation Loss: 756.7649\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day037_plane0_Fall.mat\n",
      "(10131, 493)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 12244.9411\n",
      "Validation Loss: 13228.0656\n",
      "Epoch [21/3000], Loss: 10470.1543\n",
      "Validation Loss: 11338.8009\n",
      "Epoch [41/3000], Loss: 10075.5501\n",
      "Validation Loss: 10913.1439\n",
      "Epoch [61/3000], Loss: 9763.3336\n",
      "Validation Loss: 10563.2000\n",
      "Epoch [81/3000], Loss: 9465.6572\n",
      "Validation Loss: 10237.6928\n",
      "Epoch [101/3000], Loss: 9153.9107\n",
      "Validation Loss: 9925.8659\n",
      "Epoch [121/3000], Loss: 8880.1656\n",
      "Validation Loss: 9624.6235\n",
      "Epoch [141/3000], Loss: 8589.6321\n",
      "Validation Loss: 9332.3929\n",
      "Epoch [161/3000], Loss: 8351.2169\n",
      "Validation Loss: 9048.5051\n",
      "Epoch [181/3000], Loss: 8084.8642\n",
      "Validation Loss: 8772.6637\n",
      "Epoch [201/3000], Loss: 7856.2699\n",
      "Validation Loss: 8504.6501\n",
      "Epoch [221/3000], Loss: 7603.1939\n",
      "Validation Loss: 8244.4966\n",
      "Epoch [241/3000], Loss: 7397.5604\n",
      "Validation Loss: 7991.7284\n",
      "Epoch [261/3000], Loss: 7145.0624\n",
      "Validation Loss: 7746.8348\n",
      "Epoch [281/3000], Loss: 6934.6081\n",
      "Validation Loss: 7509.5151\n",
      "Epoch [301/3000], Loss: 6724.7628\n",
      "Validation Loss: 7279.8891\n",
      "Epoch [321/3000], Loss: 6531.6346\n",
      "Validation Loss: 7057.6177\n",
      "Epoch [341/3000], Loss: 6340.0172\n",
      "Validation Loss: 6843.0422\n",
      "Epoch [361/3000], Loss: 6152.3253\n",
      "Validation Loss: 6636.0932\n",
      "Epoch [381/3000], Loss: 5971.0967\n",
      "Validation Loss: 6434.0096\n",
      "Epoch [401/3000], Loss: 5797.3216\n",
      "Validation Loss: 6240.9832\n",
      "Epoch [421/3000], Loss: 5638.4740\n",
      "Validation Loss: 6055.9001\n",
      "Epoch [441/3000], Loss: 5477.9387\n",
      "Validation Loss: 5878.4458\n",
      "Epoch [461/3000], Loss: 5324.2018\n",
      "Validation Loss: 5706.7109\n",
      "Epoch [481/3000], Loss: 4547.1268\n",
      "Validation Loss: 5093.8077\n",
      "Epoch [501/3000], Loss: 4333.8453\n",
      "Validation Loss: 4910.4787\n",
      "Epoch [521/3000], Loss: 4129.0496\n",
      "Validation Loss: 4724.6663\n",
      "Epoch [541/3000], Loss: 3939.7470\n",
      "Validation Loss: 4564.3159\n",
      "Epoch [561/3000], Loss: 3769.5538\n",
      "Validation Loss: 4598.6893\n",
      "Epoch [581/3000], Loss: 3604.8280\n",
      "Validation Loss: 4183.7920\n",
      "Epoch [601/3000], Loss: 3455.7686\n",
      "Validation Loss: 4074.8469\n",
      "Epoch [621/3000], Loss: 3278.3769\n",
      "Validation Loss: 3920.3747\n",
      "Epoch [641/3000], Loss: 3127.7549\n",
      "Validation Loss: 3761.5617\n",
      "Epoch [661/3000], Loss: 2983.5429\n",
      "Validation Loss: 3648.0079\n",
      "Epoch [681/3000], Loss: 2827.6170\n",
      "Validation Loss: 3483.0561\n",
      "Epoch [701/3000], Loss: 2695.1599\n",
      "Validation Loss: 3336.8420\n",
      "Epoch [721/3000], Loss: 2558.8182\n",
      "Validation Loss: 3181.9488\n",
      "Epoch [741/3000], Loss: 2433.6741\n",
      "Validation Loss: 3060.1809\n",
      "Epoch [761/3000], Loss: 2303.3358\n",
      "Validation Loss: 2945.4046\n",
      "Epoch [781/3000], Loss: 2185.1705\n",
      "Validation Loss: 2762.0217\n",
      "Epoch [801/3000], Loss: 2057.5284\n",
      "Validation Loss: 2692.6143\n",
      "Epoch [821/3000], Loss: 1947.6975\n",
      "Validation Loss: 2584.9878\n",
      "Epoch [841/3000], Loss: 1840.1952\n",
      "Validation Loss: 2398.0450\n",
      "Epoch [861/3000], Loss: 1735.1063\n",
      "Validation Loss: 2363.4065\n",
      "Epoch [881/3000], Loss: 1632.6101\n",
      "Validation Loss: 2248.7571\n",
      "Epoch [901/3000], Loss: 1529.3462\n",
      "Validation Loss: 2147.9572\n",
      "Epoch [921/3000], Loss: 1442.0213\n",
      "Validation Loss: 2041.5769\n",
      "Epoch [941/3000], Loss: 1346.4544\n",
      "Validation Loss: 1943.2493\n",
      "Epoch [961/3000], Loss: 1255.8173\n",
      "Validation Loss: 1875.4574\n",
      "Epoch [981/3000], Loss: 1179.1133\n",
      "Validation Loss: 1797.6488\n",
      "Epoch [1001/3000], Loss: 1095.1929\n",
      "Validation Loss: 1725.5092\n",
      "Epoch [1021/3000], Loss: 1026.3805\n",
      "Validation Loss: 1649.9590\n",
      "Epoch [1041/3000], Loss: 952.2902\n",
      "Validation Loss: 1579.5258\n",
      "Epoch [1061/3000], Loss: 884.6458\n",
      "Validation Loss: 1504.0164\n",
      "Epoch [1081/3000], Loss: 818.9513\n",
      "Validation Loss: 1467.8741\n",
      "Epoch [1101/3000], Loss: 755.5830\n",
      "Validation Loss: 1408.5456\n",
      "Epoch [1121/3000], Loss: 697.2841\n",
      "Validation Loss: 1360.2770\n",
      "Epoch [1141/3000], Loss: 641.3321\n",
      "Validation Loss: 1311.2906\n",
      "Epoch [1161/3000], Loss: 590.0633\n",
      "Validation Loss: 1265.4261\n",
      "Epoch [1181/3000], Loss: 541.8993\n",
      "Validation Loss: 1231.0969\n",
      "Epoch [1201/3000], Loss: 492.3284\n",
      "Validation Loss: 1209.1677\n",
      "Epoch [1221/3000], Loss: 447.9575\n",
      "Validation Loss: 1169.8817\n",
      "Epoch [1241/3000], Loss: 404.7165\n",
      "Validation Loss: 1138.5762\n",
      "Epoch [1261/3000], Loss: 366.7570\n",
      "Validation Loss: 1128.3058\n",
      "Epoch [1281/3000], Loss: 328.8155\n",
      "Validation Loss: 1123.0758\n",
      "Epoch [1301/3000], Loss: 296.6694\n",
      "Validation Loss: 1112.0346\n",
      "Epoch [1321/3000], Loss: 265.2985\n",
      "Validation Loss: 1095.1496\n",
      "Epoch [1341/3000], Loss: 234.1930\n",
      "Validation Loss: 1081.2741\n",
      "Epoch [1361/3000], Loss: 207.1854\n",
      "Validation Loss: 1063.3100\n",
      "Epoch [1381/3000], Loss: 183.1772\n",
      "Validation Loss: 1058.2762\n",
      "Epoch [1401/3000], Loss: 158.9318\n",
      "Validation Loss: 1038.8036\n",
      "Epoch [1421/3000], Loss: 137.8035\n",
      "Validation Loss: 1024.5220\n",
      "Epoch [1441/3000], Loss: 117.9010\n",
      "Validation Loss: 1011.7778\n",
      "Epoch [1461/3000], Loss: 100.0975\n",
      "Validation Loss: 1001.5044\n",
      "Epoch [1481/3000], Loss: 84.3361\n",
      "Validation Loss: 932.8482\n",
      "Epoch [1501/3000], Loss: 70.8059\n",
      "Validation Loss: 961.2331\n",
      "Epoch [1521/3000], Loss: 58.2483\n",
      "Validation Loss: 977.4843\n",
      "Epoch [1541/3000], Loss: 47.1976\n",
      "Validation Loss: 991.8000\n",
      "Epoch [1561/3000], Loss: 37.9605\n",
      "Validation Loss: 1004.3990\n",
      "Epoch [1581/3000], Loss: 30.1287\n",
      "Validation Loss: 1010.0031\n",
      "Epoch [1601/3000], Loss: 23.8938\n",
      "Validation Loss: 1012.0766\n",
      "Epoch [1621/3000], Loss: 18.9871\n",
      "Validation Loss: 1026.7329\n",
      "Epoch [1641/3000], Loss: 15.0531\n",
      "Validation Loss: 1048.3438\n",
      "Epoch [1661/3000], Loss: 11.6697\n",
      "Validation Loss: 1051.1079\n",
      "Epoch [1681/3000], Loss: 8.8205\n",
      "Validation Loss: 1033.3161\n",
      "Epoch [1701/3000], Loss: 6.4882\n",
      "Validation Loss: 1036.4222\n",
      "Epoch [1721/3000], Loss: 4.6807\n",
      "Validation Loss: 1049.1449\n",
      "Epoch [1741/3000], Loss: 3.3028\n",
      "Validation Loss: 1051.9555\n",
      "Epoch [1761/3000], Loss: 2.2932\n",
      "Validation Loss: 1042.5637\n",
      "Epoch [1781/3000], Loss: 1.6012\n",
      "Validation Loss: 1035.0858\n",
      "Epoch [1801/3000], Loss: 1.1143\n",
      "Validation Loss: 1019.2507\n",
      "Epoch [1821/3000], Loss: 0.7891\n",
      "Validation Loss: 1026.8618\n",
      "Epoch [1841/3000], Loss: 0.5661\n",
      "Validation Loss: 993.1860\n",
      "Epoch [1861/3000], Loss: 0.4184\n",
      "Validation Loss: 985.8092\n",
      "Epoch [1881/3000], Loss: 0.3132\n",
      "Validation Loss: 988.2244\n",
      "Epoch [1901/3000], Loss: 0.2260\n",
      "Validation Loss: 945.2906\n",
      "Epoch [1921/3000], Loss: 0.1638\n",
      "Validation Loss: 975.0685\n",
      "Epoch [1941/3000], Loss: 0.1154\n",
      "Validation Loss: 974.6614\n",
      "Epoch [1961/3000], Loss: 0.0896\n",
      "Validation Loss: 963.5087\n",
      "Epoch [1981/3000], Loss: 0.0731\n",
      "Validation Loss: 967.8834\n",
      "Epoch [2001/3000], Loss: 0.0651\n",
      "Validation Loss: 961.5930\n",
      "Epoch [2021/3000], Loss: 0.0600\n",
      "Validation Loss: 961.7777\n",
      "Epoch [2041/3000], Loss: 0.0501\n",
      "Validation Loss: 967.5023\n",
      "Epoch [2061/3000], Loss: 0.0409\n",
      "Validation Loss: 959.6511\n",
      "Epoch [2081/3000], Loss: 0.0394\n",
      "Validation Loss: 960.6434\n",
      "Epoch [2101/3000], Loss: 0.0357\n",
      "Validation Loss: 960.4976\n",
      "Epoch [2121/3000], Loss: 0.0349\n",
      "Validation Loss: 962.6064\n",
      "Epoch [2141/3000], Loss: 0.0317\n",
      "Validation Loss: 957.0791\n",
      "Epoch [2161/3000], Loss: 0.0343\n",
      "Validation Loss: 957.2059\n",
      "Epoch [2181/3000], Loss: 0.0315\n",
      "Validation Loss: 958.1381\n",
      "Epoch [2201/3000], Loss: 0.0310\n",
      "Validation Loss: 950.9184\n",
      "Epoch [2221/3000], Loss: 0.0282\n",
      "Validation Loss: 953.1410\n",
      "Epoch [2241/3000], Loss: 0.0240\n",
      "Validation Loss: 948.8463\n",
      "Epoch [2261/3000], Loss: 0.0291\n",
      "Validation Loss: 945.6039\n",
      "Epoch [2281/3000], Loss: 0.0216\n",
      "Validation Loss: 947.2594\n",
      "Epoch [2301/3000], Loss: 0.0222\n",
      "Validation Loss: 944.6122\n",
      "Epoch [2321/3000], Loss: 0.0188\n",
      "Validation Loss: 947.6040\n",
      "Epoch [2341/3000], Loss: 0.0220\n",
      "Validation Loss: 938.2089\n",
      "Epoch [2361/3000], Loss: 0.0221\n",
      "Validation Loss: 946.0042\n",
      "Epoch [2381/3000], Loss: 0.0185\n",
      "Validation Loss: 943.8275\n",
      "Epoch [2401/3000], Loss: 0.0177\n",
      "Validation Loss: 941.2145\n",
      "Epoch [2421/3000], Loss: 0.0180\n",
      "Validation Loss: 937.6881\n",
      "Epoch [2441/3000], Loss: 0.0220\n",
      "Validation Loss: 936.4482\n",
      "Epoch [2461/3000], Loss: 0.0154\n",
      "Validation Loss: 938.2898\n",
      "Epoch [2481/3000], Loss: 0.0253\n",
      "Validation Loss: 942.2195\n",
      "Epoch [2501/3000], Loss: 0.0148\n",
      "Validation Loss: 939.5201\n",
      "Epoch [2521/3000], Loss: 0.0167\n",
      "Validation Loss: 938.7083\n",
      "Epoch [2541/3000], Loss: 0.0132\n",
      "Validation Loss: 937.1780\n",
      "Epoch [2561/3000], Loss: 0.0139\n",
      "Validation Loss: 937.9801\n",
      "Epoch [2581/3000], Loss: 0.0132\n",
      "Validation Loss: 938.1564\n",
      "Epoch [2601/3000], Loss: 0.0155\n",
      "Validation Loss: 937.1519\n",
      "Epoch [2621/3000], Loss: 0.0159\n",
      "Validation Loss: 933.4546\n",
      "Epoch [2641/3000], Loss: 0.0161\n",
      "Validation Loss: 934.2939\n",
      "Epoch [2661/3000], Loss: 0.0113\n",
      "Validation Loss: 932.3739\n",
      "Epoch [2681/3000], Loss: 0.0126\n",
      "Validation Loss: 930.8610\n",
      "Epoch [2701/3000], Loss: 0.0117\n",
      "Validation Loss: 933.2102\n",
      "Epoch [2721/3000], Loss: 0.0108\n",
      "Validation Loss: 935.1994\n",
      "Epoch [2741/3000], Loss: 0.0126\n",
      "Validation Loss: 929.5684\n",
      "Epoch [2761/3000], Loss: 0.0105\n",
      "Validation Loss: 933.0801\n",
      "Epoch [2781/3000], Loss: 0.0099\n",
      "Validation Loss: 930.3265\n",
      "Epoch [2801/3000], Loss: 0.0113\n",
      "Validation Loss: 928.1858\n",
      "Epoch [2821/3000], Loss: 0.0108\n",
      "Validation Loss: 934.4055\n",
      "Epoch [2841/3000], Loss: 0.0084\n",
      "Validation Loss: 928.7624\n",
      "Epoch [2861/3000], Loss: 0.0121\n",
      "Validation Loss: 925.9374\n",
      "Epoch [2881/3000], Loss: 0.0109\n",
      "Validation Loss: 926.0759\n",
      "Epoch [2901/3000], Loss: 0.0095\n",
      "Validation Loss: 930.7798\n",
      "Epoch [2921/3000], Loss: 0.0090\n",
      "Validation Loss: 925.4690\n",
      "Epoch [2941/3000], Loss: 0.0076\n",
      "Validation Loss: 927.6716\n",
      "Epoch [2961/3000], Loss: 0.0075\n",
      "Validation Loss: 925.9422\n",
      "Epoch [2981/3000], Loss: 0.0070\n",
      "Validation Loss: 925.6666\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day041_plane0_Fall.mat\n",
      "(10477, 1325)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 11719.3266\n",
      "Validation Loss: 11919.7169\n",
      "Epoch [21/3000], Loss: 10023.7958\n",
      "Validation Loss: 10236.9347\n",
      "Epoch [41/3000], Loss: 9681.0725\n",
      "Validation Loss: 9861.8232\n",
      "Epoch [61/3000], Loss: 9377.9963\n",
      "Validation Loss: 9545.8500\n",
      "Epoch [81/3000], Loss: 9084.4776\n",
      "Validation Loss: 9250.0241\n",
      "Epoch [101/3000], Loss: 8792.3210\n",
      "Validation Loss: 8967.0711\n",
      "Epoch [121/3000], Loss: 8544.3974\n",
      "Validation Loss: 8694.4146\n",
      "Epoch [141/3000], Loss: 8292.8879\n",
      "Validation Loss: 8427.2612\n",
      "Epoch [161/3000], Loss: 8035.8039\n",
      "Validation Loss: 8171.4027\n",
      "Epoch [181/3000], Loss: 7770.1582\n",
      "Validation Loss: 7924.3349\n",
      "Epoch [201/3000], Loss: 7548.7717\n",
      "Validation Loss: 7685.4037\n",
      "Epoch [221/3000], Loss: 7334.3682\n",
      "Validation Loss: 7454.6313\n",
      "Epoch [241/3000], Loss: 7128.1760\n",
      "Validation Loss: 7232.0217\n",
      "Epoch [261/3000], Loss: 6889.1975\n",
      "Validation Loss: 7017.6015\n",
      "Epoch [281/3000], Loss: 6700.2445\n",
      "Validation Loss: 6811.2063\n",
      "Epoch [301/3000], Loss: 6507.4637\n",
      "Validation Loss: 6613.0833\n",
      "Epoch [321/3000], Loss: 6321.7510\n",
      "Validation Loss: 6422.8424\n",
      "Epoch [341/3000], Loss: 6165.0939\n",
      "Validation Loss: 6240.4935\n",
      "Epoch [361/3000], Loss: 5993.5509\n",
      "Validation Loss: 6066.1461\n",
      "Epoch [381/3000], Loss: 5815.2362\n",
      "Validation Loss: 5899.8896\n",
      "Epoch [401/3000], Loss: 5673.4650\n",
      "Validation Loss: 5741.4412\n",
      "Epoch [421/3000], Loss: 5527.1382\n",
      "Validation Loss: 5590.9984\n",
      "Epoch [441/3000], Loss: 5379.3513\n",
      "Validation Loss: 5448.2756\n",
      "Epoch [461/3000], Loss: 5266.4123\n",
      "Validation Loss: 5313.6451\n",
      "Epoch [481/3000], Loss: 5134.1050\n",
      "Validation Loss: 5186.7794\n",
      "Epoch [501/3000], Loss: 5024.8901\n",
      "Validation Loss: 5067.7942\n",
      "Epoch [521/3000], Loss: 4917.6594\n",
      "Validation Loss: 4956.3797\n",
      "Epoch [541/3000], Loss: 3824.7579\n",
      "Validation Loss: 4234.4655\n",
      "Epoch [561/3000], Loss: 3625.8091\n",
      "Validation Loss: 4001.3073\n",
      "Epoch [581/3000], Loss: 3427.3456\n",
      "Validation Loss: 3820.7080\n",
      "Epoch [601/3000], Loss: 3286.1543\n",
      "Validation Loss: 3659.2215\n",
      "Epoch [621/3000], Loss: 3120.7353\n",
      "Validation Loss: 3508.6870\n",
      "Epoch [641/3000], Loss: 2974.4836\n",
      "Validation Loss: 3366.5070\n",
      "Epoch [661/3000], Loss: 2837.9375\n",
      "Validation Loss: 3237.2843\n",
      "Epoch [681/3000], Loss: 2691.5995\n",
      "Validation Loss: 3110.7610\n",
      "Epoch [701/3000], Loss: 2563.6542\n",
      "Validation Loss: 2985.6172\n",
      "Epoch [721/3000], Loss: 2444.4973\n",
      "Validation Loss: 2861.7393\n",
      "Epoch [741/3000], Loss: 2305.9583\n",
      "Validation Loss: 2720.8782\n",
      "Epoch [761/3000], Loss: 2193.6023\n",
      "Validation Loss: 2612.0252\n",
      "Epoch [781/3000], Loss: 2070.7166\n",
      "Validation Loss: 2504.6073\n",
      "Epoch [801/3000], Loss: 1959.4334\n",
      "Validation Loss: 2402.7113\n",
      "Epoch [821/3000], Loss: 1846.8166\n",
      "Validation Loss: 2309.6242\n",
      "Epoch [841/3000], Loss: 1741.9129\n",
      "Validation Loss: 2217.0549\n",
      "Epoch [861/3000], Loss: 1643.4934\n",
      "Validation Loss: 2126.5809\n",
      "Epoch [881/3000], Loss: 1548.5481\n",
      "Validation Loss: 2037.2853\n",
      "Epoch [901/3000], Loss: 1452.8179\n",
      "Validation Loss: 1950.2285\n",
      "Epoch [921/3000], Loss: 1355.0321\n",
      "Validation Loss: 1863.9276\n",
      "Epoch [941/3000], Loss: 1269.1906\n",
      "Validation Loss: 1790.9228\n",
      "Epoch [961/3000], Loss: 1193.7020\n",
      "Validation Loss: 1712.7130\n",
      "Epoch [981/3000], Loss: 1113.8334\n",
      "Validation Loss: 1639.2341\n",
      "Epoch [1001/3000], Loss: 1036.1050\n",
      "Validation Loss: 1568.0530\n",
      "Epoch [1021/3000], Loss: 963.6754\n",
      "Validation Loss: 1487.6437\n",
      "Epoch [1041/3000], Loss: 897.5240\n",
      "Validation Loss: 1439.9263\n",
      "Epoch [1061/3000], Loss: 831.7405\n",
      "Validation Loss: 1387.6115\n",
      "Epoch [1081/3000], Loss: 767.7928\n",
      "Validation Loss: 1340.2798\n",
      "Epoch [1101/3000], Loss: 707.3106\n",
      "Validation Loss: 1293.3001\n",
      "Epoch [1121/3000], Loss: 651.3667\n",
      "Validation Loss: 1243.0974\n",
      "Epoch [1141/3000], Loss: 596.0435\n",
      "Validation Loss: 1197.4925\n",
      "Epoch [1161/3000], Loss: 545.1636\n",
      "Validation Loss: 1152.7558\n",
      "Epoch [1181/3000], Loss: 496.0020\n",
      "Validation Loss: 1106.5881\n",
      "Epoch [1201/3000], Loss: 448.1408\n",
      "Validation Loss: 1079.5376\n",
      "Epoch [1221/3000], Loss: 407.8720\n",
      "Validation Loss: 1041.9338\n",
      "Epoch [1241/3000], Loss: 365.4655\n",
      "Validation Loss: 1003.0501\n",
      "Epoch [1261/3000], Loss: 328.4504\n",
      "Validation Loss: 963.9714\n",
      "Epoch [1281/3000], Loss: 292.3789\n",
      "Validation Loss: 938.7164\n",
      "Epoch [1301/3000], Loss: 260.6845\n",
      "Validation Loss: 917.0229\n",
      "Epoch [1321/3000], Loss: 230.2003\n",
      "Validation Loss: 896.4274\n",
      "Epoch [1341/3000], Loss: 200.8320\n",
      "Validation Loss: 876.6084\n",
      "Epoch [1361/3000], Loss: 174.1083\n",
      "Validation Loss: 860.5023\n",
      "Epoch [1381/3000], Loss: 150.9887\n",
      "Validation Loss: 836.3098\n",
      "Epoch [1401/3000], Loss: 128.6934\n",
      "Validation Loss: 821.6503\n",
      "Epoch [1421/3000], Loss: 108.1980\n",
      "Validation Loss: 806.2913\n",
      "Epoch [1441/3000], Loss: 90.9733\n",
      "Validation Loss: 788.3797\n",
      "Epoch [1461/3000], Loss: 75.0673\n",
      "Validation Loss: 773.6351\n",
      "Epoch [1481/3000], Loss: 61.7593\n",
      "Validation Loss: 761.3868\n",
      "Epoch [1501/3000], Loss: 50.1774\n",
      "Validation Loss: 753.0940\n",
      "Epoch [1521/3000], Loss: 40.2640\n",
      "Validation Loss: 743.3245\n",
      "Epoch [1541/3000], Loss: 32.1024\n",
      "Validation Loss: 735.1764\n",
      "Epoch [1561/3000], Loss: 25.1147\n",
      "Validation Loss: 730.6823\n",
      "Epoch [1581/3000], Loss: 19.3215\n",
      "Validation Loss: 717.2504\n",
      "Epoch [1601/3000], Loss: 15.2483\n",
      "Validation Loss: 718.0175\n",
      "Epoch [1621/3000], Loss: 11.6787\n",
      "Validation Loss: 721.6307\n",
      "Epoch [1641/3000], Loss: 8.8430\n",
      "Validation Loss: 736.9514\n",
      "Epoch [1661/3000], Loss: 6.4711\n",
      "Validation Loss: 739.2688\n",
      "Epoch [1681/3000], Loss: 4.7732\n",
      "Validation Loss: 738.5585\n",
      "Epoch [1701/3000], Loss: 3.3743\n",
      "Validation Loss: 736.7923\n",
      "Epoch [1721/3000], Loss: 2.3881\n",
      "Validation Loss: 741.1442\n",
      "Epoch [1741/3000], Loss: 1.6504\n",
      "Validation Loss: 741.4039\n",
      "Epoch [1761/3000], Loss: 1.1145\n",
      "Validation Loss: 745.9815\n",
      "Epoch [1781/3000], Loss: 0.7021\n",
      "Validation Loss: 753.2437\n",
      "Epoch [1801/3000], Loss: 0.4516\n",
      "Validation Loss: 749.9847\n",
      "Epoch [1821/3000], Loss: 0.2753\n",
      "Validation Loss: 748.7257\n",
      "Epoch [1841/3000], Loss: 0.1724\n",
      "Validation Loss: 745.3215\n",
      "Epoch [1861/3000], Loss: 0.1165\n",
      "Validation Loss: 735.7417\n",
      "Epoch [1881/3000], Loss: 0.0714\n",
      "Validation Loss: 746.9622\n",
      "Epoch [1901/3000], Loss: 0.0510\n",
      "Validation Loss: 746.7059\n",
      "Epoch [1921/3000], Loss: 0.0451\n",
      "Validation Loss: 743.3614\n",
      "Epoch [1941/3000], Loss: 0.0328\n",
      "Validation Loss: 743.8068\n",
      "Epoch [1961/3000], Loss: 0.0367\n",
      "Validation Loss: 742.4338\n",
      "Epoch [1981/3000], Loss: 0.0238\n",
      "Validation Loss: 736.0003\n",
      "Epoch [2001/3000], Loss: 0.0235\n",
      "Validation Loss: 735.2019\n",
      "Epoch [2021/3000], Loss: 0.0242\n",
      "Validation Loss: 733.9896\n",
      "Epoch [2041/3000], Loss: 0.0247\n",
      "Validation Loss: 730.3130\n",
      "Epoch [2061/3000], Loss: 0.0208\n",
      "Validation Loss: 729.7567\n",
      "Epoch [2081/3000], Loss: 0.0179\n",
      "Validation Loss: 729.6293\n",
      "Epoch [2101/3000], Loss: 0.0185\n",
      "Validation Loss: 726.6693\n",
      "Epoch [2121/3000], Loss: 0.0231\n",
      "Validation Loss: 733.6036\n",
      "Epoch [2141/3000], Loss: 0.0193\n",
      "Validation Loss: 728.3159\n",
      "Epoch [2161/3000], Loss: 0.0277\n",
      "Validation Loss: 728.7155\n",
      "Epoch [2181/3000], Loss: 0.0169\n",
      "Validation Loss: 726.0821\n",
      "Epoch [2201/3000], Loss: 0.0155\n",
      "Validation Loss: 727.7730\n",
      "Epoch [2221/3000], Loss: 0.0143\n",
      "Validation Loss: 725.9210\n",
      "Epoch [2241/3000], Loss: 0.0136\n",
      "Validation Loss: 725.5313\n",
      "Epoch [2261/3000], Loss: 0.0184\n",
      "Validation Loss: 719.7192\n",
      "Epoch [2281/3000], Loss: 0.0133\n",
      "Validation Loss: 722.2603\n",
      "Epoch [2301/3000], Loss: 0.0133\n",
      "Validation Loss: 723.6770\n",
      "Epoch [2321/3000], Loss: 0.0126\n",
      "Validation Loss: 722.1889\n",
      "Epoch [2341/3000], Loss: 0.0121\n",
      "Validation Loss: 723.9721\n",
      "Epoch [2361/3000], Loss: 0.0099\n",
      "Validation Loss: 724.0043\n",
      "Epoch [2381/3000], Loss: 0.0096\n",
      "Validation Loss: 721.2775\n",
      "Epoch [2401/3000], Loss: 0.0129\n",
      "Validation Loss: 721.5953\n",
      "Epoch [2421/3000], Loss: 0.0137\n",
      "Validation Loss: 724.0695\n",
      "Epoch [2441/3000], Loss: 0.0113\n",
      "Validation Loss: 721.5360\n",
      "Epoch [2461/3000], Loss: 0.0136\n",
      "Validation Loss: 721.9961\n",
      "Epoch [2481/3000], Loss: 0.0100\n",
      "Validation Loss: 719.6914\n",
      "Epoch [2501/3000], Loss: 0.0082\n",
      "Validation Loss: 721.5646\n",
      "Epoch [2521/3000], Loss: 0.0200\n",
      "Validation Loss: 720.9817\n",
      "Epoch [2541/3000], Loss: 0.0082\n",
      "Validation Loss: 720.6720\n",
      "Epoch [2561/3000], Loss: 0.0135\n",
      "Validation Loss: 721.5759\n",
      "Epoch [2581/3000], Loss: 0.0109\n",
      "Validation Loss: 721.3021\n",
      "Epoch [2601/3000], Loss: 0.0089\n",
      "Validation Loss: 720.5805\n",
      "Epoch [2621/3000], Loss: 0.0102\n",
      "Validation Loss: 721.0014\n",
      "Epoch [2641/3000], Loss: 0.0079\n",
      "Validation Loss: 716.5921\n",
      "Epoch [2661/3000], Loss: 0.0072\n",
      "Validation Loss: 720.2734\n",
      "Epoch [2681/3000], Loss: 0.0146\n",
      "Validation Loss: 716.9199\n",
      "Epoch [2701/3000], Loss: 0.0087\n",
      "Validation Loss: 721.1891\n",
      "Epoch [2721/3000], Loss: 0.0235\n",
      "Validation Loss: 720.4015\n",
      "Epoch [2741/3000], Loss: 0.0075\n",
      "Validation Loss: 717.5655\n",
      "Epoch [2761/3000], Loss: 0.0067\n",
      "Validation Loss: 719.8727\n",
      "Epoch [2781/3000], Loss: 0.0103\n",
      "Validation Loss: 720.9716\n",
      "Epoch [2801/3000], Loss: 0.0081\n",
      "Validation Loss: 718.4957\n",
      "Epoch [2821/3000], Loss: 0.0116\n",
      "Validation Loss: 720.6625\n",
      "Epoch [2841/3000], Loss: 0.0105\n",
      "Validation Loss: 716.9519\n",
      "Epoch [2861/3000], Loss: 0.0047\n",
      "Validation Loss: 715.3795\n",
      "Epoch [2881/3000], Loss: 0.0066\n",
      "Validation Loss: 718.4338\n",
      "Epoch [2901/3000], Loss: 0.0048\n",
      "Validation Loss: 716.0135\n",
      "Epoch [2921/3000], Loss: 0.0078\n",
      "Validation Loss: 715.1692\n",
      "Epoch [2941/3000], Loss: 0.0082\n",
      "Validation Loss: 712.5027\n",
      "Epoch [2961/3000], Loss: 0.0121\n",
      "Validation Loss: 717.2710\n",
      "Epoch [2981/3000], Loss: 0.0071\n",
      "Validation Loss: 715.9869\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day048_plane0_Fall.mat\n",
      "(9196, 1550)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8941.2554\n",
      "Validation Loss: 7984.1735\n",
      "Epoch [21/3000], Loss: 7520.9473\n",
      "Validation Loss: 6669.9069\n",
      "Epoch [41/3000], Loss: 7200.7393\n",
      "Validation Loss: 6401.9292\n",
      "Epoch [61/3000], Loss: 6993.2652\n",
      "Validation Loss: 6180.0651\n",
      "Epoch [81/3000], Loss: 6750.4426\n",
      "Validation Loss: 5979.8624\n",
      "Epoch [101/3000], Loss: 6563.3673\n",
      "Validation Loss: 5790.2352\n",
      "Epoch [121/3000], Loss: 6351.0480\n",
      "Validation Loss: 5609.3674\n",
      "Epoch [141/3000], Loss: 6160.2914\n",
      "Validation Loss: 5435.7779\n",
      "Epoch [161/3000], Loss: 5955.8839\n",
      "Validation Loss: 5268.8425\n",
      "Epoch [181/3000], Loss: 5804.5308\n",
      "Validation Loss: 5108.3000\n",
      "Epoch [201/3000], Loss: 5625.7301\n",
      "Validation Loss: 4953.9127\n",
      "Epoch [221/3000], Loss: 5464.5984\n",
      "Validation Loss: 4805.6272\n",
      "Epoch [241/3000], Loss: 5305.3370\n",
      "Validation Loss: 4663.3348\n",
      "Epoch [261/3000], Loss: 5133.8062\n",
      "Validation Loss: 4524.9013\n",
      "Epoch [281/3000], Loss: 4987.7624\n",
      "Validation Loss: 4383.2333\n",
      "Epoch [301/3000], Loss: 4563.4469\n",
      "Validation Loss: 3959.4059\n",
      "Epoch [321/3000], Loss: 4369.4780\n",
      "Validation Loss: 3798.8013\n",
      "Epoch [341/3000], Loss: 4203.2087\n",
      "Validation Loss: 3643.9217\n",
      "Epoch [361/3000], Loss: 4037.5704\n",
      "Validation Loss: 3495.5840\n",
      "Epoch [381/3000], Loss: 3891.3834\n",
      "Validation Loss: 3350.4710\n",
      "Epoch [401/3000], Loss: 3736.2828\n",
      "Validation Loss: 3211.6756\n",
      "Epoch [421/3000], Loss: 3579.6619\n",
      "Validation Loss: 3076.2521\n",
      "Epoch [441/3000], Loss: 3446.6123\n",
      "Validation Loss: 2944.2671\n",
      "Epoch [461/3000], Loss: 3297.8505\n",
      "Validation Loss: 2816.4994\n",
      "Epoch [481/3000], Loss: 3160.4053\n",
      "Validation Loss: 2692.2024\n",
      "Epoch [501/3000], Loss: 3028.3498\n",
      "Validation Loss: 2573.7915\n",
      "Epoch [521/3000], Loss: 2894.6886\n",
      "Validation Loss: 2458.9985\n",
      "Epoch [541/3000], Loss: 2762.8788\n",
      "Validation Loss: 2344.8294\n",
      "Epoch [561/3000], Loss: 2645.7700\n",
      "Validation Loss: 2238.8855\n",
      "Epoch [581/3000], Loss: 2530.4751\n",
      "Validation Loss: 2131.5231\n",
      "Epoch [601/3000], Loss: 2422.0736\n",
      "Validation Loss: 2029.0667\n",
      "Epoch [621/3000], Loss: 2301.3460\n",
      "Validation Loss: 1932.3033\n",
      "Epoch [641/3000], Loss: 2201.5440\n",
      "Validation Loss: 1837.9962\n",
      "Epoch [661/3000], Loss: 2096.2820\n",
      "Validation Loss: 1747.8443\n",
      "Epoch [681/3000], Loss: 1990.2529\n",
      "Validation Loss: 1659.8575\n",
      "Epoch [701/3000], Loss: 1895.9256\n",
      "Validation Loss: 1576.3984\n",
      "Epoch [721/3000], Loss: 1792.1884\n",
      "Validation Loss: 1496.7623\n",
      "Epoch [741/3000], Loss: 1710.7083\n",
      "Validation Loss: 1419.7043\n",
      "Epoch [761/3000], Loss: 1620.0440\n",
      "Validation Loss: 1343.2752\n",
      "Epoch [781/3000], Loss: 1536.0985\n",
      "Validation Loss: 1270.8784\n",
      "Epoch [801/3000], Loss: 1456.0632\n",
      "Validation Loss: 1202.2970\n",
      "Epoch [821/3000], Loss: 1376.0830\n",
      "Validation Loss: 1134.1387\n",
      "Epoch [841/3000], Loss: 1300.8991\n",
      "Validation Loss: 1070.5187\n",
      "Epoch [861/3000], Loss: 1227.5197\n",
      "Validation Loss: 1010.6920\n",
      "Epoch [881/3000], Loss: 1154.2377\n",
      "Validation Loss: 953.4706\n",
      "Epoch [901/3000], Loss: 1090.0219\n",
      "Validation Loss: 898.0545\n",
      "Epoch [921/3000], Loss: 1023.5984\n",
      "Validation Loss: 845.9809\n",
      "Epoch [941/3000], Loss: 963.3598\n",
      "Validation Loss: 796.7862\n",
      "Epoch [961/3000], Loss: 903.6458\n",
      "Validation Loss: 749.8508\n",
      "Epoch [981/3000], Loss: 889.5695\n",
      "Validation Loss: 703.1741\n",
      "Epoch [1001/3000], Loss: 789.9318\n",
      "Validation Loss: 666.2161\n",
      "Epoch [1021/3000], Loss: 740.9511\n",
      "Validation Loss: 626.6341\n",
      "Epoch [1041/3000], Loss: 689.4580\n",
      "Validation Loss: 588.5569\n",
      "Epoch [1061/3000], Loss: 642.2417\n",
      "Validation Loss: 551.8020\n",
      "Epoch [1081/3000], Loss: 600.1452\n",
      "Validation Loss: 517.1231\n",
      "Epoch [1101/3000], Loss: 561.8798\n",
      "Validation Loss: 485.4114\n",
      "Epoch [1121/3000], Loss: 515.2273\n",
      "Validation Loss: 456.3956\n",
      "Epoch [1141/3000], Loss: 481.5449\n",
      "Validation Loss: 429.4763\n",
      "Epoch [1161/3000], Loss: 445.0597\n",
      "Validation Loss: 404.8298\n",
      "Epoch [1181/3000], Loss: 410.1210\n",
      "Validation Loss: 381.6705\n",
      "Epoch [1201/3000], Loss: 378.9342\n",
      "Validation Loss: 361.1726\n",
      "Epoch [1221/3000], Loss: 350.6877\n",
      "Validation Loss: 342.4106\n",
      "Epoch [1241/3000], Loss: 321.4133\n",
      "Validation Loss: 321.9749\n",
      "Epoch [1261/3000], Loss: 295.5608\n",
      "Validation Loss: 307.0060\n",
      "Epoch [1281/3000], Loss: 271.2714\n",
      "Validation Loss: 293.3671\n",
      "Epoch [1301/3000], Loss: 246.7893\n",
      "Validation Loss: 280.6555\n",
      "Epoch [1321/3000], Loss: 228.3449\n",
      "Validation Loss: 268.3645\n",
      "Epoch [1341/3000], Loss: 208.2817\n",
      "Validation Loss: 260.1358\n",
      "Epoch [1361/3000], Loss: 189.2474\n",
      "Validation Loss: 249.8553\n",
      "Epoch [1381/3000], Loss: 174.5557\n",
      "Validation Loss: 247.0694\n",
      "Epoch [1401/3000], Loss: 163.2928\n",
      "Validation Loss: 240.7414\n",
      "Epoch [1421/3000], Loss: 148.2927\n",
      "Validation Loss: 236.0191\n",
      "Epoch [1441/3000], Loss: 134.5844\n",
      "Validation Loss: 237.0405\n",
      "Epoch [1461/3000], Loss: 122.1351\n",
      "Validation Loss: 233.3114\n",
      "Epoch [1481/3000], Loss: 110.8254\n",
      "Validation Loss: 225.7179\n",
      "Epoch [1501/3000], Loss: 97.8078\n",
      "Validation Loss: 218.8294\n",
      "Epoch [1521/3000], Loss: 88.5878\n",
      "Validation Loss: 212.5856\n",
      "Epoch [1541/3000], Loss: 80.3764\n",
      "Validation Loss: 206.2113\n",
      "Epoch [1561/3000], Loss: 70.8113\n",
      "Validation Loss: 201.3380\n",
      "Epoch [1581/3000], Loss: 63.3712\n",
      "Validation Loss: 198.0402\n",
      "Epoch [1601/3000], Loss: 55.6546\n",
      "Validation Loss: 194.9059\n",
      "Epoch [1621/3000], Loss: 49.3226\n",
      "Validation Loss: 192.6090\n",
      "Epoch [1641/3000], Loss: 43.3024\n",
      "Validation Loss: 189.1336\n",
      "Epoch [1661/3000], Loss: 37.9346\n",
      "Validation Loss: 186.6766\n",
      "Epoch [1681/3000], Loss: 33.1670\n",
      "Validation Loss: 186.9823\n",
      "Epoch [1701/3000], Loss: 28.7086\n",
      "Validation Loss: 183.2558\n",
      "Epoch [1721/3000], Loss: 24.8332\n",
      "Validation Loss: 181.6082\n",
      "Epoch [1741/3000], Loss: 21.3472\n",
      "Validation Loss: 181.7685\n",
      "Epoch [1761/3000], Loss: 17.9093\n",
      "Validation Loss: 181.1395\n",
      "Epoch [1781/3000], Loss: 15.3460\n",
      "Validation Loss: 182.6617\n",
      "Epoch [1801/3000], Loss: 12.8960\n",
      "Validation Loss: 182.2340\n",
      "Epoch [1821/3000], Loss: 10.5756\n",
      "Validation Loss: 183.6510\n",
      "Epoch [1841/3000], Loss: 8.6905\n",
      "Validation Loss: 180.8485\n",
      "Epoch [1861/3000], Loss: 7.0029\n",
      "Validation Loss: 178.7421\n",
      "Epoch [1881/3000], Loss: 5.6483\n",
      "Validation Loss: 180.5530\n",
      "Epoch [1901/3000], Loss: 4.3369\n",
      "Validation Loss: 183.4839\n",
      "Epoch [1921/3000], Loss: 3.4814\n",
      "Validation Loss: 179.5788\n",
      "Epoch [1941/3000], Loss: 2.6334\n",
      "Validation Loss: 178.3612\n",
      "Epoch [1961/3000], Loss: 1.9865\n",
      "Validation Loss: 182.4175\n",
      "Epoch [1981/3000], Loss: 1.4594\n",
      "Validation Loss: 170.0971\n",
      "Epoch [2001/3000], Loss: 1.0364\n",
      "Validation Loss: 183.4997\n",
      "Epoch [2021/3000], Loss: 0.7119\n",
      "Validation Loss: 181.7047\n",
      "Epoch [2041/3000], Loss: 0.4618\n",
      "Validation Loss: 180.7153\n",
      "Epoch [2061/3000], Loss: 0.2858\n",
      "Validation Loss: 182.9338\n",
      "Epoch [2081/3000], Loss: 0.1689\n",
      "Validation Loss: 180.1440\n",
      "Epoch [2101/3000], Loss: 0.0924\n",
      "Validation Loss: 181.3256\n",
      "Epoch [2121/3000], Loss: 0.0504\n",
      "Validation Loss: 181.2701\n",
      "Epoch [2141/3000], Loss: 0.0311\n",
      "Validation Loss: 181.3022\n",
      "Epoch [2161/3000], Loss: 0.0197\n",
      "Validation Loss: 181.5870\n",
      "Epoch [2181/3000], Loss: 0.0166\n",
      "Validation Loss: 179.2475\n",
      "Epoch [2201/3000], Loss: 0.0159\n",
      "Validation Loss: 180.3912\n",
      "Epoch [2221/3000], Loss: 0.0134\n",
      "Validation Loss: 176.0108\n",
      "Epoch [2241/3000], Loss: 0.0151\n",
      "Validation Loss: 177.0832\n",
      "Epoch [2261/3000], Loss: 0.0131\n",
      "Validation Loss: 176.7420\n",
      "Epoch [2281/3000], Loss: 0.0102\n",
      "Validation Loss: 174.8273\n",
      "Epoch [2301/3000], Loss: 0.0101\n",
      "Validation Loss: 172.3410\n",
      "Epoch [2321/3000], Loss: 0.0103\n",
      "Validation Loss: 163.7069\n",
      "Epoch [2341/3000], Loss: 0.0085\n",
      "Validation Loss: 163.4120\n",
      "Epoch [2361/3000], Loss: 0.0124\n",
      "Validation Loss: 163.6106\n",
      "Epoch [2381/3000], Loss: 0.0118\n",
      "Validation Loss: 162.6775\n",
      "Epoch [2401/3000], Loss: 0.0071\n",
      "Validation Loss: 163.0004\n",
      "Epoch [2421/3000], Loss: 0.0071\n",
      "Validation Loss: 162.9289\n",
      "Epoch [2441/3000], Loss: 0.0081\n",
      "Validation Loss: 162.7373\n",
      "Epoch [2461/3000], Loss: 0.0084\n",
      "Validation Loss: 163.3244\n",
      "Epoch [2481/3000], Loss: 0.0081\n",
      "Validation Loss: 162.6455\n",
      "Epoch [2501/3000], Loss: 0.0077\n",
      "Validation Loss: 163.1307\n",
      "Epoch [2521/3000], Loss: 0.0063\n",
      "Validation Loss: 163.4095\n",
      "Epoch [2541/3000], Loss: 0.0095\n",
      "Validation Loss: 162.8859\n",
      "Epoch [2561/3000], Loss: 0.0113\n",
      "Validation Loss: 163.6396\n",
      "Epoch [2581/3000], Loss: 0.0049\n",
      "Validation Loss: 163.6512\n",
      "Epoch [2601/3000], Loss: 0.0110\n",
      "Validation Loss: 163.3672\n",
      "Epoch [2621/3000], Loss: 0.0051\n",
      "Validation Loss: 163.4036\n",
      "Epoch [2641/3000], Loss: 0.0049\n",
      "Validation Loss: 163.9547\n",
      "Epoch [2661/3000], Loss: 0.0047\n",
      "Validation Loss: 163.8338\n",
      "Epoch [2681/3000], Loss: 0.0046\n",
      "Validation Loss: 163.5268\n",
      "Epoch [2701/3000], Loss: 0.0058\n",
      "Validation Loss: 163.1714\n",
      "Epoch [2721/3000], Loss: 0.0045\n",
      "Validation Loss: 163.5244\n",
      "Epoch [2741/3000], Loss: 0.0075\n",
      "Validation Loss: 163.5858\n",
      "Epoch [2761/3000], Loss: 0.0046\n",
      "Validation Loss: 163.9476\n",
      "Epoch [2781/3000], Loss: 0.0066\n",
      "Validation Loss: 163.8466\n",
      "Epoch [2801/3000], Loss: 0.0043\n",
      "Validation Loss: 163.6218\n",
      "Epoch [2821/3000], Loss: 0.0039\n",
      "Validation Loss: 163.5120\n",
      "Epoch [2841/3000], Loss: 0.0055\n",
      "Validation Loss: 163.1384\n",
      "Epoch [2861/3000], Loss: 0.0048\n",
      "Validation Loss: 163.5007\n",
      "Epoch [2881/3000], Loss: 0.0027\n",
      "Validation Loss: 162.9719\n",
      "Epoch [2901/3000], Loss: 0.0043\n",
      "Validation Loss: 162.3674\n",
      "Epoch [2921/3000], Loss: 0.0080\n",
      "Validation Loss: 162.9337\n",
      "Epoch [2941/3000], Loss: 0.0064\n",
      "Validation Loss: 163.8535\n",
      "Epoch [2961/3000], Loss: 0.0040\n",
      "Validation Loss: 162.8723\n",
      "Epoch [2981/3000], Loss: 0.0036\n",
      "Validation Loss: 163.1513\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day050_plane0_Fall.mat\n",
      "(9082, 1480)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8764.7010\n",
      "Validation Loss: 6559.7019\n",
      "Epoch [21/3000], Loss: 7397.8343\n",
      "Validation Loss: 5432.8479\n",
      "Epoch [41/3000], Loss: 7077.6328\n",
      "Validation Loss: 5198.2882\n",
      "Epoch [61/3000], Loss: 6860.5217\n",
      "Validation Loss: 5003.4684\n",
      "Epoch [81/3000], Loss: 6641.7872\n",
      "Validation Loss: 4825.3211\n",
      "Epoch [101/3000], Loss: 6417.4755\n",
      "Validation Loss: 4657.1308\n",
      "Epoch [121/3000], Loss: 6208.1526\n",
      "Validation Loss: 4496.6549\n",
      "Epoch [141/3000], Loss: 6027.2252\n",
      "Validation Loss: 4343.1236\n",
      "Epoch [161/3000], Loss: 5829.4576\n",
      "Validation Loss: 4196.2136\n",
      "Epoch [181/3000], Loss: 5637.0674\n",
      "Validation Loss: 4053.1116\n",
      "Epoch [201/3000], Loss: 5461.3858\n",
      "Validation Loss: 3917.5735\n",
      "Epoch [221/3000], Loss: 5295.2299\n",
      "Validation Loss: 3788.6410\n",
      "Epoch [241/3000], Loss: 5135.1393\n",
      "Validation Loss: 3665.8038\n",
      "Epoch [261/3000], Loss: 4976.8397\n",
      "Validation Loss: 3547.8300\n",
      "Epoch [281/3000], Loss: 4815.8310\n",
      "Validation Loss: 3436.3078\n",
      "Epoch [301/3000], Loss: 4670.9576\n",
      "Validation Loss: 3331.0978\n",
      "Epoch [321/3000], Loss: 4527.7238\n",
      "Validation Loss: 3231.8643\n",
      "Epoch [341/3000], Loss: 4381.8809\n",
      "Validation Loss: 3129.5316\n",
      "Epoch [361/3000], Loss: 3948.6125\n",
      "Validation Loss: 2808.8756\n",
      "Epoch [381/3000], Loss: 3776.2947\n",
      "Validation Loss: 2705.5255\n",
      "Epoch [401/3000], Loss: 3625.5355\n",
      "Validation Loss: 2564.0816\n",
      "Epoch [421/3000], Loss: 3461.0714\n",
      "Validation Loss: 2519.7093\n",
      "Epoch [441/3000], Loss: 3318.6638\n",
      "Validation Loss: 2411.9514\n",
      "Epoch [461/3000], Loss: 3178.2526\n",
      "Validation Loss: 2307.0648\n",
      "Epoch [481/3000], Loss: 3031.1445\n",
      "Validation Loss: 2218.4416\n",
      "Epoch [501/3000], Loss: 2911.1658\n",
      "Validation Loss: 2127.7487\n",
      "Epoch [521/3000], Loss: 2784.0920\n",
      "Validation Loss: 2038.2650\n",
      "Epoch [541/3000], Loss: 2656.2212\n",
      "Validation Loss: 1954.0374\n",
      "Epoch [561/3000], Loss: 2533.1413\n",
      "Validation Loss: 1865.0214\n",
      "Epoch [581/3000], Loss: 2423.7743\n",
      "Validation Loss: 1788.9580\n",
      "Epoch [601/3000], Loss: 2315.5974\n",
      "Validation Loss: 1714.1015\n",
      "Epoch [621/3000], Loss: 2202.0320\n",
      "Validation Loss: 1644.1014\n",
      "Epoch [641/3000], Loss: 2098.6086\n",
      "Validation Loss: 1577.3817\n",
      "Epoch [661/3000], Loss: 2003.5567\n",
      "Validation Loss: 1508.8215\n",
      "Epoch [681/3000], Loss: 1898.6569\n",
      "Validation Loss: 1472.7597\n",
      "Epoch [701/3000], Loss: 1797.2786\n",
      "Validation Loss: 1412.5615\n",
      "Epoch [721/3000], Loss: 1718.2498\n",
      "Validation Loss: 1353.7773\n",
      "Epoch [741/3000], Loss: 1624.7154\n",
      "Validation Loss: 1299.2017\n",
      "Epoch [761/3000], Loss: 1544.2075\n",
      "Validation Loss: 1248.6187\n",
      "Epoch [781/3000], Loss: 1461.8679\n",
      "Validation Loss: 1197.8256\n",
      "Epoch [801/3000], Loss: 1385.5825\n",
      "Validation Loss: 1152.2142\n",
      "Epoch [821/3000], Loss: 1313.1513\n",
      "Validation Loss: 1109.3668\n",
      "Epoch [841/3000], Loss: 1239.4516\n",
      "Validation Loss: 1065.1335\n",
      "Epoch [861/3000], Loss: 1169.0394\n",
      "Validation Loss: 1024.8802\n",
      "Epoch [881/3000], Loss: 1106.0975\n",
      "Validation Loss: 989.1010\n",
      "Epoch [901/3000], Loss: 1041.0992\n",
      "Validation Loss: 949.7575\n",
      "Epoch [921/3000], Loss: 980.8952\n",
      "Validation Loss: 913.1275\n",
      "Epoch [941/3000], Loss: 924.9588\n",
      "Validation Loss: 877.8631\n",
      "Epoch [961/3000], Loss: 870.6468\n",
      "Validation Loss: 849.1654\n",
      "Epoch [981/3000], Loss: 818.8885\n",
      "Validation Loss: 822.5034\n",
      "Epoch [1001/3000], Loss: 767.9785\n",
      "Validation Loss: 790.8383\n",
      "Epoch [1021/3000], Loss: 720.1187\n",
      "Validation Loss: 782.7120\n",
      "Epoch [1041/3000], Loss: 675.3556\n",
      "Validation Loss: 762.1243\n",
      "Epoch [1061/3000], Loss: 634.4785\n",
      "Validation Loss: 739.3719\n",
      "Epoch [1081/3000], Loss: 590.2579\n",
      "Validation Loss: 715.0744\n",
      "Epoch [1101/3000], Loss: 551.6656\n",
      "Validation Loss: 697.2806\n",
      "Epoch [1121/3000], Loss: 516.4336\n",
      "Validation Loss: 676.4318\n",
      "Epoch [1141/3000], Loss: 481.7687\n",
      "Validation Loss: 657.9688\n",
      "Epoch [1161/3000], Loss: 445.0907\n",
      "Validation Loss: 640.0594\n",
      "Epoch [1181/3000], Loss: 415.3240\n",
      "Validation Loss: 623.0729\n",
      "Epoch [1201/3000], Loss: 384.2587\n",
      "Validation Loss: 610.3725\n",
      "Epoch [1221/3000], Loss: 359.3556\n",
      "Validation Loss: 593.8873\n",
      "Epoch [1241/3000], Loss: 334.9045\n",
      "Validation Loss: 578.9288\n",
      "Epoch [1261/3000], Loss: 311.3702\n",
      "Validation Loss: 566.5175\n",
      "Epoch [1281/3000], Loss: 289.4346\n",
      "Validation Loss: 559.6007\n",
      "Epoch [1301/3000], Loss: 269.1290\n",
      "Validation Loss: 549.1295\n",
      "Epoch [1321/3000], Loss: 249.9392\n",
      "Validation Loss: 537.4681\n",
      "Epoch [1341/3000], Loss: 228.9507\n",
      "Validation Loss: 524.5409\n",
      "Epoch [1361/3000], Loss: 212.4330\n",
      "Validation Loss: 514.9508\n",
      "Epoch [1381/3000], Loss: 206.1932\n",
      "Validation Loss: 519.9386\n",
      "Epoch [1401/3000], Loss: 179.6369\n",
      "Validation Loss: 515.8954\n",
      "Epoch [1421/3000], Loss: 164.7951\n",
      "Validation Loss: 501.7806\n",
      "Epoch [1441/3000], Loss: 150.1407\n",
      "Validation Loss: 490.6575\n",
      "Epoch [1461/3000], Loss: 136.4529\n",
      "Validation Loss: 481.6396\n",
      "Epoch [1481/3000], Loss: 124.3363\n",
      "Validation Loss: 473.3877\n",
      "Epoch [1501/3000], Loss: 112.5013\n",
      "Validation Loss: 464.0611\n",
      "Epoch [1521/3000], Loss: 101.8693\n",
      "Validation Loss: 456.0042\n",
      "Epoch [1541/3000], Loss: 91.5763\n",
      "Validation Loss: 450.2150\n",
      "Epoch [1561/3000], Loss: 82.2702\n",
      "Validation Loss: 446.1583\n",
      "Epoch [1581/3000], Loss: 73.0008\n",
      "Validation Loss: 440.1836\n",
      "Epoch [1601/3000], Loss: 64.8110\n",
      "Validation Loss: 438.4923\n",
      "Epoch [1621/3000], Loss: 57.7991\n",
      "Validation Loss: 437.8096\n",
      "Epoch [1641/3000], Loss: 50.9524\n",
      "Validation Loss: 435.7674\n",
      "Epoch [1661/3000], Loss: 44.2424\n",
      "Validation Loss: 432.9063\n",
      "Epoch [1681/3000], Loss: 39.0202\n",
      "Validation Loss: 436.2453\n",
      "Epoch [1701/3000], Loss: 33.6355\n",
      "Validation Loss: 430.9794\n",
      "Epoch [1721/3000], Loss: 29.0991\n",
      "Validation Loss: 431.9217\n",
      "Epoch [1741/3000], Loss: 24.6673\n",
      "Validation Loss: 426.3157\n",
      "Epoch [1761/3000], Loss: 20.7259\n",
      "Validation Loss: 432.3473\n",
      "Epoch [1781/3000], Loss: 17.5020\n",
      "Validation Loss: 426.4501\n",
      "Epoch [1801/3000], Loss: 14.4691\n",
      "Validation Loss: 428.9823\n",
      "Epoch [1821/3000], Loss: 12.0103\n",
      "Validation Loss: 424.3536\n",
      "Epoch [1841/3000], Loss: 9.7293\n",
      "Validation Loss: 418.0724\n",
      "Epoch [1861/3000], Loss: 7.8845\n",
      "Validation Loss: 414.2419\n",
      "Epoch [1881/3000], Loss: 6.2431\n",
      "Validation Loss: 417.6099\n",
      "Epoch [1901/3000], Loss: 4.9487\n",
      "Validation Loss: 409.1007\n",
      "Epoch [1921/3000], Loss: 3.7850\n",
      "Validation Loss: 392.4340\n",
      "Epoch [1941/3000], Loss: 2.8958\n",
      "Validation Loss: 393.2132\n",
      "Epoch [1961/3000], Loss: 2.1545\n",
      "Validation Loss: 402.4574\n",
      "Epoch [1981/3000], Loss: 1.5827\n",
      "Validation Loss: 398.6140\n",
      "Epoch [2001/3000], Loss: 1.0994\n",
      "Validation Loss: 388.5880\n",
      "Epoch [2021/3000], Loss: 0.7711\n",
      "Validation Loss: 385.3346\n",
      "Epoch [2041/3000], Loss: 0.5189\n",
      "Validation Loss: 382.0242\n",
      "Epoch [2061/3000], Loss: 0.3363\n",
      "Validation Loss: 374.8192\n",
      "Epoch [2081/3000], Loss: 0.2088\n",
      "Validation Loss: 378.6178\n",
      "Epoch [2101/3000], Loss: 0.1210\n",
      "Validation Loss: 379.7901\n",
      "Epoch [2121/3000], Loss: 0.0711\n",
      "Validation Loss: 375.0866\n",
      "Epoch [2141/3000], Loss: 0.0534\n",
      "Validation Loss: 377.6051\n",
      "Epoch [2161/3000], Loss: 0.0257\n",
      "Validation Loss: 371.8436\n",
      "Epoch [2181/3000], Loss: 0.0176\n",
      "Validation Loss: 374.8568\n",
      "Epoch [2201/3000], Loss: 0.0151\n",
      "Validation Loss: 373.8468\n",
      "Epoch [2221/3000], Loss: 0.0119\n",
      "Validation Loss: 376.3400\n",
      "Epoch [2241/3000], Loss: 0.0123\n",
      "Validation Loss: 380.5314\n",
      "Epoch [2261/3000], Loss: 0.0129\n",
      "Validation Loss: 384.7279\n",
      "Epoch [2281/3000], Loss: 0.0130\n",
      "Validation Loss: 378.8552\n",
      "Epoch [2301/3000], Loss: 0.0110\n",
      "Validation Loss: 383.6878\n",
      "Epoch [2321/3000], Loss: 0.0066\n",
      "Validation Loss: 384.1858\n",
      "Epoch [2341/3000], Loss: 0.0084\n",
      "Validation Loss: 382.7442\n",
      "Epoch [2361/3000], Loss: 0.0085\n",
      "Validation Loss: 383.4346\n",
      "Epoch [2381/3000], Loss: 0.0081\n",
      "Validation Loss: 382.9674\n",
      "Epoch [2401/3000], Loss: 0.0087\n",
      "Validation Loss: 382.5062\n",
      "Epoch [2421/3000], Loss: 0.0074\n",
      "Validation Loss: 385.1194\n",
      "Epoch [2441/3000], Loss: 0.0085\n",
      "Validation Loss: 381.1371\n",
      "Epoch [2461/3000], Loss: 0.0092\n",
      "Validation Loss: 387.1300\n",
      "Epoch [2481/3000], Loss: 0.0077\n",
      "Validation Loss: 388.5180\n",
      "Epoch [2501/3000], Loss: 0.0083\n",
      "Validation Loss: 392.0770\n",
      "Epoch [2521/3000], Loss: 0.0097\n",
      "Validation Loss: 389.3903\n",
      "Epoch [2541/3000], Loss: 0.0055\n",
      "Validation Loss: 386.0771\n",
      "Epoch [2561/3000], Loss: 0.0056\n",
      "Validation Loss: 391.7692\n",
      "Epoch [2581/3000], Loss: 0.0075\n",
      "Validation Loss: 392.6710\n",
      "Epoch [2601/3000], Loss: 0.0055\n",
      "Validation Loss: 390.5987\n",
      "Epoch [2621/3000], Loss: 0.0045\n",
      "Validation Loss: 391.9750\n",
      "Epoch [2641/3000], Loss: 0.0054\n",
      "Validation Loss: 393.3260\n",
      "Epoch [2661/3000], Loss: 0.0048\n",
      "Validation Loss: 393.1786\n",
      "Epoch [2681/3000], Loss: 0.0047\n",
      "Validation Loss: 394.2160\n",
      "Epoch [2701/3000], Loss: 0.0083\n",
      "Validation Loss: 392.9325\n",
      "Epoch [2721/3000], Loss: 0.0078\n",
      "Validation Loss: 396.5707\n",
      "Epoch [2741/3000], Loss: 0.0038\n",
      "Validation Loss: 393.2855\n",
      "Epoch [2761/3000], Loss: 0.0041\n",
      "Validation Loss: 393.4039\n",
      "Epoch [2781/3000], Loss: 0.0051\n",
      "Validation Loss: 394.4590\n",
      "Epoch [2801/3000], Loss: 0.0036\n",
      "Validation Loss: 395.0680\n",
      "Epoch [2821/3000], Loss: 0.0028\n",
      "Validation Loss: 393.7894\n",
      "Epoch [2841/3000], Loss: 0.0044\n",
      "Validation Loss: 395.6881\n",
      "Epoch [2861/3000], Loss: 0.0073\n",
      "Validation Loss: 390.4730\n",
      "Epoch [2881/3000], Loss: 0.0037\n",
      "Validation Loss: 391.0923\n",
      "Epoch [2901/3000], Loss: 0.0024\n",
      "Validation Loss: 391.8638\n",
      "Epoch [2921/3000], Loss: 0.0089\n",
      "Validation Loss: 393.9210\n",
      "Epoch [2941/3000], Loss: 0.0031\n",
      "Validation Loss: 391.7357\n",
      "Epoch [2961/3000], Loss: 0.0040\n",
      "Validation Loss: 391.6414\n",
      "Epoch [2981/3000], Loss: 0.0055\n",
      "Validation Loss: 390.0941\n",
      "Y:\\analysis\\fmats\\e216\\days\\e216_day054_plane0_Fall.mat\n",
      "(8508, 1400)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 11638.7957\n",
      "Validation Loss: 9104.1149\n",
      "Epoch [21/3000], Loss: 10077.1496\n",
      "Validation Loss: 7817.4442\n",
      "Epoch [41/3000], Loss: 9726.9374\n",
      "Validation Loss: 7537.4375\n",
      "Epoch [61/3000], Loss: 9450.6677\n",
      "Validation Loss: 7314.1091\n",
      "Epoch [81/3000], Loss: 9203.2656\n",
      "Validation Loss: 7107.7243\n",
      "Epoch [101/3000], Loss: 8944.5238\n",
      "Validation Loss: 6912.2530\n",
      "Epoch [121/3000], Loss: 8699.0930\n",
      "Validation Loss: 6724.6837\n",
      "Epoch [141/3000], Loss: 8478.7799\n",
      "Validation Loss: 6543.8889\n",
      "Epoch [161/3000], Loss: 8263.4785\n",
      "Validation Loss: 6369.3402\n",
      "Epoch [181/3000], Loss: 8050.1789\n",
      "Validation Loss: 6200.5516\n",
      "Epoch [201/3000], Loss: 7840.4520\n",
      "Validation Loss: 6033.5797\n",
      "Epoch [221/3000], Loss: 7620.8046\n",
      "Validation Loss: 5874.8827\n",
      "Epoch [241/3000], Loss: 7425.7628\n",
      "Validation Loss: 5722.4305\n",
      "Epoch [261/3000], Loss: 7233.7399\n",
      "Validation Loss: 5575.4946\n",
      "Epoch [281/3000], Loss: 7044.4038\n",
      "Validation Loss: 5434.1594\n",
      "Epoch [301/3000], Loss: 6854.8202\n",
      "Validation Loss: 5298.2819\n",
      "Epoch [321/3000], Loss: 6680.5040\n",
      "Validation Loss: 5167.8506\n",
      "Epoch [341/3000], Loss: 6510.8598\n",
      "Validation Loss: 5042.8230\n",
      "Epoch [361/3000], Loss: 6343.2288\n",
      "Validation Loss: 4923.2077\n",
      "Epoch [381/3000], Loss: 6174.0359\n",
      "Validation Loss: 4808.9651\n",
      "Epoch [401/3000], Loss: 5676.7100\n",
      "Validation Loss: 4498.1310\n",
      "Epoch [421/3000], Loss: 5467.8503\n",
      "Validation Loss: 4363.3988\n",
      "Epoch [441/3000], Loss: 5284.1258\n",
      "Validation Loss: 4237.4590\n",
      "Epoch [461/3000], Loss: 5095.7618\n",
      "Validation Loss: 4116.4320\n",
      "Epoch [481/3000], Loss: 4932.9734\n",
      "Validation Loss: 3998.2922\n",
      "Epoch [501/3000], Loss: 4764.5855\n",
      "Validation Loss: 3881.5986\n",
      "Epoch [521/3000], Loss: 4590.4422\n",
      "Validation Loss: 3768.9891\n",
      "Epoch [541/3000], Loss: 4421.6283\n",
      "Validation Loss: 3657.6155\n",
      "Epoch [561/3000], Loss: 4261.1603\n",
      "Validation Loss: 3554.1889\n",
      "Epoch [581/3000], Loss: 4121.0027\n",
      "Validation Loss: 3449.9609\n",
      "Epoch [601/3000], Loss: 3963.5106\n",
      "Validation Loss: 3353.2281\n",
      "Epoch [621/3000], Loss: 3821.7756\n",
      "Validation Loss: 3254.8910\n",
      "Epoch [641/3000], Loss: 3669.2056\n",
      "Validation Loss: 3164.1620\n",
      "Epoch [661/3000], Loss: 3534.0285\n",
      "Validation Loss: 3071.7405\n",
      "Epoch [681/3000], Loss: 3396.3537\n",
      "Validation Loss: 2990.3651\n",
      "Epoch [701/3000], Loss: 3259.2224\n",
      "Validation Loss: 2908.0164\n",
      "Epoch [721/3000], Loss: 3133.7028\n",
      "Validation Loss: 2823.1420\n",
      "Epoch [741/3000], Loss: 3003.1433\n",
      "Validation Loss: 2745.0743\n",
      "Epoch [761/3000], Loss: 2882.9585\n",
      "Validation Loss: 2671.5757\n",
      "Epoch [781/3000], Loss: 2759.9690\n",
      "Validation Loss: 2599.5217\n",
      "Epoch [801/3000], Loss: 2643.9120\n",
      "Validation Loss: 2526.1169\n",
      "Epoch [821/3000], Loss: 2526.2220\n",
      "Validation Loss: 2461.4286\n",
      "Epoch [841/3000], Loss: 2416.9198\n",
      "Validation Loss: 2395.8921\n",
      "Epoch [861/3000], Loss: 2308.2293\n",
      "Validation Loss: 2334.7395\n",
      "Epoch [881/3000], Loss: 2205.4338\n",
      "Validation Loss: 2276.3519\n",
      "Epoch [901/3000], Loss: 2104.2696\n",
      "Validation Loss: 2216.9557\n",
      "Epoch [921/3000], Loss: 2006.8648\n",
      "Validation Loss: 2164.3927\n",
      "Epoch [941/3000], Loss: 1910.8483\n",
      "Validation Loss: 2114.8938\n",
      "Epoch [961/3000], Loss: 1816.2421\n",
      "Validation Loss: 2057.7729\n",
      "Epoch [981/3000], Loss: 1725.2191\n",
      "Validation Loss: 2008.6914\n",
      "Epoch [1001/3000], Loss: 1637.7723\n",
      "Validation Loss: 1946.8995\n",
      "Epoch [1021/3000], Loss: 1556.2599\n",
      "Validation Loss: 1905.0743\n",
      "Epoch [1041/3000], Loss: 1471.2262\n",
      "Validation Loss: 1860.1761\n",
      "Epoch [1061/3000], Loss: 1392.9472\n",
      "Validation Loss: 1832.8398\n",
      "Epoch [1081/3000], Loss: 1318.8753\n",
      "Validation Loss: 1798.2454\n",
      "Epoch [1101/3000], Loss: 1247.3464\n",
      "Validation Loss: 1759.0238\n",
      "Epoch [1121/3000], Loss: 1175.8252\n",
      "Validation Loss: 1714.1466\n",
      "Epoch [1141/3000], Loss: 1107.7832\n",
      "Validation Loss: 1688.8197\n",
      "Epoch [1161/3000], Loss: 1040.5508\n",
      "Validation Loss: 1654.3918\n",
      "Epoch [1181/3000], Loss: 981.8539\n",
      "Validation Loss: 1628.0268\n",
      "Epoch [1201/3000], Loss: 917.2843\n",
      "Validation Loss: 1601.1581\n",
      "Epoch [1221/3000], Loss: 860.6710\n",
      "Validation Loss: 1562.2532\n",
      "Epoch [1241/3000], Loss: 804.4609\n",
      "Validation Loss: 1531.4110\n",
      "Epoch [1261/3000], Loss: 754.6059\n",
      "Validation Loss: 1510.0785\n",
      "Epoch [1281/3000], Loss: 700.7091\n",
      "Validation Loss: 1493.5840\n",
      "Epoch [1301/3000], Loss: 653.3458\n",
      "Validation Loss: 1477.3722\n",
      "Epoch [1321/3000], Loss: 605.7546\n",
      "Validation Loss: 1453.0788\n",
      "Epoch [1341/3000], Loss: 562.4815\n",
      "Validation Loss: 1430.8055\n",
      "Epoch [1361/3000], Loss: 519.6987\n",
      "Validation Loss: 1410.8941\n",
      "Epoch [1381/3000], Loss: 480.0257\n",
      "Validation Loss: 1414.2939\n",
      "Epoch [1401/3000], Loss: 441.9676\n",
      "Validation Loss: 1406.1290\n",
      "Epoch [1421/3000], Loss: 405.2761\n",
      "Validation Loss: 1401.7152\n",
      "Epoch [1441/3000], Loss: 371.0795\n",
      "Validation Loss: 1394.4416\n",
      "Epoch [1461/3000], Loss: 337.4440\n",
      "Validation Loss: 1399.7432\n",
      "Epoch [1481/3000], Loss: 307.1247\n",
      "Validation Loss: 1393.4140\n",
      "Epoch [1501/3000], Loss: 278.3719\n",
      "Validation Loss: 1388.6044\n",
      "Epoch [1521/3000], Loss: 251.2472\n",
      "Validation Loss: 1396.8172\n",
      "Epoch [1541/3000], Loss: 226.3025\n",
      "Validation Loss: 1394.9485\n",
      "Epoch [1561/3000], Loss: 202.8737\n",
      "Validation Loss: 1389.4131\n",
      "Epoch [1581/3000], Loss: 180.4850\n",
      "Validation Loss: 1394.1261\n",
      "Epoch [1601/3000], Loss: 159.8673\n",
      "Validation Loss: 1397.1858\n",
      "Epoch [1621/3000], Loss: 140.9337\n",
      "Validation Loss: 1402.1728\n",
      "Epoch [1641/3000], Loss: 123.4023\n",
      "Validation Loss: 1406.0136\n",
      "Epoch [1661/3000], Loss: 107.3022\n",
      "Validation Loss: 1415.3055\n",
      "Epoch [1681/3000], Loss: 92.6086\n",
      "Validation Loss: 1417.3610\n",
      "Epoch [1701/3000], Loss: 79.2488\n",
      "Validation Loss: 1442.3507\n",
      "Epoch [1721/3000], Loss: 67.4516\n",
      "Validation Loss: 1452.3271\n",
      "Epoch [1741/3000], Loss: 56.7983\n",
      "Validation Loss: 1447.4736\n",
      "Epoch [1761/3000], Loss: 47.3861\n",
      "Validation Loss: 1458.2338\n",
      "Epoch [1781/3000], Loss: 39.0668\n",
      "Validation Loss: 1465.3296\n",
      "Epoch [1801/3000], Loss: 32.0047\n",
      "Validation Loss: 1469.4485\n",
      "Epoch [1821/3000], Loss: 26.3815\n",
      "Validation Loss: 1475.6024\n",
      "Epoch [1841/3000], Loss: 21.5556\n",
      "Validation Loss: 1484.1982\n",
      "Epoch [1861/3000], Loss: 17.8866\n",
      "Validation Loss: 1492.9425\n",
      "Epoch [1881/3000], Loss: 15.1764\n",
      "Validation Loss: 1501.7271\n",
      "Epoch [1901/3000], Loss: 13.2791\n",
      "Validation Loss: 1516.7410\n",
      "Epoch [1921/3000], Loss: 11.2893\n",
      "Validation Loss: 1543.1078\n",
      "Epoch [1941/3000], Loss: 9.5688\n",
      "Validation Loss: 1527.4110\n",
      "Epoch [1961/3000], Loss: 7.9838\n",
      "Validation Loss: 1533.6133\n",
      "Epoch [1981/3000], Loss: 6.6063\n",
      "Validation Loss: 1538.0173\n",
      "Epoch [2001/3000], Loss: 5.4726\n",
      "Validation Loss: 1544.3798\n",
      "Epoch [2021/3000], Loss: 4.4812\n",
      "Validation Loss: 1544.6442\n",
      "Epoch [2041/3000], Loss: 3.5594\n",
      "Validation Loss: 1548.7961\n",
      "Epoch [2061/3000], Loss: 2.8106\n",
      "Validation Loss: 1561.9881\n",
      "Epoch [2081/3000], Loss: 2.1509\n",
      "Validation Loss: 1571.2675\n",
      "Epoch [2101/3000], Loss: 1.6156\n",
      "Validation Loss: 1581.0846\n",
      "Epoch [2121/3000], Loss: 1.1840\n",
      "Validation Loss: 1586.9846\n",
      "Epoch [2141/3000], Loss: 0.8515\n",
      "Validation Loss: 1602.4318\n",
      "Epoch [2161/3000], Loss: 0.6008\n",
      "Validation Loss: 1609.7989\n",
      "Epoch [2181/3000], Loss: 0.4082\n",
      "Validation Loss: 1609.3456\n",
      "Epoch [2201/3000], Loss: 0.2665\n",
      "Validation Loss: 1613.7666\n",
      "Epoch [2221/3000], Loss: 0.1665\n",
      "Validation Loss: 1609.4801\n",
      "Epoch [2241/3000], Loss: 0.1024\n",
      "Validation Loss: 1611.6553\n",
      "Epoch [2261/3000], Loss: 0.0596\n",
      "Validation Loss: 1614.7217\n",
      "Epoch [2281/3000], Loss: 0.0369\n",
      "Validation Loss: 1617.8555\n",
      "Epoch [2301/3000], Loss: 0.0239\n",
      "Validation Loss: 1625.2589\n",
      "Epoch [2321/3000], Loss: 0.0160\n",
      "Validation Loss: 1616.0207\n",
      "Epoch [2341/3000], Loss: 0.0114\n",
      "Validation Loss: 1614.6095\n",
      "Epoch [2361/3000], Loss: 0.0114\n",
      "Validation Loss: 1621.5474\n",
      "Epoch [2381/3000], Loss: 0.0158\n",
      "Validation Loss: 1619.2187\n",
      "Epoch [2401/3000], Loss: 0.0098\n",
      "Validation Loss: 1627.1313\n",
      "Epoch [2421/3000], Loss: 0.0094\n",
      "Validation Loss: 1626.0757\n",
      "Epoch [2441/3000], Loss: 0.0126\n",
      "Validation Loss: 1629.6352\n",
      "Epoch [2461/3000], Loss: 0.0096\n",
      "Validation Loss: 1626.5728\n",
      "Epoch [2481/3000], Loss: 0.0079\n",
      "Validation Loss: 1627.2224\n",
      "Epoch [2501/3000], Loss: 0.0139\n",
      "Validation Loss: 1627.0997\n",
      "Epoch [2521/3000], Loss: 0.0062\n",
      "Validation Loss: 1621.7503\n",
      "Epoch [2541/3000], Loss: 0.0099\n",
      "Validation Loss: 1619.4554\n",
      "Epoch [2561/3000], Loss: 0.0096\n",
      "Validation Loss: 1627.3790\n",
      "Epoch [2581/3000], Loss: 0.0090\n",
      "Validation Loss: 1623.1383\n",
      "Epoch [2601/3000], Loss: 0.0123\n",
      "Validation Loss: 1617.5500\n",
      "Epoch [2621/3000], Loss: 0.0088\n",
      "Validation Loss: 1620.6785\n",
      "Epoch [2641/3000], Loss: 0.0058\n",
      "Validation Loss: 1617.3651\n",
      "Epoch [2661/3000], Loss: 0.0077\n",
      "Validation Loss: 1620.8505\n",
      "Epoch [2681/3000], Loss: 0.0119\n",
      "Validation Loss: 1626.9231\n",
      "Epoch [2701/3000], Loss: 0.0089\n",
      "Validation Loss: 1632.9172\n",
      "Epoch [2721/3000], Loss: 0.0070\n",
      "Validation Loss: 1626.1837\n",
      "Epoch [2741/3000], Loss: 0.0121\n",
      "Validation Loss: 1637.8718\n",
      "Epoch [2761/3000], Loss: 0.0062\n",
      "Validation Loss: 1623.2280\n",
      "Epoch [2781/3000], Loss: 0.0066\n",
      "Validation Loss: 1625.5604\n",
      "Epoch [2801/3000], Loss: 0.0139\n",
      "Validation Loss: 1633.6911\n",
      "Epoch [2821/3000], Loss: 0.0083\n",
      "Validation Loss: 1635.3811\n",
      "Epoch [2841/3000], Loss: 0.0078\n",
      "Validation Loss: 1636.0539\n",
      "Epoch [2861/3000], Loss: 0.0058\n",
      "Validation Loss: 1630.2598\n",
      "Epoch [2881/3000], Loss: 0.0065\n",
      "Validation Loss: 1631.5603\n",
      "Epoch [2901/3000], Loss: 0.0051\n",
      "Validation Loss: 1630.3909\n",
      "Epoch [2921/3000], Loss: 0.0052\n",
      "Validation Loss: 1635.1202\n",
      "Epoch [2941/3000], Loss: 0.0095\n",
      "Validation Loss: 1619.7509\n",
      "Epoch [2961/3000], Loss: 0.0047\n",
      "Validation Loss: 1637.3200\n",
      "Epoch [2981/3000], Loss: 0.0032\n",
      "Validation Loss: 1633.5420\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day002_plane0_Fall.mat\n",
      "(20213, 143)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9873.7432\n",
      "Validation Loss: 8803.7212\n",
      "Epoch [21/3000], Loss: 7947.3825\n",
      "Validation Loss: 7054.7771\n",
      "Epoch [41/3000], Loss: 7393.8690\n",
      "Validation Loss: 6560.9352\n",
      "Epoch [61/3000], Loss: 6891.8796\n",
      "Validation Loss: 6111.4267\n",
      "Epoch [81/3000], Loss: 6416.6431\n",
      "Validation Loss: 5697.0151\n",
      "Epoch [101/3000], Loss: 5978.1361\n",
      "Validation Loss: 5313.8591\n",
      "Epoch [121/3000], Loss: 5571.7082\n",
      "Validation Loss: 4960.7561\n",
      "Epoch [141/3000], Loss: 5192.6011\n",
      "Validation Loss: 4635.5039\n",
      "Epoch [161/3000], Loss: 4832.0239\n",
      "Validation Loss: 4339.2401\n",
      "Epoch [181/3000], Loss: 4517.8640\n",
      "Validation Loss: 4073.7049\n",
      "Epoch [201/3000], Loss: 4227.4655\n",
      "Validation Loss: 3837.3221\n",
      "Epoch [221/3000], Loss: 3966.7379\n",
      "Validation Loss: 3629.9339\n",
      "Epoch [241/3000], Loss: 3737.2568\n",
      "Validation Loss: 3451.0842\n",
      "Epoch [261/3000], Loss: 3527.1487\n",
      "Validation Loss: 3300.5569\n",
      "Epoch [281/3000], Loss: 3352.4012\n",
      "Validation Loss: 3176.9319\n",
      "Epoch [301/3000], Loss: 3200.8290\n",
      "Validation Loss: 3080.2735\n",
      "Epoch [321/3000], Loss: 3078.8589\n",
      "Validation Loss: 3010.7227\n",
      "Epoch [341/3000], Loss: 2988.7751\n",
      "Validation Loss: 2966.3173\n",
      "Epoch [361/3000], Loss: 2228.3229\n",
      "Validation Loss: 2279.4990\n",
      "Epoch [381/3000], Loss: 1929.8431\n",
      "Validation Loss: 2062.4115\n",
      "Epoch [401/3000], Loss: 1712.5428\n",
      "Validation Loss: 1947.3344\n",
      "Epoch [421/3000], Loss: 1520.0502\n",
      "Validation Loss: 1862.5614\n",
      "Epoch [441/3000], Loss: 1346.6334\n",
      "Validation Loss: 1778.6406\n",
      "Epoch [461/3000], Loss: 1190.9572\n",
      "Validation Loss: 1717.0580\n",
      "Epoch [481/3000], Loss: 1055.7670\n",
      "Validation Loss: 1639.8622\n",
      "Epoch [501/3000], Loss: 935.0902\n",
      "Validation Loss: 1580.5349\n",
      "Epoch [521/3000], Loss: 817.7893\n",
      "Validation Loss: 1511.6196\n",
      "Epoch [541/3000], Loss: 721.2581\n",
      "Validation Loss: 1519.4502\n",
      "Epoch [561/3000], Loss: 628.1665\n",
      "Validation Loss: 1470.2619\n",
      "Epoch [581/3000], Loss: 552.0770\n",
      "Validation Loss: 1483.7505\n",
      "Epoch [601/3000], Loss: 471.1670\n",
      "Validation Loss: 1409.7780\n",
      "Epoch [621/3000], Loss: 409.2868\n",
      "Validation Loss: 1407.9380\n",
      "Epoch [641/3000], Loss: 356.1107\n",
      "Validation Loss: 1401.1997\n",
      "Epoch [661/3000], Loss: 296.9526\n",
      "Validation Loss: 1336.4447\n",
      "Epoch [681/3000], Loss: 256.3751\n",
      "Validation Loss: 1397.0382\n",
      "Epoch [701/3000], Loss: 219.6087\n",
      "Validation Loss: 1372.4998\n",
      "Epoch [721/3000], Loss: 192.2369\n",
      "Validation Loss: 1562.3053\n",
      "Epoch [741/3000], Loss: 161.1147\n",
      "Validation Loss: 1445.8342\n",
      "Epoch [761/3000], Loss: 127.1218\n",
      "Validation Loss: 1523.9286\n",
      "Epoch [781/3000], Loss: 104.5074\n",
      "Validation Loss: 1392.6100\n",
      "Epoch [801/3000], Loss: 89.4063\n",
      "Validation Loss: 1473.9351\n",
      "Epoch [821/3000], Loss: 77.7456\n",
      "Validation Loss: 1441.3229\n",
      "Epoch [841/3000], Loss: 68.3558\n",
      "Validation Loss: 1429.1617\n",
      "Epoch [861/3000], Loss: 59.7909\n",
      "Validation Loss: 1445.4079\n",
      "Epoch [881/3000], Loss: 52.3987\n",
      "Validation Loss: 1472.4836\n",
      "Epoch [901/3000], Loss: 46.8845\n",
      "Validation Loss: 1498.6663\n",
      "Epoch [921/3000], Loss: 40.3807\n",
      "Validation Loss: 1452.8610\n",
      "Epoch [941/3000], Loss: 35.7825\n",
      "Validation Loss: 1426.6354\n",
      "Epoch [961/3000], Loss: 32.6958\n",
      "Validation Loss: 1421.5860\n",
      "Epoch [981/3000], Loss: 30.8083\n",
      "Validation Loss: 1458.4554\n",
      "Epoch [1001/3000], Loss: 27.1556\n",
      "Validation Loss: 1486.6389\n",
      "Epoch [1021/3000], Loss: 25.3092\n",
      "Validation Loss: 1458.1160\n",
      "Epoch [1041/3000], Loss: 23.1954\n",
      "Validation Loss: 1447.5235\n",
      "Epoch [1061/3000], Loss: 54.6473\n",
      "Validation Loss: 1283.3521\n",
      "Epoch [1081/3000], Loss: 19.5262\n",
      "Validation Loss: 1430.5327\n",
      "Epoch [1101/3000], Loss: 19.1217\n",
      "Validation Loss: 1428.3384\n",
      "Epoch [1121/3000], Loss: 16.3080\n",
      "Validation Loss: 1455.3645\n",
      "Epoch [1141/3000], Loss: 15.0689\n",
      "Validation Loss: 1442.6014\n",
      "Epoch [1161/3000], Loss: 13.9886\n",
      "Validation Loss: 1440.1928\n",
      "Epoch [1181/3000], Loss: 13.2291\n",
      "Validation Loss: 1463.3903\n",
      "Epoch [1201/3000], Loss: 12.5956\n",
      "Validation Loss: 1399.3390\n",
      "Epoch [1221/3000], Loss: 11.1118\n",
      "Validation Loss: 1449.4767\n",
      "Epoch [1241/3000], Loss: 10.2570\n",
      "Validation Loss: 1405.3344\n",
      "Epoch [1261/3000], Loss: 9.3520\n",
      "Validation Loss: 1409.9077\n",
      "Epoch [1281/3000], Loss: 8.6802\n",
      "Validation Loss: 1414.4744\n",
      "Epoch [1301/3000], Loss: 8.6927\n",
      "Validation Loss: 1415.8465\n",
      "Epoch [1321/3000], Loss: 7.1913\n",
      "Validation Loss: 1404.9885\n",
      "Epoch [1341/3000], Loss: 6.8118\n",
      "Validation Loss: 1416.4432\n",
      "Epoch [1361/3000], Loss: 6.3660\n",
      "Validation Loss: 1352.3833\n",
      "Epoch [1381/3000], Loss: 5.8080\n",
      "Validation Loss: 1391.3529\n",
      "Epoch [1401/3000], Loss: 5.5547\n",
      "Validation Loss: 1389.4378\n",
      "Epoch [1421/3000], Loss: 5.0613\n",
      "Validation Loss: 1387.7597\n",
      "Epoch [1441/3000], Loss: 4.7550\n",
      "Validation Loss: 1354.2979\n",
      "Epoch [1461/3000], Loss: 4.3330\n",
      "Validation Loss: 1379.3606\n",
      "Epoch [1481/3000], Loss: 4.3319\n",
      "Validation Loss: 1377.1542\n",
      "Epoch [1501/3000], Loss: 3.8983\n",
      "Validation Loss: 1358.0157\n",
      "Epoch [1521/3000], Loss: 3.7537\n",
      "Validation Loss: 1376.5809\n",
      "Epoch [1541/3000], Loss: 3.5154\n",
      "Validation Loss: 1389.0790\n",
      "Epoch [1561/3000], Loss: 3.3710\n",
      "Validation Loss: 1358.8482\n",
      "Epoch [1581/3000], Loss: 3.2059\n",
      "Validation Loss: 1360.5717\n",
      "Epoch [1601/3000], Loss: 3.0273\n",
      "Validation Loss: 1389.5430\n",
      "Epoch [1621/3000], Loss: 2.8797\n",
      "Validation Loss: 1359.9958\n",
      "Epoch [1641/3000], Loss: 2.7295\n",
      "Validation Loss: 1373.7715\n",
      "Epoch [1661/3000], Loss: 2.8649\n",
      "Validation Loss: 1358.8047\n",
      "Epoch [1681/3000], Loss: 2.4794\n",
      "Validation Loss: 1363.3437\n",
      "Epoch [1701/3000], Loss: 2.3404\n",
      "Validation Loss: 1373.8477\n",
      "Epoch [1721/3000], Loss: 2.2959\n",
      "Validation Loss: 1397.0961\n",
      "Epoch [1741/3000], Loss: 2.2722\n",
      "Validation Loss: 1338.3141\n",
      "Epoch [1761/3000], Loss: 2.1211\n",
      "Validation Loss: 1346.8425\n",
      "Epoch [1781/3000], Loss: 2.0771\n",
      "Validation Loss: 1357.1441\n",
      "Epoch [1801/3000], Loss: 1.9106\n",
      "Validation Loss: 1361.0813\n",
      "Epoch [1821/3000], Loss: 1.7829\n",
      "Validation Loss: 1323.5057\n",
      "Epoch [1841/3000], Loss: 1.7145\n",
      "Validation Loss: 1337.5013\n",
      "Epoch [1861/3000], Loss: 1.6920\n",
      "Validation Loss: 1338.4118\n",
      "Epoch [1881/3000], Loss: 1.6345\n",
      "Validation Loss: 1320.6140\n",
      "Epoch [1901/3000], Loss: 1.5153\n",
      "Validation Loss: 1323.9279\n",
      "Epoch [1921/3000], Loss: 1.5232\n",
      "Validation Loss: 1336.8663\n",
      "Epoch [1941/3000], Loss: 1.5118\n",
      "Validation Loss: 1357.5807\n",
      "Epoch [1961/3000], Loss: 2.3686\n",
      "Validation Loss: 1351.4168\n",
      "Epoch [1981/3000], Loss: 1.2123\n",
      "Validation Loss: 1334.8011\n",
      "Epoch [2001/3000], Loss: 1.1955\n",
      "Validation Loss: 1340.6326\n",
      "Epoch [2021/3000], Loss: 1.1985\n",
      "Validation Loss: 1323.3328\n",
      "Epoch [2041/3000], Loss: 1.2036\n",
      "Validation Loss: 1320.0871\n",
      "Epoch [2061/3000], Loss: 1.0395\n",
      "Validation Loss: 1313.4743\n",
      "Epoch [2081/3000], Loss: 1.0102\n",
      "Validation Loss: 1322.5706\n",
      "Epoch [2101/3000], Loss: 1.0237\n",
      "Validation Loss: 1334.8637\n",
      "Epoch [2121/3000], Loss: 1.1378\n",
      "Validation Loss: 1345.7202\n",
      "Epoch [2141/3000], Loss: 0.9289\n",
      "Validation Loss: 1346.9839\n",
      "Epoch [2161/3000], Loss: 0.8979\n",
      "Validation Loss: 1340.0785\n",
      "Epoch [2181/3000], Loss: 0.9067\n",
      "Validation Loss: 1349.0880\n",
      "Epoch [2201/3000], Loss: 0.9271\n",
      "Validation Loss: 1347.1468\n",
      "Epoch [2221/3000], Loss: 0.8956\n",
      "Validation Loss: 1329.4442\n",
      "Epoch [2241/3000], Loss: 0.7559\n",
      "Validation Loss: 1331.6710\n",
      "Epoch [2261/3000], Loss: 0.7397\n",
      "Validation Loss: 1326.6742\n",
      "Epoch [2281/3000], Loss: 0.7679\n",
      "Validation Loss: 1332.3599\n",
      "Epoch [2301/3000], Loss: 0.8007\n",
      "Validation Loss: 1343.7518\n",
      "Epoch [2321/3000], Loss: 0.7277\n",
      "Validation Loss: 1299.8367\n",
      "Epoch [2341/3000], Loss: 0.6574\n",
      "Validation Loss: 1308.4907\n",
      "Epoch [2361/3000], Loss: 0.6535\n",
      "Validation Loss: 1315.6257\n",
      "Epoch [2381/3000], Loss: 0.6669\n",
      "Validation Loss: 1337.4122\n",
      "Epoch [2401/3000], Loss: 0.6618\n",
      "Validation Loss: 1326.6180\n",
      "Epoch [2421/3000], Loss: 0.6052\n",
      "Validation Loss: 1311.9458\n",
      "Epoch [2441/3000], Loss: 0.5525\n",
      "Validation Loss: 1318.4049\n",
      "Epoch [2461/3000], Loss: 0.6080\n",
      "Validation Loss: 1339.1070\n",
      "Epoch [2481/3000], Loss: 0.5755\n",
      "Validation Loss: 1346.0005\n",
      "Epoch [2501/3000], Loss: 0.6666\n",
      "Validation Loss: 1322.5752\n",
      "Epoch [2521/3000], Loss: 0.6428\n",
      "Validation Loss: 1328.4648\n",
      "Epoch [2541/3000], Loss: 0.5200\n",
      "Validation Loss: 1333.0592\n",
      "Epoch [2561/3000], Loss: 0.4963\n",
      "Validation Loss: 1333.3515\n",
      "Epoch [2581/3000], Loss: 0.5160\n",
      "Validation Loss: 1339.7260\n",
      "Epoch [2601/3000], Loss: 0.5519\n",
      "Validation Loss: 1349.8626\n",
      "Epoch [2621/3000], Loss: 0.6050\n",
      "Validation Loss: 1297.6086\n",
      "Epoch [2641/3000], Loss: 0.4540\n",
      "Validation Loss: 1311.7530\n",
      "Epoch [2661/3000], Loss: 0.4357\n",
      "Validation Loss: 1310.9786\n",
      "Epoch [2681/3000], Loss: 0.4575\n",
      "Validation Loss: 1318.3097\n",
      "Epoch [2701/3000], Loss: 0.4808\n",
      "Validation Loss: 1316.3612\n",
      "Epoch [2721/3000], Loss: 0.4821\n",
      "Validation Loss: 1310.2327\n",
      "Epoch [2741/3000], Loss: 0.4068\n",
      "Validation Loss: 1314.9805\n",
      "Epoch [2761/3000], Loss: 0.3931\n",
      "Validation Loss: 1309.9009\n",
      "Epoch [2781/3000], Loss: 0.4178\n",
      "Validation Loss: 1320.6082\n",
      "Epoch [2801/3000], Loss: 0.4599\n",
      "Validation Loss: 1334.6550\n",
      "Epoch [2821/3000], Loss: 0.4260\n",
      "Validation Loss: 1321.5359\n",
      "Epoch [2841/3000], Loss: 0.4337\n",
      "Validation Loss: 1299.3547\n",
      "Epoch [2861/3000], Loss: 0.3489\n",
      "Validation Loss: 1300.2196\n",
      "Epoch [2881/3000], Loss: 0.3378\n",
      "Validation Loss: 1306.0658\n",
      "Epoch [2901/3000], Loss: 0.3508\n",
      "Validation Loss: 1315.8458\n",
      "Epoch [2921/3000], Loss: 0.4400\n",
      "Validation Loss: 1306.4943\n",
      "Epoch [2941/3000], Loss: 0.3647\n",
      "Validation Loss: 1315.0144\n",
      "Epoch [2961/3000], Loss: 0.4211\n",
      "Validation Loss: 1306.5371\n",
      "Epoch [2981/3000], Loss: 0.3213\n",
      "Validation Loss: 1312.7139\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day003_plane0_Fall.mat\n",
      "(12957, 168)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9870.9675\n",
      "Validation Loss: 9494.0308\n",
      "Epoch [21/3000], Loss: 8159.6343\n",
      "Validation Loss: 7826.3259\n",
      "Epoch [41/3000], Loss: 7729.2857\n",
      "Validation Loss: 7408.1312\n",
      "Epoch [61/3000], Loss: 7359.9667\n",
      "Validation Loss: 7046.6137\n",
      "Epoch [81/3000], Loss: 7009.3280\n",
      "Validation Loss: 6706.9840\n",
      "Epoch [101/3000], Loss: 6674.0136\n",
      "Validation Loss: 6384.6764\n",
      "Epoch [121/3000], Loss: 6342.3663\n",
      "Validation Loss: 6076.6432\n",
      "Epoch [141/3000], Loss: 6050.1804\n",
      "Validation Loss: 5781.7685\n",
      "Epoch [161/3000], Loss: 5754.8316\n",
      "Validation Loss: 5499.8156\n",
      "Epoch [181/3000], Loss: 5479.0362\n",
      "Validation Loss: 5230.4188\n",
      "Epoch [201/3000], Loss: 5216.6132\n",
      "Validation Loss: 4973.5852\n",
      "Epoch [221/3000], Loss: 4951.7071\n",
      "Validation Loss: 4729.2615\n",
      "Epoch [241/3000], Loss: 4715.2264\n",
      "Validation Loss: 4495.0924\n",
      "Epoch [261/3000], Loss: 4480.2928\n",
      "Validation Loss: 4274.6890\n",
      "Epoch [281/3000], Loss: 4268.6875\n",
      "Validation Loss: 4066.9939\n",
      "Epoch [301/3000], Loss: 4059.2867\n",
      "Validation Loss: 3871.7603\n",
      "Epoch [321/3000], Loss: 3862.4674\n",
      "Validation Loss: 3688.8795\n",
      "Epoch [341/3000], Loss: 3685.5733\n",
      "Validation Loss: 3518.4097\n",
      "Epoch [361/3000], Loss: 3520.3105\n",
      "Validation Loss: 3360.0781\n",
      "Epoch [381/3000], Loss: 3360.4584\n",
      "Validation Loss: 3213.8923\n",
      "Epoch [401/3000], Loss: 3215.8359\n",
      "Validation Loss: 3079.8822\n",
      "Epoch [421/3000], Loss: 3089.2078\n",
      "Validation Loss: 2957.8290\n",
      "Epoch [441/3000], Loss: 2970.5882\n",
      "Validation Loss: 2847.6279\n",
      "Epoch [461/3000], Loss: 2859.4728\n",
      "Validation Loss: 2749.2551\n",
      "Epoch [481/3000], Loss: 2764.0749\n",
      "Validation Loss: 2662.4243\n",
      "Epoch [501/3000], Loss: 2680.4321\n",
      "Validation Loss: 2587.1152\n",
      "Epoch [521/3000], Loss: 2606.9180\n",
      "Validation Loss: 2522.9723\n",
      "Epoch [541/3000], Loss: 2544.7525\n",
      "Validation Loss: 2469.6502\n",
      "Epoch [561/3000], Loss: 2494.6398\n",
      "Validation Loss: 2426.7927\n",
      "Epoch [581/3000], Loss: 2164.3193\n",
      "Validation Loss: 2047.7508\n",
      "Epoch [601/3000], Loss: 1350.1897\n",
      "Validation Loss: 1352.4073\n",
      "Epoch [621/3000], Loss: 1209.8278\n",
      "Validation Loss: 1224.5064\n",
      "Epoch [641/3000], Loss: 1100.9061\n",
      "Validation Loss: 1110.7871\n",
      "Epoch [661/3000], Loss: 998.7809\n",
      "Validation Loss: 1027.6035\n",
      "Epoch [681/3000], Loss: 914.8501\n",
      "Validation Loss: 947.7805\n",
      "Epoch [701/3000], Loss: 832.9838\n",
      "Validation Loss: 881.6513\n",
      "Epoch [721/3000], Loss: 755.8330\n",
      "Validation Loss: 836.9339\n",
      "Epoch [741/3000], Loss: 682.3851\n",
      "Validation Loss: 787.8146\n",
      "Epoch [761/3000], Loss: 612.8182\n",
      "Validation Loss: 729.3436\n",
      "Epoch [781/3000], Loss: 554.4801\n",
      "Validation Loss: 700.9271\n",
      "Epoch [801/3000], Loss: 496.7843\n",
      "Validation Loss: 649.6051\n",
      "Epoch [821/3000], Loss: 444.4732\n",
      "Validation Loss: 614.4143\n",
      "Epoch [841/3000], Loss: 396.7937\n",
      "Validation Loss: 580.9882\n",
      "Epoch [861/3000], Loss: 353.1985\n",
      "Validation Loss: 546.9528\n",
      "Epoch [881/3000], Loss: 312.9379\n",
      "Validation Loss: 527.9645\n",
      "Epoch [901/3000], Loss: 278.9388\n",
      "Validation Loss: 459.5974\n",
      "Epoch [921/3000], Loss: 247.2626\n",
      "Validation Loss: 463.1983\n",
      "Epoch [941/3000], Loss: 218.3800\n",
      "Validation Loss: 470.8913\n",
      "Epoch [961/3000], Loss: 190.7878\n",
      "Validation Loss: 458.9244\n",
      "Epoch [981/3000], Loss: 189.1887\n",
      "Validation Loss: 381.6103\n",
      "Epoch [1001/3000], Loss: 145.1702\n",
      "Validation Loss: 422.2175\n",
      "Epoch [1021/3000], Loss: 126.9749\n",
      "Validation Loss: 421.9515\n",
      "Epoch [1041/3000], Loss: 111.1544\n",
      "Validation Loss: 410.4049\n",
      "Epoch [1061/3000], Loss: 98.9333\n",
      "Validation Loss: 410.8773\n",
      "Epoch [1081/3000], Loss: 86.0747\n",
      "Validation Loss: 429.7150\n",
      "Epoch [1101/3000], Loss: 75.4160\n",
      "Validation Loss: 388.1263\n",
      "Epoch [1121/3000], Loss: 65.5217\n",
      "Validation Loss: 397.3985\n",
      "Epoch [1141/3000], Loss: 55.6414\n",
      "Validation Loss: 402.3190\n",
      "Epoch [1161/3000], Loss: 46.8129\n",
      "Validation Loss: 409.5848\n",
      "Epoch [1181/3000], Loss: 39.3732\n",
      "Validation Loss: 376.4852\n",
      "Epoch [1201/3000], Loss: 31.9417\n",
      "Validation Loss: 415.6777\n",
      "Epoch [1221/3000], Loss: 26.1126\n",
      "Validation Loss: 425.1200\n",
      "Epoch [1241/3000], Loss: 21.2502\n",
      "Validation Loss: 347.0479\n",
      "Epoch [1261/3000], Loss: 17.3562\n",
      "Validation Loss: 362.3230\n",
      "Epoch [1281/3000], Loss: 13.8192\n",
      "Validation Loss: 364.5275\n",
      "Epoch [1301/3000], Loss: 10.8897\n",
      "Validation Loss: 364.1425\n",
      "Epoch [1321/3000], Loss: 8.5260\n",
      "Validation Loss: 374.5040\n",
      "Epoch [1341/3000], Loss: 6.5804\n",
      "Validation Loss: 372.8606\n",
      "Epoch [1361/3000], Loss: 5.0538\n",
      "Validation Loss: 393.3016\n",
      "Epoch [1381/3000], Loss: 3.8091\n",
      "Validation Loss: 394.8015\n",
      "Epoch [1401/3000], Loss: 2.8087\n",
      "Validation Loss: 406.9443\n",
      "Epoch [1421/3000], Loss: 2.1960\n",
      "Validation Loss: 373.8582\n",
      "Epoch [1441/3000], Loss: 1.5199\n",
      "Validation Loss: 381.8344\n",
      "Epoch [1461/3000], Loss: 1.1480\n",
      "Validation Loss: 362.8569\n",
      "Epoch [1481/3000], Loss: 0.8670\n",
      "Validation Loss: 357.5647\n",
      "Epoch [1501/3000], Loss: 0.7183\n",
      "Validation Loss: 367.1529\n",
      "Epoch [1521/3000], Loss: 0.5736\n",
      "Validation Loss: 372.9600\n",
      "Epoch [1541/3000], Loss: 0.5066\n",
      "Validation Loss: 376.2373\n",
      "Epoch [1561/3000], Loss: 0.4634\n",
      "Validation Loss: 365.5432\n",
      "Epoch [1581/3000], Loss: 28.5934\n",
      "Validation Loss: 318.0153\n",
      "Epoch [1601/3000], Loss: 0.4097\n",
      "Validation Loss: 333.3310\n",
      "Epoch [1621/3000], Loss: 0.3529\n",
      "Validation Loss: 339.2180\n",
      "Epoch [1641/3000], Loss: 0.3314\n",
      "Validation Loss: 341.1796\n",
      "Epoch [1661/3000], Loss: 0.3180\n",
      "Validation Loss: 347.2841\n",
      "Epoch [1681/3000], Loss: 0.3074\n",
      "Validation Loss: 349.3643\n",
      "Epoch [1701/3000], Loss: 0.2880\n",
      "Validation Loss: 349.4723\n",
      "Epoch [1721/3000], Loss: 0.2730\n",
      "Validation Loss: 351.8860\n",
      "Epoch [1741/3000], Loss: 0.2578\n",
      "Validation Loss: 347.0657\n",
      "Epoch [1761/3000], Loss: 0.2455\n",
      "Validation Loss: 353.1278\n",
      "Epoch [1781/3000], Loss: 0.2232\n",
      "Validation Loss: 345.0531\n",
      "Epoch [1801/3000], Loss: 0.2041\n",
      "Validation Loss: 352.0740\n",
      "Epoch [1821/3000], Loss: 0.2463\n",
      "Validation Loss: 348.2685\n",
      "Epoch [1841/3000], Loss: 0.7438\n",
      "Validation Loss: 300.2676\n",
      "Epoch [1861/3000], Loss: 0.2124\n",
      "Validation Loss: 311.5014\n",
      "Epoch [1881/3000], Loss: 0.1726\n",
      "Validation Loss: 317.5777\n",
      "Epoch [1901/3000], Loss: 0.1596\n",
      "Validation Loss: 321.4970\n",
      "Epoch [1921/3000], Loss: 0.1585\n",
      "Validation Loss: 324.9687\n",
      "Epoch [1941/3000], Loss: 0.1623\n",
      "Validation Loss: 329.3345\n",
      "Epoch [1961/3000], Loss: 0.1565\n",
      "Validation Loss: 330.5787\n",
      "Epoch [1981/3000], Loss: 0.1567\n",
      "Validation Loss: 327.2178\n",
      "Epoch [2001/3000], Loss: 0.1480\n",
      "Validation Loss: 335.3049\n",
      "Epoch [2021/3000], Loss: 0.1411\n",
      "Validation Loss: 332.1203\n",
      "Epoch [2041/3000], Loss: 0.1386\n",
      "Validation Loss: 331.7583\n",
      "Epoch [2061/3000], Loss: 0.1368\n",
      "Validation Loss: 330.0527\n",
      "Epoch [2081/3000], Loss: 0.1398\n",
      "Validation Loss: 330.7969\n",
      "Epoch [2101/3000], Loss: 2.5438\n",
      "Validation Loss: 413.8356\n",
      "Epoch [2121/3000], Loss: 0.1509\n",
      "Validation Loss: 334.6602\n",
      "Epoch [2141/3000], Loss: 0.1170\n",
      "Validation Loss: 335.8329\n",
      "Epoch [2161/3000], Loss: 0.1076\n",
      "Validation Loss: 337.6853\n",
      "Epoch [2181/3000], Loss: 0.1037\n",
      "Validation Loss: 338.6758\n",
      "Epoch [2201/3000], Loss: 0.1039\n",
      "Validation Loss: 339.9406\n",
      "Epoch [2221/3000], Loss: 0.1081\n",
      "Validation Loss: 344.1404\n",
      "Epoch [2241/3000], Loss: 0.1147\n",
      "Validation Loss: 345.2159\n",
      "Epoch [2261/3000], Loss: 0.1119\n",
      "Validation Loss: 342.6153\n",
      "Epoch [2281/3000], Loss: 0.1037\n",
      "Validation Loss: 337.6763\n",
      "Epoch [2301/3000], Loss: 0.1105\n",
      "Validation Loss: 340.9433\n",
      "Epoch [2321/3000], Loss: 0.0973\n",
      "Validation Loss: 338.6576\n",
      "Epoch [2341/3000], Loss: 0.1020\n",
      "Validation Loss: 335.9957\n",
      "Epoch [2361/3000], Loss: 0.0974\n",
      "Validation Loss: 344.3279\n",
      "Epoch [2381/3000], Loss: 0.0921\n",
      "Validation Loss: 341.9979\n",
      "Epoch [2401/3000], Loss: 0.0934\n",
      "Validation Loss: 340.5570\n",
      "Epoch [2421/3000], Loss: 0.0854\n",
      "Validation Loss: 334.8805\n",
      "Epoch [2441/3000], Loss: 0.0778\n",
      "Validation Loss: 334.8396\n",
      "Epoch [2461/3000], Loss: 0.0790\n",
      "Validation Loss: 347.3304\n",
      "Epoch [2481/3000], Loss: 0.0854\n",
      "Validation Loss: 335.2408\n",
      "Epoch [2501/3000], Loss: 0.0801\n",
      "Validation Loss: 337.8488\n",
      "Epoch [2521/3000], Loss: 0.0710\n",
      "Validation Loss: 340.4673\n",
      "Epoch [2541/3000], Loss: 0.0701\n",
      "Validation Loss: 337.6010\n",
      "Epoch [2561/3000], Loss: 0.0591\n",
      "Validation Loss: 339.9587\n",
      "Epoch [2581/3000], Loss: 0.0684\n",
      "Validation Loss: 346.0228\n",
      "Epoch [2601/3000], Loss: 0.0708\n",
      "Validation Loss: 348.6439\n",
      "Epoch [2621/3000], Loss: 0.0659\n",
      "Validation Loss: 337.3850\n",
      "Epoch [2641/3000], Loss: 0.0666\n",
      "Validation Loss: 340.6384\n",
      "Epoch [2661/3000], Loss: 0.0751\n",
      "Validation Loss: 348.5231\n",
      "Epoch [2681/3000], Loss: 0.0617\n",
      "Validation Loss: 339.3843\n",
      "Epoch [2701/3000], Loss: 0.0554\n",
      "Validation Loss: 341.3546\n",
      "Epoch [2721/3000], Loss: 0.0584\n",
      "Validation Loss: 339.1860\n",
      "Epoch [2741/3000], Loss: 0.0559\n",
      "Validation Loss: 342.2837\n",
      "Epoch [2761/3000], Loss: 0.0677\n",
      "Validation Loss: 340.9282\n",
      "Epoch [2781/3000], Loss: 0.0508\n",
      "Validation Loss: 338.8886\n",
      "Epoch [2801/3000], Loss: 0.0519\n",
      "Validation Loss: 331.6260\n",
      "Epoch [2821/3000], Loss: 0.0680\n",
      "Validation Loss: 342.0380\n",
      "Epoch [2841/3000], Loss: 0.0519\n",
      "Validation Loss: 337.0266\n",
      "Epoch [2861/3000], Loss: 0.0509\n",
      "Validation Loss: 334.9120\n",
      "Epoch [2881/3000], Loss: 0.0501\n",
      "Validation Loss: 341.2020\n",
      "Epoch [2901/3000], Loss: 0.0454\n",
      "Validation Loss: 340.5695\n",
      "Epoch [2921/3000], Loss: 0.0440\n",
      "Validation Loss: 341.9071\n",
      "Epoch [2941/3000], Loss: 0.0447\n",
      "Validation Loss: 345.6846\n",
      "Epoch [2961/3000], Loss: 0.0441\n",
      "Validation Loss: 342.3111\n",
      "Epoch [2981/3000], Loss: 0.0476\n",
      "Validation Loss: 346.4801\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day004_plane0_Fall.mat\n",
      "(6196, 131)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 10110.9012\n",
      "Validation Loss: 6590.2221\n",
      "Epoch [21/3000], Loss: 8725.1511\n",
      "Validation Loss: 5531.9328\n",
      "Epoch [41/3000], Loss: 8448.4061\n",
      "Validation Loss: 5314.9949\n",
      "Epoch [61/3000], Loss: 8233.6794\n",
      "Validation Loss: 5166.0818\n",
      "Epoch [81/3000], Loss: 8045.4464\n",
      "Validation Loss: 5034.6313\n",
      "Epoch [101/3000], Loss: 7877.2099\n",
      "Validation Loss: 4911.5822\n",
      "Epoch [121/3000], Loss: 7696.4688\n",
      "Validation Loss: 4793.5332\n",
      "Epoch [141/3000], Loss: 7579.9580\n",
      "Validation Loss: 4679.3185\n",
      "Epoch [161/3000], Loss: 7407.5386\n",
      "Validation Loss: 4569.7188\n",
      "Epoch [181/3000], Loss: 7255.5736\n",
      "Validation Loss: 4462.8958\n",
      "Epoch [201/3000], Loss: 7112.8955\n",
      "Validation Loss: 4359.4588\n",
      "Epoch [221/3000], Loss: 6974.4713\n",
      "Validation Loss: 4259.4659\n",
      "Epoch [241/3000], Loss: 6817.7584\n",
      "Validation Loss: 4162.5196\n",
      "Epoch [261/3000], Loss: 6691.7475\n",
      "Validation Loss: 4068.6697\n",
      "Epoch [281/3000], Loss: 6561.1740\n",
      "Validation Loss: 3977.7139\n",
      "Epoch [301/3000], Loss: 6415.1853\n",
      "Validation Loss: 3889.6749\n",
      "Epoch [321/3000], Loss: 6301.0862\n",
      "Validation Loss: 3804.5335\n",
      "Epoch [341/3000], Loss: 6163.3436\n",
      "Validation Loss: 3722.2573\n",
      "Epoch [361/3000], Loss: 6045.7688\n",
      "Validation Loss: 3642.8004\n",
      "Epoch [381/3000], Loss: 5929.9483\n",
      "Validation Loss: 3566.2528\n",
      "Epoch [401/3000], Loss: 5824.4741\n",
      "Validation Loss: 3492.4800\n",
      "Epoch [421/3000], Loss: 5701.4088\n",
      "Validation Loss: 3421.5450\n",
      "Epoch [441/3000], Loss: 5592.5683\n",
      "Validation Loss: 3353.4173\n",
      "Epoch [461/3000], Loss: 5490.4890\n",
      "Validation Loss: 3288.0554\n",
      "Epoch [481/3000], Loss: 5388.1138\n",
      "Validation Loss: 3225.5204\n",
      "Epoch [501/3000], Loss: 5277.3222\n",
      "Validation Loss: 3165.7810\n",
      "Epoch [521/3000], Loss: 5183.1369\n",
      "Validation Loss: 3108.7934\n",
      "Epoch [541/3000], Loss: 5082.2130\n",
      "Validation Loss: 3053.2793\n",
      "Epoch [561/3000], Loss: 4977.9320\n",
      "Validation Loss: 3001.5348\n",
      "Epoch [581/3000], Loss: 4898.4454\n",
      "Validation Loss: 2952.6904\n",
      "Epoch [601/3000], Loss: 4814.8625\n",
      "Validation Loss: 2906.6226\n",
      "Epoch [621/3000], Loss: 4725.2272\n",
      "Validation Loss: 2863.3615\n",
      "Epoch [641/3000], Loss: 4633.7443\n",
      "Validation Loss: 2822.8478\n",
      "Epoch [661/3000], Loss: 4551.8683\n",
      "Validation Loss: 2785.0509\n",
      "Epoch [681/3000], Loss: 4480.3998\n",
      "Validation Loss: 2749.9869\n",
      "Epoch [701/3000], Loss: 4408.1385\n",
      "Validation Loss: 2717.6034\n",
      "Epoch [721/3000], Loss: 4331.7223\n",
      "Validation Loss: 2687.8960\n",
      "Epoch [741/3000], Loss: 4275.9135\n",
      "Validation Loss: 2660.8937\n",
      "Epoch [761/3000], Loss: 4209.5685\n",
      "Validation Loss: 2636.5369\n",
      "Epoch [781/3000], Loss: 4145.9803\n",
      "Validation Loss: 2614.8153\n",
      "Epoch [801/3000], Loss: 4084.4695\n",
      "Validation Loss: 2595.6847\n",
      "Epoch [821/3000], Loss: 4020.7564\n",
      "Validation Loss: 2579.1359\n",
      "Epoch [841/3000], Loss: 3971.3119\n",
      "Validation Loss: 2565.1436\n",
      "Epoch [861/3000], Loss: 3920.8815\n",
      "Validation Loss: 2553.6732\n",
      "Epoch [881/3000], Loss: 3867.5508\n",
      "Validation Loss: 2544.6951\n",
      "Epoch [901/3000], Loss: 3819.1075\n",
      "Validation Loss: 2538.1952\n",
      "Epoch [921/3000], Loss: 3777.9284\n",
      "Validation Loss: 2534.0973\n",
      "Epoch [941/3000], Loss: 3736.1933\n",
      "Validation Loss: 2532.3857\n",
      "Epoch [961/3000], Loss: 3698.4711\n",
      "Validation Loss: 2532.9988\n",
      "Epoch [981/3000], Loss: 3659.7489\n",
      "Validation Loss: 2535.8786\n",
      "Epoch [1001/3000], Loss: 3623.3712\n",
      "Validation Loss: 2540.9569\n",
      "Epoch [1021/3000], Loss: 3597.0717\n",
      "Validation Loss: 2548.1550\n",
      "Epoch [1041/3000], Loss: 3567.5779\n",
      "Validation Loss: 2557.3970\n",
      "Epoch [1061/3000], Loss: 3544.7552\n",
      "Validation Loss: 2568.6062\n",
      "Epoch [1081/3000], Loss: 3520.4536\n",
      "Validation Loss: 2581.6640\n",
      "Epoch [1101/3000], Loss: 3502.1210\n",
      "Validation Loss: 2596.3613\n",
      "Epoch [1121/3000], Loss: 3480.7804\n",
      "Validation Loss: 2612.6961\n",
      "Epoch [1141/3000], Loss: 3465.9841\n",
      "Validation Loss: 2630.3767\n",
      "Epoch [1161/3000], Loss: 3451.0845\n",
      "Validation Loss: 2649.1746\n",
      "Epoch [1181/3000], Loss: 3438.8368\n",
      "Validation Loss: 2668.8485\n",
      "Epoch [1201/3000], Loss: 3426.0446\n",
      "Validation Loss: 2689.1183\n",
      "Epoch [1221/3000], Loss: 3418.3699\n",
      "Validation Loss: 2709.6670\n",
      "Epoch [1241/3000], Loss: 3412.2732\n",
      "Validation Loss: 2730.1639\n",
      "Epoch [1261/3000], Loss: 3409.9579\n",
      "Validation Loss: 2749.9069\n",
      "Epoch [1281/3000], Loss: 3404.1741\n",
      "Validation Loss: 2768.9344\n",
      "Epoch [1301/3000], Loss: 3399.4177\n",
      "Validation Loss: 2786.3539\n",
      "Epoch [1321/3000], Loss: 3396.9225\n",
      "Validation Loss: 2777.5763\n",
      "Epoch [1341/3000], Loss: 2919.8200\n",
      "Validation Loss: 2224.0005\n",
      "Epoch [1361/3000], Loss: 2052.3901\n",
      "Validation Loss: 1505.6491\n",
      "Epoch [1381/3000], Loss: 1863.2420\n",
      "Validation Loss: 1445.8253\n",
      "Epoch [1401/3000], Loss: 1756.7080\n",
      "Validation Loss: 1419.3021\n",
      "Epoch [1421/3000], Loss: 1680.4371\n",
      "Validation Loss: 1406.7972\n",
      "Epoch [1441/3000], Loss: 1612.4176\n",
      "Validation Loss: 1395.1401\n",
      "Epoch [1461/3000], Loss: 1547.0607\n",
      "Validation Loss: 1394.6205\n",
      "Epoch [1481/3000], Loss: 1482.5294\n",
      "Validation Loss: 1380.3049\n",
      "Epoch [1501/3000], Loss: 1423.9177\n",
      "Validation Loss: 1364.6920\n",
      "Epoch [1521/3000], Loss: 1366.5089\n",
      "Validation Loss: 1376.1730\n",
      "Epoch [1541/3000], Loss: 1310.6876\n",
      "Validation Loss: 1344.9293\n",
      "Epoch [1561/3000], Loss: 1254.9676\n",
      "Validation Loss: 1330.8603\n",
      "Epoch [1581/3000], Loss: 1200.4432\n",
      "Validation Loss: 1302.5867\n",
      "Epoch [1601/3000], Loss: 1151.7975\n",
      "Validation Loss: 1263.7115\n",
      "Epoch [1621/3000], Loss: 1090.1684\n",
      "Validation Loss: 1244.5073\n",
      "Epoch [1641/3000], Loss: 1039.9793\n",
      "Validation Loss: 1225.0968\n",
      "Epoch [1661/3000], Loss: 986.2531\n",
      "Validation Loss: 1209.9947\n",
      "Epoch [1681/3000], Loss: 938.9406\n",
      "Validation Loss: 1233.1865\n",
      "Epoch [1701/3000], Loss: 889.7908\n",
      "Validation Loss: 1206.9163\n",
      "Epoch [1721/3000], Loss: 842.0248\n",
      "Validation Loss: 1211.0793\n",
      "Epoch [1741/3000], Loss: 802.4933\n",
      "Validation Loss: 1212.4155\n",
      "Epoch [1761/3000], Loss: 764.6520\n",
      "Validation Loss: 1231.1041\n",
      "Epoch [1781/3000], Loss: 727.5768\n",
      "Validation Loss: 1234.7041\n",
      "Epoch [1801/3000], Loss: 692.3477\n",
      "Validation Loss: 1219.7492\n",
      "Epoch [1821/3000], Loss: 658.6874\n",
      "Validation Loss: 1220.9994\n",
      "Epoch [1841/3000], Loss: 625.6548\n",
      "Validation Loss: 1231.4391\n",
      "Epoch [1861/3000], Loss: 596.6048\n",
      "Validation Loss: 1237.6953\n",
      "Epoch [1881/3000], Loss: 562.4862\n",
      "Validation Loss: 1227.5619\n",
      "Epoch [1901/3000], Loss: 533.5511\n",
      "Validation Loss: 1238.1712\n",
      "Epoch [1921/3000], Loss: 507.8231\n",
      "Validation Loss: 1239.5945\n",
      "Epoch [1941/3000], Loss: 481.5730\n",
      "Validation Loss: 1235.3498\n",
      "Epoch [1961/3000], Loss: 455.4164\n",
      "Validation Loss: 1219.6023\n",
      "Epoch [1981/3000], Loss: 435.0843\n",
      "Validation Loss: 1229.0082\n",
      "Epoch [2001/3000], Loss: 413.0800\n",
      "Validation Loss: 1234.2964\n",
      "Epoch [2021/3000], Loss: 393.7411\n",
      "Validation Loss: 1229.5098\n",
      "Epoch [2041/3000], Loss: 373.4735\n",
      "Validation Loss: 1239.0674\n",
      "Epoch [2061/3000], Loss: 354.0819\n",
      "Validation Loss: 1248.7201\n",
      "Epoch [2081/3000], Loss: 336.3633\n",
      "Validation Loss: 1242.0629\n",
      "Epoch [2101/3000], Loss: 319.2085\n",
      "Validation Loss: 1266.7564\n",
      "Epoch [2121/3000], Loss: 299.6557\n",
      "Validation Loss: 1279.6267\n",
      "Epoch [2141/3000], Loss: 282.7890\n",
      "Validation Loss: 1301.8422\n",
      "Epoch [2161/3000], Loss: 264.8281\n",
      "Validation Loss: 1286.6803\n",
      "Epoch [2181/3000], Loss: 247.8283\n",
      "Validation Loss: 1311.0194\n",
      "Epoch [2201/3000], Loss: 231.6582\n",
      "Validation Loss: 1342.2968\n",
      "Epoch [2221/3000], Loss: 216.6234\n",
      "Validation Loss: 1312.3565\n",
      "Epoch [2241/3000], Loss: 199.2954\n",
      "Validation Loss: 1338.6977\n",
      "Epoch [2261/3000], Loss: 191.1907\n",
      "Validation Loss: 1357.6899\n",
      "Epoch [2281/3000], Loss: 168.7183\n",
      "Validation Loss: 1361.3640\n",
      "Epoch [2301/3000], Loss: 157.6587\n",
      "Validation Loss: 1369.0401\n",
      "Epoch [2321/3000], Loss: 146.0649\n",
      "Validation Loss: 1397.6265\n",
      "Epoch [2341/3000], Loss: 135.9696\n",
      "Validation Loss: 1423.1510\n",
      "Epoch [2361/3000], Loss: 126.2046\n",
      "Validation Loss: 1435.2232\n",
      "Epoch [2381/3000], Loss: 117.0783\n",
      "Validation Loss: 1482.0808\n",
      "Epoch [2401/3000], Loss: 109.4118\n",
      "Validation Loss: 1466.2940\n",
      "Epoch [2421/3000], Loss: 100.5918\n",
      "Validation Loss: 1537.1774\n",
      "Epoch [2441/3000], Loss: 92.5875\n",
      "Validation Loss: 1519.7482\n",
      "Epoch [2461/3000], Loss: 84.9746\n",
      "Validation Loss: 1517.6920\n",
      "Epoch [2481/3000], Loss: 78.4913\n",
      "Validation Loss: 1522.0763\n",
      "Epoch [2501/3000], Loss: 73.3262\n",
      "Validation Loss: 1548.1581\n",
      "Epoch [2521/3000], Loss: 68.6142\n",
      "Validation Loss: 1563.1932\n",
      "Epoch [2541/3000], Loss: 64.3793\n",
      "Validation Loss: 1591.6344\n",
      "Epoch [2561/3000], Loss: 59.5469\n",
      "Validation Loss: 1605.9578\n",
      "Epoch [2581/3000], Loss: 53.8273\n",
      "Validation Loss: 1664.6588\n",
      "Epoch [2601/3000], Loss: 46.8767\n",
      "Validation Loss: 1681.1393\n",
      "Epoch [2621/3000], Loss: 40.5563\n",
      "Validation Loss: 1704.9379\n",
      "Epoch [2641/3000], Loss: 35.9695\n",
      "Validation Loss: 1684.3500\n",
      "Epoch [2661/3000], Loss: 33.1397\n",
      "Validation Loss: 1720.2393\n",
      "Epoch [2681/3000], Loss: 28.0486\n",
      "Validation Loss: 1755.4814\n",
      "Epoch [2701/3000], Loss: 25.3488\n",
      "Validation Loss: 1733.7303\n",
      "Epoch [2721/3000], Loss: 22.9081\n",
      "Validation Loss: 1756.9157\n",
      "Epoch [2741/3000], Loss: 20.7079\n",
      "Validation Loss: 1763.4445\n",
      "Epoch [2761/3000], Loss: 18.8786\n",
      "Validation Loss: 1734.7090\n",
      "Epoch [2781/3000], Loss: 17.1513\n",
      "Validation Loss: 1743.8906\n",
      "Epoch [2801/3000], Loss: 15.8372\n",
      "Validation Loss: 1768.2640\n",
      "Epoch [2821/3000], Loss: 14.1384\n",
      "Validation Loss: 1812.5802\n",
      "Epoch [2841/3000], Loss: 12.8006\n",
      "Validation Loss: 1756.3558\n",
      "Epoch [2861/3000], Loss: 11.4889\n",
      "Validation Loss: 1806.8787\n",
      "Epoch [2881/3000], Loss: 10.4012\n",
      "Validation Loss: 1820.3252\n",
      "Epoch [2901/3000], Loss: 9.0216\n",
      "Validation Loss: 1796.8591\n",
      "Epoch [2921/3000], Loss: 7.9636\n",
      "Validation Loss: 1800.2833\n",
      "Epoch [2941/3000], Loss: 6.9931\n",
      "Validation Loss: 1818.8205\n",
      "Epoch [2961/3000], Loss: 6.1724\n",
      "Validation Loss: 1755.1443\n",
      "Epoch [2981/3000], Loss: 5.3482\n",
      "Validation Loss: 1797.2655\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day005_plane0_Fall.mat\n",
      "(15011, 150)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9530.0733\n",
      "Validation Loss: 8217.9397\n",
      "Epoch [21/3000], Loss: 7808.6544\n",
      "Validation Loss: 6679.1180\n",
      "Epoch [41/3000], Loss: 7366.4774\n",
      "Validation Loss: 6291.3835\n",
      "Epoch [61/3000], Loss: 6982.0838\n",
      "Validation Loss: 5949.0720\n",
      "Epoch [81/3000], Loss: 6622.5174\n",
      "Validation Loss: 5630.0251\n",
      "Epoch [101/3000], Loss: 6271.3420\n",
      "Validation Loss: 5329.8755\n",
      "Epoch [121/3000], Loss: 5935.1604\n",
      "Validation Loss: 5047.0526\n",
      "Epoch [141/3000], Loss: 5632.3184\n",
      "Validation Loss: 4781.0098\n",
      "Epoch [161/3000], Loss: 5327.2471\n",
      "Validation Loss: 4531.6245\n",
      "Epoch [181/3000], Loss: 5052.3581\n",
      "Validation Loss: 4298.6042\n",
      "Epoch [201/3000], Loss: 4784.9161\n",
      "Validation Loss: 4078.3651\n",
      "Epoch [221/3000], Loss: 4532.3771\n",
      "Validation Loss: 3876.2566\n",
      "Epoch [241/3000], Loss: 4306.4213\n",
      "Validation Loss: 3691.1774\n",
      "Epoch [261/3000], Loss: 4095.7328\n",
      "Validation Loss: 3522.4493\n",
      "Epoch [281/3000], Loss: 3896.9953\n",
      "Validation Loss: 3369.9104\n",
      "Epoch [301/3000], Loss: 3713.7826\n",
      "Validation Loss: 3233.4516\n",
      "Epoch [321/3000], Loss: 3557.6019\n",
      "Validation Loss: 3112.9351\n",
      "Epoch [341/3000], Loss: 3401.6123\n",
      "Validation Loss: 3008.2049\n",
      "Epoch [361/3000], Loss: 3269.9807\n",
      "Validation Loss: 2918.9461\n",
      "Epoch [381/3000], Loss: 3151.2292\n",
      "Validation Loss: 2844.8677\n",
      "Epoch [401/3000], Loss: 3045.4127\n",
      "Validation Loss: 2785.7024\n",
      "Epoch [421/3000], Loss: 2960.4485\n",
      "Validation Loss: 2740.8865\n",
      "Epoch [441/3000], Loss: 2890.3850\n",
      "Validation Loss: 2709.8666\n",
      "Epoch [461/3000], Loss: 2834.2338\n",
      "Validation Loss: 2691.8631\n",
      "Epoch [481/3000], Loss: 2789.6221\n",
      "Validation Loss: 2685.5856\n",
      "Epoch [501/3000], Loss: 2760.7696\n",
      "Validation Loss: 2689.3431\n",
      "Epoch [521/3000], Loss: 2736.6498\n",
      "Validation Loss: 2700.5568\n",
      "Epoch [541/3000], Loss: 2725.4928\n",
      "Validation Loss: 2715.6444\n",
      "Epoch [561/3000], Loss: 2718.0343\n",
      "Validation Loss: 2730.0870\n",
      "Epoch [581/3000], Loss: 2720.0604\n",
      "Validation Loss: 2740.4681\n",
      "Epoch [601/3000], Loss: 2718.4644\n",
      "Validation Loss: 2746.1750\n",
      "Epoch [621/3000], Loss: 2720.9839\n",
      "Validation Loss: 2748.5181\n",
      "Epoch [641/3000], Loss: 2721.5879\n",
      "Validation Loss: 2749.5368\n",
      "Epoch [661/3000], Loss: 2723.8536\n",
      "Validation Loss: 2749.8817\n",
      "Epoch [681/3000], Loss: 2722.1349\n",
      "Validation Loss: 2750.0970\n",
      "Epoch [701/3000], Loss: 2720.1278\n",
      "Validation Loss: 2750.1046\n",
      "Epoch [721/3000], Loss: 2724.4544\n",
      "Validation Loss: 2750.1634\n",
      "Epoch [741/3000], Loss: 2723.4311\n",
      "Validation Loss: 2750.1799\n",
      "Epoch [761/3000], Loss: 2722.6284\n",
      "Validation Loss: 2750.1176\n",
      "Epoch [781/3000], Loss: 2720.7691\n",
      "Validation Loss: 2750.2560\n",
      "Epoch [801/3000], Loss: 2718.4599\n",
      "Validation Loss: 2750.2344\n",
      "Epoch [821/3000], Loss: 2723.5364\n",
      "Validation Loss: 2750.3922\n",
      "Epoch [841/3000], Loss: 2716.4041\n",
      "Validation Loss: 2750.4128\n",
      "Epoch [861/3000], Loss: 2723.3547\n",
      "Validation Loss: 2750.2270\n",
      "Epoch [881/3000], Loss: 2718.1336\n",
      "Validation Loss: 2750.2290\n",
      "Epoch [901/3000], Loss: 2715.9888\n",
      "Validation Loss: 2750.3155\n",
      "Epoch [921/3000], Loss: 2725.4932\n",
      "Validation Loss: 2750.3006\n",
      "Epoch [941/3000], Loss: 2717.9551\n",
      "Validation Loss: 2750.2078\n",
      "Epoch [961/3000], Loss: 2721.1852\n",
      "Validation Loss: 2750.1983\n",
      "Epoch [981/3000], Loss: 2719.8362\n",
      "Validation Loss: 2750.1598\n",
      "Epoch [1001/3000], Loss: 2722.7147\n",
      "Validation Loss: 2750.2341\n",
      "Epoch [1021/3000], Loss: 2716.8162\n",
      "Validation Loss: 2750.1549\n",
      "Epoch [1041/3000], Loss: 2718.1434\n",
      "Validation Loss: 2750.1220\n",
      "Epoch [1061/3000], Loss: 1523.7445\n",
      "Validation Loss: 1786.8622\n",
      "Epoch [1081/3000], Loss: 1265.6996\n",
      "Validation Loss: 1632.3935\n",
      "Epoch [1101/3000], Loss: 1125.1935\n",
      "Validation Loss: 1591.0094\n",
      "Epoch [1121/3000], Loss: 1014.0772\n",
      "Validation Loss: 1526.3661\n",
      "Epoch [1141/3000], Loss: 915.2501\n",
      "Validation Loss: 1487.9359\n",
      "Epoch [1161/3000], Loss: 817.2567\n",
      "Validation Loss: 1468.1449\n",
      "Epoch [1181/3000], Loss: 741.2956\n",
      "Validation Loss: 1456.9032\n",
      "Epoch [1201/3000], Loss: 663.0710\n",
      "Validation Loss: 1462.9337\n",
      "Epoch [1221/3000], Loss: 597.4138\n",
      "Validation Loss: 1463.8721\n",
      "Epoch [1241/3000], Loss: 533.6467\n",
      "Validation Loss: 1449.3852\n",
      "Epoch [1261/3000], Loss: 477.5395\n",
      "Validation Loss: 1475.3211\n",
      "Epoch [1281/3000], Loss: 426.8372\n",
      "Validation Loss: 1477.0847\n",
      "Epoch [1301/3000], Loss: 379.2058\n",
      "Validation Loss: 1487.8876\n",
      "Epoch [1321/3000], Loss: 336.9075\n",
      "Validation Loss: 1498.7260\n",
      "Epoch [1341/3000], Loss: 301.1047\n",
      "Validation Loss: 1489.8749\n",
      "Epoch [1361/3000], Loss: 274.0316\n",
      "Validation Loss: 1473.1441\n",
      "Epoch [1381/3000], Loss: 245.3269\n",
      "Validation Loss: 1513.7439\n",
      "Epoch [1401/3000], Loss: 225.3825\n",
      "Validation Loss: 1465.6255\n",
      "Epoch [1421/3000], Loss: 199.7121\n",
      "Validation Loss: 1499.2865\n",
      "Epoch [1441/3000], Loss: 177.6457\n",
      "Validation Loss: 1504.7026\n",
      "Epoch [1461/3000], Loss: 163.0189\n",
      "Validation Loss: 1495.8801\n",
      "Epoch [1481/3000], Loss: 142.8799\n",
      "Validation Loss: 1569.0447\n",
      "Epoch [1501/3000], Loss: 123.8017\n",
      "Validation Loss: 1548.6739\n",
      "Epoch [1521/3000], Loss: 106.7204\n",
      "Validation Loss: 1572.0470\n",
      "Epoch [1541/3000], Loss: 91.8037\n",
      "Validation Loss: 1546.0511\n",
      "Epoch [1561/3000], Loss: 73.6759\n",
      "Validation Loss: 1536.5092\n",
      "Epoch [1581/3000], Loss: 61.2840\n",
      "Validation Loss: 1546.4721\n",
      "Epoch [1601/3000], Loss: 51.0773\n",
      "Validation Loss: 1544.3015\n",
      "Epoch [1621/3000], Loss: 42.7158\n",
      "Validation Loss: 1624.8778\n",
      "Epoch [1641/3000], Loss: 37.1091\n",
      "Validation Loss: 1601.7670\n",
      "Epoch [1661/3000], Loss: 28.8722\n",
      "Validation Loss: 1599.6132\n",
      "Epoch [1681/3000], Loss: 26.8938\n",
      "Validation Loss: 1628.5826\n",
      "Epoch [1701/3000], Loss: 21.4627\n",
      "Validation Loss: 1644.3926\n",
      "Epoch [1721/3000], Loss: 19.2449\n",
      "Validation Loss: 1623.7260\n",
      "Epoch [1741/3000], Loss: 16.9977\n",
      "Validation Loss: 1626.2724\n",
      "Epoch [1761/3000], Loss: 14.9514\n",
      "Validation Loss: 1646.6743\n",
      "Epoch [1781/3000], Loss: 13.2456\n",
      "Validation Loss: 1620.8322\n",
      "Epoch [1801/3000], Loss: 12.2070\n",
      "Validation Loss: 1614.8404\n",
      "Epoch [1821/3000], Loss: 10.6638\n",
      "Validation Loss: 1640.2399\n",
      "Epoch [1841/3000], Loss: 10.1655\n",
      "Validation Loss: 1621.2342\n",
      "Epoch [1861/3000], Loss: 9.2047\n",
      "Validation Loss: 1605.8965\n",
      "Epoch [1881/3000], Loss: 8.5964\n",
      "Validation Loss: 1587.5910\n",
      "Epoch [1901/3000], Loss: 8.0322\n",
      "Validation Loss: 1610.0926\n",
      "Epoch [1921/3000], Loss: 6.7794\n",
      "Validation Loss: 1595.2920\n",
      "Epoch [1941/3000], Loss: 6.9595\n",
      "Validation Loss: 1579.5274\n",
      "Epoch [1961/3000], Loss: 5.4558\n",
      "Validation Loss: 1623.1421\n",
      "Epoch [1981/3000], Loss: 4.8831\n",
      "Validation Loss: 1605.2938\n",
      "Epoch [2001/3000], Loss: 4.6926\n",
      "Validation Loss: 1589.9137\n",
      "Epoch [2021/3000], Loss: 4.4442\n",
      "Validation Loss: 1597.8758\n",
      "Epoch [2041/3000], Loss: 4.1985\n",
      "Validation Loss: 1581.5836\n",
      "Epoch [2061/3000], Loss: 3.8741\n",
      "Validation Loss: 1585.3513\n",
      "Epoch [2081/3000], Loss: 3.5396\n",
      "Validation Loss: 1583.3017\n",
      "Epoch [2101/3000], Loss: 5.6514\n",
      "Validation Loss: 1542.2354\n",
      "Epoch [2121/3000], Loss: 2.9397\n",
      "Validation Loss: 1561.0254\n",
      "Epoch [2141/3000], Loss: 2.8349\n",
      "Validation Loss: 1559.4293\n",
      "Epoch [2161/3000], Loss: 2.7475\n",
      "Validation Loss: 1575.7534\n",
      "Epoch [2181/3000], Loss: 2.7733\n",
      "Validation Loss: 1565.0112\n",
      "Epoch [2201/3000], Loss: 2.6482\n",
      "Validation Loss: 1587.6882\n",
      "Epoch [2221/3000], Loss: 2.5045\n",
      "Validation Loss: 1555.8080\n",
      "Epoch [2241/3000], Loss: 2.9904\n",
      "Validation Loss: 1527.9213\n",
      "Epoch [2261/3000], Loss: 1.9901\n",
      "Validation Loss: 1552.0175\n",
      "Epoch [2281/3000], Loss: 1.9505\n",
      "Validation Loss: 1564.1910\n",
      "Epoch [2301/3000], Loss: 1.8524\n",
      "Validation Loss: 1549.3167\n",
      "Epoch [2321/3000], Loss: 1.7996\n",
      "Validation Loss: 1543.1815\n",
      "Epoch [2341/3000], Loss: 1.8345\n",
      "Validation Loss: 1588.8857\n",
      "Epoch [2361/3000], Loss: 1.7824\n",
      "Validation Loss: 1551.3372\n",
      "Epoch [2381/3000], Loss: 1.5396\n",
      "Validation Loss: 1545.3291\n",
      "Epoch [2401/3000], Loss: 1.4643\n",
      "Validation Loss: 1559.2435\n",
      "Epoch [2421/3000], Loss: 1.3973\n",
      "Validation Loss: 1556.5222\n",
      "Epoch [2441/3000], Loss: 1.3811\n",
      "Validation Loss: 1542.6337\n",
      "Epoch [2461/3000], Loss: 1.3646\n",
      "Validation Loss: 1551.9275\n",
      "Epoch [2481/3000], Loss: 1.2849\n",
      "Validation Loss: 1545.4112\n",
      "Epoch [2501/3000], Loss: 1.3436\n",
      "Validation Loss: 1537.1212\n",
      "Epoch [2521/3000], Loss: 2.9043\n",
      "Validation Loss: 1563.4800\n",
      "Epoch [2541/3000], Loss: 1.0156\n",
      "Validation Loss: 1545.6372\n",
      "Epoch [2561/3000], Loss: 1.0078\n",
      "Validation Loss: 1548.7189\n",
      "Epoch [2581/3000], Loss: 0.9952\n",
      "Validation Loss: 1555.9100\n",
      "Epoch [2601/3000], Loss: 1.0007\n",
      "Validation Loss: 1554.1428\n",
      "Epoch [2621/3000], Loss: 1.0798\n",
      "Validation Loss: 1531.8017\n",
      "Epoch [2641/3000], Loss: 0.9847\n",
      "Validation Loss: 1543.3443\n",
      "Epoch [2661/3000], Loss: 0.9057\n",
      "Validation Loss: 1534.0428\n",
      "Epoch [2681/3000], Loss: 1.0096\n",
      "Validation Loss: 1595.2623\n",
      "Epoch [2701/3000], Loss: 0.9515\n",
      "Validation Loss: 1536.3208\n",
      "Epoch [2721/3000], Loss: 0.7673\n",
      "Validation Loss: 1550.5344\n",
      "Epoch [2741/3000], Loss: 0.7371\n",
      "Validation Loss: 1548.5408\n",
      "Epoch [2761/3000], Loss: 0.7621\n",
      "Validation Loss: 1535.5022\n",
      "Epoch [2781/3000], Loss: 0.7214\n",
      "Validation Loss: 1537.0233\n",
      "Epoch [2801/3000], Loss: 0.7180\n",
      "Validation Loss: 1539.2181\n",
      "Epoch [2821/3000], Loss: 0.7354\n",
      "Validation Loss: 1508.5705\n",
      "Epoch [2841/3000], Loss: 0.7888\n",
      "Validation Loss: 1518.1606\n",
      "Epoch [2861/3000], Loss: 0.7718\n",
      "Validation Loss: 1555.2813\n",
      "Epoch [2881/3000], Loss: 0.6792\n",
      "Validation Loss: 1541.7747\n",
      "Epoch [2901/3000], Loss: 0.7771\n",
      "Validation Loss: 1542.3781\n",
      "Epoch [2921/3000], Loss: 0.6543\n",
      "Validation Loss: 1542.3874\n",
      "Epoch [2941/3000], Loss: 0.6107\n",
      "Validation Loss: 1532.8710\n",
      "Epoch [2961/3000], Loss: 0.8347\n",
      "Validation Loss: 1521.5889\n",
      "Epoch [2981/3000], Loss: 0.5012\n",
      "Validation Loss: 1525.7899\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day009_plane0_Fall.mat\n",
      "(15176, 201)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9417.1904\n",
      "Validation Loss: 9303.9555\n",
      "Epoch [21/3000], Loss: 7741.7648\n",
      "Validation Loss: 7626.1082\n",
      "Epoch [41/3000], Loss: 7319.2589\n",
      "Validation Loss: 7204.7790\n",
      "Epoch [61/3000], Loss: 6954.5959\n",
      "Validation Loss: 6830.9757\n",
      "Epoch [81/3000], Loss: 6609.9727\n",
      "Validation Loss: 6485.6835\n",
      "Epoch [101/3000], Loss: 6279.0673\n",
      "Validation Loss: 6160.3931\n",
      "Epoch [121/3000], Loss: 5978.5257\n",
      "Validation Loss: 5853.0817\n",
      "Epoch [141/3000], Loss: 5688.5611\n",
      "Validation Loss: 5563.4444\n",
      "Epoch [161/3000], Loss: 5417.6686\n",
      "Validation Loss: 5291.1067\n",
      "Epoch [181/3000], Loss: 5164.3562\n",
      "Validation Loss: 5036.0521\n",
      "Epoch [201/3000], Loss: 4927.1064\n",
      "Validation Loss: 4798.0148\n",
      "Epoch [221/3000], Loss: 4703.2876\n",
      "Validation Loss: 4577.0054\n",
      "Epoch [241/3000], Loss: 4501.8955\n",
      "Validation Loss: 4372.8968\n",
      "Epoch [261/3000], Loss: 4316.8064\n",
      "Validation Loss: 4185.5815\n",
      "Epoch [281/3000], Loss: 4146.4269\n",
      "Validation Loss: 4014.9252\n",
      "Epoch [301/3000], Loss: 3994.3835\n",
      "Validation Loss: 3860.7711\n",
      "Epoch [321/3000], Loss: 3855.5998\n",
      "Validation Loss: 3723.0433\n",
      "Epoch [341/3000], Loss: 3736.7296\n",
      "Validation Loss: 3601.5648\n",
      "Epoch [361/3000], Loss: 3636.0493\n",
      "Validation Loss: 3495.8998\n",
      "Epoch [381/3000], Loss: 3540.2388\n",
      "Validation Loss: 3405.9860\n",
      "Epoch [401/3000], Loss: 3470.4664\n",
      "Validation Loss: 3331.3226\n",
      "Epoch [421/3000], Loss: 3408.6427\n",
      "Validation Loss: 3270.7985\n",
      "Epoch [441/3000], Loss: 3362.0351\n",
      "Validation Loss: 3224.8450\n",
      "Epoch [461/3000], Loss: 3338.8127\n",
      "Validation Loss: 3191.8155\n",
      "Epoch [481/3000], Loss: 3291.1363\n",
      "Validation Loss: 3141.2785\n",
      "Epoch [501/3000], Loss: 2188.0842\n",
      "Validation Loss: 2554.2994\n",
      "Epoch [521/3000], Loss: 1860.6612\n",
      "Validation Loss: 2465.4271\n",
      "Epoch [541/3000], Loss: 1643.4032\n",
      "Validation Loss: 2439.6007\n",
      "Epoch [561/3000], Loss: 1483.3131\n",
      "Validation Loss: 2395.8013\n",
      "Epoch [581/3000], Loss: 1339.4091\n",
      "Validation Loss: 2377.1661\n",
      "Epoch [601/3000], Loss: 1208.0157\n",
      "Validation Loss: 2334.4858\n",
      "Epoch [621/3000], Loss: 1089.5424\n",
      "Validation Loss: 2278.1332\n",
      "Epoch [641/3000], Loss: 971.5956\n",
      "Validation Loss: 2211.8452\n",
      "Epoch [661/3000], Loss: 867.8600\n",
      "Validation Loss: 2225.2753\n",
      "Epoch [681/3000], Loss: 779.7481\n",
      "Validation Loss: 2206.2559\n",
      "Epoch [701/3000], Loss: 697.3446\n",
      "Validation Loss: 2219.6934\n",
      "Epoch [721/3000], Loss: 622.3476\n",
      "Validation Loss: 2172.6439\n",
      "Epoch [741/3000], Loss: 551.4876\n",
      "Validation Loss: 2152.9438\n",
      "Epoch [761/3000], Loss: 484.4582\n",
      "Validation Loss: 2171.5518\n",
      "Epoch [781/3000], Loss: 423.1655\n",
      "Validation Loss: 2101.4889\n",
      "Epoch [801/3000], Loss: 371.2092\n",
      "Validation Loss: 2058.8842\n",
      "Epoch [821/3000], Loss: 322.2446\n",
      "Validation Loss: 2115.0577\n",
      "Epoch [841/3000], Loss: 278.7575\n",
      "Validation Loss: 2066.5057\n",
      "Epoch [861/3000], Loss: 241.1030\n",
      "Validation Loss: 2088.8098\n",
      "Epoch [881/3000], Loss: 203.7370\n",
      "Validation Loss: 2047.4670\n",
      "Epoch [901/3000], Loss: 171.6514\n",
      "Validation Loss: 2016.8553\n",
      "Epoch [921/3000], Loss: 146.0377\n",
      "Validation Loss: 2021.5601\n",
      "Epoch [941/3000], Loss: 125.9718\n",
      "Validation Loss: 2011.7120\n",
      "Epoch [961/3000], Loss: 107.7026\n",
      "Validation Loss: 1993.9197\n",
      "Epoch [981/3000], Loss: 92.6887\n",
      "Validation Loss: 1985.9757\n",
      "Epoch [1001/3000], Loss: 80.2534\n",
      "Validation Loss: 1965.1322\n",
      "Epoch [1021/3000], Loss: 71.3820\n",
      "Validation Loss: 1969.7255\n",
      "Epoch [1041/3000], Loss: 61.6861\n",
      "Validation Loss: 1982.9348\n",
      "Epoch [1061/3000], Loss: 53.5751\n",
      "Validation Loss: 2015.2297\n",
      "Epoch [1081/3000], Loss: 45.0073\n",
      "Validation Loss: 2005.2919\n",
      "Epoch [1101/3000], Loss: 39.0045\n",
      "Validation Loss: 1986.5191\n",
      "Epoch [1121/3000], Loss: 29.2478\n",
      "Validation Loss: 1985.8336\n",
      "Epoch [1141/3000], Loss: 23.8017\n",
      "Validation Loss: 1987.5985\n",
      "Epoch [1161/3000], Loss: 18.9762\n",
      "Validation Loss: 1983.8758\n",
      "Epoch [1181/3000], Loss: 16.1653\n",
      "Validation Loss: 1993.5772\n",
      "Epoch [1201/3000], Loss: 13.4297\n",
      "Validation Loss: 1967.7971\n",
      "Epoch [1221/3000], Loss: 11.2160\n",
      "Validation Loss: 1980.6366\n",
      "Epoch [1241/3000], Loss: 9.1213\n",
      "Validation Loss: 1943.1581\n",
      "Epoch [1261/3000], Loss: 7.6275\n",
      "Validation Loss: 1959.4746\n",
      "Epoch [1281/3000], Loss: 6.8982\n",
      "Validation Loss: 1914.1740\n",
      "Epoch [1301/3000], Loss: 5.8497\n",
      "Validation Loss: 1926.7543\n",
      "Epoch [1321/3000], Loss: 4.9984\n",
      "Validation Loss: 1916.7265\n",
      "Epoch [1341/3000], Loss: 4.6053\n",
      "Validation Loss: 1903.1501\n",
      "Epoch [1361/3000], Loss: 4.0358\n",
      "Validation Loss: 1907.8279\n",
      "Epoch [1381/3000], Loss: 3.6613\n",
      "Validation Loss: 1899.5006\n",
      "Epoch [1401/3000], Loss: 3.4594\n",
      "Validation Loss: 1885.3704\n",
      "Epoch [1421/3000], Loss: 3.1389\n",
      "Validation Loss: 1891.6207\n",
      "Epoch [1441/3000], Loss: 3.2096\n",
      "Validation Loss: 1881.1072\n",
      "Epoch [1461/3000], Loss: 2.7550\n",
      "Validation Loss: 1878.7763\n",
      "Epoch [1481/3000], Loss: 2.4434\n",
      "Validation Loss: 1880.2603\n",
      "Epoch [1501/3000], Loss: 2.3923\n",
      "Validation Loss: 1877.5663\n",
      "Epoch [1521/3000], Loss: 3.0654\n",
      "Validation Loss: 1879.1710\n",
      "Epoch [1541/3000], Loss: 2.3350\n",
      "Validation Loss: 1858.2863\n",
      "Epoch [1561/3000], Loss: 1.8740\n",
      "Validation Loss: 1852.7779\n",
      "Epoch [1581/3000], Loss: 1.6600\n",
      "Validation Loss: 1842.6614\n",
      "Epoch [1601/3000], Loss: 1.6803\n",
      "Validation Loss: 1851.1404\n",
      "Epoch [1621/3000], Loss: 1.6385\n",
      "Validation Loss: 1848.0248\n",
      "Epoch [1641/3000], Loss: 1.5071\n",
      "Validation Loss: 1841.2571\n",
      "Epoch [1661/3000], Loss: 1.1869\n",
      "Validation Loss: 1811.4790\n",
      "Epoch [1681/3000], Loss: 1.1103\n",
      "Validation Loss: 1817.2506\n",
      "Epoch [1701/3000], Loss: 1.0993\n",
      "Validation Loss: 1811.5599\n",
      "Epoch [1721/3000], Loss: 1.1332\n",
      "Validation Loss: 1824.1107\n",
      "Epoch [1741/3000], Loss: 1.1097\n",
      "Validation Loss: 1826.7519\n",
      "Epoch [1761/3000], Loss: 0.9938\n",
      "Validation Loss: 1807.3506\n",
      "Epoch [1781/3000], Loss: 1.1006\n",
      "Validation Loss: 1816.3051\n",
      "Epoch [1801/3000], Loss: 0.8898\n",
      "Validation Loss: 1808.0538\n",
      "Epoch [1821/3000], Loss: 0.7882\n",
      "Validation Loss: 1808.2195\n",
      "Epoch [1841/3000], Loss: 0.7873\n",
      "Validation Loss: 1799.3077\n",
      "Epoch [1861/3000], Loss: 1.1746\n",
      "Validation Loss: 1842.5784\n",
      "Epoch [1881/3000], Loss: 0.6968\n",
      "Validation Loss: 1823.6497\n",
      "Epoch [1901/3000], Loss: 0.7162\n",
      "Validation Loss: 1825.5519\n",
      "Epoch [1921/3000], Loss: 0.7136\n",
      "Validation Loss: 1807.9862\n",
      "Epoch [1941/3000], Loss: 0.7988\n",
      "Validation Loss: 1833.7705\n",
      "Epoch [1961/3000], Loss: 0.8344\n",
      "Validation Loss: 1793.4013\n",
      "Epoch [1981/3000], Loss: 0.7198\n",
      "Validation Loss: 1807.1340\n",
      "Epoch [2001/3000], Loss: 0.6569\n",
      "Validation Loss: 1803.7628\n",
      "Epoch [2021/3000], Loss: 0.7011\n",
      "Validation Loss: 1805.8917\n",
      "Epoch [2041/3000], Loss: 0.5392\n",
      "Validation Loss: 1797.6272\n",
      "Epoch [2061/3000], Loss: 0.5000\n",
      "Validation Loss: 1796.6572\n",
      "Epoch [2081/3000], Loss: 0.5187\n",
      "Validation Loss: 1790.9811\n",
      "Epoch [2101/3000], Loss: 0.5351\n",
      "Validation Loss: 1789.3723\n",
      "Epoch [2121/3000], Loss: 0.6102\n",
      "Validation Loss: 1782.8849\n",
      "Epoch [2141/3000], Loss: 0.4780\n",
      "Validation Loss: 1787.8950\n",
      "Epoch [2161/3000], Loss: 0.8855\n",
      "Validation Loss: 1805.7459\n",
      "Epoch [2181/3000], Loss: 0.4476\n",
      "Validation Loss: 1787.8345\n",
      "Epoch [2201/3000], Loss: 1.0365\n",
      "Validation Loss: 1802.7477\n",
      "Epoch [2221/3000], Loss: 0.4771\n",
      "Validation Loss: 1783.7993\n",
      "Epoch [2241/3000], Loss: 0.4085\n",
      "Validation Loss: 1781.8385\n",
      "Epoch [2261/3000], Loss: 0.3587\n",
      "Validation Loss: 1782.4167\n",
      "Epoch [2281/3000], Loss: 0.3994\n",
      "Validation Loss: 1789.8916\n",
      "Epoch [2301/3000], Loss: 0.3006\n",
      "Validation Loss: 1784.3802\n",
      "Epoch [2321/3000], Loss: 0.2977\n",
      "Validation Loss: 1791.2823\n",
      "Epoch [2341/3000], Loss: 0.3018\n",
      "Validation Loss: 1781.0294\n",
      "Epoch [2361/3000], Loss: 0.3336\n",
      "Validation Loss: 1773.8872\n",
      "Epoch [2381/3000], Loss: 0.3359\n",
      "Validation Loss: 1768.8270\n",
      "Epoch [2401/3000], Loss: 0.3828\n",
      "Validation Loss: 1800.4296\n",
      "Epoch [2421/3000], Loss: 0.2898\n",
      "Validation Loss: 1795.8066\n",
      "Epoch [2441/3000], Loss: 0.2718\n",
      "Validation Loss: 1787.6933\n",
      "Epoch [2461/3000], Loss: 0.2807\n",
      "Validation Loss: 1777.7470\n",
      "Epoch [2481/3000], Loss: 0.3115\n",
      "Validation Loss: 1785.8985\n",
      "Epoch [2501/3000], Loss: 0.3238\n",
      "Validation Loss: 1783.6535\n",
      "Epoch [2521/3000], Loss: 0.2670\n",
      "Validation Loss: 1774.5183\n",
      "Epoch [2541/3000], Loss: 0.3309\n",
      "Validation Loss: 1772.1333\n",
      "Epoch [2561/3000], Loss: 0.5457\n",
      "Validation Loss: 1822.3097\n",
      "Epoch [2581/3000], Loss: 0.2692\n",
      "Validation Loss: 1775.6554\n",
      "Epoch [2601/3000], Loss: 0.4870\n",
      "Validation Loss: 1774.1708\n",
      "Epoch [2621/3000], Loss: 0.2352\n",
      "Validation Loss: 1774.3743\n",
      "Epoch [2641/3000], Loss: 0.2678\n",
      "Validation Loss: 1765.6385\n",
      "Epoch [2661/3000], Loss: 0.3005\n",
      "Validation Loss: 1765.8466\n",
      "Epoch [2681/3000], Loss: 0.2949\n",
      "Validation Loss: 1790.2553\n",
      "Epoch [2701/3000], Loss: 0.2219\n",
      "Validation Loss: 1765.7734\n",
      "Epoch [2721/3000], Loss: 0.2379\n",
      "Validation Loss: 1757.5387\n",
      "Epoch [2741/3000], Loss: 0.2387\n",
      "Validation Loss: 1751.5289\n",
      "Epoch [2761/3000], Loss: 0.1737\n",
      "Validation Loss: 1754.2194\n",
      "Epoch [2781/3000], Loss: 0.1641\n",
      "Validation Loss: 1757.7108\n",
      "Epoch [2801/3000], Loss: 0.1658\n",
      "Validation Loss: 1760.6702\n",
      "Epoch [2821/3000], Loss: 0.1709\n",
      "Validation Loss: 1769.2124\n",
      "Epoch [2841/3000], Loss: 0.2240\n",
      "Validation Loss: 1748.9399\n",
      "Epoch [2861/3000], Loss: 0.1883\n",
      "Validation Loss: 1761.6474\n",
      "Epoch [2881/3000], Loss: 0.2101\n",
      "Validation Loss: 1769.4774\n",
      "Epoch [2901/3000], Loss: 0.2949\n",
      "Validation Loss: 1759.8384\n",
      "Epoch [2921/3000], Loss: 0.2107\n",
      "Validation Loss: 1776.7434\n",
      "Epoch [2941/3000], Loss: 0.1536\n",
      "Validation Loss: 1776.5085\n",
      "Epoch [2961/3000], Loss: 0.1411\n",
      "Validation Loss: 1774.1732\n",
      "Epoch [2981/3000], Loss: 0.1409\n",
      "Validation Loss: 1771.4962\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day012_plane0_Fall.mat\n",
      "(10140, 98)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9036.6209\n",
      "Validation Loss: 8200.0754\n",
      "Epoch [21/3000], Loss: 7560.4901\n",
      "Validation Loss: 6865.4179\n",
      "Epoch [41/3000], Loss: 7237.2581\n",
      "Validation Loss: 6578.4286\n",
      "Epoch [61/3000], Loss: 6954.0351\n",
      "Validation Loss: 6334.0171\n",
      "Epoch [81/3000], Loss: 6734.2617\n",
      "Validation Loss: 6109.5279\n",
      "Epoch [101/3000], Loss: 6472.1097\n",
      "Validation Loss: 5891.4316\n",
      "Epoch [121/3000], Loss: 6238.2561\n",
      "Validation Loss: 5687.1192\n",
      "Epoch [141/3000], Loss: 6025.9876\n",
      "Validation Loss: 5491.4710\n",
      "Epoch [161/3000], Loss: 5809.9286\n",
      "Validation Loss: 5303.6473\n",
      "Epoch [181/3000], Loss: 5607.6416\n",
      "Validation Loss: 5123.6313\n",
      "Epoch [201/3000], Loss: 5391.0154\n",
      "Validation Loss: 4951.1561\n",
      "Epoch [221/3000], Loss: 5215.8999\n",
      "Validation Loss: 4786.2141\n",
      "Epoch [241/3000], Loss: 5031.0407\n",
      "Validation Loss: 4628.7589\n",
      "Epoch [261/3000], Loss: 4828.6519\n",
      "Validation Loss: 4478.7430\n",
      "Epoch [281/3000], Loss: 4681.9868\n",
      "Validation Loss: 4335.9379\n",
      "Epoch [301/3000], Loss: 4517.6206\n",
      "Validation Loss: 4200.5589\n",
      "Epoch [321/3000], Loss: 4350.6796\n",
      "Validation Loss: 4072.6148\n",
      "Epoch [341/3000], Loss: 4219.9027\n",
      "Validation Loss: 3950.2624\n",
      "Epoch [361/3000], Loss: 4083.4159\n",
      "Validation Loss: 3836.2598\n",
      "Epoch [381/3000], Loss: 3948.8241\n",
      "Validation Loss: 3729.7100\n",
      "Epoch [401/3000], Loss: 3806.7102\n",
      "Validation Loss: 3630.4176\n",
      "Epoch [421/3000], Loss: 3708.8094\n",
      "Validation Loss: 3538.3582\n",
      "Epoch [441/3000], Loss: 3597.1144\n",
      "Validation Loss: 3453.4457\n",
      "Epoch [461/3000], Loss: 3491.8957\n",
      "Validation Loss: 3375.6833\n",
      "Epoch [481/3000], Loss: 3396.1588\n",
      "Validation Loss: 3304.9171\n",
      "Epoch [501/3000], Loss: 3307.4291\n",
      "Validation Loss: 3241.0999\n",
      "Epoch [521/3000], Loss: 3227.6415\n",
      "Validation Loss: 3184.2463\n",
      "Epoch [541/3000], Loss: 3152.0988\n",
      "Validation Loss: 3134.0817\n",
      "Epoch [561/3000], Loss: 3080.3845\n",
      "Validation Loss: 3090.6750\n",
      "Epoch [581/3000], Loss: 3022.4532\n",
      "Validation Loss: 3053.8404\n",
      "Epoch [601/3000], Loss: 2960.0916\n",
      "Validation Loss: 3023.3786\n",
      "Epoch [621/3000], Loss: 2920.4873\n",
      "Validation Loss: 2999.0616\n",
      "Epoch [641/3000], Loss: 2881.4589\n",
      "Validation Loss: 2980.7320\n",
      "Epoch [661/3000], Loss: 2849.3855\n",
      "Validation Loss: 2968.0705\n",
      "Epoch [681/3000], Loss: 2817.7643\n",
      "Validation Loss: 2960.6498\n",
      "Epoch [701/3000], Loss: 2790.1043\n",
      "Validation Loss: 2958.0130\n",
      "Epoch [721/3000], Loss: 2768.9147\n",
      "Validation Loss: 2959.5332\n",
      "Epoch [741/3000], Loss: 2755.0746\n",
      "Validation Loss: 2964.3456\n",
      "Epoch [761/3000], Loss: 2751.1642\n",
      "Validation Loss: 2971.3546\n",
      "Epoch [781/3000], Loss: 2749.4296\n",
      "Validation Loss: 2979.3762\n",
      "Epoch [801/3000], Loss: 2738.7637\n",
      "Validation Loss: 2987.2282\n",
      "Epoch [821/3000], Loss: 2742.5495\n",
      "Validation Loss: 2993.6010\n",
      "Epoch [841/3000], Loss: 2743.5094\n",
      "Validation Loss: 2998.1818\n",
      "Epoch [861/3000], Loss: 2743.2735\n",
      "Validation Loss: 3001.2540\n",
      "Epoch [881/3000], Loss: 2743.6871\n",
      "Validation Loss: 3002.9966\n",
      "Epoch [901/3000], Loss: 2744.3905\n",
      "Validation Loss: 3004.0949\n",
      "Epoch [921/3000], Loss: 2742.1786\n",
      "Validation Loss: 3004.7189\n",
      "Epoch [941/3000], Loss: 2742.1800\n",
      "Validation Loss: 3004.8822\n",
      "Epoch [961/3000], Loss: 2746.9052\n",
      "Validation Loss: 3005.2139\n",
      "Epoch [981/3000], Loss: 2741.7232\n",
      "Validation Loss: 3005.2156\n",
      "Epoch [1001/3000], Loss: 2739.1956\n",
      "Validation Loss: 3005.3208\n",
      "Epoch [1021/3000], Loss: 2741.2979\n",
      "Validation Loss: 3005.2391\n",
      "Epoch [1041/3000], Loss: 2737.0101\n",
      "Validation Loss: 3005.3092\n",
      "Epoch [1061/3000], Loss: 2741.4294\n",
      "Validation Loss: 3005.3104\n",
      "Epoch [1081/3000], Loss: 1642.9347\n",
      "Validation Loss: 1557.5892\n",
      "Epoch [1101/3000], Loss: 1419.0655\n",
      "Validation Loss: 1532.6104\n",
      "Epoch [1121/3000], Loss: 1283.0150\n",
      "Validation Loss: 1509.2298\n",
      "Epoch [1141/3000], Loss: 1188.8083\n",
      "Validation Loss: 1497.5470\n",
      "Epoch [1161/3000], Loss: 1103.2965\n",
      "Validation Loss: 1524.6387\n",
      "Epoch [1181/3000], Loss: 1032.4464\n",
      "Validation Loss: 1511.9559\n",
      "Epoch [1201/3000], Loss: 967.1966\n",
      "Validation Loss: 1478.3018\n",
      "Epoch [1221/3000], Loss: 909.1653\n",
      "Validation Loss: 1443.2231\n",
      "Epoch [1241/3000], Loss: 853.2016\n",
      "Validation Loss: 1387.3889\n",
      "Epoch [1261/3000], Loss: 787.3902\n",
      "Validation Loss: 1391.4954\n",
      "Epoch [1281/3000], Loss: 740.3302\n",
      "Validation Loss: 1348.6149\n",
      "Epoch [1301/3000], Loss: 697.9498\n",
      "Validation Loss: 1339.5183\n",
      "Epoch [1321/3000], Loss: 657.2670\n",
      "Validation Loss: 1245.2832\n",
      "Epoch [1341/3000], Loss: 612.0614\n",
      "Validation Loss: 1300.7921\n",
      "Epoch [1361/3000], Loss: 566.9627\n",
      "Validation Loss: 1253.9914\n",
      "Epoch [1381/3000], Loss: 534.6238\n",
      "Validation Loss: 1210.3914\n",
      "Epoch [1401/3000], Loss: 506.7600\n",
      "Validation Loss: 1162.8216\n",
      "Epoch [1421/3000], Loss: 475.5107\n",
      "Validation Loss: 1258.8947\n",
      "Epoch [1441/3000], Loss: 444.2541\n",
      "Validation Loss: 1262.5232\n",
      "Epoch [1461/3000], Loss: 408.0033\n",
      "Validation Loss: 1259.0930\n",
      "Epoch [1481/3000], Loss: 360.2739\n",
      "Validation Loss: 1338.7949\n",
      "Epoch [1501/3000], Loss: 329.6513\n",
      "Validation Loss: 1366.2933\n",
      "Epoch [1521/3000], Loss: 303.2046\n",
      "Validation Loss: 1282.0499\n",
      "Epoch [1541/3000], Loss: 289.9037\n",
      "Validation Loss: 1397.6996\n",
      "Epoch [1561/3000], Loss: 260.4849\n",
      "Validation Loss: 1279.1611\n",
      "Epoch [1581/3000], Loss: 242.4545\n",
      "Validation Loss: 1251.8083\n",
      "Epoch [1601/3000], Loss: 226.1145\n",
      "Validation Loss: 1284.2362\n",
      "Epoch [1621/3000], Loss: 201.2331\n",
      "Validation Loss: 1275.3195\n",
      "Epoch [1641/3000], Loss: 191.0356\n",
      "Validation Loss: 1271.9149\n",
      "Epoch [1661/3000], Loss: 173.8836\n",
      "Validation Loss: 1341.3062\n",
      "Epoch [1681/3000], Loss: 152.6317\n",
      "Validation Loss: 1320.2466\n",
      "Epoch [1701/3000], Loss: 134.8012\n",
      "Validation Loss: 1359.8182\n",
      "Epoch [1721/3000], Loss: 133.4929\n",
      "Validation Loss: 1439.1887\n",
      "Epoch [1741/3000], Loss: 105.4357\n",
      "Validation Loss: 1383.3713\n",
      "Epoch [1761/3000], Loss: 98.7382\n",
      "Validation Loss: 1487.2119\n",
      "Epoch [1781/3000], Loss: 85.5581\n",
      "Validation Loss: 1302.6975\n",
      "Epoch [1801/3000], Loss: 77.8414\n",
      "Validation Loss: 1369.7326\n",
      "Epoch [1821/3000], Loss: 71.1788\n",
      "Validation Loss: 1336.7528\n",
      "Epoch [1841/3000], Loss: 65.0571\n",
      "Validation Loss: 1481.2362\n",
      "Epoch [1861/3000], Loss: 60.9971\n",
      "Validation Loss: 1341.4074\n",
      "Epoch [1881/3000], Loss: 57.0353\n",
      "Validation Loss: 1403.4233\n",
      "Epoch [1901/3000], Loss: 51.8178\n",
      "Validation Loss: 1386.0697\n",
      "Epoch [1921/3000], Loss: 88.6742\n",
      "Validation Loss: 1531.2788\n",
      "Epoch [1941/3000], Loss: 44.9463\n",
      "Validation Loss: 1389.6670\n",
      "Epoch [1961/3000], Loss: 40.8143\n",
      "Validation Loss: 1404.4334\n",
      "Epoch [1981/3000], Loss: 36.7398\n",
      "Validation Loss: 1355.3200\n",
      "Epoch [2001/3000], Loss: 34.4215\n",
      "Validation Loss: 1365.2014\n",
      "Epoch [2021/3000], Loss: 29.9967\n",
      "Validation Loss: 1435.7937\n",
      "Epoch [2041/3000], Loss: 27.6854\n",
      "Validation Loss: 1419.3570\n",
      "Epoch [2061/3000], Loss: 25.4769\n",
      "Validation Loss: 1372.1603\n",
      "Epoch [2081/3000], Loss: 22.5105\n",
      "Validation Loss: 1345.7102\n",
      "Epoch [2101/3000], Loss: 20.3700\n",
      "Validation Loss: 1378.4222\n",
      "Epoch [2121/3000], Loss: 18.6482\n",
      "Validation Loss: 1383.3998\n",
      "Epoch [2141/3000], Loss: 20.8487\n",
      "Validation Loss: 1345.4206\n",
      "Epoch [2161/3000], Loss: 15.9501\n",
      "Validation Loss: 1403.8171\n",
      "Epoch [2181/3000], Loss: 15.1205\n",
      "Validation Loss: 1304.5855\n",
      "Epoch [2201/3000], Loss: 13.8866\n",
      "Validation Loss: 1469.1454\n",
      "Epoch [2221/3000], Loss: 12.0042\n",
      "Validation Loss: 1387.5458\n",
      "Epoch [2241/3000], Loss: 11.0746\n",
      "Validation Loss: 1402.4772\n",
      "Epoch [2261/3000], Loss: 10.2009\n",
      "Validation Loss: 1403.7839\n",
      "Epoch [2281/3000], Loss: 39.3290\n",
      "Validation Loss: 1688.6816\n",
      "Epoch [2301/3000], Loss: 8.9389\n",
      "Validation Loss: 1425.7505\n",
      "Epoch [2321/3000], Loss: 8.4212\n",
      "Validation Loss: 1422.3692\n",
      "Epoch [2341/3000], Loss: 7.8245\n",
      "Validation Loss: 1426.7576\n",
      "Epoch [2361/3000], Loss: 7.3205\n",
      "Validation Loss: 1445.8179\n",
      "Epoch [2381/3000], Loss: 9.5388\n",
      "Validation Loss: 1397.8023\n",
      "Epoch [2401/3000], Loss: 6.4780\n",
      "Validation Loss: 1429.1182\n",
      "Epoch [2421/3000], Loss: 6.0528\n",
      "Validation Loss: 1428.3968\n",
      "Epoch [2441/3000], Loss: 5.8278\n",
      "Validation Loss: 1438.5731\n",
      "Epoch [2461/3000], Loss: 5.4389\n",
      "Validation Loss: 1445.4028\n",
      "Epoch [2481/3000], Loss: 5.2841\n",
      "Validation Loss: 1453.2947\n",
      "Epoch [2501/3000], Loss: 4.9574\n",
      "Validation Loss: 1449.9095\n",
      "Epoch [2521/3000], Loss: 4.6946\n",
      "Validation Loss: 1448.1138\n",
      "Epoch [2541/3000], Loss: 4.4824\n",
      "Validation Loss: 1469.2157\n",
      "Epoch [2561/3000], Loss: 4.2919\n",
      "Validation Loss: 1403.9648\n",
      "Epoch [2581/3000], Loss: 3.7980\n",
      "Validation Loss: 1499.4413\n",
      "Epoch [2601/3000], Loss: 23.9562\n",
      "Validation Loss: 1433.2798\n",
      "Epoch [2621/3000], Loss: 3.4294\n",
      "Validation Loss: 1468.1196\n",
      "Epoch [2641/3000], Loss: 3.2625\n",
      "Validation Loss: 1462.9090\n",
      "Epoch [2661/3000], Loss: 3.0972\n",
      "Validation Loss: 1488.7735\n",
      "Epoch [2681/3000], Loss: 2.9640\n",
      "Validation Loss: 1482.8099\n",
      "Epoch [2701/3000], Loss: 2.7175\n",
      "Validation Loss: 1475.2879\n",
      "Epoch [2721/3000], Loss: 2.4957\n",
      "Validation Loss: 1490.4603\n",
      "Epoch [2741/3000], Loss: 2.7079\n",
      "Validation Loss: 1460.2602\n",
      "Epoch [2761/3000], Loss: 2.3494\n",
      "Validation Loss: 1495.9560\n",
      "Epoch [2781/3000], Loss: 2.2347\n",
      "Validation Loss: 1510.2662\n",
      "Epoch [2801/3000], Loss: 2.1584\n",
      "Validation Loss: 1495.0382\n",
      "Epoch [2821/3000], Loss: 2.0770\n",
      "Validation Loss: 1497.6809\n",
      "Epoch [2841/3000], Loss: 1.9061\n",
      "Validation Loss: 1492.5538\n",
      "Epoch [2861/3000], Loss: 1.7985\n",
      "Validation Loss: 1507.4547\n",
      "Epoch [2881/3000], Loss: 1.7242\n",
      "Validation Loss: 1493.5768\n",
      "Epoch [2901/3000], Loss: 1.6895\n",
      "Validation Loss: 1505.2059\n",
      "Epoch [2921/3000], Loss: 1.5171\n",
      "Validation Loss: 1523.3842\n",
      "Epoch [2941/3000], Loss: 1.4554\n",
      "Validation Loss: 1518.7594\n",
      "Epoch [2961/3000], Loss: 1.4078\n",
      "Validation Loss: 1514.9044\n",
      "Epoch [2981/3000], Loss: 1.3510\n",
      "Validation Loss: 1519.1069\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day014_plane0_Fall.mat\n",
      "(12439, 125)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8599.3552\n",
      "Validation Loss: 6788.6706\n",
      "Epoch [21/3000], Loss: 7103.1409\n",
      "Validation Loss: 5514.5768\n",
      "Epoch [41/3000], Loss: 6778.2045\n",
      "Validation Loss: 5234.3323\n",
      "Epoch [61/3000], Loss: 6467.8235\n",
      "Validation Loss: 4989.5878\n",
      "Epoch [81/3000], Loss: 6205.5877\n",
      "Validation Loss: 4764.1113\n",
      "Epoch [101/3000], Loss: 5950.2443\n",
      "Validation Loss: 4552.5175\n",
      "Epoch [121/3000], Loss: 5699.9303\n",
      "Validation Loss: 4353.3154\n",
      "Epoch [141/3000], Loss: 5467.7596\n",
      "Validation Loss: 4165.8321\n",
      "Epoch [161/3000], Loss: 5253.1582\n",
      "Validation Loss: 3989.2501\n",
      "Epoch [181/3000], Loss: 5025.4912\n",
      "Validation Loss: 3822.6910\n",
      "Epoch [201/3000], Loss: 4826.6209\n",
      "Validation Loss: 3668.4867\n",
      "Epoch [221/3000], Loss: 4639.4366\n",
      "Validation Loss: 3525.4657\n",
      "Epoch [241/3000], Loss: 4452.0029\n",
      "Validation Loss: 3393.6048\n",
      "Epoch [261/3000], Loss: 4287.1791\n",
      "Validation Loss: 3272.6974\n",
      "Epoch [281/3000], Loss: 4141.3734\n",
      "Validation Loss: 3162.7636\n",
      "Epoch [301/3000], Loss: 4002.0871\n",
      "Validation Loss: 3063.6149\n",
      "Epoch [321/3000], Loss: 3861.7176\n",
      "Validation Loss: 2975.2803\n",
      "Epoch [341/3000], Loss: 3738.9172\n",
      "Validation Loss: 2896.6519\n",
      "Epoch [361/3000], Loss: 3625.5755\n",
      "Validation Loss: 2829.1023\n",
      "Epoch [381/3000], Loss: 3530.6768\n",
      "Validation Loss: 2772.1488\n",
      "Epoch [401/3000], Loss: 3445.5982\n",
      "Validation Loss: 2725.3791\n",
      "Epoch [421/3000], Loss: 3355.8521\n",
      "Validation Loss: 2688.5023\n",
      "Epoch [441/3000], Loss: 3295.1167\n",
      "Validation Loss: 2661.2715\n",
      "Epoch [461/3000], Loss: 3227.1708\n",
      "Validation Loss: 2643.2415\n",
      "Epoch [481/3000], Loss: 3183.9859\n",
      "Validation Loss: 2633.9064\n",
      "Epoch [501/3000], Loss: 3142.4870\n",
      "Validation Loss: 2632.5587\n",
      "Epoch [521/3000], Loss: 3111.6510\n",
      "Validation Loss: 2638.2388\n",
      "Epoch [541/3000], Loss: 3088.5475\n",
      "Validation Loss: 2649.6618\n",
      "Epoch [561/3000], Loss: 3075.4144\n",
      "Validation Loss: 2648.4365\n",
      "Epoch [581/3000], Loss: 1983.4159\n",
      "Validation Loss: 1502.9957\n",
      "Epoch [601/3000], Loss: 1716.1687\n",
      "Validation Loss: 1403.7882\n",
      "Epoch [621/3000], Loss: 1553.4309\n",
      "Validation Loss: 1339.3712\n",
      "Epoch [641/3000], Loss: 1424.7197\n",
      "Validation Loss: 1308.2459\n",
      "Epoch [661/3000], Loss: 1295.8190\n",
      "Validation Loss: 1249.1196\n",
      "Epoch [681/3000], Loss: 1193.7576\n",
      "Validation Loss: 1190.4321\n",
      "Epoch [701/3000], Loss: 1088.3012\n",
      "Validation Loss: 1136.8668\n",
      "Epoch [721/3000], Loss: 1002.2027\n",
      "Validation Loss: 1092.7537\n",
      "Epoch [741/3000], Loss: 912.5313\n",
      "Validation Loss: 1054.6253\n",
      "Epoch [761/3000], Loss: 838.9291\n",
      "Validation Loss: 1019.0828\n",
      "Epoch [781/3000], Loss: 769.7545\n",
      "Validation Loss: 1000.4433\n",
      "Epoch [801/3000], Loss: 705.4881\n",
      "Validation Loss: 962.9163\n",
      "Epoch [821/3000], Loss: 650.0095\n",
      "Validation Loss: 949.6115\n",
      "Epoch [841/3000], Loss: 596.0629\n",
      "Validation Loss: 907.8377\n",
      "Epoch [861/3000], Loss: 545.4260\n",
      "Validation Loss: 894.5676\n",
      "Epoch [881/3000], Loss: 495.6114\n",
      "Validation Loss: 836.1992\n",
      "Epoch [901/3000], Loss: 441.6869\n",
      "Validation Loss: 810.9992\n",
      "Epoch [921/3000], Loss: 398.7200\n",
      "Validation Loss: 819.9220\n",
      "Epoch [941/3000], Loss: 354.1897\n",
      "Validation Loss: 789.4241\n",
      "Epoch [961/3000], Loss: 311.4468\n",
      "Validation Loss: 785.4950\n",
      "Epoch [981/3000], Loss: 277.3190\n",
      "Validation Loss: 773.3497\n",
      "Epoch [1001/3000], Loss: 245.6014\n",
      "Validation Loss: 781.8794\n",
      "Epoch [1021/3000], Loss: 218.3702\n",
      "Validation Loss: 823.4002\n",
      "Epoch [1041/3000], Loss: 191.7545\n",
      "Validation Loss: 844.6785\n",
      "Epoch [1061/3000], Loss: 169.9988\n",
      "Validation Loss: 862.3764\n",
      "Epoch [1081/3000], Loss: 150.1423\n",
      "Validation Loss: 910.0990\n",
      "Epoch [1101/3000], Loss: 132.4712\n",
      "Validation Loss: 897.8807\n",
      "Epoch [1121/3000], Loss: 119.0124\n",
      "Validation Loss: 893.6136\n",
      "Epoch [1141/3000], Loss: 103.7171\n",
      "Validation Loss: 926.7762\n",
      "Epoch [1161/3000], Loss: 92.0096\n",
      "Validation Loss: 938.2575\n",
      "Epoch [1181/3000], Loss: 80.1647\n",
      "Validation Loss: 967.5638\n",
      "Epoch [1201/3000], Loss: 67.7325\n",
      "Validation Loss: 965.9193\n",
      "Epoch [1221/3000], Loss: 57.8156\n",
      "Validation Loss: 992.8480\n",
      "Epoch [1241/3000], Loss: 47.8354\n",
      "Validation Loss: 1054.9243\n",
      "Epoch [1261/3000], Loss: 39.9530\n",
      "Validation Loss: 1052.9769\n",
      "Epoch [1281/3000], Loss: 32.9914\n",
      "Validation Loss: 1090.3542\n",
      "Epoch [1301/3000], Loss: 27.4679\n",
      "Validation Loss: 1107.5449\n",
      "Epoch [1321/3000], Loss: 22.2713\n",
      "Validation Loss: 1119.4242\n",
      "Epoch [1341/3000], Loss: 18.7834\n",
      "Validation Loss: 1102.7998\n",
      "Epoch [1361/3000], Loss: 15.6810\n",
      "Validation Loss: 1109.4175\n",
      "Epoch [1381/3000], Loss: 12.7601\n",
      "Validation Loss: 1120.3722\n",
      "Epoch [1401/3000], Loss: 10.1816\n",
      "Validation Loss: 1120.7395\n",
      "Epoch [1421/3000], Loss: 8.7926\n",
      "Validation Loss: 1110.5136\n",
      "Epoch [1441/3000], Loss: 7.5547\n",
      "Validation Loss: 1103.4007\n",
      "Epoch [1461/3000], Loss: 6.3738\n",
      "Validation Loss: 1092.6234\n",
      "Epoch [1481/3000], Loss: 5.2795\n",
      "Validation Loss: 1064.5902\n",
      "Epoch [1501/3000], Loss: 4.5577\n",
      "Validation Loss: 1077.2691\n",
      "Epoch [1521/3000], Loss: 3.9549\n",
      "Validation Loss: 1069.3085\n",
      "Epoch [1541/3000], Loss: 3.4802\n",
      "Validation Loss: 1055.4860\n",
      "Epoch [1561/3000], Loss: 3.0236\n",
      "Validation Loss: 1047.5786\n",
      "Epoch [1581/3000], Loss: 2.6469\n",
      "Validation Loss: 1020.1455\n",
      "Epoch [1601/3000], Loss: 2.0729\n",
      "Validation Loss: 1023.5918\n",
      "Epoch [1621/3000], Loss: 2.3168\n",
      "Validation Loss: 979.7692\n",
      "Epoch [1641/3000], Loss: 1.7304\n",
      "Validation Loss: 998.6964\n",
      "Epoch [1661/3000], Loss: 1.5721\n",
      "Validation Loss: 1000.6643\n",
      "Epoch [1681/3000], Loss: 1.4343\n",
      "Validation Loss: 1005.6636\n",
      "Epoch [1701/3000], Loss: 1.3357\n",
      "Validation Loss: 1006.0243\n",
      "Epoch [1721/3000], Loss: 1.2207\n",
      "Validation Loss: 999.0899\n",
      "Epoch [1741/3000], Loss: 1.0261\n",
      "Validation Loss: 993.0376\n",
      "Epoch [1761/3000], Loss: 0.9189\n",
      "Validation Loss: 991.4371\n",
      "Epoch [1781/3000], Loss: 0.7975\n",
      "Validation Loss: 987.2035\n",
      "Epoch [1801/3000], Loss: 0.6906\n",
      "Validation Loss: 982.9220\n",
      "Epoch [1821/3000], Loss: 0.9630\n",
      "Validation Loss: 949.3927\n",
      "Epoch [1841/3000], Loss: 0.5977\n",
      "Validation Loss: 968.6399\n",
      "Epoch [1861/3000], Loss: 0.5547\n",
      "Validation Loss: 974.0801\n",
      "Epoch [1881/3000], Loss: 0.5324\n",
      "Validation Loss: 975.8850\n",
      "Epoch [1901/3000], Loss: 0.5124\n",
      "Validation Loss: 978.5760\n",
      "Epoch [1921/3000], Loss: 0.4924\n",
      "Validation Loss: 977.2955\n",
      "Epoch [1941/3000], Loss: 0.4602\n",
      "Validation Loss: 979.3650\n",
      "Epoch [1961/3000], Loss: 0.4397\n",
      "Validation Loss: 981.0447\n",
      "Epoch [1981/3000], Loss: 0.4284\n",
      "Validation Loss: 978.3228\n",
      "Epoch [2001/3000], Loss: 0.3828\n",
      "Validation Loss: 986.1498\n",
      "Epoch [2021/3000], Loss: 0.3528\n",
      "Validation Loss: 983.2968\n",
      "Epoch [2041/3000], Loss: 0.3260\n",
      "Validation Loss: 989.1992\n",
      "Epoch [2061/3000], Loss: 0.3284\n",
      "Validation Loss: 982.4251\n",
      "Epoch [2081/3000], Loss: 0.3543\n",
      "Validation Loss: 987.3367\n",
      "Epoch [2101/3000], Loss: 0.3008\n",
      "Validation Loss: 985.0252\n",
      "Epoch [2121/3000], Loss: 0.5368\n",
      "Validation Loss: 977.5837\n",
      "Epoch [2141/3000], Loss: 0.2462\n",
      "Validation Loss: 979.4116\n",
      "Epoch [2161/3000], Loss: 0.2252\n",
      "Validation Loss: 983.3399\n",
      "Epoch [2181/3000], Loss: 0.2229\n",
      "Validation Loss: 983.6375\n",
      "Epoch [2201/3000], Loss: 0.2225\n",
      "Validation Loss: 982.5851\n",
      "Epoch [2221/3000], Loss: 0.2207\n",
      "Validation Loss: 982.1631\n",
      "Epoch [2241/3000], Loss: 0.2260\n",
      "Validation Loss: 986.2482\n",
      "Epoch [2261/3000], Loss: 0.2463\n",
      "Validation Loss: 988.9496\n",
      "Epoch [2281/3000], Loss: 0.1972\n",
      "Validation Loss: 986.6377\n",
      "Epoch [2301/3000], Loss: 0.2056\n",
      "Validation Loss: 984.8546\n",
      "Epoch [2321/3000], Loss: 0.1905\n",
      "Validation Loss: 984.9422\n",
      "Epoch [2341/3000], Loss: 0.1939\n",
      "Validation Loss: 989.5097\n",
      "Epoch [2361/3000], Loss: 0.7327\n",
      "Validation Loss: 975.1360\n",
      "Epoch [2381/3000], Loss: 0.2327\n",
      "Validation Loss: 975.2301\n",
      "Epoch [2401/3000], Loss: 0.1780\n",
      "Validation Loss: 976.7538\n",
      "Epoch [2421/3000], Loss: 0.1589\n",
      "Validation Loss: 978.2608\n",
      "Epoch [2441/3000], Loss: 0.1541\n",
      "Validation Loss: 980.0494\n",
      "Epoch [2461/3000], Loss: 0.1489\n",
      "Validation Loss: 982.7638\n",
      "Epoch [2481/3000], Loss: 0.1492\n",
      "Validation Loss: 981.5005\n",
      "Epoch [2501/3000], Loss: 0.1523\n",
      "Validation Loss: 981.5437\n",
      "Epoch [2521/3000], Loss: 0.1491\n",
      "Validation Loss: 984.0944\n",
      "Epoch [2541/3000], Loss: 0.1646\n",
      "Validation Loss: 981.3870\n",
      "Epoch [2561/3000], Loss: 0.1561\n",
      "Validation Loss: 981.7127\n",
      "Epoch [2581/3000], Loss: 0.1826\n",
      "Validation Loss: 990.5280\n",
      "Epoch [2601/3000], Loss: 0.1658\n",
      "Validation Loss: 985.5686\n",
      "Epoch [2621/3000], Loss: 0.1473\n",
      "Validation Loss: 985.7563\n",
      "Epoch [2641/3000], Loss: 0.1532\n",
      "Validation Loss: 982.2531\n",
      "Epoch [2661/3000], Loss: 0.1258\n",
      "Validation Loss: 985.5656\n",
      "Epoch [2681/3000], Loss: 0.1317\n",
      "Validation Loss: 984.6695\n",
      "Epoch [2701/3000], Loss: 0.1265\n",
      "Validation Loss: 984.1323\n",
      "Epoch [2721/3000], Loss: 0.1355\n",
      "Validation Loss: 989.5458\n",
      "Epoch [2741/3000], Loss: 0.1052\n",
      "Validation Loss: 986.2546\n",
      "Epoch [2761/3000], Loss: 0.1080\n",
      "Validation Loss: 986.9293\n",
      "Epoch [2781/3000], Loss: 0.1169\n",
      "Validation Loss: 987.6430\n",
      "Epoch [2801/3000], Loss: 0.0999\n",
      "Validation Loss: 984.4643\n",
      "Epoch [2821/3000], Loss: 0.1274\n",
      "Validation Loss: 990.7471\n",
      "Epoch [2841/3000], Loss: 0.0978\n",
      "Validation Loss: 983.2678\n",
      "Epoch [2861/3000], Loss: 0.1119\n",
      "Validation Loss: 991.4955\n",
      "Epoch [2881/3000], Loss: 0.0872\n",
      "Validation Loss: 995.4891\n",
      "Epoch [2901/3000], Loss: 0.0876\n",
      "Validation Loss: 992.5813\n",
      "Epoch [2921/3000], Loss: 0.0872\n",
      "Validation Loss: 992.7399\n",
      "Epoch [2941/3000], Loss: 0.0871\n",
      "Validation Loss: 994.4536\n",
      "Epoch [2961/3000], Loss: 7.0685\n",
      "Validation Loss: 1021.6879\n",
      "Epoch [2981/3000], Loss: 0.1447\n",
      "Validation Loss: 983.1997\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day016_plane0_Fall.mat\n",
      "(17289, 155)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9448.6769\n",
      "Validation Loss: 9476.6891\n",
      "Epoch [21/3000], Loss: 7691.7111\n",
      "Validation Loss: 7707.9340\n",
      "Epoch [41/3000], Loss: 7192.3614\n",
      "Validation Loss: 7242.2519\n",
      "Epoch [61/3000], Loss: 6782.4950\n",
      "Validation Loss: 6822.4615\n",
      "Epoch [81/3000], Loss: 6386.7183\n",
      "Validation Loss: 6430.8388\n",
      "Epoch [101/3000], Loss: 6007.3577\n",
      "Validation Loss: 6063.2310\n",
      "Epoch [121/3000], Loss: 5662.9137\n",
      "Validation Loss: 5718.5950\n",
      "Epoch [141/3000], Loss: 5332.7952\n",
      "Validation Loss: 5396.3180\n",
      "Epoch [161/3000], Loss: 5037.2356\n",
      "Validation Loss: 5096.2078\n",
      "Epoch [181/3000], Loss: 4749.3672\n",
      "Validation Loss: 4818.1808\n",
      "Epoch [201/3000], Loss: 4486.0855\n",
      "Validation Loss: 4558.2379\n",
      "Epoch [221/3000], Loss: 4248.7099\n",
      "Validation Loss: 4321.7387\n",
      "Epoch [241/3000], Loss: 4025.9999\n",
      "Validation Loss: 4108.2769\n",
      "Epoch [261/3000], Loss: 3834.7582\n",
      "Validation Loss: 3916.6054\n",
      "Epoch [281/3000], Loss: 3659.4798\n",
      "Validation Loss: 3746.6212\n",
      "Epoch [301/3000], Loss: 3505.5729\n",
      "Validation Loss: 3598.0809\n",
      "Epoch [321/3000], Loss: 3375.2515\n",
      "Validation Loss: 3470.4953\n",
      "Epoch [341/3000], Loss: 3267.0378\n",
      "Validation Loss: 3363.6515\n",
      "Epoch [361/3000], Loss: 3178.6800\n",
      "Validation Loss: 3276.8750\n",
      "Epoch [381/3000], Loss: 3103.4258\n",
      "Validation Loss: 3209.3487\n",
      "Epoch [401/3000], Loss: 3052.9959\n",
      "Validation Loss: 3160.1234\n",
      "Epoch [421/3000], Loss: 3013.4136\n",
      "Validation Loss: 3127.5934\n",
      "Epoch [441/3000], Loss: 2994.6619\n",
      "Validation Loss: 3109.1229\n",
      "Epoch [461/3000], Loss: 2982.0506\n",
      "Validation Loss: 3101.1438\n",
      "Epoch [481/3000], Loss: 2981.9801\n",
      "Validation Loss: 3099.0365\n",
      "Epoch [501/3000], Loss: 1854.1385\n",
      "Validation Loss: 2982.6733\n",
      "Epoch [521/3000], Loss: 1501.9583\n",
      "Validation Loss: 2858.3561\n",
      "Epoch [541/3000], Loss: 1331.7444\n",
      "Validation Loss: 2830.1340\n",
      "Epoch [561/3000], Loss: 1185.7189\n",
      "Validation Loss: 2828.5507\n",
      "Epoch [581/3000], Loss: 1062.3461\n",
      "Validation Loss: 2860.4957\n",
      "Epoch [601/3000], Loss: 947.3151\n",
      "Validation Loss: 2809.8892\n",
      "Epoch [621/3000], Loss: 841.6107\n",
      "Validation Loss: 2763.5619\n",
      "Epoch [641/3000], Loss: 752.9859\n",
      "Validation Loss: 2757.4707\n",
      "Epoch [661/3000], Loss: 654.9881\n",
      "Validation Loss: 2733.3438\n",
      "Epoch [681/3000], Loss: 570.4136\n",
      "Validation Loss: 2760.9814\n",
      "Epoch [701/3000], Loss: 493.7092\n",
      "Validation Loss: 2715.3945\n",
      "Epoch [721/3000], Loss: 420.5427\n",
      "Validation Loss: 2675.6348\n",
      "Epoch [741/3000], Loss: 369.3763\n",
      "Validation Loss: 2660.6137\n",
      "Epoch [761/3000], Loss: 316.6728\n",
      "Validation Loss: 2769.0494\n",
      "Epoch [781/3000], Loss: 275.4257\n",
      "Validation Loss: 2686.9978\n",
      "Epoch [801/3000], Loss: 233.3095\n",
      "Validation Loss: 2673.3996\n",
      "Epoch [821/3000], Loss: 202.3279\n",
      "Validation Loss: 2707.7352\n",
      "Epoch [841/3000], Loss: 172.8555\n",
      "Validation Loss: 2646.0352\n",
      "Epoch [861/3000], Loss: 146.7294\n",
      "Validation Loss: 2703.3822\n",
      "Epoch [881/3000], Loss: 123.3144\n",
      "Validation Loss: 2779.8917\n",
      "Epoch [901/3000], Loss: 104.0310\n",
      "Validation Loss: 2762.5100\n",
      "Epoch [921/3000], Loss: 95.8285\n",
      "Validation Loss: 2885.6536\n",
      "Epoch [941/3000], Loss: 71.9374\n",
      "Validation Loss: 2815.6071\n",
      "Epoch [961/3000], Loss: 59.8837\n",
      "Validation Loss: 2844.0500\n",
      "Epoch [981/3000], Loss: 50.4351\n",
      "Validation Loss: 2865.1515\n",
      "Epoch [1001/3000], Loss: 42.6878\n",
      "Validation Loss: 2826.7993\n",
      "Epoch [1021/3000], Loss: 37.0174\n",
      "Validation Loss: 2782.4341\n",
      "Epoch [1041/3000], Loss: 29.6914\n",
      "Validation Loss: 2875.9223\n",
      "Epoch [1061/3000], Loss: 25.5534\n",
      "Validation Loss: 2790.5210\n",
      "Epoch [1081/3000], Loss: 22.0332\n",
      "Validation Loss: 2951.8580\n",
      "Epoch [1101/3000], Loss: 19.0166\n",
      "Validation Loss: 3020.4852\n",
      "Epoch [1121/3000], Loss: 16.5512\n",
      "Validation Loss: 2889.6976\n",
      "Epoch [1141/3000], Loss: 15.6368\n",
      "Validation Loss: 2958.0769\n",
      "Epoch [1161/3000], Loss: 12.4061\n",
      "Validation Loss: 2915.9582\n",
      "Epoch [1181/3000], Loss: 10.9980\n",
      "Validation Loss: 2944.9404\n",
      "Epoch [1201/3000], Loss: 9.8909\n",
      "Validation Loss: 2921.2787\n",
      "Epoch [1221/3000], Loss: 9.0134\n",
      "Validation Loss: 2895.9831\n",
      "Epoch [1241/3000], Loss: 7.6542\n",
      "Validation Loss: 2915.4734\n",
      "Epoch [1261/3000], Loss: 7.0848\n",
      "Validation Loss: 2946.4423\n",
      "Epoch [1281/3000], Loss: 6.6308\n",
      "Validation Loss: 2880.2135\n",
      "Epoch [1301/3000], Loss: 6.3500\n",
      "Validation Loss: 2902.8212\n",
      "Epoch [1321/3000], Loss: 5.1864\n",
      "Validation Loss: 2911.1374\n",
      "Epoch [1341/3000], Loss: 4.4444\n",
      "Validation Loss: 2860.0583\n",
      "Epoch [1361/3000], Loss: 3.9673\n",
      "Validation Loss: 2879.8349\n",
      "Epoch [1381/3000], Loss: 3.6462\n",
      "Validation Loss: 2867.4479\n",
      "Epoch [1401/3000], Loss: 3.4163\n",
      "Validation Loss: 2858.0113\n",
      "Epoch [1421/3000], Loss: 3.2947\n",
      "Validation Loss: 2816.5073\n",
      "Epoch [1441/3000], Loss: 3.0826\n",
      "Validation Loss: 2788.7813\n",
      "Epoch [1461/3000], Loss: 2.6290\n",
      "Validation Loss: 2832.3845\n",
      "Epoch [1481/3000], Loss: 2.4740\n",
      "Validation Loss: 2832.1467\n",
      "Epoch [1501/3000], Loss: 2.4063\n",
      "Validation Loss: 2821.9366\n",
      "Epoch [1521/3000], Loss: 2.3590\n",
      "Validation Loss: 2815.0074\n",
      "Epoch [1541/3000], Loss: 2.2165\n",
      "Validation Loss: 2774.5620\n",
      "Epoch [1561/3000], Loss: 1.8764\n",
      "Validation Loss: 2818.9697\n",
      "Epoch [1581/3000], Loss: 1.6854\n",
      "Validation Loss: 2822.4869\n",
      "Epoch [1601/3000], Loss: 1.5904\n",
      "Validation Loss: 2809.0115\n",
      "Epoch [1621/3000], Loss: 1.5591\n",
      "Validation Loss: 2798.6285\n",
      "Epoch [1641/3000], Loss: 1.5381\n",
      "Validation Loss: 2768.7242\n",
      "Epoch [1661/3000], Loss: 1.3811\n",
      "Validation Loss: 2784.4042\n",
      "Epoch [1681/3000], Loss: 1.2788\n",
      "Validation Loss: 2778.9177\n",
      "Epoch [1701/3000], Loss: 1.2637\n",
      "Validation Loss: 2787.4862\n",
      "Epoch [1721/3000], Loss: 1.2642\n",
      "Validation Loss: 2774.0141\n",
      "Epoch [1741/3000], Loss: 1.2925\n",
      "Validation Loss: 2779.5497\n",
      "Epoch [1761/3000], Loss: 1.2107\n",
      "Validation Loss: 2761.3772\n",
      "Epoch [1781/3000], Loss: 0.9805\n",
      "Validation Loss: 2743.0634\n",
      "Epoch [1801/3000], Loss: 0.8929\n",
      "Validation Loss: 2757.7204\n",
      "Epoch [1821/3000], Loss: 0.8567\n",
      "Validation Loss: 2757.6526\n",
      "Epoch [1841/3000], Loss: 0.8570\n",
      "Validation Loss: 2768.0924\n",
      "Epoch [1861/3000], Loss: 0.8265\n",
      "Validation Loss: 2757.4449\n",
      "Epoch [1881/3000], Loss: 1.0123\n",
      "Validation Loss: 2702.9219\n",
      "Epoch [1901/3000], Loss: 0.7673\n",
      "Validation Loss: 2764.4954\n",
      "Epoch [1921/3000], Loss: 0.7086\n",
      "Validation Loss: 2741.9687\n",
      "Epoch [1941/3000], Loss: 0.6788\n",
      "Validation Loss: 2766.8613\n",
      "Epoch [1961/3000], Loss: 0.6325\n",
      "Validation Loss: 2764.4791\n",
      "Epoch [1981/3000], Loss: 0.7054\n",
      "Validation Loss: 2768.5736\n",
      "Epoch [2001/3000], Loss: 0.5554\n",
      "Validation Loss: 2766.6431\n",
      "Epoch [2021/3000], Loss: 0.5396\n",
      "Validation Loss: 2774.5885\n",
      "Epoch [2041/3000], Loss: 0.5272\n",
      "Validation Loss: 2760.2168\n",
      "Epoch [2061/3000], Loss: 0.5419\n",
      "Validation Loss: 2778.8338\n",
      "Epoch [2081/3000], Loss: 0.5691\n",
      "Validation Loss: 2761.6766\n",
      "Epoch [2101/3000], Loss: 0.5253\n",
      "Validation Loss: 2742.7829\n",
      "Epoch [2121/3000], Loss: 0.5114\n",
      "Validation Loss: 2750.4830\n",
      "Epoch [2141/3000], Loss: 0.5694\n",
      "Validation Loss: 2749.3555\n",
      "Epoch [2161/3000], Loss: 0.4602\n",
      "Validation Loss: 2747.4691\n",
      "Epoch [2181/3000], Loss: 0.4722\n",
      "Validation Loss: 2742.0039\n",
      "Epoch [2201/3000], Loss: 34.8970\n",
      "Validation Loss: 2669.4159\n",
      "Epoch [2221/3000], Loss: 0.3441\n",
      "Validation Loss: 2741.1237\n",
      "Epoch [2241/3000], Loss: 0.3378\n",
      "Validation Loss: 2738.9015\n",
      "Epoch [2261/3000], Loss: 0.3291\n",
      "Validation Loss: 2742.7794\n",
      "Epoch [2281/3000], Loss: 0.3640\n",
      "Validation Loss: 2738.3869\n",
      "Epoch [2301/3000], Loss: 0.3397\n",
      "Validation Loss: 2753.9127\n",
      "Epoch [2321/3000], Loss: 0.3769\n",
      "Validation Loss: 2734.1682\n",
      "Epoch [2341/3000], Loss: 0.3605\n",
      "Validation Loss: 2767.0610\n",
      "Epoch [2361/3000], Loss: 0.3028\n",
      "Validation Loss: 2733.8519\n",
      "Epoch [2381/3000], Loss: 0.3204\n",
      "Validation Loss: 2759.6399\n",
      "Epoch [2401/3000], Loss: 3.9486\n",
      "Validation Loss: 2754.8646\n",
      "Epoch [2421/3000], Loss: 0.3136\n",
      "Validation Loss: 2746.9960\n",
      "Epoch [2441/3000], Loss: 0.2608\n",
      "Validation Loss: 2740.5381\n",
      "Epoch [2461/3000], Loss: 0.2458\n",
      "Validation Loss: 2729.2560\n",
      "Epoch [2481/3000], Loss: 0.2496\n",
      "Validation Loss: 2729.5036\n",
      "Epoch [2501/3000], Loss: 0.2936\n",
      "Validation Loss: 2742.5765\n",
      "Epoch [2521/3000], Loss: 0.2801\n",
      "Validation Loss: 2752.5922\n",
      "Epoch [2541/3000], Loss: 25.8934\n",
      "Validation Loss: 2785.9227\n",
      "Epoch [2561/3000], Loss: 0.2290\n",
      "Validation Loss: 2763.3305\n",
      "Epoch [2581/3000], Loss: 0.2141\n",
      "Validation Loss: 2760.2562\n",
      "Epoch [2601/3000], Loss: 0.2168\n",
      "Validation Loss: 2752.4833\n",
      "Epoch [2621/3000], Loss: 0.2343\n",
      "Validation Loss: 2740.6513\n",
      "Epoch [2641/3000], Loss: 0.2626\n",
      "Validation Loss: 2750.0044\n",
      "Epoch [2661/3000], Loss: 0.2657\n",
      "Validation Loss: 2739.5782\n",
      "Epoch [2681/3000], Loss: 0.2659\n",
      "Validation Loss: 2751.3029\n",
      "Epoch [2701/3000], Loss: 0.2167\n",
      "Validation Loss: 2746.2954\n",
      "Epoch [2721/3000], Loss: 0.3916\n",
      "Validation Loss: 2756.9096\n",
      "Epoch [2741/3000], Loss: 0.2173\n",
      "Validation Loss: 2750.7295\n",
      "Epoch [2761/3000], Loss: 0.2310\n",
      "Validation Loss: 2748.3670\n",
      "Epoch [2781/3000], Loss: 7.9904\n",
      "Validation Loss: 2737.0136\n",
      "Epoch [2801/3000], Loss: 0.1825\n",
      "Validation Loss: 2731.1493\n",
      "Epoch [2821/3000], Loss: 0.1576\n",
      "Validation Loss: 2740.1583\n",
      "Epoch [2841/3000], Loss: 0.1543\n",
      "Validation Loss: 2733.8496\n",
      "Epoch [2861/3000], Loss: 0.1686\n",
      "Validation Loss: 2732.0813\n",
      "Epoch [2881/3000], Loss: 0.1918\n",
      "Validation Loss: 2727.8870\n",
      "Epoch [2901/3000], Loss: 0.1781\n",
      "Validation Loss: 2733.9188\n",
      "Epoch [2921/3000], Loss: 0.2420\n",
      "Validation Loss: 2742.9516\n",
      "Epoch [2941/3000], Loss: 0.1949\n",
      "Validation Loss: 2735.9556\n",
      "Epoch [2961/3000], Loss: 0.1668\n",
      "Validation Loss: 2744.6954\n",
      "Epoch [2981/3000], Loss: 0.1707\n",
      "Validation Loss: 2739.7043\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day017_plane0_Fall.mat\n",
      "(11308, 209)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 10132.7506\n",
      "Validation Loss: 9935.2500\n",
      "Epoch [21/3000], Loss: 8417.2839\n",
      "Validation Loss: 8222.9062\n",
      "Epoch [41/3000], Loss: 8028.5644\n",
      "Validation Loss: 7844.0811\n",
      "Epoch [61/3000], Loss: 7702.0040\n",
      "Validation Loss: 7518.8839\n",
      "Epoch [81/3000], Loss: 7381.8499\n",
      "Validation Loss: 7208.2145\n",
      "Epoch [101/3000], Loss: 7090.7458\n",
      "Validation Loss: 6915.7884\n",
      "Epoch [121/3000], Loss: 6794.1663\n",
      "Validation Loss: 6629.8728\n",
      "Epoch [141/3000], Loss: 6519.6878\n",
      "Validation Loss: 6358.3702\n",
      "Epoch [161/3000], Loss: 6264.5631\n",
      "Validation Loss: 6097.0133\n",
      "Epoch [181/3000], Loss: 6005.6796\n",
      "Validation Loss: 5845.3943\n",
      "Epoch [201/3000], Loss: 5766.4737\n",
      "Validation Loss: 5603.3857\n",
      "Epoch [221/3000], Loss: 5526.1579\n",
      "Validation Loss: 5368.4733\n",
      "Epoch [241/3000], Loss: 5299.2722\n",
      "Validation Loss: 5142.1450\n",
      "Epoch [261/3000], Loss: 5081.6489\n",
      "Validation Loss: 4926.6701\n",
      "Epoch [281/3000], Loss: 4870.1453\n",
      "Validation Loss: 4719.3907\n",
      "Epoch [301/3000], Loss: 4672.2735\n",
      "Validation Loss: 4522.2590\n",
      "Epoch [321/3000], Loss: 4479.9547\n",
      "Validation Loss: 4335.3956\n",
      "Epoch [341/3000], Loss: 4299.7623\n",
      "Validation Loss: 4158.2264\n",
      "Epoch [361/3000], Loss: 4130.8761\n",
      "Validation Loss: 3990.5997\n",
      "Epoch [381/3000], Loss: 3969.0345\n",
      "Validation Loss: 3832.4945\n",
      "Epoch [401/3000], Loss: 3818.0972\n",
      "Validation Loss: 3683.8360\n",
      "Epoch [421/3000], Loss: 3674.0833\n",
      "Validation Loss: 3544.5494\n",
      "Epoch [441/3000], Loss: 3544.2383\n",
      "Validation Loss: 3414.6726\n",
      "Epoch [461/3000], Loss: 3421.6780\n",
      "Validation Loss: 3294.0436\n",
      "Epoch [481/3000], Loss: 3301.7698\n",
      "Validation Loss: 3182.7311\n",
      "Epoch [501/3000], Loss: 3201.1780\n",
      "Validation Loss: 3080.5396\n",
      "Epoch [521/3000], Loss: 3105.2309\n",
      "Validation Loss: 2987.5194\n",
      "Epoch [541/3000], Loss: 3020.9846\n",
      "Validation Loss: 2903.3904\n",
      "Epoch [561/3000], Loss: 2941.9811\n",
      "Validation Loss: 2828.1978\n",
      "Epoch [581/3000], Loss: 2873.6512\n",
      "Validation Loss: 2761.7582\n",
      "Epoch [601/3000], Loss: 2812.3109\n",
      "Validation Loss: 2703.8909\n",
      "Epoch [621/3000], Loss: 2762.0551\n",
      "Validation Loss: 2654.3836\n",
      "Epoch [641/3000], Loss: 2719.8582\n",
      "Validation Loss: 2612.9854\n",
      "Epoch [661/3000], Loss: 2638.9255\n",
      "Validation Loss: 2523.7543\n",
      "Epoch [681/3000], Loss: 2494.3934\n",
      "Validation Loss: 2404.5972\n",
      "Epoch [701/3000], Loss: 2350.9914\n",
      "Validation Loss: 2254.1872\n",
      "Epoch [721/3000], Loss: 2103.3458\n",
      "Validation Loss: 2029.8536\n",
      "Epoch [741/3000], Loss: 1760.2956\n",
      "Validation Loss: 1717.7393\n",
      "Epoch [761/3000], Loss: 1188.7003\n",
      "Validation Loss: 1231.5551\n",
      "Epoch [781/3000], Loss: 1021.3947\n",
      "Validation Loss: 1082.3644\n",
      "Epoch [801/3000], Loss: 927.6377\n",
      "Validation Loss: 1010.4612\n",
      "Epoch [821/3000], Loss: 843.8336\n",
      "Validation Loss: 941.7363\n",
      "Epoch [841/3000], Loss: 768.0103\n",
      "Validation Loss: 871.7180\n",
      "Epoch [861/3000], Loss: 693.6811\n",
      "Validation Loss: 818.7676\n",
      "Epoch [881/3000], Loss: 629.8182\n",
      "Validation Loss: 760.2508\n",
      "Epoch [901/3000], Loss: 572.7805\n",
      "Validation Loss: 708.3802\n",
      "Epoch [921/3000], Loss: 518.8615\n",
      "Validation Loss: 667.5522\n",
      "Epoch [941/3000], Loss: 469.9162\n",
      "Validation Loss: 636.8086\n",
      "Epoch [961/3000], Loss: 427.4478\n",
      "Validation Loss: 600.2789\n",
      "Epoch [981/3000], Loss: 385.1319\n",
      "Validation Loss: 560.4990\n",
      "Epoch [1001/3000], Loss: 345.8404\n",
      "Validation Loss: 539.0658\n",
      "Epoch [1021/3000], Loss: 304.1035\n",
      "Validation Loss: 522.2052\n",
      "Epoch [1041/3000], Loss: 271.2677\n",
      "Validation Loss: 508.7791\n",
      "Epoch [1061/3000], Loss: 239.7465\n",
      "Validation Loss: 483.4731\n",
      "Epoch [1081/3000], Loss: 212.3299\n",
      "Validation Loss: 466.7328\n",
      "Epoch [1101/3000], Loss: 187.9441\n",
      "Validation Loss: 455.4074\n",
      "Epoch [1121/3000], Loss: 166.1902\n",
      "Validation Loss: 442.4152\n",
      "Epoch [1141/3000], Loss: 148.3306\n",
      "Validation Loss: 428.1603\n",
      "Epoch [1161/3000], Loss: 130.1866\n",
      "Validation Loss: 405.2412\n",
      "Epoch [1181/3000], Loss: 113.8850\n",
      "Validation Loss: 399.1199\n",
      "Epoch [1201/3000], Loss: 99.2197\n",
      "Validation Loss: 402.8711\n",
      "Epoch [1221/3000], Loss: 87.0539\n",
      "Validation Loss: 402.3131\n",
      "Epoch [1241/3000], Loss: 76.0463\n",
      "Validation Loss: 393.1134\n",
      "Epoch [1261/3000], Loss: 66.6093\n",
      "Validation Loss: 406.4751\n",
      "Epoch [1281/3000], Loss: 57.8663\n",
      "Validation Loss: 405.1896\n",
      "Epoch [1301/3000], Loss: 50.3622\n",
      "Validation Loss: 397.4881\n",
      "Epoch [1321/3000], Loss: 43.9655\n",
      "Validation Loss: 398.6094\n",
      "Epoch [1341/3000], Loss: 37.8366\n",
      "Validation Loss: 397.1085\n",
      "Epoch [1361/3000], Loss: 32.0397\n",
      "Validation Loss: 392.0595\n",
      "Epoch [1381/3000], Loss: 26.5256\n",
      "Validation Loss: 395.8366\n",
      "Epoch [1401/3000], Loss: 21.7306\n",
      "Validation Loss: 395.8687\n",
      "Epoch [1421/3000], Loss: 17.5787\n",
      "Validation Loss: 394.4488\n",
      "Epoch [1441/3000], Loss: 13.8953\n",
      "Validation Loss: 402.4123\n",
      "Epoch [1461/3000], Loss: 11.0228\n",
      "Validation Loss: 400.3739\n",
      "Epoch [1481/3000], Loss: 8.6758\n",
      "Validation Loss: 395.0712\n",
      "Epoch [1501/3000], Loss: 6.7323\n",
      "Validation Loss: 408.1492\n",
      "Epoch [1521/3000], Loss: 5.3759\n",
      "Validation Loss: 407.1483\n",
      "Epoch [1541/3000], Loss: 4.1879\n",
      "Validation Loss: 402.0112\n",
      "Epoch [1561/3000], Loss: 3.3205\n",
      "Validation Loss: 403.9454\n",
      "Epoch [1581/3000], Loss: 2.6446\n",
      "Validation Loss: 406.3640\n",
      "Epoch [1601/3000], Loss: 2.1514\n",
      "Validation Loss: 388.6171\n",
      "Epoch [1621/3000], Loss: 1.7427\n",
      "Validation Loss: 409.5578\n",
      "Epoch [1641/3000], Loss: 1.4233\n",
      "Validation Loss: 401.7631\n",
      "Epoch [1661/3000], Loss: 1.1530\n",
      "Validation Loss: 412.4373\n",
      "Epoch [1681/3000], Loss: 0.9097\n",
      "Validation Loss: 407.5697\n",
      "Epoch [1701/3000], Loss: 0.7144\n",
      "Validation Loss: 403.2488\n",
      "Epoch [1721/3000], Loss: 0.5533\n",
      "Validation Loss: 407.6030\n",
      "Epoch [1741/3000], Loss: 0.4609\n",
      "Validation Loss: 412.2119\n",
      "Epoch [1761/3000], Loss: 0.4128\n",
      "Validation Loss: 401.9731\n",
      "Epoch [1781/3000], Loss: 0.3160\n",
      "Validation Loss: 405.5824\n",
      "Epoch [1801/3000], Loss: 0.2693\n",
      "Validation Loss: 411.8905\n",
      "Epoch [1821/3000], Loss: 0.2315\n",
      "Validation Loss: 407.4051\n",
      "Epoch [1841/3000], Loss: 0.2104\n",
      "Validation Loss: 408.1880\n",
      "Epoch [1861/3000], Loss: 0.2143\n",
      "Validation Loss: 407.4130\n",
      "Epoch [1881/3000], Loss: 0.1737\n",
      "Validation Loss: 403.8140\n",
      "Epoch [1901/3000], Loss: 0.1642\n",
      "Validation Loss: 404.0139\n",
      "Epoch [1921/3000], Loss: 0.1674\n",
      "Validation Loss: 402.0247\n",
      "Epoch [1941/3000], Loss: 0.1501\n",
      "Validation Loss: 405.1306\n",
      "Epoch [1961/3000], Loss: 0.1344\n",
      "Validation Loss: 396.6487\n",
      "Epoch [1981/3000], Loss: 0.1370\n",
      "Validation Loss: 400.4646\n",
      "Epoch [2001/3000], Loss: 0.1312\n",
      "Validation Loss: 402.3657\n",
      "Epoch [2021/3000], Loss: 0.1268\n",
      "Validation Loss: 403.3078\n",
      "Epoch [2041/3000], Loss: 0.1354\n",
      "Validation Loss: 404.0129\n",
      "Epoch [2061/3000], Loss: 0.1240\n",
      "Validation Loss: 390.9480\n",
      "Epoch [2081/3000], Loss: 0.1325\n",
      "Validation Loss: 402.4513\n",
      "Epoch [2101/3000], Loss: 0.1140\n",
      "Validation Loss: 400.1078\n",
      "Epoch [2121/3000], Loss: 0.0993\n",
      "Validation Loss: 399.4495\n",
      "Epoch [2141/3000], Loss: 0.0978\n",
      "Validation Loss: 403.5473\n",
      "Epoch [2161/3000], Loss: 0.1300\n",
      "Validation Loss: 400.8082\n",
      "Epoch [2181/3000], Loss: 0.0877\n",
      "Validation Loss: 389.4390\n",
      "Epoch [2201/3000], Loss: 0.0954\n",
      "Validation Loss: 398.2828\n",
      "Epoch [2221/3000], Loss: 0.1080\n",
      "Validation Loss: 396.7684\n",
      "Epoch [2241/3000], Loss: 0.0889\n",
      "Validation Loss: 391.2455\n",
      "Epoch [2261/3000], Loss: 0.0776\n",
      "Validation Loss: 395.1943\n",
      "Epoch [2281/3000], Loss: 0.0747\n",
      "Validation Loss: 397.5019\n",
      "Epoch [2301/3000], Loss: 0.0810\n",
      "Validation Loss: 397.9644\n",
      "Epoch [2321/3000], Loss: 0.0719\n",
      "Validation Loss: 406.4406\n",
      "Epoch [2341/3000], Loss: 0.0716\n",
      "Validation Loss: 404.0523\n",
      "Epoch [2361/3000], Loss: 0.0784\n",
      "Validation Loss: 398.5726\n",
      "Epoch [2381/3000], Loss: 0.0762\n",
      "Validation Loss: 398.6166\n",
      "Epoch [2401/3000], Loss: 0.0641\n",
      "Validation Loss: 396.0243\n",
      "Epoch [2421/3000], Loss: 0.0733\n",
      "Validation Loss: 401.4452\n",
      "Epoch [2441/3000], Loss: 0.0630\n",
      "Validation Loss: 398.5398\n",
      "Epoch [2461/3000], Loss: 0.0645\n",
      "Validation Loss: 400.6025\n",
      "Epoch [2481/3000], Loss: 0.0640\n",
      "Validation Loss: 398.9494\n",
      "Epoch [2501/3000], Loss: 0.0692\n",
      "Validation Loss: 392.5892\n",
      "Epoch [2521/3000], Loss: 0.0567\n",
      "Validation Loss: 396.2719\n",
      "Epoch [2541/3000], Loss: 0.0743\n",
      "Validation Loss: 398.3960\n",
      "Epoch [2561/3000], Loss: 0.0685\n",
      "Validation Loss: 397.9755\n",
      "Epoch [2581/3000], Loss: 0.0508\n",
      "Validation Loss: 396.1030\n",
      "Epoch [2601/3000], Loss: 0.0581\n",
      "Validation Loss: 401.7755\n",
      "Epoch [2621/3000], Loss: 0.0552\n",
      "Validation Loss: 404.6030\n",
      "Epoch [2641/3000], Loss: 0.0465\n",
      "Validation Loss: 388.0156\n",
      "Epoch [2661/3000], Loss: 0.0487\n",
      "Validation Loss: 401.5089\n",
      "Epoch [2681/3000], Loss: 0.0686\n",
      "Validation Loss: 402.6063\n",
      "Epoch [2701/3000], Loss: 0.0466\n",
      "Validation Loss: 400.3791\n",
      "Epoch [2721/3000], Loss: 0.0442\n",
      "Validation Loss: 401.8698\n",
      "Epoch [2741/3000], Loss: 0.0581\n",
      "Validation Loss: 385.5119\n",
      "Epoch [2761/3000], Loss: 0.0425\n",
      "Validation Loss: 399.4311\n",
      "Epoch [2781/3000], Loss: 0.0536\n",
      "Validation Loss: 394.2454\n",
      "Epoch [2801/3000], Loss: 0.0564\n",
      "Validation Loss: 398.2486\n",
      "Epoch [2821/3000], Loss: 0.0379\n",
      "Validation Loss: 394.2762\n",
      "Epoch [2841/3000], Loss: 0.0381\n",
      "Validation Loss: 399.5753\n",
      "Epoch [2861/3000], Loss: 0.0418\n",
      "Validation Loss: 399.5090\n",
      "Epoch [2881/3000], Loss: 0.0350\n",
      "Validation Loss: 398.9550\n",
      "Epoch [2901/3000], Loss: 0.0349\n",
      "Validation Loss: 401.0804\n",
      "Epoch [2921/3000], Loss: 0.0359\n",
      "Validation Loss: 399.9016\n",
      "Epoch [2941/3000], Loss: 0.0462\n",
      "Validation Loss: 398.8289\n",
      "Epoch [2961/3000], Loss: 0.0396\n",
      "Validation Loss: 391.8939\n",
      "Epoch [2981/3000], Loss: 0.0356\n",
      "Validation Loss: 395.1049\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day018_plane0_Fall.mat\n",
      "(12029, 210)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9634.1108\n",
      "Validation Loss: 9088.7059\n",
      "Epoch [21/3000], Loss: 7878.4976\n",
      "Validation Loss: 7417.1059\n",
      "Epoch [41/3000], Loss: 7470.9930\n",
      "Validation Loss: 7056.4854\n",
      "Epoch [61/3000], Loss: 7164.7568\n",
      "Validation Loss: 6747.4676\n",
      "Epoch [81/3000], Loss: 6845.4135\n",
      "Validation Loss: 6457.5220\n",
      "Epoch [101/3000], Loss: 6553.5183\n",
      "Validation Loss: 6181.1820\n",
      "Epoch [121/3000], Loss: 6261.6086\n",
      "Validation Loss: 5917.4731\n",
      "Epoch [141/3000], Loss: 5997.4748\n",
      "Validation Loss: 5665.1319\n",
      "Epoch [161/3000], Loss: 5739.4333\n",
      "Validation Loss: 5423.7082\n",
      "Epoch [181/3000], Loss: 5490.8819\n",
      "Validation Loss: 5193.0092\n",
      "Epoch [201/3000], Loss: 5235.9175\n",
      "Validation Loss: 4972.7297\n",
      "Epoch [221/3000], Loss: 5023.1735\n",
      "Validation Loss: 4763.1414\n",
      "Epoch [241/3000], Loss: 4805.3126\n",
      "Validation Loss: 4563.8047\n",
      "Epoch [261/3000], Loss: 4597.3948\n",
      "Validation Loss: 4374.8754\n",
      "Epoch [281/3000], Loss: 4403.8562\n",
      "Validation Loss: 4196.3278\n",
      "Epoch [301/3000], Loss: 4209.9885\n",
      "Validation Loss: 4028.0424\n",
      "Epoch [321/3000], Loss: 4031.3232\n",
      "Validation Loss: 3870.1354\n",
      "Epoch [341/3000], Loss: 3869.2809\n",
      "Validation Loss: 3722.5344\n",
      "Epoch [361/3000], Loss: 3719.0994\n",
      "Validation Loss: 3584.9859\n",
      "Epoch [381/3000], Loss: 3576.8942\n",
      "Validation Loss: 3457.5685\n",
      "Epoch [401/3000], Loss: 3438.0601\n",
      "Validation Loss: 3340.2794\n",
      "Epoch [421/3000], Loss: 3309.3240\n",
      "Validation Loss: 3232.8560\n",
      "Epoch [441/3000], Loss: 3193.8396\n",
      "Validation Loss: 3135.4109\n",
      "Epoch [461/3000], Loss: 3087.9377\n",
      "Validation Loss: 3047.7929\n",
      "Epoch [481/3000], Loss: 2989.3953\n",
      "Validation Loss: 2969.0546\n",
      "Epoch [501/3000], Loss: 2903.7823\n",
      "Validation Loss: 2900.3106\n",
      "Epoch [521/3000], Loss: 2807.7879\n",
      "Validation Loss: 2813.2036\n",
      "Epoch [541/3000], Loss: 2102.1048\n",
      "Validation Loss: 2125.4972\n",
      "Epoch [561/3000], Loss: 1797.8624\n",
      "Validation Loss: 1746.4692\n",
      "Epoch [581/3000], Loss: 1646.6854\n",
      "Validation Loss: 1607.4344\n",
      "Epoch [601/3000], Loss: 1531.1373\n",
      "Validation Loss: 1548.7615\n",
      "Epoch [621/3000], Loss: 1412.0405\n",
      "Validation Loss: 1446.1901\n",
      "Epoch [641/3000], Loss: 1311.7347\n",
      "Validation Loss: 1368.2414\n",
      "Epoch [661/3000], Loss: 1202.8482\n",
      "Validation Loss: 1278.1393\n",
      "Epoch [681/3000], Loss: 1113.7294\n",
      "Validation Loss: 1202.3788\n",
      "Epoch [701/3000], Loss: 1028.0505\n",
      "Validation Loss: 1121.7847\n",
      "Epoch [721/3000], Loss: 945.5093\n",
      "Validation Loss: 1061.5472\n",
      "Epoch [741/3000], Loss: 869.9504\n",
      "Validation Loss: 975.1337\n",
      "Epoch [761/3000], Loss: 796.4634\n",
      "Validation Loss: 969.0679\n",
      "Epoch [781/3000], Loss: 730.0358\n",
      "Validation Loss: 886.4395\n",
      "Epoch [801/3000], Loss: 668.2842\n",
      "Validation Loss: 844.7028\n",
      "Epoch [821/3000], Loss: 593.5770\n",
      "Validation Loss: 793.0971\n",
      "Epoch [841/3000], Loss: 532.3303\n",
      "Validation Loss: 754.3998\n",
      "Epoch [861/3000], Loss: 480.6448\n",
      "Validation Loss: 740.5770\n",
      "Epoch [881/3000], Loss: 432.9137\n",
      "Validation Loss: 714.9725\n",
      "Epoch [901/3000], Loss: 393.0528\n",
      "Validation Loss: 676.5539\n",
      "Epoch [921/3000], Loss: 358.1444\n",
      "Validation Loss: 717.9348\n",
      "Epoch [941/3000], Loss: 317.7391\n",
      "Validation Loss: 645.6905\n",
      "Epoch [961/3000], Loss: 284.7660\n",
      "Validation Loss: 626.7959\n",
      "Epoch [981/3000], Loss: 261.2353\n",
      "Validation Loss: 617.7556\n",
      "Epoch [1001/3000], Loss: 226.5557\n",
      "Validation Loss: 567.8278\n",
      "Epoch [1021/3000], Loss: 201.5959\n",
      "Validation Loss: 550.5701\n",
      "Epoch [1041/3000], Loss: 178.9497\n",
      "Validation Loss: 533.5877\n",
      "Epoch [1061/3000], Loss: 158.7945\n",
      "Validation Loss: 517.9023\n",
      "Epoch [1081/3000], Loss: 139.6220\n",
      "Validation Loss: 518.3668\n",
      "Epoch [1101/3000], Loss: 123.6022\n",
      "Validation Loss: 499.2410\n",
      "Epoch [1121/3000], Loss: 110.1817\n",
      "Validation Loss: 478.0870\n",
      "Epoch [1141/3000], Loss: 96.4941\n",
      "Validation Loss: 484.3463\n",
      "Epoch [1161/3000], Loss: 85.0893\n",
      "Validation Loss: 490.9081\n",
      "Epoch [1181/3000], Loss: 73.7814\n",
      "Validation Loss: 469.4566\n",
      "Epoch [1201/3000], Loss: 64.7340\n",
      "Validation Loss: 471.0090\n",
      "Epoch [1221/3000], Loss: 55.6864\n",
      "Validation Loss: 443.3623\n",
      "Epoch [1241/3000], Loss: 46.7790\n",
      "Validation Loss: 475.7482\n",
      "Epoch [1261/3000], Loss: 75.0265\n",
      "Validation Loss: 736.6337\n",
      "Epoch [1281/3000], Loss: 33.2667\n",
      "Validation Loss: 420.8238\n",
      "Epoch [1301/3000], Loss: 27.7647\n",
      "Validation Loss: 411.5043\n",
      "Epoch [1321/3000], Loss: 23.0076\n",
      "Validation Loss: 407.8105\n",
      "Epoch [1341/3000], Loss: 18.7768\n",
      "Validation Loss: 407.5836\n",
      "Epoch [1361/3000], Loss: 15.4581\n",
      "Validation Loss: 397.4983\n",
      "Epoch [1381/3000], Loss: 12.5304\n",
      "Validation Loss: 397.7856\n",
      "Epoch [1401/3000], Loss: 10.3981\n",
      "Validation Loss: 387.2110\n",
      "Epoch [1421/3000], Loss: 8.3253\n",
      "Validation Loss: 392.6205\n",
      "Epoch [1441/3000], Loss: 6.7429\n",
      "Validation Loss: 394.5592\n",
      "Epoch [1461/3000], Loss: 5.5078\n",
      "Validation Loss: 407.2022\n",
      "Epoch [1481/3000], Loss: 4.6257\n",
      "Validation Loss: 390.5290\n",
      "Epoch [1501/3000], Loss: 3.8962\n",
      "Validation Loss: 389.6195\n",
      "Epoch [1521/3000], Loss: 3.1047\n",
      "Validation Loss: 392.5083\n",
      "Epoch [1541/3000], Loss: 2.4560\n",
      "Validation Loss: 390.3244\n",
      "Epoch [1561/3000], Loss: 1.8599\n",
      "Validation Loss: 391.0608\n",
      "Epoch [1581/3000], Loss: 1.4160\n",
      "Validation Loss: 386.6965\n",
      "Epoch [1601/3000], Loss: 1.0905\n",
      "Validation Loss: 387.4729\n",
      "Epoch [1621/3000], Loss: 0.8124\n",
      "Validation Loss: 382.2799\n",
      "Epoch [1641/3000], Loss: 0.6475\n",
      "Validation Loss: 374.4967\n",
      "Epoch [1661/3000], Loss: 0.5088\n",
      "Validation Loss: 384.3648\n",
      "Epoch [1681/3000], Loss: 0.3923\n",
      "Validation Loss: 372.0324\n",
      "Epoch [1701/3000], Loss: 0.3261\n",
      "Validation Loss: 370.0363\n",
      "Epoch [1721/3000], Loss: 0.2828\n",
      "Validation Loss: 374.7415\n",
      "Epoch [1741/3000], Loss: 0.2643\n",
      "Validation Loss: 378.9246\n",
      "Epoch [1761/3000], Loss: 0.2336\n",
      "Validation Loss: 369.1255\n",
      "Epoch [1781/3000], Loss: 0.2069\n",
      "Validation Loss: 381.5050\n",
      "Epoch [1801/3000], Loss: 0.2031\n",
      "Validation Loss: 366.0187\n",
      "Epoch [1821/3000], Loss: 0.1705\n",
      "Validation Loss: 374.8077\n",
      "Epoch [1841/3000], Loss: 0.3087\n",
      "Validation Loss: 439.0308\n",
      "Epoch [1861/3000], Loss: 0.1617\n",
      "Validation Loss: 418.7959\n",
      "Epoch [1881/3000], Loss: 0.1440\n",
      "Validation Loss: 409.3049\n",
      "Epoch [1901/3000], Loss: 0.1397\n",
      "Validation Loss: 404.9667\n",
      "Epoch [1921/3000], Loss: 0.1361\n",
      "Validation Loss: 401.9070\n",
      "Epoch [1941/3000], Loss: 0.1402\n",
      "Validation Loss: 399.6539\n",
      "Epoch [1961/3000], Loss: 0.1419\n",
      "Validation Loss: 394.2489\n",
      "Epoch [1981/3000], Loss: 0.1274\n",
      "Validation Loss: 394.7994\n",
      "Epoch [2001/3000], Loss: 0.1248\n",
      "Validation Loss: 394.5703\n",
      "Epoch [2021/3000], Loss: 0.1239\n",
      "Validation Loss: 397.6922\n",
      "Epoch [2041/3000], Loss: 0.1156\n",
      "Validation Loss: 390.0385\n",
      "Epoch [2061/3000], Loss: 0.1305\n",
      "Validation Loss: 394.6581\n",
      "Epoch [2081/3000], Loss: 0.1073\n",
      "Validation Loss: 389.0438\n",
      "Epoch [2101/3000], Loss: 0.1212\n",
      "Validation Loss: 390.6643\n",
      "Epoch [2121/3000], Loss: 0.1123\n",
      "Validation Loss: 417.8500\n",
      "Epoch [2141/3000], Loss: 0.0914\n",
      "Validation Loss: 411.4176\n",
      "Epoch [2161/3000], Loss: 0.0861\n",
      "Validation Loss: 406.2366\n",
      "Epoch [2181/3000], Loss: 0.0846\n",
      "Validation Loss: 402.3538\n",
      "Epoch [2201/3000], Loss: 0.0858\n",
      "Validation Loss: 401.7491\n",
      "Epoch [2221/3000], Loss: 0.0861\n",
      "Validation Loss: 400.2673\n",
      "Epoch [2241/3000], Loss: 0.0877\n",
      "Validation Loss: 395.3745\n",
      "Epoch [2261/3000], Loss: 0.0882\n",
      "Validation Loss: 395.0102\n",
      "Epoch [2281/3000], Loss: 0.0956\n",
      "Validation Loss: 394.3624\n",
      "Epoch [2301/3000], Loss: 0.0817\n",
      "Validation Loss: 396.5636\n",
      "Epoch [2321/3000], Loss: 0.0936\n",
      "Validation Loss: 395.1954\n",
      "Epoch [2341/3000], Loss: 0.0807\n",
      "Validation Loss: 397.7167\n",
      "Epoch [2361/3000], Loss: 0.0781\n",
      "Validation Loss: 394.0394\n",
      "Epoch [2381/3000], Loss: 0.0789\n",
      "Validation Loss: 389.6549\n",
      "Epoch [2401/3000], Loss: 0.0717\n",
      "Validation Loss: 398.6078\n",
      "Epoch [2421/3000], Loss: 0.0696\n",
      "Validation Loss: 391.8862\n",
      "Epoch [2441/3000], Loss: 0.0685\n",
      "Validation Loss: 400.1137\n",
      "Epoch [2461/3000], Loss: 0.0679\n",
      "Validation Loss: 394.6445\n",
      "Epoch [2481/3000], Loss: 0.0582\n",
      "Validation Loss: 403.6457\n",
      "Epoch [2501/3000], Loss: 0.0667\n",
      "Validation Loss: 395.0586\n",
      "Epoch [2521/3000], Loss: 0.0616\n",
      "Validation Loss: 394.5554\n",
      "Epoch [2541/3000], Loss: 0.0806\n",
      "Validation Loss: 399.5442\n",
      "Epoch [2561/3000], Loss: 0.0616\n",
      "Validation Loss: 400.6370\n",
      "Epoch [2581/3000], Loss: 0.0530\n",
      "Validation Loss: 396.3994\n",
      "Epoch [2601/3000], Loss: 0.0498\n",
      "Validation Loss: 398.0147\n",
      "Epoch [2621/3000], Loss: 0.0498\n",
      "Validation Loss: 395.2734\n",
      "Epoch [2641/3000], Loss: 0.0477\n",
      "Validation Loss: 396.3734\n",
      "Epoch [2661/3000], Loss: 0.0469\n",
      "Validation Loss: 388.8794\n",
      "Epoch [2681/3000], Loss: 0.0480\n",
      "Validation Loss: 396.2452\n",
      "Epoch [2701/3000], Loss: 0.0456\n",
      "Validation Loss: 396.7362\n",
      "Epoch [2721/3000], Loss: 0.0414\n",
      "Validation Loss: 396.1386\n",
      "Epoch [2741/3000], Loss: 0.0418\n",
      "Validation Loss: 395.2710\n",
      "Epoch [2761/3000], Loss: 0.0399\n",
      "Validation Loss: 394.6667\n",
      "Epoch [2781/3000], Loss: 0.0511\n",
      "Validation Loss: 389.6034\n",
      "Epoch [2801/3000], Loss: 0.0440\n",
      "Validation Loss: 398.2153\n",
      "Epoch [2821/3000], Loss: 0.0350\n",
      "Validation Loss: 392.6886\n",
      "Epoch [2841/3000], Loss: 0.0425\n",
      "Validation Loss: 398.1010\n",
      "Epoch [2861/3000], Loss: 0.0432\n",
      "Validation Loss: 393.7621\n",
      "Epoch [2881/3000], Loss: 0.0385\n",
      "Validation Loss: 411.5697\n",
      "Epoch [2901/3000], Loss: 0.0482\n",
      "Validation Loss: 396.4285\n",
      "Epoch [2921/3000], Loss: 0.0420\n",
      "Validation Loss: 398.5137\n",
      "Epoch [2941/3000], Loss: 0.0341\n",
      "Validation Loss: 393.6879\n",
      "Epoch [2961/3000], Loss: 0.0315\n",
      "Validation Loss: 395.0679\n",
      "Epoch [2981/3000], Loss: 0.0391\n",
      "Validation Loss: 402.2240\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day020_plane0_Fall.mat\n",
      "(13118, 130)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9216.3788\n",
      "Validation Loss: 9793.6538\n",
      "Epoch [21/3000], Loss: 7538.1068\n",
      "Validation Loss: 8099.4567\n",
      "Epoch [41/3000], Loss: 7141.2380\n",
      "Validation Loss: 7701.2858\n",
      "Epoch [61/3000], Loss: 6794.8604\n",
      "Validation Loss: 7351.5650\n",
      "Epoch [81/3000], Loss: 6468.1398\n",
      "Validation Loss: 7023.6526\n",
      "Epoch [101/3000], Loss: 6158.2004\n",
      "Validation Loss: 6712.1475\n",
      "Epoch [121/3000], Loss: 5867.6886\n",
      "Validation Loss: 6415.0167\n",
      "Epoch [141/3000], Loss: 5586.7443\n",
      "Validation Loss: 6131.4620\n",
      "Epoch [161/3000], Loss: 5316.1576\n",
      "Validation Loss: 5861.1678\n",
      "Epoch [181/3000], Loss: 5064.3468\n",
      "Validation Loss: 5601.1195\n",
      "Epoch [201/3000], Loss: 4817.8264\n",
      "Validation Loss: 5356.0797\n",
      "Epoch [221/3000], Loss: 4595.6567\n",
      "Validation Loss: 5124.1006\n",
      "Epoch [241/3000], Loss: 4381.9386\n",
      "Validation Loss: 4905.2833\n",
      "Epoch [261/3000], Loss: 4169.5198\n",
      "Validation Loss: 4699.3993\n",
      "Epoch [281/3000], Loss: 3982.0264\n",
      "Validation Loss: 4506.3793\n",
      "Epoch [301/3000], Loss: 3803.3046\n",
      "Validation Loss: 4326.2599\n",
      "Epoch [321/3000], Loss: 3640.9997\n",
      "Validation Loss: 4158.8272\n",
      "Epoch [341/3000], Loss: 3491.8663\n",
      "Validation Loss: 4004.0224\n",
      "Epoch [361/3000], Loss: 3352.6712\n",
      "Validation Loss: 3861.9514\n",
      "Epoch [381/3000], Loss: 3225.6401\n",
      "Validation Loss: 3732.3259\n",
      "Epoch [401/3000], Loss: 3108.2980\n",
      "Validation Loss: 3615.1595\n",
      "Epoch [421/3000], Loss: 3009.2575\n",
      "Validation Loss: 3510.1756\n",
      "Epoch [441/3000], Loss: 2920.2428\n",
      "Validation Loss: 3417.3646\n",
      "Epoch [461/3000], Loss: 2841.1732\n",
      "Validation Loss: 3336.4939\n",
      "Epoch [481/3000], Loss: 2775.7670\n",
      "Validation Loss: 3267.1554\n",
      "Epoch [501/3000], Loss: 2717.7429\n",
      "Validation Loss: 3209.1683\n",
      "Epoch [521/3000], Loss: 2675.6251\n",
      "Validation Loss: 3162.2377\n",
      "Epoch [541/3000], Loss: 2643.0192\n",
      "Validation Loss: 3125.6337\n",
      "Epoch [561/3000], Loss: 2616.8821\n",
      "Validation Loss: 3098.6765\n",
      "Epoch [581/3000], Loss: 2598.0803\n",
      "Validation Loss: 3080.3517\n",
      "Epoch [601/3000], Loss: 2593.0200\n",
      "Validation Loss: 3069.1193\n",
      "Epoch [621/3000], Loss: 2586.0592\n",
      "Validation Loss: 3063.1765\n",
      "Epoch [641/3000], Loss: 2586.8026\n",
      "Validation Loss: 3060.5405\n",
      "Epoch [661/3000], Loss: 2586.4562\n",
      "Validation Loss: 3059.5154\n",
      "Epoch [681/3000], Loss: 2585.5684\n",
      "Validation Loss: 3059.1112\n",
      "Epoch [701/3000], Loss: 2587.6646\n",
      "Validation Loss: 3058.9665\n",
      "Epoch [721/3000], Loss: 2586.9492\n",
      "Validation Loss: 3058.8942\n",
      "Epoch [741/3000], Loss: 2586.4439\n",
      "Validation Loss: 3058.8749\n",
      "Epoch [761/3000], Loss: 2588.0930\n",
      "Validation Loss: 3058.8669\n",
      "Epoch [781/3000], Loss: 2585.7272\n",
      "Validation Loss: 3058.8500\n",
      "Epoch [801/3000], Loss: 2584.3863\n",
      "Validation Loss: 3058.8429\n",
      "Epoch [821/3000], Loss: 2586.0132\n",
      "Validation Loss: 3058.8401\n",
      "Epoch [841/3000], Loss: 2583.7371\n",
      "Validation Loss: 3058.8537\n",
      "Epoch [861/3000], Loss: 2583.3815\n",
      "Validation Loss: 3058.8388\n",
      "Epoch [881/3000], Loss: 2587.3536\n",
      "Validation Loss: 3058.8618\n",
      "Epoch [901/3000], Loss: 2586.6044\n",
      "Validation Loss: 3058.8589\n",
      "Epoch [921/3000], Loss: 2586.3091\n",
      "Validation Loss: 3058.8498\n",
      "Epoch [941/3000], Loss: 2584.7704\n",
      "Validation Loss: 3058.8521\n",
      "Epoch [961/3000], Loss: 2585.9051\n",
      "Validation Loss: 3058.8426\n",
      "Epoch [981/3000], Loss: 2584.7861\n",
      "Validation Loss: 3058.8444\n",
      "Epoch [1001/3000], Loss: 2583.9038\n",
      "Validation Loss: 3058.8514\n",
      "Epoch [1021/3000], Loss: 2586.4977\n",
      "Validation Loss: 3058.8498\n",
      "Epoch [1041/3000], Loss: 2586.4492\n",
      "Validation Loss: 3058.8628\n",
      "Epoch [1061/3000], Loss: 2586.8783\n",
      "Validation Loss: 3058.8529\n",
      "Epoch [1081/3000], Loss: 2586.5872\n",
      "Validation Loss: 3058.8433\n",
      "Epoch [1101/3000], Loss: 2583.5063\n",
      "Validation Loss: 3058.8533\n",
      "Epoch [1121/3000], Loss: 2584.0259\n",
      "Validation Loss: 3058.8563\n",
      "Epoch [1141/3000], Loss: 2584.7291\n",
      "Validation Loss: 3058.8607\n",
      "Epoch [1161/3000], Loss: 2584.4355\n",
      "Validation Loss: 3058.8612\n",
      "Epoch [1181/3000], Loss: 2585.5487\n",
      "Validation Loss: 3058.8441\n",
      "Epoch [1201/3000], Loss: 2585.4759\n",
      "Validation Loss: 3058.8375\n",
      "Epoch [1221/3000], Loss: 2585.3888\n",
      "Validation Loss: 3058.8409\n",
      "Epoch [1241/3000], Loss: 2584.6853\n",
      "Validation Loss: 3058.8610\n",
      "Epoch [1261/3000], Loss: 2585.8633\n",
      "Validation Loss: 3058.8596\n",
      "Epoch [1281/3000], Loss: 2584.8014\n",
      "Validation Loss: 3058.8586\n",
      "Epoch [1301/3000], Loss: 2584.3199\n",
      "Validation Loss: 3058.8590\n",
      "Epoch [1321/3000], Loss: 2584.0205\n",
      "Validation Loss: 3058.8479\n",
      "Epoch [1341/3000], Loss: 2586.1384\n",
      "Validation Loss: 3058.8466\n",
      "Epoch [1361/3000], Loss: 2585.5634\n",
      "Validation Loss: 3058.8359\n",
      "Epoch [1381/3000], Loss: 2585.6390\n",
      "Validation Loss: 3058.8583\n",
      "Epoch [1401/3000], Loss: 2582.6440\n",
      "Validation Loss: 3058.8476\n",
      "Epoch [1421/3000], Loss: 2585.4898\n",
      "Validation Loss: 3058.8454\n",
      "Epoch [1441/3000], Loss: 2583.1593\n",
      "Validation Loss: 3058.8476\n",
      "Epoch [1461/3000], Loss: 2581.9537\n",
      "Validation Loss: 3058.8365\n",
      "Epoch [1481/3000], Loss: 2583.2363\n",
      "Validation Loss: 3058.8410\n",
      "Epoch [1501/3000], Loss: 2583.8051\n",
      "Validation Loss: 3058.8529\n",
      "Epoch [1521/3000], Loss: 2585.6200\n",
      "Validation Loss: 3058.8574\n",
      "Epoch [1541/3000], Loss: 2586.1598\n",
      "Validation Loss: 3058.8541\n",
      "Epoch [1561/3000], Loss: 2586.8039\n",
      "Validation Loss: 3058.8459\n",
      "Epoch [1581/3000], Loss: 2584.6907\n",
      "Validation Loss: 3058.8356\n",
      "Epoch [1601/3000], Loss: 2585.0354\n",
      "Validation Loss: 3058.8570\n",
      "Epoch [1621/3000], Loss: 2585.3356\n",
      "Validation Loss: 3058.8470\n",
      "Epoch [1641/3000], Loss: 2582.9333\n",
      "Validation Loss: 3058.8345\n",
      "Epoch [1661/3000], Loss: 2582.1345\n",
      "Validation Loss: 3058.8478\n",
      "Epoch [1681/3000], Loss: 2586.0731\n",
      "Validation Loss: 3058.8489\n",
      "Epoch [1701/3000], Loss: 2585.9973\n",
      "Validation Loss: 3058.8454\n",
      "Epoch [1721/3000], Loss: 2584.4106\n",
      "Validation Loss: 3058.8446\n",
      "Epoch [1741/3000], Loss: 2586.5552\n",
      "Validation Loss: 3058.8487\n",
      "Epoch [1761/3000], Loss: 2582.8222\n",
      "Validation Loss: 3058.8416\n",
      "Epoch [1781/3000], Loss: 2583.9031\n",
      "Validation Loss: 3058.8469\n",
      "Epoch [1801/3000], Loss: 2584.1636\n",
      "Validation Loss: 3058.8434\n",
      "Epoch [1821/3000], Loss: 2584.1554\n",
      "Validation Loss: 3058.8469\n",
      "Epoch [1841/3000], Loss: 2584.2539\n",
      "Validation Loss: 3058.8421\n",
      "Epoch [1861/3000], Loss: 2586.1143\n",
      "Validation Loss: 3058.8342\n",
      "Epoch [1881/3000], Loss: 2585.8383\n",
      "Validation Loss: 3058.8506\n",
      "Epoch [1901/3000], Loss: 2586.3405\n",
      "Validation Loss: 3058.8521\n",
      "Epoch [1921/3000], Loss: 2585.6589\n",
      "Validation Loss: 3058.8598\n",
      "Epoch [1941/3000], Loss: 2583.2520\n",
      "Validation Loss: 3058.8375\n",
      "Epoch [1961/3000], Loss: 2582.0714\n",
      "Validation Loss: 3058.8459\n",
      "Epoch [1981/3000], Loss: 2583.4918\n",
      "Validation Loss: 3058.8415\n",
      "Epoch [2001/3000], Loss: 2586.2118\n",
      "Validation Loss: 3058.8328\n",
      "Epoch [2021/3000], Loss: 2582.9388\n",
      "Validation Loss: 3058.8441\n",
      "Epoch [2041/3000], Loss: 2587.2068\n",
      "Validation Loss: 3058.8455\n",
      "Epoch [2061/3000], Loss: 2585.0988\n",
      "Validation Loss: 3058.8572\n",
      "Epoch [2081/3000], Loss: 2585.5755\n",
      "Validation Loss: 3058.8509\n",
      "Epoch [2101/3000], Loss: 2582.6578\n",
      "Validation Loss: 3058.8583\n",
      "Epoch [2121/3000], Loss: 2586.0580\n",
      "Validation Loss: 3058.8391\n",
      "Epoch [2141/3000], Loss: 2584.9937\n",
      "Validation Loss: 3058.8523\n",
      "Epoch [2161/3000], Loss: 2587.3772\n",
      "Validation Loss: 3058.8425\n",
      "Epoch [2181/3000], Loss: 2586.7223\n",
      "Validation Loss: 3058.8684\n",
      "Epoch [2201/3000], Loss: 2585.7697\n",
      "Validation Loss: 3058.8495\n",
      "Epoch [2221/3000], Loss: 2585.2987\n",
      "Validation Loss: 3058.8534\n",
      "Epoch [2241/3000], Loss: 2587.2081\n",
      "Validation Loss: 3058.8359\n",
      "Epoch [2261/3000], Loss: 2585.7944\n",
      "Validation Loss: 3058.8382\n",
      "Epoch [2281/3000], Loss: 2583.4291\n",
      "Validation Loss: 3058.8360\n",
      "Epoch [2301/3000], Loss: 2585.7531\n",
      "Validation Loss: 3058.8436\n",
      "Epoch [2321/3000], Loss: 2587.6372\n",
      "Validation Loss: 3058.8466\n",
      "Epoch [2341/3000], Loss: 2583.5720\n",
      "Validation Loss: 3058.8387\n",
      "Epoch [2361/3000], Loss: 2584.2459\n",
      "Validation Loss: 3058.8265\n",
      "Epoch [2381/3000], Loss: 2584.7038\n",
      "Validation Loss: 3058.8382\n",
      "Epoch [2401/3000], Loss: 2585.5972\n",
      "Validation Loss: 3058.8449\n",
      "Epoch [2421/3000], Loss: 2582.5238\n",
      "Validation Loss: 3058.8403\n",
      "Epoch [2441/3000], Loss: 2585.7034\n",
      "Validation Loss: 3058.8443\n",
      "Epoch [2461/3000], Loss: 2584.5413\n",
      "Validation Loss: 3058.8457\n",
      "Epoch [2481/3000], Loss: 2584.1434\n",
      "Validation Loss: 3058.8393\n",
      "Epoch [2501/3000], Loss: 2585.9456\n",
      "Validation Loss: 3058.8579\n",
      "Epoch [2521/3000], Loss: 2585.4253\n",
      "Validation Loss: 3058.8565\n",
      "Epoch [2541/3000], Loss: 2584.6799\n",
      "Validation Loss: 3058.8660\n",
      "Epoch [2561/3000], Loss: 2587.7038\n",
      "Validation Loss: 3058.8484\n",
      "Epoch [2581/3000], Loss: 2587.4696\n",
      "Validation Loss: 3058.8448\n",
      "Epoch [2601/3000], Loss: 2586.2410\n",
      "Validation Loss: 3058.8460\n",
      "Epoch [2621/3000], Loss: 2585.8321\n",
      "Validation Loss: 3058.8606\n",
      "Epoch [2641/3000], Loss: 2585.9571\n",
      "Validation Loss: 3058.8541\n",
      "Epoch [2661/3000], Loss: 2585.7470\n",
      "Validation Loss: 3058.8636\n",
      "Epoch [2681/3000], Loss: 2585.3020\n",
      "Validation Loss: 3058.8627\n",
      "Epoch [2701/3000], Loss: 2586.1020\n",
      "Validation Loss: 3058.8455\n",
      "Epoch [2721/3000], Loss: 2587.7847\n",
      "Validation Loss: 3058.8580\n",
      "Epoch [2741/3000], Loss: 2586.6624\n",
      "Validation Loss: 3058.8625\n",
      "Epoch [2761/3000], Loss: 2583.4126\n",
      "Validation Loss: 3058.8471\n",
      "Epoch [2781/3000], Loss: 2584.9630\n",
      "Validation Loss: 3058.8466\n",
      "Epoch [2801/3000], Loss: 2585.2354\n",
      "Validation Loss: 3058.8514\n",
      "Epoch [2821/3000], Loss: 2586.4920\n",
      "Validation Loss: 3058.8557\n",
      "Epoch [2841/3000], Loss: 2583.5393\n",
      "Validation Loss: 3058.8438\n",
      "Epoch [2861/3000], Loss: 2585.2352\n",
      "Validation Loss: 3058.8602\n",
      "Epoch [2881/3000], Loss: 2584.5897\n",
      "Validation Loss: 3058.8467\n",
      "Epoch [2901/3000], Loss: 2586.1717\n",
      "Validation Loss: 3058.8560\n",
      "Epoch [2921/3000], Loss: 2584.0023\n",
      "Validation Loss: 3058.8492\n",
      "Epoch [2941/3000], Loss: 2584.1668\n",
      "Validation Loss: 3058.8534\n",
      "Epoch [2961/3000], Loss: 2582.7608\n",
      "Validation Loss: 3058.8450\n",
      "Epoch [2981/3000], Loss: 2585.0330\n",
      "Validation Loss: 3058.8446\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day026_plane0_Fall.mat\n",
      "(9780, 110)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8671.7578\n",
      "Validation Loss: 7886.5713\n",
      "Epoch [21/3000], Loss: 7357.6808\n",
      "Validation Loss: 6635.0801\n",
      "Epoch [41/3000], Loss: 7059.6958\n",
      "Validation Loss: 6365.0578\n",
      "Epoch [61/3000], Loss: 6811.1115\n",
      "Validation Loss: 6137.2696\n",
      "Epoch [81/3000], Loss: 6574.3469\n",
      "Validation Loss: 5926.3217\n",
      "Epoch [101/3000], Loss: 6356.6560\n",
      "Validation Loss: 5726.3495\n",
      "Epoch [121/3000], Loss: 6141.9265\n",
      "Validation Loss: 5535.1817\n",
      "Epoch [141/3000], Loss: 5953.2459\n",
      "Validation Loss: 5352.0044\n",
      "Epoch [161/3000], Loss: 5754.8353\n",
      "Validation Loss: 5176.2471\n",
      "Epoch [181/3000], Loss: 5578.9062\n",
      "Validation Loss: 5007.6260\n",
      "Epoch [201/3000], Loss: 5396.4917\n",
      "Validation Loss: 4846.1341\n",
      "Epoch [221/3000], Loss: 5221.1655\n",
      "Validation Loss: 4691.5647\n",
      "Epoch [241/3000], Loss: 5064.8986\n",
      "Validation Loss: 4544.0370\n",
      "Epoch [261/3000], Loss: 4897.6939\n",
      "Validation Loss: 4399.8653\n",
      "Epoch [281/3000], Loss: 4743.1853\n",
      "Validation Loss: 4264.6814\n",
      "Epoch [301/3000], Loss: 4605.0840\n",
      "Validation Loss: 4136.8844\n",
      "Epoch [321/3000], Loss: 4465.4098\n",
      "Validation Loss: 4016.1866\n",
      "Epoch [341/3000], Loss: 4336.5448\n",
      "Validation Loss: 3902.3959\n",
      "Epoch [361/3000], Loss: 4202.6022\n",
      "Validation Loss: 3795.5676\n",
      "Epoch [381/3000], Loss: 4091.5277\n",
      "Validation Loss: 3695.5213\n",
      "Epoch [401/3000], Loss: 3975.0921\n",
      "Validation Loss: 3600.0967\n",
      "Epoch [421/3000], Loss: 3878.7166\n",
      "Validation Loss: 3512.4510\n",
      "Epoch [441/3000], Loss: 3779.9774\n",
      "Validation Loss: 3432.3149\n",
      "Epoch [461/3000], Loss: 3687.7152\n",
      "Validation Loss: 3358.8758\n",
      "Epoch [481/3000], Loss: 3605.1411\n",
      "Validation Loss: 3291.1035\n",
      "Epoch [501/3000], Loss: 3524.7905\n",
      "Validation Loss: 3230.8868\n",
      "Epoch [521/3000], Loss: 3456.6106\n",
      "Validation Loss: 3177.3013\n",
      "Epoch [541/3000], Loss: 3393.4745\n",
      "Validation Loss: 3130.1700\n",
      "Epoch [561/3000], Loss: 3341.3779\n",
      "Validation Loss: 3089.3205\n",
      "Epoch [581/3000], Loss: 3290.8023\n",
      "Validation Loss: 3054.7518\n",
      "Epoch [601/3000], Loss: 3245.7510\n",
      "Validation Loss: 3026.1473\n",
      "Epoch [621/3000], Loss: 3207.8260\n",
      "Validation Loss: 3003.3335\n",
      "Epoch [641/3000], Loss: 2984.6132\n",
      "Validation Loss: 2786.4886\n",
      "Epoch [661/3000], Loss: 2217.1305\n",
      "Validation Loss: 2210.9454\n",
      "Epoch [681/3000], Loss: 2031.3557\n",
      "Validation Loss: 2136.4946\n",
      "Epoch [701/3000], Loss: 1899.8556\n",
      "Validation Loss: 2062.9162\n",
      "Epoch [721/3000], Loss: 1793.7213\n",
      "Validation Loss: 2018.0592\n",
      "Epoch [741/3000], Loss: 1688.2606\n",
      "Validation Loss: 1970.4331\n",
      "Epoch [761/3000], Loss: 1594.8132\n",
      "Validation Loss: 1936.9055\n",
      "Epoch [781/3000], Loss: 1504.3206\n",
      "Validation Loss: 1880.5339\n",
      "Epoch [801/3000], Loss: 1424.0608\n",
      "Validation Loss: 1829.3596\n",
      "Epoch [821/3000], Loss: 1333.7004\n",
      "Validation Loss: 1793.7080\n",
      "Epoch [841/3000], Loss: 1262.3446\n",
      "Validation Loss: 1731.7518\n",
      "Epoch [861/3000], Loss: 1192.3159\n",
      "Validation Loss: 1679.0655\n",
      "Epoch [881/3000], Loss: 1126.5280\n",
      "Validation Loss: 1652.6874\n",
      "Epoch [901/3000], Loss: 1047.4852\n",
      "Validation Loss: 1611.6486\n",
      "Epoch [921/3000], Loss: 980.4462\n",
      "Validation Loss: 1607.2598\n",
      "Epoch [941/3000], Loss: 915.7244\n",
      "Validation Loss: 1621.7343\n",
      "Epoch [961/3000], Loss: 859.0272\n",
      "Validation Loss: 1508.1328\n",
      "Epoch [981/3000], Loss: 806.5170\n",
      "Validation Loss: 1529.7714\n",
      "Epoch [1001/3000], Loss: 755.4872\n",
      "Validation Loss: 1475.0522\n",
      "Epoch [1021/3000], Loss: 706.1564\n",
      "Validation Loss: 1466.5249\n",
      "Epoch [1041/3000], Loss: 657.7114\n",
      "Validation Loss: 1436.0323\n",
      "Epoch [1061/3000], Loss: 610.8236\n",
      "Validation Loss: 1449.9812\n",
      "Epoch [1081/3000], Loss: 569.1211\n",
      "Validation Loss: 1444.8471\n",
      "Epoch [1101/3000], Loss: 528.9625\n",
      "Validation Loss: 1480.7587\n",
      "Epoch [1121/3000], Loss: 489.8937\n",
      "Validation Loss: 1415.4187\n",
      "Epoch [1141/3000], Loss: 452.5125\n",
      "Validation Loss: 1465.8066\n",
      "Epoch [1161/3000], Loss: 417.8346\n",
      "Validation Loss: 1451.0528\n",
      "Epoch [1181/3000], Loss: 384.3566\n",
      "Validation Loss: 1456.3132\n",
      "Epoch [1201/3000], Loss: 351.7961\n",
      "Validation Loss: 1469.9188\n",
      "Epoch [1221/3000], Loss: 321.0308\n",
      "Validation Loss: 1469.7069\n",
      "Epoch [1241/3000], Loss: 294.6975\n",
      "Validation Loss: 1436.0887\n",
      "Epoch [1261/3000], Loss: 266.2567\n",
      "Validation Loss: 1468.2294\n",
      "Epoch [1281/3000], Loss: 242.3950\n",
      "Validation Loss: 1492.1366\n",
      "Epoch [1301/3000], Loss: 220.8562\n",
      "Validation Loss: 1489.2429\n",
      "Epoch [1321/3000], Loss: 199.6510\n",
      "Validation Loss: 1483.7170\n",
      "Epoch [1341/3000], Loss: 180.8717\n",
      "Validation Loss: 1491.1163\n",
      "Epoch [1361/3000], Loss: 163.3861\n",
      "Validation Loss: 1481.0429\n",
      "Epoch [1381/3000], Loss: 147.6498\n",
      "Validation Loss: 1466.3609\n",
      "Epoch [1401/3000], Loss: 133.1025\n",
      "Validation Loss: 1475.3643\n",
      "Epoch [1421/3000], Loss: 120.2592\n",
      "Validation Loss: 1455.4155\n",
      "Epoch [1441/3000], Loss: 107.4609\n",
      "Validation Loss: 1489.9641\n",
      "Epoch [1461/3000], Loss: 96.1091\n",
      "Validation Loss: 1454.4268\n",
      "Epoch [1481/3000], Loss: 86.4464\n",
      "Validation Loss: 1510.8286\n",
      "Epoch [1501/3000], Loss: 77.6600\n",
      "Validation Loss: 1427.3590\n",
      "Epoch [1521/3000], Loss: 69.8493\n",
      "Validation Loss: 1453.9149\n",
      "Epoch [1541/3000], Loss: 62.7676\n",
      "Validation Loss: 1461.7110\n",
      "Epoch [1561/3000], Loss: 55.2865\n",
      "Validation Loss: 1409.4526\n",
      "Epoch [1581/3000], Loss: 66.0662\n",
      "Validation Loss: 1515.7245\n",
      "Epoch [1601/3000], Loss: 43.2675\n",
      "Validation Loss: 1497.3016\n",
      "Epoch [1621/3000], Loss: 36.7654\n",
      "Validation Loss: 1471.2855\n",
      "Epoch [1641/3000], Loss: 32.5285\n",
      "Validation Loss: 1505.5911\n",
      "Epoch [1661/3000], Loss: 28.3720\n",
      "Validation Loss: 1494.9478\n",
      "Epoch [1681/3000], Loss: 24.3381\n",
      "Validation Loss: 1479.6051\n",
      "Epoch [1701/3000], Loss: 21.1829\n",
      "Validation Loss: 1508.0023\n",
      "Epoch [1721/3000], Loss: 17.8386\n",
      "Validation Loss: 1521.2524\n",
      "Epoch [1741/3000], Loss: 15.3385\n",
      "Validation Loss: 1523.6879\n",
      "Epoch [1761/3000], Loss: 13.0937\n",
      "Validation Loss: 1515.4395\n",
      "Epoch [1781/3000], Loss: 10.7998\n",
      "Validation Loss: 1537.7941\n",
      "Epoch [1801/3000], Loss: 60.7784\n",
      "Validation Loss: 1366.0199\n",
      "Epoch [1821/3000], Loss: 8.1584\n",
      "Validation Loss: 1543.3202\n",
      "Epoch [1841/3000], Loss: 7.2379\n",
      "Validation Loss: 1539.1551\n",
      "Epoch [1861/3000], Loss: 6.4442\n",
      "Validation Loss: 1564.4867\n",
      "Epoch [1881/3000], Loss: 5.6282\n",
      "Validation Loss: 1573.8741\n",
      "Epoch [1901/3000], Loss: 4.8931\n",
      "Validation Loss: 1601.4448\n",
      "Epoch [1921/3000], Loss: 4.1855\n",
      "Validation Loss: 1565.7316\n",
      "Epoch [1941/3000], Loss: 3.4951\n",
      "Validation Loss: 1567.9620\n",
      "Epoch [1961/3000], Loss: 32.6023\n",
      "Validation Loss: 1512.5050\n",
      "Epoch [1981/3000], Loss: 2.9729\n",
      "Validation Loss: 1525.3659\n",
      "Epoch [2001/3000], Loss: 2.7342\n",
      "Validation Loss: 1537.3989\n",
      "Epoch [2021/3000], Loss: 2.5562\n",
      "Validation Loss: 1555.6206\n",
      "Epoch [2041/3000], Loss: 2.3569\n",
      "Validation Loss: 1549.7204\n",
      "Epoch [2061/3000], Loss: 2.1634\n",
      "Validation Loss: 1548.3664\n",
      "Epoch [2081/3000], Loss: 2.0289\n",
      "Validation Loss: 1555.9452\n",
      "Epoch [2101/3000], Loss: 1.8198\n",
      "Validation Loss: 1554.3288\n",
      "Epoch [2121/3000], Loss: 1.6073\n",
      "Validation Loss: 1570.4616\n",
      "Epoch [2141/3000], Loss: 1.4822\n",
      "Validation Loss: 1561.4796\n",
      "Epoch [2161/3000], Loss: 1.3474\n",
      "Validation Loss: 1538.2020\n",
      "Epoch [2181/3000], Loss: 1.1643\n",
      "Validation Loss: 1531.4128\n",
      "Epoch [2201/3000], Loss: 1.0580\n",
      "Validation Loss: 1563.7378\n",
      "Epoch [2221/3000], Loss: 1.1150\n",
      "Validation Loss: 1510.6504\n",
      "Epoch [2241/3000], Loss: 0.9273\n",
      "Validation Loss: 1529.7554\n",
      "Epoch [2261/3000], Loss: 0.8768\n",
      "Validation Loss: 1530.5007\n",
      "Epoch [2281/3000], Loss: 0.8476\n",
      "Validation Loss: 1533.9074\n",
      "Epoch [2301/3000], Loss: 0.8164\n",
      "Validation Loss: 1536.6619\n",
      "Epoch [2321/3000], Loss: 0.8116\n",
      "Validation Loss: 1547.9946\n",
      "Epoch [2341/3000], Loss: 0.7650\n",
      "Validation Loss: 1547.5264\n",
      "Epoch [2361/3000], Loss: 0.6926\n",
      "Validation Loss: 1547.5736\n",
      "Epoch [2381/3000], Loss: 0.6645\n",
      "Validation Loss: 1539.7341\n",
      "Epoch [2401/3000], Loss: 0.7790\n",
      "Validation Loss: 1550.0490\n",
      "Epoch [2421/3000], Loss: 0.5852\n",
      "Validation Loss: 1524.7928\n",
      "Epoch [2441/3000], Loss: 0.5596\n",
      "Validation Loss: 1557.3172\n",
      "Epoch [2461/3000], Loss: 2.3367\n",
      "Validation Loss: 1515.0270\n",
      "Epoch [2481/3000], Loss: 0.5385\n",
      "Validation Loss: 1505.6015\n",
      "Epoch [2501/3000], Loss: 0.4823\n",
      "Validation Loss: 1517.6306\n",
      "Epoch [2521/3000], Loss: 0.4635\n",
      "Validation Loss: 1515.1054\n",
      "Epoch [2541/3000], Loss: 0.4543\n",
      "Validation Loss: 1521.8300\n",
      "Epoch [2561/3000], Loss: 0.4390\n",
      "Validation Loss: 1511.0034\n",
      "Epoch [2581/3000], Loss: 0.4343\n",
      "Validation Loss: 1525.5929\n",
      "Epoch [2601/3000], Loss: 0.4529\n",
      "Validation Loss: 1506.8380\n",
      "Epoch [2621/3000], Loss: 0.4149\n",
      "Validation Loss: 1517.3776\n",
      "Epoch [2641/3000], Loss: 0.3994\n",
      "Validation Loss: 1530.3458\n",
      "Epoch [2661/3000], Loss: 0.3821\n",
      "Validation Loss: 1511.8678\n",
      "Epoch [2681/3000], Loss: 0.3726\n",
      "Validation Loss: 1538.3022\n",
      "Epoch [2701/3000], Loss: 0.3405\n",
      "Validation Loss: 1525.7197\n",
      "Epoch [2721/3000], Loss: 0.3904\n",
      "Validation Loss: 1537.4959\n",
      "Epoch [2741/3000], Loss: 0.3150\n",
      "Validation Loss: 1521.0310\n",
      "Epoch [2761/3000], Loss: 0.3030\n",
      "Validation Loss: 1521.4542\n",
      "Epoch [2781/3000], Loss: 0.2995\n",
      "Validation Loss: 1521.1128\n",
      "Epoch [2801/3000], Loss: 0.2968\n",
      "Validation Loss: 1522.7317\n",
      "Epoch [2821/3000], Loss: 0.2900\n",
      "Validation Loss: 1523.8672\n",
      "Epoch [2841/3000], Loss: 0.2568\n",
      "Validation Loss: 1532.3349\n",
      "Epoch [2861/3000], Loss: 0.2414\n",
      "Validation Loss: 1535.6787\n",
      "Epoch [2881/3000], Loss: 0.2502\n",
      "Validation Loss: 1533.4812\n",
      "Epoch [2901/3000], Loss: 0.2669\n",
      "Validation Loss: 1521.6272\n",
      "Epoch [2921/3000], Loss: 0.3921\n",
      "Validation Loss: 1515.7211\n",
      "Epoch [2941/3000], Loss: 0.2308\n",
      "Validation Loss: 1514.8418\n",
      "Epoch [2961/3000], Loss: 0.2022\n",
      "Validation Loss: 1519.7412\n",
      "Epoch [2981/3000], Loss: 0.1937\n",
      "Validation Loss: 1521.4816\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day027_plane0_Fall.mat\n",
      "(5980, 85)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8221.2686\n",
      "Validation Loss: 6043.1563\n",
      "Epoch [21/3000], Loss: 7046.0496\n",
      "Validation Loss: 5132.2460\n",
      "Epoch [41/3000], Loss: 6761.2089\n",
      "Validation Loss: 4938.8011\n",
      "Epoch [61/3000], Loss: 6582.6235\n",
      "Validation Loss: 4812.9543\n",
      "Epoch [81/3000], Loss: 6449.4427\n",
      "Validation Loss: 4703.3021\n",
      "Epoch [101/3000], Loss: 6324.5669\n",
      "Validation Loss: 4600.9579\n",
      "Epoch [121/3000], Loss: 6174.5510\n",
      "Validation Loss: 4504.0476\n",
      "Epoch [141/3000], Loss: 6032.6870\n",
      "Validation Loss: 4411.2576\n",
      "Epoch [161/3000], Loss: 5907.9367\n",
      "Validation Loss: 4322.0083\n",
      "Epoch [181/3000], Loss: 5793.6906\n",
      "Validation Loss: 4235.9759\n",
      "Epoch [201/3000], Loss: 5675.8449\n",
      "Validation Loss: 4152.9441\n",
      "Epoch [221/3000], Loss: 5553.3223\n",
      "Validation Loss: 4072.7202\n",
      "Epoch [241/3000], Loss: 5443.3210\n",
      "Validation Loss: 3995.3760\n",
      "Epoch [261/3000], Loss: 5342.8620\n",
      "Validation Loss: 3920.6851\n",
      "Epoch [281/3000], Loss: 5211.1527\n",
      "Validation Loss: 3848.6461\n",
      "Epoch [301/3000], Loss: 5135.4692\n",
      "Validation Loss: 3779.2250\n",
      "Epoch [321/3000], Loss: 5027.7804\n",
      "Validation Loss: 3712.4369\n",
      "Epoch [341/3000], Loss: 4929.8751\n",
      "Validation Loss: 3648.2529\n",
      "Epoch [361/3000], Loss: 4835.1915\n",
      "Validation Loss: 3586.5643\n",
      "Epoch [381/3000], Loss: 4722.7803\n",
      "Validation Loss: 3527.5857\n",
      "Epoch [401/3000], Loss: 4633.7267\n",
      "Validation Loss: 3471.1253\n",
      "Epoch [421/3000], Loss: 4557.5295\n",
      "Validation Loss: 3417.2103\n",
      "Epoch [441/3000], Loss: 4447.3345\n",
      "Validation Loss: 3365.8581\n",
      "Epoch [461/3000], Loss: 4378.8203\n",
      "Validation Loss: 3316.9931\n",
      "Epoch [481/3000], Loss: 4291.5588\n",
      "Validation Loss: 3270.0903\n",
      "Epoch [501/3000], Loss: 4213.9539\n",
      "Validation Loss: 3225.7776\n",
      "Epoch [521/3000], Loss: 4123.1908\n",
      "Validation Loss: 3184.2775\n",
      "Epoch [541/3000], Loss: 4061.5227\n",
      "Validation Loss: 3145.3817\n",
      "Epoch [561/3000], Loss: 3996.2084\n",
      "Validation Loss: 3108.9339\n",
      "Epoch [581/3000], Loss: 3926.0053\n",
      "Validation Loss: 3075.0285\n",
      "Epoch [601/3000], Loss: 3856.2664\n",
      "Validation Loss: 3043.5734\n",
      "Epoch [621/3000], Loss: 3790.5686\n",
      "Validation Loss: 3014.5793\n",
      "Epoch [641/3000], Loss: 3735.9784\n",
      "Validation Loss: 2988.0364\n",
      "Epoch [661/3000], Loss: 3669.7659\n",
      "Validation Loss: 2963.8775\n",
      "Epoch [681/3000], Loss: 3615.9321\n",
      "Validation Loss: 2942.1586\n",
      "Epoch [701/3000], Loss: 3561.8501\n",
      "Validation Loss: 2922.7905\n",
      "Epoch [721/3000], Loss: 3517.1722\n",
      "Validation Loss: 2905.8027\n",
      "Epoch [741/3000], Loss: 3466.0505\n",
      "Validation Loss: 2891.1543\n",
      "Epoch [761/3000], Loss: 3421.5182\n",
      "Validation Loss: 2878.8060\n",
      "Epoch [781/3000], Loss: 3380.1580\n",
      "Validation Loss: 2868.7272\n",
      "Epoch [801/3000], Loss: 3338.5326\n",
      "Validation Loss: 2860.9050\n",
      "Epoch [821/3000], Loss: 3300.6467\n",
      "Validation Loss: 2855.2839\n",
      "Epoch [841/3000], Loss: 3262.2024\n",
      "Validation Loss: 2851.8113\n",
      "Epoch [861/3000], Loss: 3216.0697\n",
      "Validation Loss: 2850.4603\n",
      "Epoch [881/3000], Loss: 3198.1843\n",
      "Validation Loss: 2851.1735\n",
      "Epoch [901/3000], Loss: 3160.6296\n",
      "Validation Loss: 2853.8864\n",
      "Epoch [921/3000], Loss: 3136.4423\n",
      "Validation Loss: 2858.5273\n",
      "Epoch [941/3000], Loss: 3115.2228\n",
      "Validation Loss: 2865.0141\n",
      "Epoch [961/3000], Loss: 3096.8751\n",
      "Validation Loss: 2873.2643\n",
      "Epoch [981/3000], Loss: 3073.9512\n",
      "Validation Loss: 2883.1638\n",
      "Epoch [1001/3000], Loss: 3053.6900\n",
      "Validation Loss: 2894.6025\n",
      "Epoch [1021/3000], Loss: 3035.2698\n",
      "Validation Loss: 2907.4155\n",
      "Epoch [1041/3000], Loss: 3027.3338\n",
      "Validation Loss: 2921.4044\n",
      "Epoch [1061/3000], Loss: 3016.9152\n",
      "Validation Loss: 2936.4317\n",
      "Epoch [1081/3000], Loss: 3000.3998\n",
      "Validation Loss: 2952.3166\n",
      "Epoch [1101/3000], Loss: 2994.7839\n",
      "Validation Loss: 2968.7130\n",
      "Epoch [1121/3000], Loss: 2986.2426\n",
      "Validation Loss: 2985.4208\n",
      "Epoch [1141/3000], Loss: 2985.8108\n",
      "Validation Loss: 3001.8547\n",
      "Epoch [1161/3000], Loss: 2975.3727\n",
      "Validation Loss: 3017.8656\n",
      "Epoch [1181/3000], Loss: 2971.2321\n",
      "Validation Loss: 3032.9427\n",
      "Epoch [1201/3000], Loss: 2968.5088\n",
      "Validation Loss: 3046.7094\n",
      "Epoch [1221/3000], Loss: 2966.6893\n",
      "Validation Loss: 3058.4956\n",
      "Epoch [1241/3000], Loss: 2967.0385\n",
      "Validation Loss: 3069.0589\n",
      "Epoch [1261/3000], Loss: 2974.8774\n",
      "Validation Loss: 3077.5949\n",
      "Epoch [1281/3000], Loss: 2963.2419\n",
      "Validation Loss: 3084.5884\n",
      "Epoch [1301/3000], Loss: 2969.8189\n",
      "Validation Loss: 3089.9048\n",
      "Epoch [1321/3000], Loss: 2963.4801\n",
      "Validation Loss: 3093.7987\n",
      "Epoch [1341/3000], Loss: 2969.2697\n",
      "Validation Loss: 3096.5135\n",
      "Epoch [1361/3000], Loss: 2964.4267\n",
      "Validation Loss: 3098.3639\n",
      "Epoch [1381/3000], Loss: 2971.5817\n",
      "Validation Loss: 3100.2754\n",
      "Epoch [1401/3000], Loss: 2972.5080\n",
      "Validation Loss: 3101.3467\n",
      "Epoch [1421/3000], Loss: 2975.5034\n",
      "Validation Loss: 3102.3256\n",
      "Epoch [1441/3000], Loss: 2962.2789\n",
      "Validation Loss: 3102.9375\n",
      "Epoch [1461/3000], Loss: 2968.9985\n",
      "Validation Loss: 3103.4432\n",
      "Epoch [1481/3000], Loss: 2970.9112\n",
      "Validation Loss: 3103.5020\n",
      "Epoch [1501/3000], Loss: 2965.2364\n",
      "Validation Loss: 3103.5508\n",
      "Epoch [1521/3000], Loss: 2967.7586\n",
      "Validation Loss: 3103.6794\n",
      "Epoch [1541/3000], Loss: 2967.6477\n",
      "Validation Loss: 3103.5807\n",
      "Epoch [1561/3000], Loss: 2966.1783\n",
      "Validation Loss: 3103.5015\n",
      "Epoch [1581/3000], Loss: 2967.1996\n",
      "Validation Loss: 3103.5580\n",
      "Epoch [1601/3000], Loss: 2976.5011\n",
      "Validation Loss: 3103.2022\n",
      "Epoch [1621/3000], Loss: 2962.4455\n",
      "Validation Loss: 3103.5768\n",
      "Epoch [1641/3000], Loss: 2963.8156\n",
      "Validation Loss: 3103.7965\n",
      "Epoch [1661/3000], Loss: 2975.4252\n",
      "Validation Loss: 3103.8976\n",
      "Epoch [1681/3000], Loss: 2962.9566\n",
      "Validation Loss: 3103.9003\n",
      "Epoch [1701/3000], Loss: 2967.2688\n",
      "Validation Loss: 3103.9427\n",
      "Epoch [1721/3000], Loss: 2965.9970\n",
      "Validation Loss: 3103.9248\n",
      "Epoch [1741/3000], Loss: 2969.7405\n",
      "Validation Loss: 3104.0871\n",
      "Epoch [1761/3000], Loss: 1787.3726\n",
      "Validation Loss: 1448.3312\n",
      "Epoch [1781/3000], Loss: 1587.4113\n",
      "Validation Loss: 1323.7698\n",
      "Epoch [1801/3000], Loss: 1471.9566\n",
      "Validation Loss: 1260.2932\n",
      "Epoch [1821/3000], Loss: 1409.3110\n",
      "Validation Loss: 1231.1407\n",
      "Epoch [1841/3000], Loss: 1338.1165\n",
      "Validation Loss: 1190.8352\n",
      "Epoch [1861/3000], Loss: 1287.0453\n",
      "Validation Loss: 1154.5696\n",
      "Epoch [1881/3000], Loss: 1230.6873\n",
      "Validation Loss: 1124.4243\n",
      "Epoch [1901/3000], Loss: 1178.1685\n",
      "Validation Loss: 1091.3340\n",
      "Epoch [1921/3000], Loss: 1142.8718\n",
      "Validation Loss: 1063.1290\n",
      "Epoch [1941/3000], Loss: 1083.1163\n",
      "Validation Loss: 1037.1435\n",
      "Epoch [1961/3000], Loss: 1036.7940\n",
      "Validation Loss: 1018.4146\n",
      "Epoch [1981/3000], Loss: 1005.8510\n",
      "Validation Loss: 992.3874\n",
      "Epoch [2001/3000], Loss: 952.8613\n",
      "Validation Loss: 973.7140\n",
      "Epoch [2021/3000], Loss: 921.7706\n",
      "Validation Loss: 961.3515\n",
      "Epoch [2041/3000], Loss: 882.8295\n",
      "Validation Loss: 946.3155\n",
      "Epoch [2061/3000], Loss: 843.3513\n",
      "Validation Loss: 927.8172\n",
      "Epoch [2081/3000], Loss: 812.4229\n",
      "Validation Loss: 905.4666\n",
      "Epoch [2101/3000], Loss: 782.1664\n",
      "Validation Loss: 888.9103\n",
      "Epoch [2121/3000], Loss: 749.8884\n",
      "Validation Loss: 871.2965\n",
      "Epoch [2141/3000], Loss: 712.8307\n",
      "Validation Loss: 849.3724\n",
      "Epoch [2161/3000], Loss: 682.3587\n",
      "Validation Loss: 837.6763\n",
      "Epoch [2181/3000], Loss: 669.2925\n",
      "Validation Loss: 838.7316\n",
      "Epoch [2201/3000], Loss: 626.8322\n",
      "Validation Loss: 817.4480\n",
      "Epoch [2221/3000], Loss: 601.0626\n",
      "Validation Loss: 801.5095\n",
      "Epoch [2241/3000], Loss: 573.5592\n",
      "Validation Loss: 788.5213\n",
      "Epoch [2261/3000], Loss: 549.3338\n",
      "Validation Loss: 777.9276\n",
      "Epoch [2281/3000], Loss: 523.8856\n",
      "Validation Loss: 771.7442\n",
      "Epoch [2301/3000], Loss: 500.7659\n",
      "Validation Loss: 767.2262\n",
      "Epoch [2321/3000], Loss: 475.5424\n",
      "Validation Loss: 749.3869\n",
      "Epoch [2341/3000], Loss: 455.1076\n",
      "Validation Loss: 736.5121\n",
      "Epoch [2361/3000], Loss: 435.1843\n",
      "Validation Loss: 723.7248\n",
      "Epoch [2381/3000], Loss: 416.6874\n",
      "Validation Loss: 713.8324\n",
      "Epoch [2401/3000], Loss: 397.7207\n",
      "Validation Loss: 710.5015\n",
      "Epoch [2421/3000], Loss: 381.0549\n",
      "Validation Loss: 700.6909\n",
      "Epoch [2441/3000], Loss: 360.9470\n",
      "Validation Loss: 684.7055\n",
      "Epoch [2461/3000], Loss: 346.7331\n",
      "Validation Loss: 675.9644\n",
      "Epoch [2481/3000], Loss: 332.1015\n",
      "Validation Loss: 677.3466\n",
      "Epoch [2501/3000], Loss: 315.4791\n",
      "Validation Loss: 663.3977\n",
      "Epoch [2521/3000], Loss: 302.9380\n",
      "Validation Loss: 652.5974\n",
      "Epoch [2541/3000], Loss: 290.6564\n",
      "Validation Loss: 636.9101\n",
      "Epoch [2561/3000], Loss: 273.8820\n",
      "Validation Loss: 629.7836\n",
      "Epoch [2581/3000], Loss: 256.3706\n",
      "Validation Loss: 629.3113\n",
      "Epoch [2601/3000], Loss: 241.1874\n",
      "Validation Loss: 622.5013\n",
      "Epoch [2621/3000], Loss: 227.8322\n",
      "Validation Loss: 611.1340\n",
      "Epoch [2641/3000], Loss: 213.1430\n",
      "Validation Loss: 593.7630\n",
      "Epoch [2661/3000], Loss: 197.8924\n",
      "Validation Loss: 596.8136\n",
      "Epoch [2681/3000], Loss: 186.9050\n",
      "Validation Loss: 582.2694\n",
      "Epoch [2701/3000], Loss: 175.3154\n",
      "Validation Loss: 575.9317\n",
      "Epoch [2721/3000], Loss: 163.7208\n",
      "Validation Loss: 566.7298\n",
      "Epoch [2741/3000], Loss: 153.6495\n",
      "Validation Loss: 549.4953\n",
      "Epoch [2761/3000], Loss: 146.6937\n",
      "Validation Loss: 580.5099\n",
      "Epoch [2781/3000], Loss: 137.2841\n",
      "Validation Loss: 566.7352\n",
      "Epoch [2801/3000], Loss: 129.0823\n",
      "Validation Loss: 560.1364\n",
      "Epoch [2821/3000], Loss: 118.5164\n",
      "Validation Loss: 553.1173\n",
      "Epoch [2841/3000], Loss: 114.7517\n",
      "Validation Loss: 548.8201\n",
      "Epoch [2861/3000], Loss: 106.5305\n",
      "Validation Loss: 540.1766\n",
      "Epoch [2881/3000], Loss: 100.9374\n",
      "Validation Loss: 538.5993\n",
      "Epoch [2901/3000], Loss: 95.1810\n",
      "Validation Loss: 558.0754\n",
      "Epoch [2921/3000], Loss: 89.7651\n",
      "Validation Loss: 551.7949\n",
      "Epoch [2941/3000], Loss: 84.2549\n",
      "Validation Loss: 546.0183\n",
      "Epoch [2961/3000], Loss: 79.0432\n",
      "Validation Loss: 540.9795\n",
      "Epoch [2981/3000], Loss: 73.1586\n",
      "Validation Loss: 537.0960\n",
      "Y:\\analysis\\fmats\\e217\\days\\e217_day029_plane0_Fall.mat\n",
      "(22706, 58)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9936.5362\n",
      "Validation Loss: 9877.1743\n",
      "Epoch [21/3000], Loss: 7914.1577\n",
      "Validation Loss: 7820.9552\n",
      "Epoch [41/3000], Loss: 7298.2060\n",
      "Validation Loss: 7190.0671\n",
      "Epoch [61/3000], Loss: 6731.2620\n",
      "Validation Loss: 6611.4634\n",
      "Epoch [81/3000], Loss: 6204.9956\n",
      "Validation Loss: 6074.9877\n",
      "Epoch [101/3000], Loss: 5723.5757\n",
      "Validation Loss: 5577.0252\n",
      "Epoch [121/3000], Loss: 5270.4611\n",
      "Validation Loss: 5115.3997\n",
      "Epoch [141/3000], Loss: 4845.9388\n",
      "Validation Loss: 4685.0144\n",
      "Epoch [161/3000], Loss: 4470.5373\n",
      "Validation Loss: 4298.0122\n",
      "Epoch [181/3000], Loss: 4131.7858\n",
      "Validation Loss: 3949.4224\n",
      "Epoch [201/3000], Loss: 3832.4010\n",
      "Validation Loss: 3638.5583\n",
      "Epoch [221/3000], Loss: 3565.6640\n",
      "Validation Loss: 3362.6938\n",
      "Epoch [241/3000], Loss: 3336.1331\n",
      "Validation Loss: 3125.5961\n",
      "Epoch [261/3000], Loss: 3147.0668\n",
      "Validation Loss: 2925.3561\n",
      "Epoch [281/3000], Loss: 2994.3191\n",
      "Validation Loss: 2759.7985\n",
      "Epoch [301/3000], Loss: 2861.5402\n",
      "Validation Loss: 2619.5760\n",
      "Epoch [321/3000], Loss: 2772.7030\n",
      "Validation Loss: 2520.4950\n",
      "Epoch [341/3000], Loss: 2700.1420\n",
      "Validation Loss: 2442.5329\n",
      "Epoch [361/3000], Loss: 2666.0774\n",
      "Validation Loss: 2401.0201\n",
      "Epoch [381/3000], Loss: 2651.9905\n",
      "Validation Loss: 2382.2981\n",
      "Epoch [401/3000], Loss: 2641.9614\n",
      "Validation Loss: 2373.8117\n",
      "Epoch [421/3000], Loss: 2527.0081\n",
      "Validation Loss: 2270.5898\n",
      "Epoch [441/3000], Loss: 2350.9053\n",
      "Validation Loss: 2109.3465\n",
      "Epoch [461/3000], Loss: 2068.0747\n",
      "Validation Loss: 1875.1549\n",
      "Epoch [481/3000], Loss: 1704.2216\n",
      "Validation Loss: 1535.4444\n",
      "Epoch [501/3000], Loss: 1528.6937\n",
      "Validation Loss: 1437.3383\n",
      "Epoch [521/3000], Loss: 1385.7358\n",
      "Validation Loss: 1360.9331\n",
      "Epoch [541/3000], Loss: 1277.1048\n",
      "Validation Loss: 1327.2751\n",
      "Epoch [561/3000], Loss: 1185.3057\n",
      "Validation Loss: 1321.3385\n",
      "Epoch [581/3000], Loss: 1103.5389\n",
      "Validation Loss: 1301.7482\n",
      "Epoch [601/3000], Loss: 1028.2654\n",
      "Validation Loss: 1297.8499\n",
      "Epoch [621/3000], Loss: 968.2496\n",
      "Validation Loss: 1300.1887\n",
      "Epoch [641/3000], Loss: 909.5840\n",
      "Validation Loss: 1316.7246\n",
      "Epoch [661/3000], Loss: 855.6090\n",
      "Validation Loss: 1355.6861\n",
      "Epoch [681/3000], Loss: 807.0161\n",
      "Validation Loss: 1372.6039\n",
      "Epoch [701/3000], Loss: 752.4422\n",
      "Validation Loss: 1403.0396\n",
      "Epoch [721/3000], Loss: 712.2312\n",
      "Validation Loss: 1437.7103\n",
      "Epoch [741/3000], Loss: 659.5584\n",
      "Validation Loss: 1465.4954\n",
      "Epoch [761/3000], Loss: 628.8381\n",
      "Validation Loss: 1526.4130\n",
      "Epoch [781/3000], Loss: 584.8268\n",
      "Validation Loss: 1525.4415\n",
      "Epoch [801/3000], Loss: 555.7426\n",
      "Validation Loss: 1637.9791\n",
      "Epoch [821/3000], Loss: 521.0908\n",
      "Validation Loss: 1567.9382\n",
      "Epoch [841/3000], Loss: 487.9588\n",
      "Validation Loss: 1587.8736\n",
      "Epoch [861/3000], Loss: 466.0294\n",
      "Validation Loss: 1604.1073\n",
      "Epoch [881/3000], Loss: 428.8220\n",
      "Validation Loss: 1620.3456\n",
      "Epoch [901/3000], Loss: 404.1057\n",
      "Validation Loss: 1660.3941\n",
      "Epoch [921/3000], Loss: 376.7295\n",
      "Validation Loss: 1667.4717\n",
      "Epoch [941/3000], Loss: 359.7311\n",
      "Validation Loss: 1693.5528\n",
      "Epoch [961/3000], Loss: 343.1311\n",
      "Validation Loss: 1705.8612\n",
      "Epoch [981/3000], Loss: 319.0691\n",
      "Validation Loss: 1739.9211\n",
      "Epoch [1001/3000], Loss: 301.7166\n",
      "Validation Loss: 1749.2682\n",
      "Epoch [1021/3000], Loss: 277.6595\n",
      "Validation Loss: 1770.8746\n",
      "Epoch [1041/3000], Loss: 258.1830\n",
      "Validation Loss: 1774.7043\n",
      "Epoch [1061/3000], Loss: 246.5501\n",
      "Validation Loss: 1827.1245\n",
      "Epoch [1081/3000], Loss: 239.5922\n",
      "Validation Loss: 1825.2960\n",
      "Epoch [1101/3000], Loss: 219.2937\n",
      "Validation Loss: 1861.4360\n",
      "Epoch [1121/3000], Loss: 206.3677\n",
      "Validation Loss: 1864.1512\n",
      "Epoch [1141/3000], Loss: 202.4057\n",
      "Validation Loss: 1872.7980\n",
      "Epoch [1161/3000], Loss: 181.2809\n",
      "Validation Loss: 1896.5808\n",
      "Epoch [1181/3000], Loss: 170.2848\n",
      "Validation Loss: 1884.3081\n",
      "Epoch [1201/3000], Loss: 165.3284\n",
      "Validation Loss: 1942.2802\n",
      "Epoch [1221/3000], Loss: 148.6610\n",
      "Validation Loss: 1942.2323\n",
      "Epoch [1241/3000], Loss: 138.1529\n",
      "Validation Loss: 1933.9865\n",
      "Epoch [1261/3000], Loss: 128.9823\n",
      "Validation Loss: 1973.1327\n",
      "Epoch [1281/3000], Loss: 121.0209\n",
      "Validation Loss: 1961.4645\n",
      "Epoch [1301/3000], Loss: 114.8346\n",
      "Validation Loss: 1963.2727\n",
      "Epoch [1321/3000], Loss: 112.5557\n",
      "Validation Loss: 1967.5646\n",
      "Epoch [1341/3000], Loss: 105.7167\n",
      "Validation Loss: 1976.7687\n",
      "Epoch [1361/3000], Loss: 95.7186\n",
      "Validation Loss: 1989.0424\n",
      "Epoch [1381/3000], Loss: 88.9926\n",
      "Validation Loss: 1992.5807\n",
      "Epoch [1401/3000], Loss: 141.1154\n",
      "Validation Loss: 1986.6660\n",
      "Epoch [1421/3000], Loss: 80.4589\n",
      "Validation Loss: 1991.8944\n",
      "Epoch [1441/3000], Loss: 75.5977\n",
      "Validation Loss: 1992.6472\n",
      "Epoch [1461/3000], Loss: 69.6005\n",
      "Validation Loss: 1981.5997\n",
      "Epoch [1481/3000], Loss: 66.2421\n",
      "Validation Loss: 1996.6925\n",
      "Epoch [1501/3000], Loss: 61.8627\n",
      "Validation Loss: 1998.5500\n",
      "Epoch [1521/3000], Loss: 58.7476\n",
      "Validation Loss: 1985.7835\n",
      "Epoch [1541/3000], Loss: 56.3681\n",
      "Validation Loss: 1986.1848\n",
      "Epoch [1561/3000], Loss: 52.5693\n",
      "Validation Loss: 1987.6653\n",
      "Epoch [1581/3000], Loss: 49.7742\n",
      "Validation Loss: 1995.0019\n",
      "Epoch [1601/3000], Loss: 46.7597\n",
      "Validation Loss: 1993.4470\n",
      "Epoch [1621/3000], Loss: 42.7962\n",
      "Validation Loss: 1989.2620\n",
      "Epoch [1641/3000], Loss: 40.4431\n",
      "Validation Loss: 1997.7123\n",
      "Epoch [1661/3000], Loss: 38.1067\n",
      "Validation Loss: 2014.9229\n",
      "Epoch [1681/3000], Loss: 36.8179\n",
      "Validation Loss: 1992.8696\n",
      "Epoch [1701/3000], Loss: 44.7724\n",
      "Validation Loss: 2004.3394\n",
      "Epoch [1721/3000], Loss: 32.3666\n",
      "Validation Loss: 2020.6589\n",
      "Epoch [1741/3000], Loss: 29.5912\n",
      "Validation Loss: 2013.0258\n",
      "Epoch [1761/3000], Loss: 31.4610\n",
      "Validation Loss: 1987.9286\n",
      "Epoch [1781/3000], Loss: 28.8204\n",
      "Validation Loss: 2014.5920\n",
      "Epoch [1801/3000], Loss: 24.7160\n",
      "Validation Loss: 2025.9323\n",
      "Epoch [1821/3000], Loss: 23.2884\n",
      "Validation Loss: 2011.5349\n",
      "Epoch [1841/3000], Loss: 24.0908\n",
      "Validation Loss: 2007.4193\n",
      "Epoch [1861/3000], Loss: 21.9596\n",
      "Validation Loss: 2031.6276\n",
      "Epoch [1881/3000], Loss: 20.6890\n",
      "Validation Loss: 2032.4778\n",
      "Epoch [1901/3000], Loss: 19.9084\n",
      "Validation Loss: 2023.4674\n",
      "Epoch [1921/3000], Loss: 18.5434\n",
      "Validation Loss: 2010.1736\n",
      "Epoch [1941/3000], Loss: 18.3943\n",
      "Validation Loss: 2015.1073\n",
      "Epoch [1961/3000], Loss: 17.9351\n",
      "Validation Loss: 2021.0669\n",
      "Epoch [1981/3000], Loss: 15.9476\n",
      "Validation Loss: 2022.7002\n",
      "Epoch [2001/3000], Loss: 14.9020\n",
      "Validation Loss: 2024.2613\n",
      "Epoch [2021/3000], Loss: 14.3265\n",
      "Validation Loss: 2020.3717\n",
      "Epoch [2041/3000], Loss: 13.3595\n",
      "Validation Loss: 2019.1079\n",
      "Epoch [2061/3000], Loss: 12.7669\n",
      "Validation Loss: 2032.3651\n",
      "Epoch [2081/3000], Loss: 11.8911\n",
      "Validation Loss: 2014.4957\n",
      "Epoch [2101/3000], Loss: 11.9300\n",
      "Validation Loss: 2007.9328\n",
      "Epoch [2121/3000], Loss: 11.6724\n",
      "Validation Loss: 2017.3406\n",
      "Epoch [2141/3000], Loss: 11.7949\n",
      "Validation Loss: 2019.8230\n",
      "Epoch [2161/3000], Loss: 66.9361\n",
      "Validation Loss: 1993.5779\n",
      "Epoch [2181/3000], Loss: 10.1613\n",
      "Validation Loss: 2022.6837\n",
      "Epoch [2201/3000], Loss: 9.6879\n",
      "Validation Loss: 2019.6062\n",
      "Epoch [2221/3000], Loss: 8.9879\n",
      "Validation Loss: 2011.2500\n",
      "Epoch [2241/3000], Loss: 10.0450\n",
      "Validation Loss: 2017.5673\n",
      "Epoch [2261/3000], Loss: 9.5557\n",
      "Validation Loss: 1996.3319\n",
      "Epoch [2281/3000], Loss: 8.5651\n",
      "Validation Loss: 2014.9293\n",
      "Epoch [2301/3000], Loss: 8.1449\n",
      "Validation Loss: 2006.8918\n",
      "Epoch [2321/3000], Loss: 8.5710\n",
      "Validation Loss: 2012.3939\n",
      "Epoch [2341/3000], Loss: 6.8855\n",
      "Validation Loss: 1993.7996\n",
      "Epoch [2361/3000], Loss: 6.9343\n",
      "Validation Loss: 1995.9469\n",
      "Epoch [2381/3000], Loss: 7.5732\n",
      "Validation Loss: 2020.4488\n",
      "Epoch [2401/3000], Loss: 7.0718\n",
      "Validation Loss: 1988.0630\n",
      "Epoch [2421/3000], Loss: 6.2138\n",
      "Validation Loss: 1997.1027\n",
      "Epoch [2441/3000], Loss: 6.4863\n",
      "Validation Loss: 2003.6652\n",
      "Epoch [2461/3000], Loss: 7.1536\n",
      "Validation Loss: 1991.4331\n",
      "Epoch [2481/3000], Loss: 6.3788\n",
      "Validation Loss: 1995.9755\n",
      "Epoch [2501/3000], Loss: 14.2230\n",
      "Validation Loss: 1947.9827\n",
      "Epoch [2521/3000], Loss: 5.5987\n",
      "Validation Loss: 2018.8290\n",
      "Epoch [2541/3000], Loss: 6.2104\n",
      "Validation Loss: 1977.2490\n",
      "Epoch [2561/3000], Loss: 4.7617\n",
      "Validation Loss: 1990.1448\n",
      "Epoch [2581/3000], Loss: 5.1510\n",
      "Validation Loss: 1995.5833\n",
      "Epoch [2601/3000], Loss: 4.8383\n",
      "Validation Loss: 1995.2546\n",
      "Epoch [2621/3000], Loss: 4.5762\n",
      "Validation Loss: 1979.2143\n",
      "Epoch [2641/3000], Loss: 4.2165\n",
      "Validation Loss: 1983.1638\n",
      "Epoch [2661/3000], Loss: 4.9998\n",
      "Validation Loss: 1996.7098\n",
      "Epoch [2681/3000], Loss: 4.5495\n",
      "Validation Loss: 1965.6288\n",
      "Epoch [2701/3000], Loss: 3.8176\n",
      "Validation Loss: 1984.7246\n",
      "Epoch [2721/3000], Loss: 4.3189\n",
      "Validation Loss: 1974.2497\n",
      "Epoch [2741/3000], Loss: 4.0144\n",
      "Validation Loss: 1972.7886\n",
      "Epoch [2761/3000], Loss: 4.3001\n",
      "Validation Loss: 1983.6416\n",
      "Epoch [2781/3000], Loss: 4.9034\n",
      "Validation Loss: 1973.9293\n",
      "Epoch [2801/3000], Loss: 3.8563\n",
      "Validation Loss: 1966.0640\n",
      "Epoch [2821/3000], Loss: 3.9648\n",
      "Validation Loss: 1972.9957\n",
      "Epoch [2841/3000], Loss: 3.4596\n",
      "Validation Loss: 1965.6004\n",
      "Epoch [2861/3000], Loss: 2.9856\n",
      "Validation Loss: 1967.1091\n",
      "Epoch [2881/3000], Loss: 3.0842\n",
      "Validation Loss: 1973.9124\n",
      "Epoch [2901/3000], Loss: 3.2833\n",
      "Validation Loss: 1952.7164\n",
      "Epoch [2921/3000], Loss: 3.0240\n",
      "Validation Loss: 1969.4754\n",
      "Epoch [2941/3000], Loss: 2.6366\n",
      "Validation Loss: 1965.0624\n",
      "Epoch [2961/3000], Loss: 2.8818\n",
      "Validation Loss: 1952.2483\n",
      "Epoch [2981/3000], Loss: 2.9686\n",
      "Validation Loss: 1976.6843\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day065_plane0_Fall.mat\n",
      "(5001, 95)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7097.1999\n",
      "Validation Loss: 5992.8322\n",
      "Epoch [21/3000], Loss: 6195.1191\n",
      "Validation Loss: 5146.5044\n",
      "Epoch [41/3000], Loss: 5905.7519\n",
      "Validation Loss: 4935.2216\n",
      "Epoch [61/3000], Loss: 5818.9798\n",
      "Validation Loss: 4820.8435\n",
      "Epoch [81/3000], Loss: 5700.8846\n",
      "Validation Loss: 4725.1764\n",
      "Epoch [101/3000], Loss: 5587.6583\n",
      "Validation Loss: 4637.0920\n",
      "Epoch [121/3000], Loss: 5493.6158\n",
      "Validation Loss: 4553.9046\n",
      "Epoch [141/3000], Loss: 5369.9894\n",
      "Validation Loss: 4474.1763\n",
      "Epoch [161/3000], Loss: 5320.4525\n",
      "Validation Loss: 4395.8633\n",
      "Epoch [181/3000], Loss: 5238.4617\n",
      "Validation Loss: 4321.0733\n",
      "Epoch [201/3000], Loss: 5127.2460\n",
      "Validation Loss: 4248.6818\n",
      "Epoch [221/3000], Loss: 5061.2012\n",
      "Validation Loss: 4178.5404\n",
      "Epoch [241/3000], Loss: 4968.5476\n",
      "Validation Loss: 4110.4374\n",
      "Epoch [261/3000], Loss: 4904.3505\n",
      "Validation Loss: 4044.2653\n",
      "Epoch [281/3000], Loss: 4808.8347\n",
      "Validation Loss: 3980.0809\n",
      "Epoch [301/3000], Loss: 4712.3421\n",
      "Validation Loss: 3917.7532\n",
      "Epoch [321/3000], Loss: 4687.3184\n",
      "Validation Loss: 3857.1631\n",
      "Epoch [341/3000], Loss: 4609.4374\n",
      "Validation Loss: 3798.4245\n",
      "Epoch [361/3000], Loss: 4543.4076\n",
      "Validation Loss: 3741.4740\n",
      "Epoch [381/3000], Loss: 4490.2404\n",
      "Validation Loss: 3686.2643\n",
      "Epoch [401/3000], Loss: 4387.9354\n",
      "Validation Loss: 3632.8022\n",
      "Epoch [421/3000], Loss: 4350.2700\n",
      "Validation Loss: 3581.1217\n",
      "Epoch [441/3000], Loss: 4288.5414\n",
      "Validation Loss: 3531.1449\n",
      "Epoch [461/3000], Loss: 4224.5908\n",
      "Validation Loss: 3482.9009\n",
      "Epoch [481/3000], Loss: 4164.0154\n",
      "Validation Loss: 3436.4324\n",
      "Epoch [501/3000], Loss: 4112.5205\n",
      "Validation Loss: 3391.6876\n",
      "Epoch [521/3000], Loss: 4060.0004\n",
      "Validation Loss: 3348.6370\n",
      "Epoch [541/3000], Loss: 3991.0482\n",
      "Validation Loss: 3307.3157\n",
      "Epoch [561/3000], Loss: 3948.2417\n",
      "Validation Loss: 3267.6865\n",
      "Epoch [581/3000], Loss: 3885.7880\n",
      "Validation Loss: 3229.8160\n",
      "Epoch [601/3000], Loss: 3885.3001\n",
      "Validation Loss: 3193.5675\n",
      "Epoch [621/3000], Loss: 3815.0341\n",
      "Validation Loss: 3158.8924\n",
      "Epoch [641/3000], Loss: 3775.4107\n",
      "Validation Loss: 3125.9599\n",
      "Epoch [661/3000], Loss: 3729.9920\n",
      "Validation Loss: 3094.6849\n",
      "Epoch [681/3000], Loss: 3693.8272\n",
      "Validation Loss: 3065.1112\n",
      "Epoch [701/3000], Loss: 3643.5054\n",
      "Validation Loss: 3037.1620\n",
      "Epoch [721/3000], Loss: 3583.7370\n",
      "Validation Loss: 3010.8667\n",
      "Epoch [741/3000], Loss: 3563.1477\n",
      "Validation Loss: 2986.2319\n",
      "Epoch [761/3000], Loss: 3552.7423\n",
      "Validation Loss: 2963.0443\n",
      "Epoch [781/3000], Loss: 3512.8383\n",
      "Validation Loss: 2941.4812\n",
      "Epoch [801/3000], Loss: 3472.6758\n",
      "Validation Loss: 2921.4991\n",
      "Epoch [821/3000], Loss: 3456.8683\n",
      "Validation Loss: 2903.0739\n",
      "Epoch [841/3000], Loss: 3424.0798\n",
      "Validation Loss: 2886.2319\n",
      "Epoch [861/3000], Loss: 3372.4323\n",
      "Validation Loss: 2870.8512\n",
      "Epoch [881/3000], Loss: 3375.2022\n",
      "Validation Loss: 2856.9747\n",
      "Epoch [901/3000], Loss: 3348.6209\n",
      "Validation Loss: 2844.5486\n",
      "Epoch [921/3000], Loss: 3345.8431\n",
      "Validation Loss: 2833.5083\n",
      "Epoch [941/3000], Loss: 3336.0241\n",
      "Validation Loss: 2823.9203\n",
      "Epoch [961/3000], Loss: 3294.2472\n",
      "Validation Loss: 2815.6823\n",
      "Epoch [981/3000], Loss: 3262.4148\n",
      "Validation Loss: 2808.7615\n",
      "Epoch [1001/3000], Loss: 3253.5062\n",
      "Validation Loss: 2803.1841\n",
      "Epoch [1021/3000], Loss: 3256.5353\n",
      "Validation Loss: 2798.7526\n",
      "Epoch [1041/3000], Loss: 3249.1249\n",
      "Validation Loss: 2795.5279\n",
      "Epoch [1061/3000], Loss: 3228.8959\n",
      "Validation Loss: 2793.4087\n",
      "Epoch [1081/3000], Loss: 3207.2204\n",
      "Validation Loss: 2792.3203\n",
      "Epoch [1101/3000], Loss: 3220.9606\n",
      "Validation Loss: 2792.1772\n",
      "Epoch [1121/3000], Loss: 3206.0159\n",
      "Validation Loss: 2792.8963\n",
      "Epoch [1141/3000], Loss: 3199.1776\n",
      "Validation Loss: 2794.3432\n",
      "Epoch [1161/3000], Loss: 3191.2831\n",
      "Validation Loss: 2796.3865\n",
      "Epoch [1181/3000], Loss: 3190.9069\n",
      "Validation Loss: 2798.9406\n",
      "Epoch [1201/3000], Loss: 3181.8107\n",
      "Validation Loss: 2801.8543\n",
      "Epoch [1221/3000], Loss: 3196.4758\n",
      "Validation Loss: 2804.9259\n",
      "Epoch [1241/3000], Loss: 3116.3443\n",
      "Validation Loss: 2704.0240\n",
      "Epoch [1261/3000], Loss: 2191.9049\n",
      "Validation Loss: 1686.7661\n",
      "Epoch [1281/3000], Loss: 2017.4447\n",
      "Validation Loss: 1598.2594\n",
      "Epoch [1301/3000], Loss: 1928.2085\n",
      "Validation Loss: 1548.9163\n",
      "Epoch [1321/3000], Loss: 1861.0498\n",
      "Validation Loss: 1506.9282\n",
      "Epoch [1341/3000], Loss: 1784.8236\n",
      "Validation Loss: 1495.7588\n",
      "Epoch [1361/3000], Loss: 1744.3870\n",
      "Validation Loss: 1479.5052\n",
      "Epoch [1381/3000], Loss: 1686.3518\n",
      "Validation Loss: 1438.1898\n",
      "Epoch [1401/3000], Loss: 1646.9316\n",
      "Validation Loss: 1393.4576\n",
      "Epoch [1421/3000], Loss: 1611.0492\n",
      "Validation Loss: 1399.9147\n",
      "Epoch [1441/3000], Loss: 1567.3630\n",
      "Validation Loss: 1344.8206\n",
      "Epoch [1461/3000], Loss: 1549.0848\n",
      "Validation Loss: 1337.7919\n",
      "Epoch [1481/3000], Loss: 1494.5344\n",
      "Validation Loss: 1346.0196\n",
      "Epoch [1501/3000], Loss: 1451.1557\n",
      "Validation Loss: 1283.1662\n",
      "Epoch [1521/3000], Loss: 1414.9749\n",
      "Validation Loss: 1283.4550\n",
      "Epoch [1541/3000], Loss: 1365.7033\n",
      "Validation Loss: 1233.4484\n",
      "Epoch [1561/3000], Loss: 1339.1167\n",
      "Validation Loss: 1275.1954\n",
      "Epoch [1581/3000], Loss: 1306.4067\n",
      "Validation Loss: 1230.2009\n",
      "Epoch [1601/3000], Loss: 1275.5361\n",
      "Validation Loss: 1206.6492\n",
      "Epoch [1621/3000], Loss: 1230.3496\n",
      "Validation Loss: 1160.7466\n",
      "Epoch [1641/3000], Loss: 1221.7977\n",
      "Validation Loss: 1116.3524\n",
      "Epoch [1661/3000], Loss: 1195.1185\n",
      "Validation Loss: 1104.4490\n",
      "Epoch [1681/3000], Loss: 1156.1113\n",
      "Validation Loss: 1122.6181\n",
      "Epoch [1701/3000], Loss: 1124.9228\n",
      "Validation Loss: 1100.6111\n",
      "Epoch [1721/3000], Loss: 1082.6363\n",
      "Validation Loss: 1089.0701\n",
      "Epoch [1741/3000], Loss: 1065.0217\n",
      "Validation Loss: 1070.8556\n",
      "Epoch [1761/3000], Loss: 1045.1672\n",
      "Validation Loss: 1068.9185\n",
      "Epoch [1781/3000], Loss: 1021.6445\n",
      "Validation Loss: 1079.8090\n",
      "Epoch [1801/3000], Loss: 995.2532\n",
      "Validation Loss: 1035.5346\n",
      "Epoch [1821/3000], Loss: 973.5773\n",
      "Validation Loss: 1058.1096\n",
      "Epoch [1841/3000], Loss: 944.5865\n",
      "Validation Loss: 996.7605\n",
      "Epoch [1861/3000], Loss: 919.6467\n",
      "Validation Loss: 1013.0357\n",
      "Epoch [1881/3000], Loss: 887.1382\n",
      "Validation Loss: 1017.3897\n",
      "Epoch [1901/3000], Loss: 862.8207\n",
      "Validation Loss: 998.2649\n",
      "Epoch [1921/3000], Loss: 840.9463\n",
      "Validation Loss: 1040.5591\n",
      "Epoch [1941/3000], Loss: 814.3675\n",
      "Validation Loss: 1004.3602\n",
      "Epoch [1961/3000], Loss: 790.8900\n",
      "Validation Loss: 990.7780\n",
      "Epoch [1981/3000], Loss: 758.9639\n",
      "Validation Loss: 1004.3224\n",
      "Epoch [2001/3000], Loss: 732.9773\n",
      "Validation Loss: 984.6515\n",
      "Epoch [2021/3000], Loss: 708.1578\n",
      "Validation Loss: 975.7972\n",
      "Epoch [2041/3000], Loss: 683.2701\n",
      "Validation Loss: 980.7134\n",
      "Epoch [2061/3000], Loss: 658.9721\n",
      "Validation Loss: 972.3128\n",
      "Epoch [2081/3000], Loss: 652.8292\n",
      "Validation Loss: 954.8341\n",
      "Epoch [2101/3000], Loss: 622.5358\n",
      "Validation Loss: 970.6098\n",
      "Epoch [2121/3000], Loss: 607.2355\n",
      "Validation Loss: 1000.4854\n",
      "Epoch [2141/3000], Loss: 584.5722\n",
      "Validation Loss: 970.4785\n",
      "Epoch [2161/3000], Loss: 559.0477\n",
      "Validation Loss: 963.8850\n",
      "Epoch [2181/3000], Loss: 552.8012\n",
      "Validation Loss: 985.7363\n",
      "Epoch [2201/3000], Loss: 530.3524\n",
      "Validation Loss: 1008.4626\n",
      "Epoch [2221/3000], Loss: 507.6671\n",
      "Validation Loss: 947.5558\n",
      "Epoch [2241/3000], Loss: 497.3015\n",
      "Validation Loss: 1020.2383\n",
      "Epoch [2261/3000], Loss: 469.7616\n",
      "Validation Loss: 949.6101\n",
      "Epoch [2281/3000], Loss: 458.7190\n",
      "Validation Loss: 950.3862\n",
      "Epoch [2301/3000], Loss: 445.7694\n",
      "Validation Loss: 942.8053\n",
      "Epoch [2321/3000], Loss: 425.6387\n",
      "Validation Loss: 885.6166\n",
      "Epoch [2341/3000], Loss: 412.0498\n",
      "Validation Loss: 951.8485\n",
      "Epoch [2361/3000], Loss: 406.5818\n",
      "Validation Loss: 932.3112\n",
      "Epoch [2381/3000], Loss: 384.9350\n",
      "Validation Loss: 938.3165\n",
      "Epoch [2401/3000], Loss: 369.7653\n",
      "Validation Loss: 930.2143\n",
      "Epoch [2421/3000], Loss: 352.1429\n",
      "Validation Loss: 963.7533\n",
      "Epoch [2441/3000], Loss: 333.6227\n",
      "Validation Loss: 989.1194\n",
      "Epoch [2461/3000], Loss: 318.4688\n",
      "Validation Loss: 989.9024\n",
      "Epoch [2481/3000], Loss: 306.4411\n",
      "Validation Loss: 955.9347\n",
      "Epoch [2501/3000], Loss: 294.7882\n",
      "Validation Loss: 1011.6627\n",
      "Epoch [2521/3000], Loss: 281.8857\n",
      "Validation Loss: 1079.7418\n",
      "Epoch [2541/3000], Loss: 272.8661\n",
      "Validation Loss: 997.3233\n",
      "Epoch [2561/3000], Loss: 269.3761\n",
      "Validation Loss: 970.9560\n",
      "Epoch [2581/3000], Loss: 245.4883\n",
      "Validation Loss: 991.2742\n",
      "Epoch [2601/3000], Loss: 232.4720\n",
      "Validation Loss: 1023.9000\n",
      "Epoch [2621/3000], Loss: 222.8678\n",
      "Validation Loss: 1023.5537\n",
      "Epoch [2641/3000], Loss: 213.7888\n",
      "Validation Loss: 987.3249\n",
      "Epoch [2661/3000], Loss: 202.6677\n",
      "Validation Loss: 1019.2626\n",
      "Epoch [2681/3000], Loss: 195.2131\n",
      "Validation Loss: 999.4585\n",
      "Epoch [2701/3000], Loss: 184.0967\n",
      "Validation Loss: 1022.6046\n",
      "Epoch [2721/3000], Loss: 175.5384\n",
      "Validation Loss: 1034.9084\n",
      "Epoch [2741/3000], Loss: 167.5812\n",
      "Validation Loss: 1028.0463\n",
      "Epoch [2761/3000], Loss: 159.6567\n",
      "Validation Loss: 1004.9395\n",
      "Epoch [2781/3000], Loss: 149.8647\n",
      "Validation Loss: 1030.5652\n",
      "Epoch [2801/3000], Loss: 146.9362\n",
      "Validation Loss: 1149.4034\n",
      "Epoch [2821/3000], Loss: 136.5388\n",
      "Validation Loss: 1075.8466\n",
      "Epoch [2841/3000], Loss: 129.1914\n",
      "Validation Loss: 1085.2850\n",
      "Epoch [2861/3000], Loss: 119.9553\n",
      "Validation Loss: 1070.2905\n",
      "Epoch [2881/3000], Loss: 112.1307\n",
      "Validation Loss: 1104.6044\n",
      "Epoch [2901/3000], Loss: 106.9055\n",
      "Validation Loss: 1073.6057\n",
      "Epoch [2921/3000], Loss: 101.5514\n",
      "Validation Loss: 1107.2672\n",
      "Epoch [2941/3000], Loss: 97.0521\n",
      "Validation Loss: 1124.0738\n",
      "Epoch [2961/3000], Loss: 95.2046\n",
      "Validation Loss: 1051.4500\n",
      "Epoch [2981/3000], Loss: 84.7916\n",
      "Validation Loss: 1099.4707\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day066_plane0_Fall.mat\n",
      "(5052, 92)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7616.1717\n",
      "Validation Loss: 6992.4172\n",
      "Epoch [21/3000], Loss: 6637.7550\n",
      "Validation Loss: 6086.4769\n",
      "Epoch [41/3000], Loss: 6377.2475\n",
      "Validation Loss: 5858.9634\n",
      "Epoch [61/3000], Loss: 6225.0093\n",
      "Validation Loss: 5733.2396\n",
      "Epoch [81/3000], Loss: 6103.7758\n",
      "Validation Loss: 5627.1093\n",
      "Epoch [101/3000], Loss: 6027.2369\n",
      "Validation Loss: 5528.1046\n",
      "Epoch [121/3000], Loss: 5945.1389\n",
      "Validation Loss: 5434.8056\n",
      "Epoch [141/3000], Loss: 5818.0143\n",
      "Validation Loss: 5346.1986\n",
      "Epoch [161/3000], Loss: 5725.1799\n",
      "Validation Loss: 5260.8016\n",
      "Epoch [181/3000], Loss: 5632.3653\n",
      "Validation Loss: 5178.1967\n",
      "Epoch [201/3000], Loss: 5526.2626\n",
      "Validation Loss: 5097.9375\n",
      "Epoch [221/3000], Loss: 5437.5219\n",
      "Validation Loss: 5019.9236\n",
      "Epoch [241/3000], Loss: 5308.2294\n",
      "Validation Loss: 4943.8837\n",
      "Epoch [261/3000], Loss: 5284.7791\n",
      "Validation Loss: 4869.8440\n",
      "Epoch [281/3000], Loss: 5207.5740\n",
      "Validation Loss: 4797.7390\n",
      "Epoch [301/3000], Loss: 5108.5306\n",
      "Validation Loss: 4727.5128\n",
      "Epoch [321/3000], Loss: 5073.5921\n",
      "Validation Loss: 4659.0411\n",
      "Epoch [341/3000], Loss: 4965.8793\n",
      "Validation Loss: 4592.4128\n",
      "Epoch [361/3000], Loss: 4886.5063\n",
      "Validation Loss: 4527.6139\n",
      "Epoch [381/3000], Loss: 4833.2761\n",
      "Validation Loss: 4464.5143\n",
      "Epoch [401/3000], Loss: 4752.1525\n",
      "Validation Loss: 4403.2178\n",
      "Epoch [421/3000], Loss: 4675.7208\n",
      "Validation Loss: 4343.5966\n",
      "Epoch [441/3000], Loss: 4597.9954\n",
      "Validation Loss: 4285.7056\n",
      "Epoch [461/3000], Loss: 4524.3377\n",
      "Validation Loss: 4229.6190\n",
      "Epoch [481/3000], Loss: 4462.9952\n",
      "Validation Loss: 4175.1938\n",
      "Epoch [501/3000], Loss: 4385.2551\n",
      "Validation Loss: 4122.4885\n",
      "Epoch [521/3000], Loss: 4353.0627\n",
      "Validation Loss: 4071.4462\n",
      "Epoch [541/3000], Loss: 4278.7953\n",
      "Validation Loss: 4022.1517\n",
      "Epoch [561/3000], Loss: 4216.1662\n",
      "Validation Loss: 3974.5521\n",
      "Epoch [581/3000], Loss: 4182.1960\n",
      "Validation Loss: 3928.6685\n",
      "Epoch [601/3000], Loss: 4122.8673\n",
      "Validation Loss: 3884.3799\n",
      "Epoch [621/3000], Loss: 4081.2034\n",
      "Validation Loss: 3841.9715\n",
      "Epoch [641/3000], Loss: 4000.3571\n",
      "Validation Loss: 3800.4539\n",
      "Epoch [661/3000], Loss: 3964.7443\n",
      "Validation Loss: 3760.8961\n",
      "Epoch [681/3000], Loss: 3921.7854\n",
      "Validation Loss: 3723.1864\n",
      "Epoch [701/3000], Loss: 3881.4044\n",
      "Validation Loss: 3687.2826\n",
      "Epoch [721/3000], Loss: 3828.9811\n",
      "Validation Loss: 3652.9868\n",
      "Epoch [741/3000], Loss: 3776.8624\n",
      "Validation Loss: 3620.4261\n",
      "Epoch [761/3000], Loss: 3742.6457\n",
      "Validation Loss: 3589.4803\n",
      "Epoch [781/3000], Loss: 3699.2950\n",
      "Validation Loss: 3560.2424\n",
      "Epoch [801/3000], Loss: 3686.4330\n",
      "Validation Loss: 3532.5091\n",
      "Epoch [821/3000], Loss: 3663.4125\n",
      "Validation Loss: 3506.4384\n",
      "Epoch [841/3000], Loss: 3595.1320\n",
      "Validation Loss: 3482.0284\n",
      "Epoch [861/3000], Loss: 3538.8031\n",
      "Validation Loss: 3459.1327\n",
      "Epoch [881/3000], Loss: 3559.0191\n",
      "Validation Loss: 3437.7431\n",
      "Epoch [901/3000], Loss: 3513.1157\n",
      "Validation Loss: 3417.9571\n",
      "Epoch [921/3000], Loss: 3479.7075\n",
      "Validation Loss: 3399.7276\n",
      "Epoch [941/3000], Loss: 3482.7142\n",
      "Validation Loss: 3382.9719\n",
      "Epoch [961/3000], Loss: 3429.6623\n",
      "Validation Loss: 3367.7379\n",
      "Epoch [981/3000], Loss: 3425.3009\n",
      "Validation Loss: 3353.9689\n",
      "Epoch [1001/3000], Loss: 3379.2914\n",
      "Validation Loss: 3341.7065\n",
      "Epoch [1021/3000], Loss: 3357.7049\n",
      "Validation Loss: 3330.8007\n",
      "Epoch [1041/3000], Loss: 3351.2454\n",
      "Validation Loss: 3321.1879\n",
      "Epoch [1061/3000], Loss: 3343.8261\n",
      "Validation Loss: 3312.9743\n",
      "Epoch [1081/3000], Loss: 3329.6861\n",
      "Validation Loss: 3306.1206\n",
      "Epoch [1101/3000], Loss: 3314.6346\n",
      "Validation Loss: 3300.5033\n",
      "Epoch [1121/3000], Loss: 3292.1536\n",
      "Validation Loss: 3296.1168\n",
      "Epoch [1141/3000], Loss: 3287.9609\n",
      "Validation Loss: 3292.8153\n",
      "Epoch [1161/3000], Loss: 3265.7974\n",
      "Validation Loss: 3290.6006\n",
      "Epoch [1181/3000], Loss: 3276.3079\n",
      "Validation Loss: 3289.3815\n",
      "Epoch [1201/3000], Loss: 3253.9855\n",
      "Validation Loss: 3289.0739\n",
      "Epoch [1221/3000], Loss: 3234.1214\n",
      "Validation Loss: 3281.0462\n",
      "Epoch [1241/3000], Loss: 2160.3941\n",
      "Validation Loss: 2024.1249\n",
      "Epoch [1261/3000], Loss: 2031.0048\n",
      "Validation Loss: 1912.9425\n",
      "Epoch [1281/3000], Loss: 1955.3329\n",
      "Validation Loss: 1847.7232\n",
      "Epoch [1301/3000], Loss: 1864.2440\n",
      "Validation Loss: 1797.9848\n",
      "Epoch [1321/3000], Loss: 1815.7213\n",
      "Validation Loss: 1749.7479\n",
      "Epoch [1341/3000], Loss: 1768.1283\n",
      "Validation Loss: 1706.0986\n",
      "Epoch [1361/3000], Loss: 1727.9708\n",
      "Validation Loss: 1667.1321\n",
      "Epoch [1381/3000], Loss: 1657.2171\n",
      "Validation Loss: 1654.1535\n",
      "Epoch [1401/3000], Loss: 1614.4018\n",
      "Validation Loss: 1604.8356\n",
      "Epoch [1421/3000], Loss: 1586.6209\n",
      "Validation Loss: 1605.8307\n",
      "Epoch [1441/3000], Loss: 1525.2522\n",
      "Validation Loss: 1581.6786\n",
      "Epoch [1461/3000], Loss: 1487.3797\n",
      "Validation Loss: 1585.1618\n",
      "Epoch [1481/3000], Loss: 1430.5896\n",
      "Validation Loss: 1558.9799\n",
      "Epoch [1501/3000], Loss: 1406.7139\n",
      "Validation Loss: 1558.8054\n",
      "Epoch [1521/3000], Loss: 1376.8252\n",
      "Validation Loss: 1547.6459\n",
      "Epoch [1541/3000], Loss: 1329.2088\n",
      "Validation Loss: 1524.4188\n",
      "Epoch [1561/3000], Loss: 1301.2131\n",
      "Validation Loss: 1508.8062\n",
      "Epoch [1581/3000], Loss: 1267.1453\n",
      "Validation Loss: 1505.7499\n",
      "Epoch [1601/3000], Loss: 1228.4411\n",
      "Validation Loss: 1474.7279\n",
      "Epoch [1621/3000], Loss: 1212.4835\n",
      "Validation Loss: 1487.2533\n",
      "Epoch [1641/3000], Loss: 1169.7919\n",
      "Validation Loss: 1444.2120\n",
      "Epoch [1661/3000], Loss: 1131.7722\n",
      "Validation Loss: 1435.4555\n",
      "Epoch [1681/3000], Loss: 1114.9374\n",
      "Validation Loss: 1398.1443\n",
      "Epoch [1701/3000], Loss: 1081.5525\n",
      "Validation Loss: 1368.6255\n",
      "Epoch [1721/3000], Loss: 1035.4932\n",
      "Validation Loss: 1325.0977\n",
      "Epoch [1741/3000], Loss: 1007.1814\n",
      "Validation Loss: 1325.5601\n",
      "Epoch [1761/3000], Loss: 988.1042\n",
      "Validation Loss: 1297.2617\n",
      "Epoch [1781/3000], Loss: 948.2822\n",
      "Validation Loss: 1261.8364\n",
      "Epoch [1801/3000], Loss: 921.6133\n",
      "Validation Loss: 1281.1617\n",
      "Epoch [1821/3000], Loss: 895.7884\n",
      "Validation Loss: 1231.9834\n",
      "Epoch [1841/3000], Loss: 872.6356\n",
      "Validation Loss: 1217.9449\n",
      "Epoch [1861/3000], Loss: 841.7711\n",
      "Validation Loss: 1239.5652\n",
      "Epoch [1881/3000], Loss: 818.5436\n",
      "Validation Loss: 1204.5451\n",
      "Epoch [1901/3000], Loss: 793.9787\n",
      "Validation Loss: 1176.4618\n",
      "Epoch [1921/3000], Loss: 772.5014\n",
      "Validation Loss: 1206.6045\n",
      "Epoch [1941/3000], Loss: 756.1411\n",
      "Validation Loss: 1169.6452\n",
      "Epoch [1961/3000], Loss: 736.1833\n",
      "Validation Loss: 1153.8886\n",
      "Epoch [1981/3000], Loss: 704.3038\n",
      "Validation Loss: 1182.5291\n",
      "Epoch [2001/3000], Loss: 697.4803\n",
      "Validation Loss: 1227.3657\n",
      "Epoch [2021/3000], Loss: 682.4248\n",
      "Validation Loss: 1248.9429\n",
      "Epoch [2041/3000], Loss: 655.6457\n",
      "Validation Loss: 1156.6316\n",
      "Epoch [2061/3000], Loss: 635.1658\n",
      "Validation Loss: 1142.1583\n",
      "Epoch [2081/3000], Loss: 629.5037\n",
      "Validation Loss: 1134.0863\n",
      "Epoch [2101/3000], Loss: 603.0160\n",
      "Validation Loss: 1095.1184\n",
      "Epoch [2121/3000], Loss: 589.8431\n",
      "Validation Loss: 1086.9815\n",
      "Epoch [2141/3000], Loss: 577.5652\n",
      "Validation Loss: 1113.4277\n",
      "Epoch [2161/3000], Loss: 547.4075\n",
      "Validation Loss: 1069.7240\n",
      "Epoch [2181/3000], Loss: 540.0103\n",
      "Validation Loss: 1043.5149\n",
      "Epoch [2201/3000], Loss: 519.5477\n",
      "Validation Loss: 1062.6568\n",
      "Epoch [2221/3000], Loss: 510.9702\n",
      "Validation Loss: 1099.8748\n",
      "Epoch [2241/3000], Loss: 502.0614\n",
      "Validation Loss: 1085.7913\n",
      "Epoch [2261/3000], Loss: 478.0778\n",
      "Validation Loss: 1037.9344\n",
      "Epoch [2281/3000], Loss: 470.1169\n",
      "Validation Loss: 1054.3468\n",
      "Epoch [2301/3000], Loss: 454.8933\n",
      "Validation Loss: 1029.2613\n",
      "Epoch [2321/3000], Loss: 445.4423\n",
      "Validation Loss: 1014.2342\n",
      "Epoch [2341/3000], Loss: 446.5484\n",
      "Validation Loss: 1017.3555\n",
      "Epoch [2361/3000], Loss: 453.2753\n",
      "Validation Loss: 1061.0747\n",
      "Epoch [2381/3000], Loss: 399.8998\n",
      "Validation Loss: 1022.9944\n",
      "Epoch [2401/3000], Loss: 383.8945\n",
      "Validation Loss: 1010.1675\n",
      "Epoch [2421/3000], Loss: 367.9923\n",
      "Validation Loss: 1003.6297\n",
      "Epoch [2441/3000], Loss: 361.2840\n",
      "Validation Loss: 992.4736\n",
      "Epoch [2461/3000], Loss: 339.3642\n",
      "Validation Loss: 996.8077\n",
      "Epoch [2481/3000], Loss: 328.2976\n",
      "Validation Loss: 984.4105\n",
      "Epoch [2501/3000], Loss: 316.1282\n",
      "Validation Loss: 973.6637\n",
      "Epoch [2521/3000], Loss: 309.3691\n",
      "Validation Loss: 971.1943\n",
      "Epoch [2541/3000], Loss: 310.4233\n",
      "Validation Loss: 946.8672\n",
      "Epoch [2561/3000], Loss: 286.9368\n",
      "Validation Loss: 950.5963\n",
      "Epoch [2581/3000], Loss: 274.2563\n",
      "Validation Loss: 945.8291\n",
      "Epoch [2601/3000], Loss: 269.1474\n",
      "Validation Loss: 949.8722\n",
      "Epoch [2621/3000], Loss: 261.4616\n",
      "Validation Loss: 941.8066\n",
      "Epoch [2641/3000], Loss: 247.3699\n",
      "Validation Loss: 931.7031\n",
      "Epoch [2661/3000], Loss: 237.7918\n",
      "Validation Loss: 922.3666\n",
      "Epoch [2681/3000], Loss: 228.0040\n",
      "Validation Loss: 922.7032\n",
      "Epoch [2701/3000], Loss: 217.4066\n",
      "Validation Loss: 917.1203\n",
      "Epoch [2721/3000], Loss: 211.2995\n",
      "Validation Loss: 917.2380\n",
      "Epoch [2741/3000], Loss: 200.1991\n",
      "Validation Loss: 902.1202\n",
      "Epoch [2761/3000], Loss: 195.5077\n",
      "Validation Loss: 908.6503\n",
      "Epoch [2781/3000], Loss: 187.5514\n",
      "Validation Loss: 894.0053\n",
      "Epoch [2801/3000], Loss: 181.9313\n",
      "Validation Loss: 898.7404\n",
      "Epoch [2821/3000], Loss: 176.2433\n",
      "Validation Loss: 892.2484\n",
      "Epoch [2841/3000], Loss: 167.0155\n",
      "Validation Loss: 893.1170\n",
      "Epoch [2861/3000], Loss: 157.0198\n",
      "Validation Loss: 883.6283\n",
      "Epoch [2881/3000], Loss: 149.5892\n",
      "Validation Loss: 899.0042\n",
      "Epoch [2901/3000], Loss: 144.5891\n",
      "Validation Loss: 906.2534\n",
      "Epoch [2921/3000], Loss: 141.1886\n",
      "Validation Loss: 885.1497\n",
      "Epoch [2941/3000], Loss: 134.5884\n",
      "Validation Loss: 898.8269\n",
      "Epoch [2961/3000], Loss: 131.7577\n",
      "Validation Loss: 904.9746\n",
      "Epoch [2981/3000], Loss: 126.1203\n",
      "Validation Loss: 916.7634\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day067_plane0_Fall.mat\n",
      "(5660, 71)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7474.2117\n",
      "Validation Loss: 8481.2988\n",
      "Epoch [21/3000], Loss: 6474.4648\n",
      "Validation Loss: 7400.0490\n",
      "Epoch [41/3000], Loss: 6236.7342\n",
      "Validation Loss: 7156.7946\n",
      "Epoch [61/3000], Loss: 6093.8738\n",
      "Validation Loss: 6992.9596\n",
      "Epoch [81/3000], Loss: 5958.7983\n",
      "Validation Loss: 6850.4240\n",
      "Epoch [101/3000], Loss: 5840.4468\n",
      "Validation Loss: 6721.0402\n",
      "Epoch [121/3000], Loss: 5724.4268\n",
      "Validation Loss: 6597.9696\n",
      "Epoch [141/3000], Loss: 5622.9516\n",
      "Validation Loss: 6479.4041\n",
      "Epoch [161/3000], Loss: 5514.5835\n",
      "Validation Loss: 6364.5532\n",
      "Epoch [181/3000], Loss: 5409.1325\n",
      "Validation Loss: 6252.9935\n",
      "Epoch [201/3000], Loss: 5315.1048\n",
      "Validation Loss: 6144.3435\n",
      "Epoch [221/3000], Loss: 5216.2576\n",
      "Validation Loss: 6038.4992\n",
      "Epoch [241/3000], Loss: 5131.6189\n",
      "Validation Loss: 5935.2791\n",
      "Epoch [261/3000], Loss: 5035.5497\n",
      "Validation Loss: 5834.6409\n",
      "Epoch [281/3000], Loss: 4946.5091\n",
      "Validation Loss: 5736.4764\n",
      "Epoch [301/3000], Loss: 4860.3244\n",
      "Validation Loss: 5640.7840\n",
      "Epoch [321/3000], Loss: 4778.7905\n",
      "Validation Loss: 5547.5623\n",
      "Epoch [341/3000], Loss: 4688.9337\n",
      "Validation Loss: 5456.6817\n",
      "Epoch [361/3000], Loss: 4616.3111\n",
      "Validation Loss: 5368.2085\n",
      "Epoch [381/3000], Loss: 4533.0436\n",
      "Validation Loss: 5282.1814\n",
      "Epoch [401/3000], Loss: 4455.9991\n",
      "Validation Loss: 5198.5002\n",
      "Epoch [421/3000], Loss: 4388.5942\n",
      "Validation Loss: 5117.1356\n",
      "Epoch [441/3000], Loss: 4319.5030\n",
      "Validation Loss: 5038.1971\n",
      "Epoch [461/3000], Loss: 4256.4589\n",
      "Validation Loss: 4961.5862\n",
      "Epoch [481/3000], Loss: 4191.0378\n",
      "Validation Loss: 4885.7811\n",
      "Epoch [501/3000], Loss: 4122.3301\n",
      "Validation Loss: 4813.5050\n",
      "Epoch [521/3000], Loss: 4065.0725\n",
      "Validation Loss: 4743.6846\n",
      "Epoch [541/3000], Loss: 4000.3894\n",
      "Validation Loss: 4676.2531\n",
      "Epoch [561/3000], Loss: 3944.4265\n",
      "Validation Loss: 4611.1192\n",
      "Epoch [581/3000], Loss: 3891.4869\n",
      "Validation Loss: 4548.3442\n",
      "Epoch [601/3000], Loss: 3837.8937\n",
      "Validation Loss: 4487.8983\n",
      "Epoch [621/3000], Loss: 3792.5771\n",
      "Validation Loss: 4429.8018\n",
      "Epoch [641/3000], Loss: 3749.0209\n",
      "Validation Loss: 4374.0033\n",
      "Epoch [661/3000], Loss: 3701.4015\n",
      "Validation Loss: 4320.4911\n",
      "Epoch [681/3000], Loss: 3654.3427\n",
      "Validation Loss: 4269.2411\n",
      "Epoch [701/3000], Loss: 3620.3687\n",
      "Validation Loss: 4220.3300\n",
      "Epoch [721/3000], Loss: 3577.5196\n",
      "Validation Loss: 4173.6566\n",
      "Epoch [741/3000], Loss: 3543.5409\n",
      "Validation Loss: 4129.2310\n",
      "Epoch [761/3000], Loss: 3509.2314\n",
      "Validation Loss: 4087.0812\n",
      "Epoch [781/3000], Loss: 3482.2122\n",
      "Validation Loss: 4047.1534\n",
      "Epoch [801/3000], Loss: 3448.2936\n",
      "Validation Loss: 4009.4960\n",
      "Epoch [821/3000], Loss: 3426.0796\n",
      "Validation Loss: 3973.9431\n",
      "Epoch [841/3000], Loss: 3396.1015\n",
      "Validation Loss: 3940.6523\n",
      "Epoch [861/3000], Loss: 3373.8943\n",
      "Validation Loss: 3909.4637\n",
      "Epoch [881/3000], Loss: 3350.2908\n",
      "Validation Loss: 3880.4646\n",
      "Epoch [901/3000], Loss: 3333.0346\n",
      "Validation Loss: 3853.4851\n",
      "Epoch [921/3000], Loss: 3313.5119\n",
      "Validation Loss: 3828.6611\n",
      "Epoch [941/3000], Loss: 3301.5831\n",
      "Validation Loss: 3805.8571\n",
      "Epoch [961/3000], Loss: 3287.6714\n",
      "Validation Loss: 3785.0132\n",
      "Epoch [981/3000], Loss: 3271.0909\n",
      "Validation Loss: 3766.1499\n",
      "Epoch [1001/3000], Loss: 3267.8120\n",
      "Validation Loss: 3749.2360\n",
      "Epoch [1021/3000], Loss: 3257.5965\n",
      "Validation Loss: 3734.1756\n",
      "Epoch [1041/3000], Loss: 3250.0280\n",
      "Validation Loss: 3720.8848\n",
      "Epoch [1061/3000], Loss: 3241.9295\n",
      "Validation Loss: 3709.4444\n",
      "Epoch [1081/3000], Loss: 3236.6805\n",
      "Validation Loss: 3699.5784\n",
      "Epoch [1101/3000], Loss: 3231.5646\n",
      "Validation Loss: 3691.2060\n",
      "Epoch [1121/3000], Loss: 2240.4459\n",
      "Validation Loss: 2771.3699\n",
      "Epoch [1141/3000], Loss: 2072.8888\n",
      "Validation Loss: 2720.1852\n",
      "Epoch [1161/3000], Loss: 1986.4990\n",
      "Validation Loss: 2702.0106\n",
      "Epoch [1181/3000], Loss: 1914.7322\n",
      "Validation Loss: 2616.9865\n",
      "Epoch [1201/3000], Loss: 1848.9696\n",
      "Validation Loss: 2627.9649\n",
      "Epoch [1221/3000], Loss: 1800.6052\n",
      "Validation Loss: 2568.7914\n",
      "Epoch [1241/3000], Loss: 1774.7465\n",
      "Validation Loss: 2628.5074\n",
      "Epoch [1261/3000], Loss: 1699.9621\n",
      "Validation Loss: 2546.7224\n",
      "Epoch [1281/3000], Loss: 1656.7864\n",
      "Validation Loss: 2517.8419\n",
      "Epoch [1301/3000], Loss: 1619.6198\n",
      "Validation Loss: 2468.3357\n",
      "Epoch [1321/3000], Loss: 1564.1767\n",
      "Validation Loss: 2429.7205\n",
      "Epoch [1341/3000], Loss: 1520.9621\n",
      "Validation Loss: 2468.4275\n",
      "Epoch [1361/3000], Loss: 1480.6859\n",
      "Validation Loss: 2377.0164\n",
      "Epoch [1381/3000], Loss: 1434.4414\n",
      "Validation Loss: 2393.7413\n",
      "Epoch [1401/3000], Loss: 1390.2699\n",
      "Validation Loss: 2358.8483\n",
      "Epoch [1421/3000], Loss: 1347.2484\n",
      "Validation Loss: 2325.9586\n",
      "Epoch [1441/3000], Loss: 1317.3588\n",
      "Validation Loss: 2306.7806\n",
      "Epoch [1461/3000], Loss: 1273.0701\n",
      "Validation Loss: 2251.5958\n",
      "Epoch [1481/3000], Loss: 1233.9392\n",
      "Validation Loss: 2245.0684\n",
      "Epoch [1501/3000], Loss: 1193.9221\n",
      "Validation Loss: 2208.9055\n",
      "Epoch [1521/3000], Loss: 1160.6489\n",
      "Validation Loss: 2219.3274\n",
      "Epoch [1541/3000], Loss: 1132.8416\n",
      "Validation Loss: 2194.1155\n",
      "Epoch [1561/3000], Loss: 1087.7992\n",
      "Validation Loss: 2157.8241\n",
      "Epoch [1581/3000], Loss: 1058.1950\n",
      "Validation Loss: 2214.9145\n",
      "Epoch [1601/3000], Loss: 1020.0016\n",
      "Validation Loss: 2106.7158\n",
      "Epoch [1621/3000], Loss: 994.6643\n",
      "Validation Loss: 2043.8232\n",
      "Epoch [1641/3000], Loss: 973.6387\n",
      "Validation Loss: 1992.4764\n",
      "Epoch [1661/3000], Loss: 940.1311\n",
      "Validation Loss: 2050.9303\n",
      "Epoch [1681/3000], Loss: 910.0863\n",
      "Validation Loss: 2092.0657\n",
      "Epoch [1701/3000], Loss: 884.4088\n",
      "Validation Loss: 1995.4558\n",
      "Epoch [1721/3000], Loss: 857.3540\n",
      "Validation Loss: 1935.2006\n",
      "Epoch [1741/3000], Loss: 828.1182\n",
      "Validation Loss: 1911.0843\n",
      "Epoch [1761/3000], Loss: 831.6552\n",
      "Validation Loss: 1891.2640\n",
      "Epoch [1781/3000], Loss: 777.3509\n",
      "Validation Loss: 1843.6145\n",
      "Epoch [1801/3000], Loss: 750.0249\n",
      "Validation Loss: 1824.4394\n",
      "Epoch [1821/3000], Loss: 723.8853\n",
      "Validation Loss: 1796.5725\n",
      "Epoch [1841/3000], Loss: 697.5813\n",
      "Validation Loss: 1754.7839\n",
      "Epoch [1861/3000], Loss: 658.8701\n",
      "Validation Loss: 1726.1300\n",
      "Epoch [1881/3000], Loss: 632.5841\n",
      "Validation Loss: 1756.9621\n",
      "Epoch [1901/3000], Loss: 615.7323\n",
      "Validation Loss: 1697.8978\n",
      "Epoch [1921/3000], Loss: 590.0797\n",
      "Validation Loss: 1682.9461\n",
      "Epoch [1941/3000], Loss: 580.3014\n",
      "Validation Loss: 1640.5700\n",
      "Epoch [1961/3000], Loss: 552.9191\n",
      "Validation Loss: 1652.3418\n",
      "Epoch [1981/3000], Loss: 543.6125\n",
      "Validation Loss: 1654.0165\n",
      "Epoch [2001/3000], Loss: 520.4927\n",
      "Validation Loss: 1685.5687\n",
      "Epoch [2021/3000], Loss: 502.8135\n",
      "Validation Loss: 1633.6181\n",
      "Epoch [2041/3000], Loss: 491.3053\n",
      "Validation Loss: 1636.9996\n",
      "Epoch [2061/3000], Loss: 474.4496\n",
      "Validation Loss: 1648.5825\n",
      "Epoch [2081/3000], Loss: 463.7977\n",
      "Validation Loss: 1571.0518\n",
      "Epoch [2101/3000], Loss: 441.4321\n",
      "Validation Loss: 1586.2219\n",
      "Epoch [2121/3000], Loss: 429.9279\n",
      "Validation Loss: 1659.4189\n",
      "Epoch [2141/3000], Loss: 415.1776\n",
      "Validation Loss: 1570.3876\n",
      "Epoch [2161/3000], Loss: 404.1418\n",
      "Validation Loss: 1545.3376\n",
      "Epoch [2181/3000], Loss: 394.3396\n",
      "Validation Loss: 1647.7964\n",
      "Epoch [2201/3000], Loss: 384.5999\n",
      "Validation Loss: 1581.2811\n",
      "Epoch [2221/3000], Loss: 371.9169\n",
      "Validation Loss: 1609.1124\n",
      "Epoch [2241/3000], Loss: 365.7544\n",
      "Validation Loss: 1578.3432\n",
      "Epoch [2261/3000], Loss: 353.1863\n",
      "Validation Loss: 1599.0978\n",
      "Epoch [2281/3000], Loss: 342.4953\n",
      "Validation Loss: 1556.0192\n",
      "Epoch [2301/3000], Loss: 332.1097\n",
      "Validation Loss: 1530.0206\n",
      "Epoch [2321/3000], Loss: 321.7983\n",
      "Validation Loss: 1560.1591\n",
      "Epoch [2341/3000], Loss: 313.6220\n",
      "Validation Loss: 1515.3613\n",
      "Epoch [2361/3000], Loss: 306.0098\n",
      "Validation Loss: 1572.0340\n",
      "Epoch [2381/3000], Loss: 297.6294\n",
      "Validation Loss: 1520.4691\n",
      "Epoch [2401/3000], Loss: 288.3718\n",
      "Validation Loss: 1569.7257\n",
      "Epoch [2421/3000], Loss: 280.9260\n",
      "Validation Loss: 1618.1475\n",
      "Epoch [2441/3000], Loss: 270.7486\n",
      "Validation Loss: 1568.9871\n",
      "Epoch [2461/3000], Loss: 261.5060\n",
      "Validation Loss: 1572.8701\n",
      "Epoch [2481/3000], Loss: 257.8761\n",
      "Validation Loss: 1659.9788\n",
      "Epoch [2501/3000], Loss: 245.7727\n",
      "Validation Loss: 1612.4266\n",
      "Epoch [2521/3000], Loss: 242.3625\n",
      "Validation Loss: 1596.0358\n",
      "Epoch [2541/3000], Loss: 229.6761\n",
      "Validation Loss: 1611.4245\n",
      "Epoch [2561/3000], Loss: 222.4718\n",
      "Validation Loss: 1560.3407\n",
      "Epoch [2581/3000], Loss: 213.4490\n",
      "Validation Loss: 1594.9362\n",
      "Epoch [2601/3000], Loss: 205.7515\n",
      "Validation Loss: 1594.2524\n",
      "Epoch [2621/3000], Loss: 199.9906\n",
      "Validation Loss: 1626.7409\n",
      "Epoch [2641/3000], Loss: 190.4921\n",
      "Validation Loss: 1617.9339\n",
      "Epoch [2661/3000], Loss: 197.9734\n",
      "Validation Loss: 1675.2972\n",
      "Epoch [2681/3000], Loss: 178.8204\n",
      "Validation Loss: 1669.3127\n",
      "Epoch [2701/3000], Loss: 170.4253\n",
      "Validation Loss: 1650.1033\n",
      "Epoch [2721/3000], Loss: 165.7984\n",
      "Validation Loss: 1691.8652\n",
      "Epoch [2741/3000], Loss: 158.9167\n",
      "Validation Loss: 1708.5768\n",
      "Epoch [2761/3000], Loss: 152.6739\n",
      "Validation Loss: 1691.9483\n",
      "Epoch [2781/3000], Loss: 146.2788\n",
      "Validation Loss: 1739.9566\n",
      "Epoch [2801/3000], Loss: 140.8612\n",
      "Validation Loss: 1725.1677\n",
      "Epoch [2821/3000], Loss: 135.4728\n",
      "Validation Loss: 1728.1732\n",
      "Epoch [2841/3000], Loss: 130.9139\n",
      "Validation Loss: 1735.3661\n",
      "Epoch [2861/3000], Loss: 126.5159\n",
      "Validation Loss: 1779.7049\n",
      "Epoch [2881/3000], Loss: 121.2982\n",
      "Validation Loss: 1786.7266\n",
      "Epoch [2901/3000], Loss: 117.8396\n",
      "Validation Loss: 1780.4393\n",
      "Epoch [2921/3000], Loss: 113.2536\n",
      "Validation Loss: 1794.3503\n",
      "Epoch [2941/3000], Loss: 108.5033\n",
      "Validation Loss: 1817.3625\n",
      "Epoch [2961/3000], Loss: 104.6063\n",
      "Validation Loss: 1838.1171\n",
      "Epoch [2981/3000], Loss: 101.7014\n",
      "Validation Loss: 1804.8169\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day068_plane0_Fall.mat\n",
      "(8202, 74)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8464.3419\n",
      "Validation Loss: 8600.9163\n",
      "Epoch [21/3000], Loss: 7382.3281\n",
      "Validation Loss: 7469.1721\n",
      "Epoch [41/3000], Loss: 7117.7815\n",
      "Validation Loss: 7225.7819\n",
      "Epoch [61/3000], Loss: 6963.5974\n",
      "Validation Loss: 7031.9358\n",
      "Epoch [81/3000], Loss: 6778.0608\n",
      "Validation Loss: 6855.0016\n",
      "Epoch [101/3000], Loss: 6608.5079\n",
      "Validation Loss: 6688.0014\n",
      "Epoch [121/3000], Loss: 6468.8482\n",
      "Validation Loss: 6527.8412\n",
      "Epoch [141/3000], Loss: 6308.8783\n",
      "Validation Loss: 6373.8870\n",
      "Epoch [161/3000], Loss: 6169.0365\n",
      "Validation Loss: 6225.4294\n",
      "Epoch [181/3000], Loss: 5986.1429\n",
      "Validation Loss: 6082.1910\n",
      "Epoch [201/3000], Loss: 5907.9770\n",
      "Validation Loss: 5943.4672\n",
      "Epoch [221/3000], Loss: 5769.3412\n",
      "Validation Loss: 5809.7355\n",
      "Epoch [241/3000], Loss: 5647.9078\n",
      "Validation Loss: 5680.7456\n",
      "Epoch [261/3000], Loss: 5546.9443\n",
      "Validation Loss: 5555.7340\n",
      "Epoch [281/3000], Loss: 5389.7707\n",
      "Validation Loss: 5434.1404\n",
      "Epoch [301/3000], Loss: 5306.9596\n",
      "Validation Loss: 5317.1548\n",
      "Epoch [321/3000], Loss: 5187.6352\n",
      "Validation Loss: 5206.0327\n",
      "Epoch [341/3000], Loss: 5057.5465\n",
      "Validation Loss: 5099.5610\n",
      "Epoch [361/3000], Loss: 4991.8000\n",
      "Validation Loss: 4997.7139\n",
      "Epoch [381/3000], Loss: 4902.1861\n",
      "Validation Loss: 4900.7380\n",
      "Epoch [401/3000], Loss: 4816.4738\n",
      "Validation Loss: 4807.0389\n",
      "Epoch [421/3000], Loss: 4725.1917\n",
      "Validation Loss: 4718.6416\n",
      "Epoch [441/3000], Loss: 4635.4864\n",
      "Validation Loss: 4635.2934\n",
      "Epoch [461/3000], Loss: 4567.4577\n",
      "Validation Loss: 4556.3553\n",
      "Epoch [481/3000], Loss: 4500.0292\n",
      "Validation Loss: 4482.1843\n",
      "Epoch [501/3000], Loss: 4420.2401\n",
      "Validation Loss: 4412.3230\n",
      "Epoch [521/3000], Loss: 4367.2569\n",
      "Validation Loss: 4347.0795\n",
      "Epoch [541/3000], Loss: 4316.9051\n",
      "Validation Loss: 4286.2251\n",
      "Epoch [561/3000], Loss: 4274.0432\n",
      "Validation Loss: 4229.9579\n",
      "Epoch [581/3000], Loss: 4233.3022\n",
      "Validation Loss: 4177.9991\n",
      "Epoch [601/3000], Loss: 4178.0701\n",
      "Validation Loss: 4130.1903\n",
      "Epoch [621/3000], Loss: 4150.2299\n",
      "Validation Loss: 4086.7150\n",
      "Epoch [641/3000], Loss: 4119.5963\n",
      "Validation Loss: 4047.4420\n",
      "Epoch [661/3000], Loss: 4076.6900\n",
      "Validation Loss: 4012.3075\n",
      "Epoch [681/3000], Loss: 4046.5027\n",
      "Validation Loss: 3981.1927\n",
      "Epoch [701/3000], Loss: 4024.3837\n",
      "Validation Loss: 3953.8431\n",
      "Epoch [721/3000], Loss: 4002.8921\n",
      "Validation Loss: 3930.6188\n",
      "Epoch [741/3000], Loss: 3977.8549\n",
      "Validation Loss: 3910.9069\n",
      "Epoch [761/3000], Loss: 3985.0027\n",
      "Validation Loss: 3894.5385\n",
      "Epoch [781/3000], Loss: 3965.7952\n",
      "Validation Loss: 3881.3122\n",
      "Epoch [801/3000], Loss: 3943.2266\n",
      "Validation Loss: 3846.8861\n",
      "Epoch [821/3000], Loss: 2787.9090\n",
      "Validation Loss: 2866.7713\n",
      "Epoch [841/3000], Loss: 2623.3680\n",
      "Validation Loss: 2789.8111\n",
      "Epoch [861/3000], Loss: 2533.3498\n",
      "Validation Loss: 2736.3976\n",
      "Epoch [881/3000], Loss: 2446.5968\n",
      "Validation Loss: 2662.5753\n",
      "Epoch [901/3000], Loss: 2340.8083\n",
      "Validation Loss: 2594.4936\n",
      "Epoch [921/3000], Loss: 2257.4284\n",
      "Validation Loss: 2528.8913\n",
      "Epoch [941/3000], Loss: 2189.5914\n",
      "Validation Loss: 2471.9561\n",
      "Epoch [961/3000], Loss: 2108.2118\n",
      "Validation Loss: 2400.6230\n",
      "Epoch [981/3000], Loss: 2037.2892\n",
      "Validation Loss: 2339.2858\n",
      "Epoch [1001/3000], Loss: 1956.7293\n",
      "Validation Loss: 2324.6691\n",
      "Epoch [1021/3000], Loss: 1874.0863\n",
      "Validation Loss: 2309.7569\n",
      "Epoch [1041/3000], Loss: 1820.0564\n",
      "Validation Loss: 2246.3136\n",
      "Epoch [1061/3000], Loss: 1750.4950\n",
      "Validation Loss: 2226.8035\n",
      "Epoch [1081/3000], Loss: 1687.4868\n",
      "Validation Loss: 2191.8700\n",
      "Epoch [1101/3000], Loss: 1609.5503\n",
      "Validation Loss: 2200.6847\n",
      "Epoch [1121/3000], Loss: 1564.4993\n",
      "Validation Loss: 2161.1951\n",
      "Epoch [1141/3000], Loss: 1499.1094\n",
      "Validation Loss: 2083.6959\n",
      "Epoch [1161/3000], Loss: 1451.9665\n",
      "Validation Loss: 2075.9245\n",
      "Epoch [1181/3000], Loss: 1391.5950\n",
      "Validation Loss: 2051.1229\n",
      "Epoch [1201/3000], Loss: 1345.6993\n",
      "Validation Loss: 1984.7969\n",
      "Epoch [1221/3000], Loss: 1272.0114\n",
      "Validation Loss: 1958.4657\n",
      "Epoch [1241/3000], Loss: 1209.2680\n",
      "Validation Loss: 1933.3527\n",
      "Epoch [1261/3000], Loss: 1144.5008\n",
      "Validation Loss: 1886.1918\n",
      "Epoch [1281/3000], Loss: 1084.6525\n",
      "Validation Loss: 1883.7501\n",
      "Epoch [1301/3000], Loss: 1037.3982\n",
      "Validation Loss: 1882.1113\n",
      "Epoch [1321/3000], Loss: 998.8308\n",
      "Validation Loss: 1833.2151\n",
      "Epoch [1341/3000], Loss: 973.0997\n",
      "Validation Loss: 1796.1437\n",
      "Epoch [1361/3000], Loss: 913.7927\n",
      "Validation Loss: 1805.6701\n",
      "Epoch [1381/3000], Loss: 883.3567\n",
      "Validation Loss: 1772.0744\n",
      "Epoch [1401/3000], Loss: 836.6913\n",
      "Validation Loss: 1789.8873\n",
      "Epoch [1421/3000], Loss: 801.7678\n",
      "Validation Loss: 1768.3026\n",
      "Epoch [1441/3000], Loss: 777.3621\n",
      "Validation Loss: 1758.3612\n",
      "Epoch [1461/3000], Loss: 726.8719\n",
      "Validation Loss: 1738.8756\n",
      "Epoch [1481/3000], Loss: 691.5590\n",
      "Validation Loss: 1737.1921\n",
      "Epoch [1501/3000], Loss: 652.5813\n",
      "Validation Loss: 1765.5636\n",
      "Epoch [1521/3000], Loss: 621.3198\n",
      "Validation Loss: 1759.3219\n",
      "Epoch [1541/3000], Loss: 577.1962\n",
      "Validation Loss: 1789.2781\n",
      "Epoch [1561/3000], Loss: 541.7344\n",
      "Validation Loss: 1792.3272\n",
      "Epoch [1581/3000], Loss: 517.7082\n",
      "Validation Loss: 1807.8966\n",
      "Epoch [1601/3000], Loss: 485.8403\n",
      "Validation Loss: 1822.9478\n",
      "Epoch [1621/3000], Loss: 458.2610\n",
      "Validation Loss: 1804.1039\n",
      "Epoch [1641/3000], Loss: 438.8233\n",
      "Validation Loss: 1831.3621\n",
      "Epoch [1661/3000], Loss: 422.2791\n",
      "Validation Loss: 1756.9016\n",
      "Epoch [1681/3000], Loss: 387.5603\n",
      "Validation Loss: 1775.5788\n",
      "Epoch [1701/3000], Loss: 367.5642\n",
      "Validation Loss: 1832.1973\n",
      "Epoch [1721/3000], Loss: 346.5069\n",
      "Validation Loss: 1801.0649\n",
      "Epoch [1741/3000], Loss: 335.6870\n",
      "Validation Loss: 1872.2539\n",
      "Epoch [1761/3000], Loss: 310.3815\n",
      "Validation Loss: 1829.3389\n",
      "Epoch [1781/3000], Loss: 305.5671\n",
      "Validation Loss: 1816.8498\n",
      "Epoch [1801/3000], Loss: 291.8463\n",
      "Validation Loss: 1915.3072\n",
      "Epoch [1821/3000], Loss: 270.5841\n",
      "Validation Loss: 1759.9533\n",
      "Epoch [1841/3000], Loss: 251.4143\n",
      "Validation Loss: 1929.5556\n",
      "Epoch [1861/3000], Loss: 243.8290\n",
      "Validation Loss: 1723.0380\n",
      "Epoch [1881/3000], Loss: 224.7001\n",
      "Validation Loss: 1767.5467\n",
      "Epoch [1901/3000], Loss: 212.5965\n",
      "Validation Loss: 1768.9790\n",
      "Epoch [1921/3000], Loss: 201.1553\n",
      "Validation Loss: 1852.2910\n",
      "Epoch [1941/3000], Loss: 190.8389\n",
      "Validation Loss: 1750.8189\n",
      "Epoch [1961/3000], Loss: 180.3010\n",
      "Validation Loss: 1776.1020\n",
      "Epoch [1981/3000], Loss: 174.1909\n",
      "Validation Loss: 1796.0541\n",
      "Epoch [2001/3000], Loss: 162.0368\n",
      "Validation Loss: 1706.1928\n",
      "Epoch [2021/3000], Loss: 156.1948\n",
      "Validation Loss: 1632.2361\n",
      "Epoch [2041/3000], Loss: 146.6989\n",
      "Validation Loss: 1667.8474\n",
      "Epoch [2061/3000], Loss: 139.2231\n",
      "Validation Loss: 1749.0379\n",
      "Epoch [2081/3000], Loss: 127.8949\n",
      "Validation Loss: 1760.8167\n",
      "Epoch [2101/3000], Loss: 121.6969\n",
      "Validation Loss: 1732.0831\n",
      "Epoch [2121/3000], Loss: 119.7519\n",
      "Validation Loss: 1735.9052\n",
      "Epoch [2141/3000], Loss: 106.4751\n",
      "Validation Loss: 1674.1995\n",
      "Epoch [2161/3000], Loss: 107.8989\n",
      "Validation Loss: 1698.8086\n",
      "Epoch [2181/3000], Loss: 103.2416\n",
      "Validation Loss: 1735.5529\n",
      "Epoch [2201/3000], Loss: 96.4943\n",
      "Validation Loss: 1752.5831\n",
      "Epoch [2221/3000], Loss: 84.8367\n",
      "Validation Loss: 1721.9631\n",
      "Epoch [2241/3000], Loss: 86.5832\n",
      "Validation Loss: 1637.8125\n",
      "Epoch [2261/3000], Loss: 77.2753\n",
      "Validation Loss: 1710.4159\n",
      "Epoch [2281/3000], Loss: 83.6658\n",
      "Validation Loss: 1593.3111\n",
      "Epoch [2301/3000], Loss: 68.6858\n",
      "Validation Loss: 1724.7895\n",
      "Epoch [2321/3000], Loss: 70.5601\n",
      "Validation Loss: 1692.0179\n",
      "Epoch [2341/3000], Loss: 62.6712\n",
      "Validation Loss: 1619.5274\n",
      "Epoch [2361/3000], Loss: 121.7068\n",
      "Validation Loss: 1515.8931\n",
      "Epoch [2381/3000], Loss: 54.7818\n",
      "Validation Loss: 1580.0210\n",
      "Epoch [2401/3000], Loss: 54.8285\n",
      "Validation Loss: 1615.3735\n",
      "Epoch [2421/3000], Loss: 49.0286\n",
      "Validation Loss: 1625.6352\n",
      "Epoch [2441/3000], Loss: 46.8539\n",
      "Validation Loss: 1624.6586\n",
      "Epoch [2461/3000], Loss: 44.1952\n",
      "Validation Loss: 1645.5690\n",
      "Epoch [2481/3000], Loss: 43.6613\n",
      "Validation Loss: 1669.5895\n",
      "Epoch [2501/3000], Loss: 40.1292\n",
      "Validation Loss: 1637.7399\n",
      "Epoch [2521/3000], Loss: 38.6261\n",
      "Validation Loss: 1640.5659\n",
      "Epoch [2541/3000], Loss: 63.0880\n",
      "Validation Loss: 1615.7125\n",
      "Epoch [2561/3000], Loss: 33.4178\n",
      "Validation Loss: 1600.1242\n",
      "Epoch [2581/3000], Loss: 32.2270\n",
      "Validation Loss: 1598.8632\n",
      "Epoch [2601/3000], Loss: 31.0430\n",
      "Validation Loss: 1631.0866\n",
      "Epoch [2621/3000], Loss: 31.8973\n",
      "Validation Loss: 1609.6142\n",
      "Epoch [2641/3000], Loss: 27.9214\n",
      "Validation Loss: 1598.0416\n",
      "Epoch [2661/3000], Loss: 26.1495\n",
      "Validation Loss: 1627.2416\n",
      "Epoch [2681/3000], Loss: 25.5880\n",
      "Validation Loss: 1618.0143\n",
      "Epoch [2701/3000], Loss: 24.6478\n",
      "Validation Loss: 1600.3450\n",
      "Epoch [2721/3000], Loss: 22.9728\n",
      "Validation Loss: 1624.7102\n",
      "Epoch [2741/3000], Loss: 22.7610\n",
      "Validation Loss: 1609.5363\n",
      "Epoch [2761/3000], Loss: 21.0714\n",
      "Validation Loss: 1621.7210\n",
      "Epoch [2781/3000], Loss: 20.3071\n",
      "Validation Loss: 1606.6627\n",
      "Epoch [2801/3000], Loss: 20.1164\n",
      "Validation Loss: 1634.1362\n",
      "Epoch [2821/3000], Loss: 18.2595\n",
      "Validation Loss: 1618.5220\n",
      "Epoch [2841/3000], Loss: 17.5487\n",
      "Validation Loss: 1616.1395\n",
      "Epoch [2861/3000], Loss: 16.2728\n",
      "Validation Loss: 1625.0499\n",
      "Epoch [2881/3000], Loss: 16.4700\n",
      "Validation Loss: 1606.7292\n",
      "Epoch [2901/3000], Loss: 15.3557\n",
      "Validation Loss: 1620.4247\n",
      "Epoch [2921/3000], Loss: 15.5936\n",
      "Validation Loss: 1632.6575\n",
      "Epoch [2941/3000], Loss: 15.8610\n",
      "Validation Loss: 1652.0752\n",
      "Epoch [2961/3000], Loss: 12.9574\n",
      "Validation Loss: 1602.2742\n",
      "Epoch [2981/3000], Loss: 12.4903\n",
      "Validation Loss: 1629.3549\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day069_plane0_Fall.mat\n",
      "(11053, 117)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9953.8397\n",
      "Validation Loss: 8118.9843\n",
      "Epoch [21/3000], Loss: 8423.7017\n",
      "Validation Loss: 6782.0264\n",
      "Epoch [41/3000], Loss: 8098.0990\n",
      "Validation Loss: 6510.7994\n",
      "Epoch [61/3000], Loss: 7823.8587\n",
      "Validation Loss: 6277.5485\n",
      "Epoch [81/3000], Loss: 7572.2837\n",
      "Validation Loss: 6064.5707\n",
      "Epoch [101/3000], Loss: 7328.9081\n",
      "Validation Loss: 5864.3875\n",
      "Epoch [121/3000], Loss: 7107.0149\n",
      "Validation Loss: 5674.7456\n",
      "Epoch [141/3000], Loss: 6887.7750\n",
      "Validation Loss: 5494.9809\n",
      "Epoch [161/3000], Loss: 6674.5398\n",
      "Validation Loss: 5323.6172\n",
      "Epoch [181/3000], Loss: 6476.2482\n",
      "Validation Loss: 5161.2546\n",
      "Epoch [201/3000], Loss: 6280.6933\n",
      "Validation Loss: 5008.5645\n",
      "Epoch [221/3000], Loss: 6091.5586\n",
      "Validation Loss: 4865.0869\n",
      "Epoch [241/3000], Loss: 5922.4078\n",
      "Validation Loss: 4730.6368\n",
      "Epoch [261/3000], Loss: 5758.5966\n",
      "Validation Loss: 4605.2067\n",
      "Epoch [281/3000], Loss: 5603.0606\n",
      "Validation Loss: 4488.6508\n",
      "Epoch [301/3000], Loss: 5454.9438\n",
      "Validation Loss: 4381.0586\n",
      "Epoch [321/3000], Loss: 5321.1441\n",
      "Validation Loss: 4282.2585\n",
      "Epoch [341/3000], Loss: 5189.7343\n",
      "Validation Loss: 4192.2202\n",
      "Epoch [361/3000], Loss: 5071.9502\n",
      "Validation Loss: 4110.8360\n",
      "Epoch [381/3000], Loss: 4957.9620\n",
      "Validation Loss: 4038.0542\n",
      "Epoch [401/3000], Loss: 4856.8761\n",
      "Validation Loss: 3973.7611\n",
      "Epoch [421/3000], Loss: 4764.2580\n",
      "Validation Loss: 3917.8200\n",
      "Epoch [441/3000], Loss: 4679.3973\n",
      "Validation Loss: 3870.1658\n",
      "Epoch [461/3000], Loss: 4600.8751\n",
      "Validation Loss: 3830.5483\n",
      "Epoch [481/3000], Loss: 4532.2302\n",
      "Validation Loss: 3798.7982\n",
      "Epoch [501/3000], Loss: 4476.9355\n",
      "Validation Loss: 3774.6211\n",
      "Epoch [521/3000], Loss: 4424.0558\n",
      "Validation Loss: 3757.7412\n",
      "Epoch [541/3000], Loss: 4378.0430\n",
      "Validation Loss: 3747.7921\n",
      "Epoch [561/3000], Loss: 4345.7181\n",
      "Validation Loss: 3744.2483\n",
      "Epoch [581/3000], Loss: 4319.2745\n",
      "Validation Loss: 3746.4229\n",
      "Epoch [601/3000], Loss: 4295.4978\n",
      "Validation Loss: 3753.4423\n",
      "Epoch [621/3000], Loss: 4277.0650\n",
      "Validation Loss: 3764.1711\n",
      "Epoch [641/3000], Loss: 4266.6949\n",
      "Validation Loss: 3777.1243\n",
      "Epoch [661/3000], Loss: 4257.6537\n",
      "Validation Loss: 3790.5429\n",
      "Epoch [681/3000], Loss: 4252.3820\n",
      "Validation Loss: 3802.8429\n",
      "Epoch [701/3000], Loss: 4253.7124\n",
      "Validation Loss: 3812.9830\n",
      "Epoch [721/3000], Loss: 4251.7548\n",
      "Validation Loss: 3820.3014\n",
      "Epoch [741/3000], Loss: 4252.2657\n",
      "Validation Loss: 3824.9339\n",
      "Epoch [761/3000], Loss: 4253.2036\n",
      "Validation Loss: 3828.0075\n",
      "Epoch [781/3000], Loss: 4253.2083\n",
      "Validation Loss: 3829.9075\n",
      "Epoch [801/3000], Loss: 4252.6549\n",
      "Validation Loss: 3830.9626\n",
      "Epoch [821/3000], Loss: 4252.4349\n",
      "Validation Loss: 3831.5853\n",
      "Epoch [841/3000], Loss: 4254.4128\n",
      "Validation Loss: 3831.8324\n",
      "Epoch [861/3000], Loss: 4250.2493\n",
      "Validation Loss: 3832.2772\n",
      "Epoch [881/3000], Loss: 4252.1016\n",
      "Validation Loss: 3832.3989\n",
      "Epoch [901/3000], Loss: 4252.1456\n",
      "Validation Loss: 3832.4680\n",
      "Epoch [921/3000], Loss: 4254.1937\n",
      "Validation Loss: 3832.4428\n",
      "Epoch [941/3000], Loss: 3428.5990\n",
      "Validation Loss: 3475.7813\n",
      "Epoch [961/3000], Loss: 2830.3417\n",
      "Validation Loss: 3406.8607\n",
      "Epoch [981/3000], Loss: 2637.9233\n",
      "Validation Loss: 3322.1019\n",
      "Epoch [1001/3000], Loss: 2487.9438\n",
      "Validation Loss: 3282.9059\n",
      "Epoch [1021/3000], Loss: 2365.1509\n",
      "Validation Loss: 3259.3895\n",
      "Epoch [1041/3000], Loss: 2250.7863\n",
      "Validation Loss: 3258.8719\n",
      "Epoch [1061/3000], Loss: 2140.1299\n",
      "Validation Loss: 3247.1511\n",
      "Epoch [1081/3000], Loss: 2028.7430\n",
      "Validation Loss: 3274.1586\n",
      "Epoch [1101/3000], Loss: 1916.8619\n",
      "Validation Loss: 3278.3891\n",
      "Epoch [1121/3000], Loss: 1821.9917\n",
      "Validation Loss: 3297.8043\n",
      "Epoch [1141/3000], Loss: 1723.1484\n",
      "Validation Loss: 3333.5507\n",
      "Epoch [1161/3000], Loss: 1635.6883\n",
      "Validation Loss: 3459.6004\n",
      "Epoch [1181/3000], Loss: 1529.4629\n",
      "Validation Loss: 3457.6320\n",
      "Epoch [1201/3000], Loss: 1448.6452\n",
      "Validation Loss: 3435.0331\n",
      "Epoch [1221/3000], Loss: 1363.5534\n",
      "Validation Loss: 3432.0915\n",
      "Epoch [1241/3000], Loss: 1298.2843\n",
      "Validation Loss: 3417.2935\n",
      "Epoch [1261/3000], Loss: 1213.8358\n",
      "Validation Loss: 3430.7280\n",
      "Epoch [1281/3000], Loss: 1134.7017\n",
      "Validation Loss: 3444.2063\n",
      "Epoch [1301/3000], Loss: 1067.1478\n",
      "Validation Loss: 3555.1783\n",
      "Epoch [1321/3000], Loss: 1007.8279\n",
      "Validation Loss: 3698.4091\n",
      "Epoch [1341/3000], Loss: 942.7893\n",
      "Validation Loss: 3617.8309\n",
      "Epoch [1361/3000], Loss: 891.7147\n",
      "Validation Loss: 3561.3211\n",
      "Epoch [1381/3000], Loss: 834.4604\n",
      "Validation Loss: 3609.5041\n",
      "Epoch [1401/3000], Loss: 776.6787\n",
      "Validation Loss: 3663.1038\n",
      "Epoch [1421/3000], Loss: 726.4368\n",
      "Validation Loss: 3846.7848\n",
      "Epoch [1441/3000], Loss: 686.5237\n",
      "Validation Loss: 3491.1261\n",
      "Epoch [1461/3000], Loss: 620.5511\n",
      "Validation Loss: 3584.1681\n",
      "Epoch [1481/3000], Loss: 581.6655\n",
      "Validation Loss: 3672.6176\n",
      "Epoch [1501/3000], Loss: 529.4724\n",
      "Validation Loss: 3782.8086\n",
      "Epoch [1521/3000], Loss: 492.9823\n",
      "Validation Loss: 3637.2345\n",
      "Epoch [1541/3000], Loss: 466.8842\n",
      "Validation Loss: 4010.5631\n",
      "Epoch [1561/3000], Loss: 421.4048\n",
      "Validation Loss: 3859.5633\n",
      "Epoch [1581/3000], Loss: 383.8579\n",
      "Validation Loss: 3830.0834\n",
      "Epoch [1601/3000], Loss: 358.8765\n",
      "Validation Loss: 3645.5879\n",
      "Epoch [1621/3000], Loss: 312.3554\n",
      "Validation Loss: 3782.8709\n",
      "Epoch [1641/3000], Loss: 280.1790\n",
      "Validation Loss: 3934.6903\n",
      "Epoch [1661/3000], Loss: 258.2544\n",
      "Validation Loss: 3993.7291\n",
      "Epoch [1681/3000], Loss: 232.2532\n",
      "Validation Loss: 3850.6158\n",
      "Epoch [1701/3000], Loss: 216.8264\n",
      "Validation Loss: 3994.3348\n",
      "Epoch [1721/3000], Loss: 195.2888\n",
      "Validation Loss: 3816.9150\n",
      "Epoch [1741/3000], Loss: 180.6459\n",
      "Validation Loss: 4222.8879\n",
      "Epoch [1761/3000], Loss: 168.9300\n",
      "Validation Loss: 4389.7772\n",
      "Epoch [1781/3000], Loss: 152.3615\n",
      "Validation Loss: 4216.6044\n",
      "Epoch [1801/3000], Loss: 141.7496\n",
      "Validation Loss: 4422.1768\n",
      "Epoch [1821/3000], Loss: 132.1954\n",
      "Validation Loss: 4229.3565\n",
      "Epoch [1841/3000], Loss: 122.7866\n",
      "Validation Loss: 4323.1750\n",
      "Epoch [1861/3000], Loss: 112.8870\n",
      "Validation Loss: 4171.7898\n",
      "Epoch [1881/3000], Loss: 107.1300\n",
      "Validation Loss: 4261.0552\n",
      "Epoch [1901/3000], Loss: 99.8346\n",
      "Validation Loss: 4222.2341\n",
      "Epoch [1921/3000], Loss: 99.0410\n",
      "Validation Loss: 4073.0782\n",
      "Epoch [1941/3000], Loss: 88.5742\n",
      "Validation Loss: 4150.9853\n",
      "Epoch [1961/3000], Loss: 90.1566\n",
      "Validation Loss: 3937.6448\n",
      "Epoch [1981/3000], Loss: 78.0405\n",
      "Validation Loss: 4287.3858\n",
      "Epoch [2001/3000], Loss: 73.4426\n",
      "Validation Loss: 4398.4229\n",
      "Epoch [2021/3000], Loss: 70.3142\n",
      "Validation Loss: 4363.7183\n",
      "Epoch [2041/3000], Loss: 120.8639\n",
      "Validation Loss: 3784.1234\n",
      "Epoch [2061/3000], Loss: 73.1779\n",
      "Validation Loss: 4311.8537\n",
      "Epoch [2081/3000], Loss: 57.2396\n",
      "Validation Loss: 4209.6290\n",
      "Epoch [2101/3000], Loss: 54.7984\n",
      "Validation Loss: 4134.0531\n",
      "Epoch [2121/3000], Loss: 51.4124\n",
      "Validation Loss: 4319.4822\n",
      "Epoch [2141/3000], Loss: 50.5387\n",
      "Validation Loss: 4332.0414\n",
      "Epoch [2161/3000], Loss: 45.5141\n",
      "Validation Loss: 4082.5425\n",
      "Epoch [2181/3000], Loss: 42.7866\n",
      "Validation Loss: 4237.8807\n",
      "Epoch [2201/3000], Loss: 40.6700\n",
      "Validation Loss: 4267.0815\n",
      "Epoch [2221/3000], Loss: 39.3359\n",
      "Validation Loss: 4266.1438\n",
      "Epoch [2241/3000], Loss: 35.8603\n",
      "Validation Loss: 4288.6534\n",
      "Epoch [2261/3000], Loss: 34.0292\n",
      "Validation Loss: 4144.6413\n",
      "Epoch [2281/3000], Loss: 32.3244\n",
      "Validation Loss: 4285.6327\n",
      "Epoch [2301/3000], Loss: 30.7257\n",
      "Validation Loss: 4253.8800\n",
      "Epoch [2321/3000], Loss: 29.6029\n",
      "Validation Loss: 4145.2008\n",
      "Epoch [2341/3000], Loss: 27.3321\n",
      "Validation Loss: 4092.0121\n",
      "Epoch [2361/3000], Loss: 25.3206\n",
      "Validation Loss: 4189.1816\n",
      "Epoch [2381/3000], Loss: 24.7042\n",
      "Validation Loss: 4262.1734\n",
      "Epoch [2401/3000], Loss: 22.9973\n",
      "Validation Loss: 4168.6281\n",
      "Epoch [2421/3000], Loss: 21.9326\n",
      "Validation Loss: 4009.5447\n",
      "Epoch [2441/3000], Loss: 20.2885\n",
      "Validation Loss: 4178.2801\n",
      "Epoch [2461/3000], Loss: 19.8244\n",
      "Validation Loss: 4003.9717\n",
      "Epoch [2481/3000], Loss: 18.6697\n",
      "Validation Loss: 4273.3120\n",
      "Epoch [2501/3000], Loss: 18.3992\n",
      "Validation Loss: 4074.0828\n",
      "Epoch [2521/3000], Loss: 16.4639\n",
      "Validation Loss: 4204.3564\n",
      "Epoch [2541/3000], Loss: 16.2569\n",
      "Validation Loss: 4135.1312\n",
      "Epoch [2561/3000], Loss: 15.9984\n",
      "Validation Loss: 4070.2285\n",
      "Epoch [2581/3000], Loss: 15.2418\n",
      "Validation Loss: 4254.1436\n",
      "Epoch [2601/3000], Loss: 13.5069\n",
      "Validation Loss: 4192.3824\n",
      "Epoch [2621/3000], Loss: 13.0322\n",
      "Validation Loss: 4229.2088\n",
      "Epoch [2641/3000], Loss: 13.3832\n",
      "Validation Loss: 4215.8472\n",
      "Epoch [2661/3000], Loss: 12.2437\n",
      "Validation Loss: 4137.9683\n",
      "Epoch [2681/3000], Loss: 11.6412\n",
      "Validation Loss: 4185.9475\n",
      "Epoch [2701/3000], Loss: 11.2062\n",
      "Validation Loss: 4234.4898\n",
      "Epoch [2721/3000], Loss: 11.5848\n",
      "Validation Loss: 4234.5364\n",
      "Epoch [2741/3000], Loss: 10.4816\n",
      "Validation Loss: 4179.0025\n",
      "Epoch [2761/3000], Loss: 10.0158\n",
      "Validation Loss: 4207.4382\n",
      "Epoch [2781/3000], Loss: 10.0411\n",
      "Validation Loss: 4224.0154\n",
      "Epoch [2801/3000], Loss: 9.4213\n",
      "Validation Loss: 4090.6452\n",
      "Epoch [2821/3000], Loss: 9.9214\n",
      "Validation Loss: 4002.2213\n",
      "Epoch [2841/3000], Loss: 8.9102\n",
      "Validation Loss: 4141.0005\n",
      "Epoch [2861/3000], Loss: 8.6880\n",
      "Validation Loss: 4426.9224\n",
      "Epoch [2881/3000], Loss: 7.7573\n",
      "Validation Loss: 4210.9271\n",
      "Epoch [2901/3000], Loss: 7.3625\n",
      "Validation Loss: 4249.2033\n",
      "Epoch [2921/3000], Loss: 7.3555\n",
      "Validation Loss: 4211.3793\n",
      "Epoch [2941/3000], Loss: 7.2665\n",
      "Validation Loss: 4273.8683\n",
      "Epoch [2961/3000], Loss: 6.6491\n",
      "Validation Loss: 4121.4700\n",
      "Epoch [2981/3000], Loss: 6.4127\n",
      "Validation Loss: 4190.8050\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day070_plane0_Fall.mat\n",
      "(5010, 103)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7017.3983\n",
      "Validation Loss: 5354.1158\n",
      "Epoch [21/3000], Loss: 6170.2583\n",
      "Validation Loss: 4667.4121\n",
      "Epoch [41/3000], Loss: 5959.0711\n",
      "Validation Loss: 4494.6732\n",
      "Epoch [61/3000], Loss: 5804.0703\n",
      "Validation Loss: 4400.1086\n",
      "Epoch [81/3000], Loss: 5731.8287\n",
      "Validation Loss: 4320.1040\n",
      "Epoch [101/3000], Loss: 5589.0213\n",
      "Validation Loss: 4247.1812\n",
      "Epoch [121/3000], Loss: 5519.5557\n",
      "Validation Loss: 4179.0437\n",
      "Epoch [141/3000], Loss: 5421.0584\n",
      "Validation Loss: 4114.3583\n",
      "Epoch [161/3000], Loss: 5352.4031\n",
      "Validation Loss: 4051.6918\n",
      "Epoch [181/3000], Loss: 5263.1121\n",
      "Validation Loss: 3989.3759\n",
      "Epoch [201/3000], Loss: 5182.6296\n",
      "Validation Loss: 3931.3218\n",
      "Epoch [221/3000], Loss: 5107.0791\n",
      "Validation Loss: 3875.3499\n",
      "Epoch [241/3000], Loss: 5016.5776\n",
      "Validation Loss: 3820.8900\n",
      "Epoch [261/3000], Loss: 4971.2120\n",
      "Validation Loss: 3768.6381\n",
      "Epoch [281/3000], Loss: 4888.6329\n",
      "Validation Loss: 3718.3470\n",
      "Epoch [301/3000], Loss: 4835.1191\n",
      "Validation Loss: 3669.8365\n",
      "Epoch [321/3000], Loss: 4743.6030\n",
      "Validation Loss: 3623.2077\n",
      "Epoch [341/3000], Loss: 4677.9117\n",
      "Validation Loss: 3578.2311\n",
      "Epoch [361/3000], Loss: 4625.0721\n",
      "Validation Loss: 3534.9728\n",
      "Epoch [381/3000], Loss: 4554.5606\n",
      "Validation Loss: 3493.4651\n",
      "Epoch [401/3000], Loss: 4505.9137\n",
      "Validation Loss: 3453.6819\n",
      "Epoch [421/3000], Loss: 4394.6182\n",
      "Validation Loss: 3415.5655\n",
      "Epoch [441/3000], Loss: 4378.1647\n",
      "Validation Loss: 3379.1155\n",
      "Epoch [461/3000], Loss: 4292.8487\n",
      "Validation Loss: 3344.3200\n",
      "Epoch [481/3000], Loss: 4273.6995\n",
      "Validation Loss: 3311.1265\n",
      "Epoch [501/3000], Loss: 4219.9112\n",
      "Validation Loss: 3279.6547\n",
      "Epoch [521/3000], Loss: 4156.4655\n",
      "Validation Loss: 3249.7640\n",
      "Epoch [541/3000], Loss: 4122.6550\n",
      "Validation Loss: 3221.5181\n",
      "Epoch [561/3000], Loss: 4070.7437\n",
      "Validation Loss: 3194.9514\n",
      "Epoch [581/3000], Loss: 4014.6594\n",
      "Validation Loss: 3169.9676\n",
      "Epoch [601/3000], Loss: 3996.6810\n",
      "Validation Loss: 3146.5856\n",
      "Epoch [621/3000], Loss: 3945.6555\n",
      "Validation Loss: 3124.8278\n",
      "Epoch [641/3000], Loss: 3883.2547\n",
      "Validation Loss: 3104.6027\n",
      "Epoch [661/3000], Loss: 3870.4939\n",
      "Validation Loss: 3085.9761\n",
      "Epoch [681/3000], Loss: 3797.2073\n",
      "Validation Loss: 3068.8909\n",
      "Epoch [701/3000], Loss: 3780.1124\n",
      "Validation Loss: 3053.3418\n",
      "Epoch [721/3000], Loss: 3729.6964\n",
      "Validation Loss: 3039.3160\n",
      "Epoch [741/3000], Loss: 3725.5977\n",
      "Validation Loss: 3026.8098\n",
      "Epoch [761/3000], Loss: 3676.9975\n",
      "Validation Loss: 3015.7815\n",
      "Epoch [781/3000], Loss: 3660.1226\n",
      "Validation Loss: 3006.2427\n",
      "Epoch [801/3000], Loss: 3625.7381\n",
      "Validation Loss: 2998.1424\n",
      "Epoch [821/3000], Loss: 3594.6460\n",
      "Validation Loss: 2991.4597\n",
      "Epoch [841/3000], Loss: 3574.6940\n",
      "Validation Loss: 2986.0968\n",
      "Epoch [861/3000], Loss: 3554.3632\n",
      "Validation Loss: 2982.1635\n",
      "Epoch [881/3000], Loss: 3527.5401\n",
      "Validation Loss: 2979.5976\n",
      "Epoch [901/3000], Loss: 3502.1586\n",
      "Validation Loss: 2978.3473\n",
      "Epoch [921/3000], Loss: 3485.4153\n",
      "Validation Loss: 2978.3508\n",
      "Epoch [941/3000], Loss: 3459.5782\n",
      "Validation Loss: 2979.5570\n",
      "Epoch [961/3000], Loss: 3384.4189\n",
      "Validation Loss: 2858.3787\n",
      "Epoch [981/3000], Loss: 2599.1193\n",
      "Validation Loss: 1977.1564\n",
      "Epoch [1001/3000], Loss: 2452.8992\n",
      "Validation Loss: 1905.2461\n",
      "Epoch [1021/3000], Loss: 2381.9365\n",
      "Validation Loss: 1860.3056\n",
      "Epoch [1041/3000], Loss: 2305.4325\n",
      "Validation Loss: 1823.1217\n",
      "Epoch [1061/3000], Loss: 2253.2218\n",
      "Validation Loss: 1784.5625\n",
      "Epoch [1081/3000], Loss: 2191.2198\n",
      "Validation Loss: 1750.5117\n",
      "Epoch [1101/3000], Loss: 2129.6858\n",
      "Validation Loss: 1725.2492\n",
      "Epoch [1121/3000], Loss: 2087.2719\n",
      "Validation Loss: 1692.2109\n",
      "Epoch [1141/3000], Loss: 2033.5809\n",
      "Validation Loss: 1669.6598\n",
      "Epoch [1161/3000], Loss: 1985.0635\n",
      "Validation Loss: 1622.0749\n",
      "Epoch [1181/3000], Loss: 1943.5882\n",
      "Validation Loss: 1594.8461\n",
      "Epoch [1201/3000], Loss: 1882.1448\n",
      "Validation Loss: 1584.0253\n",
      "Epoch [1221/3000], Loss: 1855.7495\n",
      "Validation Loss: 1564.2896\n",
      "Epoch [1241/3000], Loss: 1799.3145\n",
      "Validation Loss: 1536.0371\n",
      "Epoch [1261/3000], Loss: 1744.2408\n",
      "Validation Loss: 1492.0130\n",
      "Epoch [1281/3000], Loss: 1696.3305\n",
      "Validation Loss: 1463.4212\n",
      "Epoch [1301/3000], Loss: 1652.9404\n",
      "Validation Loss: 1488.4149\n",
      "Epoch [1321/3000], Loss: 1608.3958\n",
      "Validation Loss: 1446.0810\n",
      "Epoch [1341/3000], Loss: 1573.6277\n",
      "Validation Loss: 1407.9865\n",
      "Epoch [1361/3000], Loss: 1525.7140\n",
      "Validation Loss: 1389.6820\n",
      "Epoch [1381/3000], Loss: 1487.6257\n",
      "Validation Loss: 1411.4076\n",
      "Epoch [1401/3000], Loss: 1444.4385\n",
      "Validation Loss: 1375.3519\n",
      "Epoch [1421/3000], Loss: 1425.1165\n",
      "Validation Loss: 1365.6377\n",
      "Epoch [1441/3000], Loss: 1410.6790\n",
      "Validation Loss: 1274.3781\n",
      "Epoch [1461/3000], Loss: 1337.6273\n",
      "Validation Loss: 1296.5292\n",
      "Epoch [1481/3000], Loss: 1319.2918\n",
      "Validation Loss: 1248.7185\n",
      "Epoch [1501/3000], Loss: 1278.2586\n",
      "Validation Loss: 1299.2819\n",
      "Epoch [1521/3000], Loss: 1238.8270\n",
      "Validation Loss: 1261.6699\n",
      "Epoch [1541/3000], Loss: 1214.0765\n",
      "Validation Loss: 1263.1458\n",
      "Epoch [1561/3000], Loss: 1173.2126\n",
      "Validation Loss: 1221.9210\n",
      "Epoch [1581/3000], Loss: 1149.8757\n",
      "Validation Loss: 1218.4432\n",
      "Epoch [1601/3000], Loss: 1123.5893\n",
      "Validation Loss: 1207.9969\n",
      "Epoch [1621/3000], Loss: 1092.9259\n",
      "Validation Loss: 1162.1635\n",
      "Epoch [1641/3000], Loss: 1062.4664\n",
      "Validation Loss: 1162.1553\n",
      "Epoch [1661/3000], Loss: 1050.5900\n",
      "Validation Loss: 1240.2807\n",
      "Epoch [1681/3000], Loss: 1004.9889\n",
      "Validation Loss: 1127.9221\n",
      "Epoch [1701/3000], Loss: 983.0453\n",
      "Validation Loss: 1111.2351\n",
      "Epoch [1721/3000], Loss: 942.0312\n",
      "Validation Loss: 1097.0170\n",
      "Epoch [1741/3000], Loss: 930.0649\n",
      "Validation Loss: 1090.9354\n",
      "Epoch [1761/3000], Loss: 897.1984\n",
      "Validation Loss: 1079.7939\n",
      "Epoch [1781/3000], Loss: 884.1197\n",
      "Validation Loss: 1067.3818\n",
      "Epoch [1801/3000], Loss: 852.3609\n",
      "Validation Loss: 1048.4178\n",
      "Epoch [1821/3000], Loss: 868.4889\n",
      "Validation Loss: 994.4736\n",
      "Epoch [1841/3000], Loss: 800.6134\n",
      "Validation Loss: 1032.1967\n",
      "Epoch [1861/3000], Loss: 785.4655\n",
      "Validation Loss: 1024.2190\n",
      "Epoch [1881/3000], Loss: 759.4508\n",
      "Validation Loss: 1005.0146\n",
      "Epoch [1901/3000], Loss: 741.0660\n",
      "Validation Loss: 1018.5082\n",
      "Epoch [1921/3000], Loss: 715.5401\n",
      "Validation Loss: 972.4957\n",
      "Epoch [1941/3000], Loss: 689.8593\n",
      "Validation Loss: 985.5663\n",
      "Epoch [1961/3000], Loss: 672.0452\n",
      "Validation Loss: 962.9410\n",
      "Epoch [1981/3000], Loss: 662.6844\n",
      "Validation Loss: 946.5125\n",
      "Epoch [2001/3000], Loss: 639.6325\n",
      "Validation Loss: 960.0645\n",
      "Epoch [2021/3000], Loss: 623.3521\n",
      "Validation Loss: 949.4217\n",
      "Epoch [2041/3000], Loss: 611.4396\n",
      "Validation Loss: 956.4791\n",
      "Epoch [2061/3000], Loss: 592.0568\n",
      "Validation Loss: 934.2412\n",
      "Epoch [2081/3000], Loss: 567.9489\n",
      "Validation Loss: 916.1421\n",
      "Epoch [2101/3000], Loss: 552.6919\n",
      "Validation Loss: 904.4299\n",
      "Epoch [2121/3000], Loss: 537.2392\n",
      "Validation Loss: 909.2823\n",
      "Epoch [2141/3000], Loss: 518.6558\n",
      "Validation Loss: 955.0153\n",
      "Epoch [2161/3000], Loss: 515.3500\n",
      "Validation Loss: 869.9848\n",
      "Epoch [2181/3000], Loss: 490.8701\n",
      "Validation Loss: 898.2403\n",
      "Epoch [2201/3000], Loss: 472.1551\n",
      "Validation Loss: 939.9995\n",
      "Epoch [2221/3000], Loss: 458.2684\n",
      "Validation Loss: 921.0199\n",
      "Epoch [2241/3000], Loss: 444.6913\n",
      "Validation Loss: 883.1095\n",
      "Epoch [2261/3000], Loss: 430.3533\n",
      "Validation Loss: 920.3117\n",
      "Epoch [2281/3000], Loss: 413.7790\n",
      "Validation Loss: 916.0483\n",
      "Epoch [2301/3000], Loss: 399.4346\n",
      "Validation Loss: 911.3879\n",
      "Epoch [2321/3000], Loss: 386.1817\n",
      "Validation Loss: 905.7211\n",
      "Epoch [2341/3000], Loss: 379.9161\n",
      "Validation Loss: 905.7601\n",
      "Epoch [2361/3000], Loss: 366.3175\n",
      "Validation Loss: 897.9510\n",
      "Epoch [2381/3000], Loss: 352.8376\n",
      "Validation Loss: 895.0974\n",
      "Epoch [2401/3000], Loss: 370.0000\n",
      "Validation Loss: 842.6503\n",
      "Epoch [2421/3000], Loss: 333.2317\n",
      "Validation Loss: 866.0029\n",
      "Epoch [2441/3000], Loss: 324.8093\n",
      "Validation Loss: 873.6582\n",
      "Epoch [2461/3000], Loss: 311.1243\n",
      "Validation Loss: 875.3729\n",
      "Epoch [2481/3000], Loss: 303.7445\n",
      "Validation Loss: 875.9681\n",
      "Epoch [2501/3000], Loss: 294.3147\n",
      "Validation Loss: 886.0971\n",
      "Epoch [2521/3000], Loss: 281.9523\n",
      "Validation Loss: 876.7117\n",
      "Epoch [2541/3000], Loss: 274.3597\n",
      "Validation Loss: 878.1020\n",
      "Epoch [2561/3000], Loss: 261.0421\n",
      "Validation Loss: 882.4632\n",
      "Epoch [2581/3000], Loss: 276.4516\n",
      "Validation Loss: 813.9767\n",
      "Epoch [2601/3000], Loss: 244.3743\n",
      "Validation Loss: 838.8929\n",
      "Epoch [2621/3000], Loss: 238.0449\n",
      "Validation Loss: 840.3112\n",
      "Epoch [2641/3000], Loss: 228.2729\n",
      "Validation Loss: 843.8816\n",
      "Epoch [2661/3000], Loss: 222.3025\n",
      "Validation Loss: 839.1713\n",
      "Epoch [2681/3000], Loss: 216.1677\n",
      "Validation Loss: 841.2242\n",
      "Epoch [2701/3000], Loss: 203.5028\n",
      "Validation Loss: 846.8849\n",
      "Epoch [2721/3000], Loss: 198.6081\n",
      "Validation Loss: 847.5802\n",
      "Epoch [2741/3000], Loss: 190.5568\n",
      "Validation Loss: 844.8744\n",
      "Epoch [2761/3000], Loss: 183.4001\n",
      "Validation Loss: 848.8225\n",
      "Epoch [2781/3000], Loss: 178.3407\n",
      "Validation Loss: 843.8439\n",
      "Epoch [2801/3000], Loss: 169.2041\n",
      "Validation Loss: 848.0571\n",
      "Epoch [2821/3000], Loss: 163.2600\n",
      "Validation Loss: 831.1625\n",
      "Epoch [2841/3000], Loss: 154.3697\n",
      "Validation Loss: 833.2424\n",
      "Epoch [2861/3000], Loss: 149.2926\n",
      "Validation Loss: 830.2029\n",
      "Epoch [2881/3000], Loss: 142.6899\n",
      "Validation Loss: 836.2549\n",
      "Epoch [2901/3000], Loss: 136.1654\n",
      "Validation Loss: 834.6491\n",
      "Epoch [2921/3000], Loss: 130.3139\n",
      "Validation Loss: 831.6796\n",
      "Epoch [2941/3000], Loss: 122.5578\n",
      "Validation Loss: 827.5560\n",
      "Epoch [2961/3000], Loss: 115.6623\n",
      "Validation Loss: 818.9107\n",
      "Epoch [2981/3000], Loss: 111.0726\n",
      "Validation Loss: 829.3118\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day072_plane0_Fall.mat\n",
      "(3310, 93)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 4258.5132\n",
      "Validation Loss: 3487.0980\n",
      "Epoch [21/3000], Loss: 3838.5330\n",
      "Validation Loss: 3122.4059\n",
      "Epoch [41/3000], Loss: 3574.7946\n",
      "Validation Loss: 2899.1780\n",
      "Epoch [61/3000], Loss: 3470.4332\n",
      "Validation Loss: 2828.8036\n",
      "Epoch [81/3000], Loss: 3419.1787\n",
      "Validation Loss: 2781.3864\n",
      "Epoch [101/3000], Loss: 3378.9132\n",
      "Validation Loss: 2741.8187\n",
      "Epoch [121/3000], Loss: 3288.6565\n",
      "Validation Loss: 2705.8006\n",
      "Epoch [141/3000], Loss: 3195.2807\n",
      "Validation Loss: 2670.3132\n",
      "Epoch [161/3000], Loss: 3234.5452\n",
      "Validation Loss: 2638.3180\n",
      "Epoch [181/3000], Loss: 3168.9829\n",
      "Validation Loss: 2607.8508\n",
      "Epoch [201/3000], Loss: 3179.9964\n",
      "Validation Loss: 2578.6415\n",
      "Epoch [221/3000], Loss: 3092.9548\n",
      "Validation Loss: 2550.4842\n",
      "Epoch [241/3000], Loss: 3080.6835\n",
      "Validation Loss: 2523.4448\n",
      "Epoch [261/3000], Loss: 3061.3472\n",
      "Validation Loss: 2497.2638\n",
      "Epoch [281/3000], Loss: 3036.2826\n",
      "Validation Loss: 2471.9628\n",
      "Epoch [301/3000], Loss: 2963.0663\n",
      "Validation Loss: 2447.3729\n",
      "Epoch [321/3000], Loss: 2963.7467\n",
      "Validation Loss: 2423.6414\n",
      "Epoch [341/3000], Loss: 2954.3722\n",
      "Validation Loss: 2400.6019\n",
      "Epoch [361/3000], Loss: 2895.1784\n",
      "Validation Loss: 2378.3430\n",
      "Epoch [381/3000], Loss: 2857.0239\n",
      "Validation Loss: 2356.8481\n",
      "Epoch [401/3000], Loss: 2816.8354\n",
      "Validation Loss: 2336.0380\n",
      "Epoch [421/3000], Loss: 2777.7597\n",
      "Validation Loss: 2315.9460\n",
      "Epoch [441/3000], Loss: 2760.2952\n",
      "Validation Loss: 2296.5071\n",
      "Epoch [461/3000], Loss: 2784.4730\n",
      "Validation Loss: 2277.8139\n",
      "Epoch [481/3000], Loss: 2754.5374\n",
      "Validation Loss: 2259.8093\n",
      "Epoch [501/3000], Loss: 2696.8067\n",
      "Validation Loss: 2242.4726\n",
      "Epoch [521/3000], Loss: 2682.4902\n",
      "Validation Loss: 2225.7702\n",
      "Epoch [541/3000], Loss: 2671.5007\n",
      "Validation Loss: 2209.6510\n",
      "Epoch [561/3000], Loss: 2608.7868\n",
      "Validation Loss: 2194.1999\n",
      "Epoch [581/3000], Loss: 2616.9538\n",
      "Validation Loss: 2179.4554\n",
      "Epoch [601/3000], Loss: 2561.7303\n",
      "Validation Loss: 2165.2874\n",
      "Epoch [621/3000], Loss: 2573.1848\n",
      "Validation Loss: 2151.8098\n",
      "Epoch [641/3000], Loss: 2565.8684\n",
      "Validation Loss: 2138.9399\n",
      "Epoch [661/3000], Loss: 2490.1019\n",
      "Validation Loss: 2126.6566\n",
      "Epoch [681/3000], Loss: 2513.0548\n",
      "Validation Loss: 2115.0457\n",
      "Epoch [701/3000], Loss: 2506.6021\n",
      "Validation Loss: 2104.0803\n",
      "Epoch [721/3000], Loss: 2485.4407\n",
      "Validation Loss: 2093.7360\n",
      "Epoch [741/3000], Loss: 2452.5011\n",
      "Validation Loss: 2083.9322\n",
      "Epoch [761/3000], Loss: 2450.8832\n",
      "Validation Loss: 2074.6857\n",
      "Epoch [781/3000], Loss: 2457.0581\n",
      "Validation Loss: 2066.0383\n",
      "Epoch [801/3000], Loss: 2413.1263\n",
      "Validation Loss: 2058.0294\n",
      "Epoch [821/3000], Loss: 2403.6271\n",
      "Validation Loss: 2050.5768\n",
      "Epoch [841/3000], Loss: 2370.0352\n",
      "Validation Loss: 2043.7329\n",
      "Epoch [861/3000], Loss: 2348.9148\n",
      "Validation Loss: 2037.4196\n",
      "Epoch [881/3000], Loss: 2342.9986\n",
      "Validation Loss: 2031.6740\n",
      "Epoch [901/3000], Loss: 2363.1348\n",
      "Validation Loss: 2026.4757\n",
      "Epoch [921/3000], Loss: 2343.3495\n",
      "Validation Loss: 2021.8136\n",
      "Epoch [941/3000], Loss: 2362.1463\n",
      "Validation Loss: 2017.6721\n",
      "Epoch [961/3000], Loss: 2322.7180\n",
      "Validation Loss: 2014.0961\n",
      "Epoch [981/3000], Loss: 2322.0054\n",
      "Validation Loss: 2010.9822\n",
      "Epoch [1001/3000], Loss: 2286.1818\n",
      "Validation Loss: 2008.3684\n",
      "Epoch [1021/3000], Loss: 2319.9774\n",
      "Validation Loss: 2006.2202\n",
      "Epoch [1041/3000], Loss: 2318.4917\n",
      "Validation Loss: 2004.5600\n",
      "Epoch [1061/3000], Loss: 2303.7922\n",
      "Validation Loss: 2003.3447\n",
      "Epoch [1081/3000], Loss: 2276.1767\n",
      "Validation Loss: 2002.5577\n",
      "Epoch [1101/3000], Loss: 2277.0067\n",
      "Validation Loss: 2002.1807\n",
      "Epoch [1121/3000], Loss: 2268.8321\n",
      "Validation Loss: 2002.2022\n",
      "Epoch [1141/3000], Loss: 2273.4953\n",
      "Validation Loss: 2002.5944\n",
      "Epoch [1161/3000], Loss: 2244.9104\n",
      "Validation Loss: 2003.3217\n",
      "Epoch [1181/3000], Loss: 2279.9290\n",
      "Validation Loss: 2004.3744\n",
      "Epoch [1201/3000], Loss: 2249.6148\n",
      "Validation Loss: 2005.7038\n",
      "Epoch [1221/3000], Loss: 2230.7076\n",
      "Validation Loss: 2007.3394\n",
      "Epoch [1241/3000], Loss: 2251.1273\n",
      "Validation Loss: 2009.1707\n",
      "Epoch [1261/3000], Loss: 2229.7737\n",
      "Validation Loss: 2011.1726\n",
      "Epoch [1281/3000], Loss: 2217.8228\n",
      "Validation Loss: 2013.3248\n",
      "Epoch [1301/3000], Loss: 1813.8543\n",
      "Validation Loss: 1421.5087\n",
      "Epoch [1321/3000], Loss: 1531.9360\n",
      "Validation Loss: 1232.6344\n",
      "Epoch [1341/3000], Loss: 1469.1214\n",
      "Validation Loss: 1183.4505\n",
      "Epoch [1361/3000], Loss: 1411.5372\n",
      "Validation Loss: 1155.2115\n",
      "Epoch [1381/3000], Loss: 1366.7923\n",
      "Validation Loss: 1121.1961\n",
      "Epoch [1401/3000], Loss: 1320.8194\n",
      "Validation Loss: 1103.4889\n",
      "Epoch [1421/3000], Loss: 1311.9123\n",
      "Validation Loss: 1079.6910\n",
      "Epoch [1441/3000], Loss: 1284.5760\n",
      "Validation Loss: 1058.2141\n",
      "Epoch [1461/3000], Loss: 1265.7350\n",
      "Validation Loss: 1035.7464\n",
      "Epoch [1481/3000], Loss: 1245.6302\n",
      "Validation Loss: 1022.4136\n",
      "Epoch [1501/3000], Loss: 1205.2339\n",
      "Validation Loss: 994.1713\n",
      "Epoch [1521/3000], Loss: 1163.5303\n",
      "Validation Loss: 978.0008\n",
      "Epoch [1541/3000], Loss: 1173.7405\n",
      "Validation Loss: 958.6543\n",
      "Epoch [1561/3000], Loss: 1142.1710\n",
      "Validation Loss: 942.5347\n",
      "Epoch [1581/3000], Loss: 1126.0231\n",
      "Validation Loss: 925.3498\n",
      "Epoch [1601/3000], Loss: 1090.4375\n",
      "Validation Loss: 919.2599\n",
      "Epoch [1621/3000], Loss: 1068.0261\n",
      "Validation Loss: 901.2169\n",
      "Epoch [1641/3000], Loss: 1048.4001\n",
      "Validation Loss: 886.8874\n",
      "Epoch [1661/3000], Loss: 1032.5428\n",
      "Validation Loss: 871.9078\n",
      "Epoch [1681/3000], Loss: 986.2177\n",
      "Validation Loss: 863.5530\n",
      "Epoch [1701/3000], Loss: 1010.0453\n",
      "Validation Loss: 854.0697\n",
      "Epoch [1721/3000], Loss: 956.6622\n",
      "Validation Loss: 845.9944\n",
      "Epoch [1741/3000], Loss: 954.2430\n",
      "Validation Loss: 821.8298\n",
      "Epoch [1761/3000], Loss: 971.4390\n",
      "Validation Loss: 824.6359\n",
      "Epoch [1781/3000], Loss: 937.9108\n",
      "Validation Loss: 803.8393\n",
      "Epoch [1801/3000], Loss: 902.1841\n",
      "Validation Loss: 786.5876\n",
      "Epoch [1821/3000], Loss: 899.8927\n",
      "Validation Loss: 784.8509\n",
      "Epoch [1841/3000], Loss: 884.1892\n",
      "Validation Loss: 768.9121\n",
      "Epoch [1861/3000], Loss: 850.1941\n",
      "Validation Loss: 764.7914\n",
      "Epoch [1881/3000], Loss: 842.3772\n",
      "Validation Loss: 748.3419\n",
      "Epoch [1901/3000], Loss: 838.9039\n",
      "Validation Loss: 765.4969\n",
      "Epoch [1921/3000], Loss: 808.6472\n",
      "Validation Loss: 739.0207\n",
      "Epoch [1941/3000], Loss: 792.3323\n",
      "Validation Loss: 705.4571\n",
      "Epoch [1961/3000], Loss: 773.7514\n",
      "Validation Loss: 694.6469\n",
      "Epoch [1981/3000], Loss: 771.7173\n",
      "Validation Loss: 692.6534\n",
      "Epoch [2001/3000], Loss: 766.2878\n",
      "Validation Loss: 690.3746\n",
      "Epoch [2021/3000], Loss: 754.6467\n",
      "Validation Loss: 678.9971\n",
      "Epoch [2041/3000], Loss: 731.8805\n",
      "Validation Loss: 673.8714\n",
      "Epoch [2061/3000], Loss: 720.9836\n",
      "Validation Loss: 663.6932\n",
      "Epoch [2081/3000], Loss: 729.9710\n",
      "Validation Loss: 651.3199\n",
      "Epoch [2101/3000], Loss: 704.2310\n",
      "Validation Loss: 654.8188\n",
      "Epoch [2121/3000], Loss: 689.7517\n",
      "Validation Loss: 642.1563\n",
      "Epoch [2141/3000], Loss: 670.3980\n",
      "Validation Loss: 628.1849\n",
      "Epoch [2161/3000], Loss: 658.8643\n",
      "Validation Loss: 617.7506\n",
      "Epoch [2181/3000], Loss: 638.6426\n",
      "Validation Loss: 601.0184\n",
      "Epoch [2201/3000], Loss: 643.1848\n",
      "Validation Loss: 597.2397\n",
      "Epoch [2221/3000], Loss: 617.6931\n",
      "Validation Loss: 581.5701\n",
      "Epoch [2241/3000], Loss: 625.9063\n",
      "Validation Loss: 589.5231\n",
      "Epoch [2261/3000], Loss: 580.3764\n",
      "Validation Loss: 604.9386\n",
      "Epoch [2281/3000], Loss: 579.7284\n",
      "Validation Loss: 610.5357\n",
      "Epoch [2301/3000], Loss: 582.6492\n",
      "Validation Loss: 576.8015\n",
      "Epoch [2321/3000], Loss: 565.6714\n",
      "Validation Loss: 569.6772\n",
      "Epoch [2341/3000], Loss: 549.8490\n",
      "Validation Loss: 553.6753\n",
      "Epoch [2361/3000], Loss: 519.9070\n",
      "Validation Loss: 561.6247\n",
      "Epoch [2381/3000], Loss: 534.5240\n",
      "Validation Loss: 552.6667\n",
      "Epoch [2401/3000], Loss: 503.1318\n",
      "Validation Loss: 544.7031\n",
      "Epoch [2421/3000], Loss: 503.5626\n",
      "Validation Loss: 525.0379\n",
      "Epoch [2441/3000], Loss: 497.6751\n",
      "Validation Loss: 539.9423\n",
      "Epoch [2461/3000], Loss: 474.9577\n",
      "Validation Loss: 559.4027\n",
      "Epoch [2481/3000], Loss: 464.7743\n",
      "Validation Loss: 524.1595\n",
      "Epoch [2501/3000], Loss: 459.1842\n",
      "Validation Loss: 519.8251\n",
      "Epoch [2521/3000], Loss: 460.2606\n",
      "Validation Loss: 503.3590\n",
      "Epoch [2541/3000], Loss: 435.3569\n",
      "Validation Loss: 507.3586\n",
      "Epoch [2561/3000], Loss: 441.2495\n",
      "Validation Loss: 516.8167\n",
      "Epoch [2581/3000], Loss: 419.0261\n",
      "Validation Loss: 495.4511\n",
      "Epoch [2601/3000], Loss: 421.5717\n",
      "Validation Loss: 498.9570\n",
      "Epoch [2621/3000], Loss: 410.4654\n",
      "Validation Loss: 493.9293\n",
      "Epoch [2641/3000], Loss: 398.5652\n",
      "Validation Loss: 500.4998\n",
      "Epoch [2661/3000], Loss: 388.7233\n",
      "Validation Loss: 472.9717\n",
      "Epoch [2681/3000], Loss: 389.4293\n",
      "Validation Loss: 492.2398\n",
      "Epoch [2701/3000], Loss: 372.9774\n",
      "Validation Loss: 488.7099\n",
      "Epoch [2721/3000], Loss: 372.8721\n",
      "Validation Loss: 476.5573\n",
      "Epoch [2741/3000], Loss: 363.0147\n",
      "Validation Loss: 494.4052\n",
      "Epoch [2761/3000], Loss: 360.5522\n",
      "Validation Loss: 467.8325\n",
      "Epoch [2781/3000], Loss: 344.7820\n",
      "Validation Loss: 479.1831\n",
      "Epoch [2801/3000], Loss: 349.2649\n",
      "Validation Loss: 486.1635\n",
      "Epoch [2821/3000], Loss: 336.8984\n",
      "Validation Loss: 480.5396\n",
      "Epoch [2841/3000], Loss: 328.6687\n",
      "Validation Loss: 479.5861\n",
      "Epoch [2861/3000], Loss: 314.9782\n",
      "Validation Loss: 479.6390\n",
      "Epoch [2881/3000], Loss: 314.1831\n",
      "Validation Loss: 477.5234\n",
      "Epoch [2901/3000], Loss: 321.7014\n",
      "Validation Loss: 479.7023\n",
      "Epoch [2921/3000], Loss: 296.9992\n",
      "Validation Loss: 466.5897\n",
      "Epoch [2941/3000], Loss: 295.3142\n",
      "Validation Loss: 490.8284\n",
      "Epoch [2961/3000], Loss: 288.1782\n",
      "Validation Loss: 460.0268\n",
      "Epoch [2981/3000], Loss: 276.9622\n",
      "Validation Loss: 480.2442\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day073_plane0_Fall.mat\n",
      "(6975, 115)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7748.2903\n",
      "Validation Loss: 7043.9390\n",
      "Epoch [21/3000], Loss: 6732.9301\n",
      "Validation Loss: 6091.9826\n",
      "Epoch [41/3000], Loss: 6530.3101\n",
      "Validation Loss: 5896.1178\n",
      "Epoch [61/3000], Loss: 6362.1202\n",
      "Validation Loss: 5754.3353\n",
      "Epoch [81/3000], Loss: 6219.5161\n",
      "Validation Loss: 5622.6576\n",
      "Epoch [101/3000], Loss: 6076.6918\n",
      "Validation Loss: 5502.3936\n",
      "Epoch [121/3000], Loss: 5947.3881\n",
      "Validation Loss: 5388.2701\n",
      "Epoch [141/3000], Loss: 5824.4356\n",
      "Validation Loss: 5277.9512\n",
      "Epoch [161/3000], Loss: 5716.0837\n",
      "Validation Loss: 5173.1522\n",
      "Epoch [181/3000], Loss: 5589.7911\n",
      "Validation Loss: 5072.5714\n",
      "Epoch [201/3000], Loss: 5482.6329\n",
      "Validation Loss: 4975.9107\n",
      "Epoch [221/3000], Loss: 5382.6399\n",
      "Validation Loss: 4882.9823\n",
      "Epoch [241/3000], Loss: 5275.2823\n",
      "Validation Loss: 4793.7313\n",
      "Epoch [261/3000], Loss: 5174.9740\n",
      "Validation Loss: 4708.1838\n",
      "Epoch [281/3000], Loss: 5079.0531\n",
      "Validation Loss: 4626.1652\n",
      "Epoch [301/3000], Loss: 4981.7855\n",
      "Validation Loss: 4547.6319\n",
      "Epoch [321/3000], Loss: 4902.5261\n",
      "Validation Loss: 4472.6700\n",
      "Epoch [341/3000], Loss: 4818.5528\n",
      "Validation Loss: 4401.2886\n",
      "Epoch [361/3000], Loss: 4744.7607\n",
      "Validation Loss: 4333.3254\n",
      "Epoch [381/3000], Loss: 4668.5973\n",
      "Validation Loss: 4268.8249\n",
      "Epoch [401/3000], Loss: 4590.9454\n",
      "Validation Loss: 4207.8833\n",
      "Epoch [421/3000], Loss: 4512.3443\n",
      "Validation Loss: 4150.3642\n",
      "Epoch [441/3000], Loss: 4446.2507\n",
      "Validation Loss: 4096.2408\n",
      "Epoch [461/3000], Loss: 4384.2929\n",
      "Validation Loss: 4045.5406\n",
      "Epoch [481/3000], Loss: 4326.0958\n",
      "Validation Loss: 3998.1763\n",
      "Epoch [501/3000], Loss: 4272.3622\n",
      "Validation Loss: 3954.0894\n",
      "Epoch [521/3000], Loss: 4212.0454\n",
      "Validation Loss: 3913.3318\n",
      "Epoch [541/3000], Loss: 4167.3964\n",
      "Validation Loss: 3875.8063\n",
      "Epoch [561/3000], Loss: 4116.0094\n",
      "Validation Loss: 3841.5994\n",
      "Epoch [581/3000], Loss: 4082.7584\n",
      "Validation Loss: 3810.5425\n",
      "Epoch [601/3000], Loss: 4041.0103\n",
      "Validation Loss: 3782.6311\n",
      "Epoch [621/3000], Loss: 3995.5697\n",
      "Validation Loss: 3757.8646\n",
      "Epoch [641/3000], Loss: 3976.3159\n",
      "Validation Loss: 3736.1331\n",
      "Epoch [661/3000], Loss: 3938.4996\n",
      "Validation Loss: 3717.3260\n",
      "Epoch [681/3000], Loss: 3920.7239\n",
      "Validation Loss: 3701.3972\n",
      "Epoch [701/3000], Loss: 3889.1904\n",
      "Validation Loss: 3688.1971\n",
      "Epoch [721/3000], Loss: 3857.1417\n",
      "Validation Loss: 3677.6868\n",
      "Epoch [741/3000], Loss: 3851.2215\n",
      "Validation Loss: 3669.7156\n",
      "Epoch [761/3000], Loss: 3834.6781\n",
      "Validation Loss: 3664.0552\n",
      "Epoch [781/3000], Loss: 3815.0798\n",
      "Validation Loss: 3660.5300\n",
      "Epoch [801/3000], Loss: 3804.3814\n",
      "Validation Loss: 3658.9164\n",
      "Epoch [821/3000], Loss: 3799.6115\n",
      "Validation Loss: 3658.9466\n",
      "Epoch [841/3000], Loss: 3792.4445\n",
      "Validation Loss: 3660.3018\n",
      "Epoch [861/3000], Loss: 3791.3911\n",
      "Validation Loss: 3662.6167\n",
      "Epoch [881/3000], Loss: 3783.9440\n",
      "Validation Loss: 3665.5121\n",
      "Epoch [901/3000], Loss: 3781.3474\n",
      "Validation Loss: 3668.7067\n",
      "Epoch [921/3000], Loss: 3783.1244\n",
      "Validation Loss: 3671.7535\n",
      "Epoch [941/3000], Loss: 3783.0978\n",
      "Validation Loss: 3674.4197\n",
      "Epoch [961/3000], Loss: 2679.3507\n",
      "Validation Loss: 2378.4460\n",
      "Epoch [981/3000], Loss: 2418.2761\n",
      "Validation Loss: 2251.0471\n",
      "Epoch [1001/3000], Loss: 2282.4979\n",
      "Validation Loss: 2163.0490\n",
      "Epoch [1021/3000], Loss: 2181.5504\n",
      "Validation Loss: 2115.8178\n",
      "Epoch [1041/3000], Loss: 2089.0206\n",
      "Validation Loss: 2069.6233\n",
      "Epoch [1061/3000], Loss: 2005.7824\n",
      "Validation Loss: 2032.6326\n",
      "Epoch [1081/3000], Loss: 1922.8053\n",
      "Validation Loss: 2022.7716\n",
      "Epoch [1101/3000], Loss: 1847.5533\n",
      "Validation Loss: 1932.3302\n",
      "Epoch [1121/3000], Loss: 1772.0995\n",
      "Validation Loss: 1873.2860\n",
      "Epoch [1141/3000], Loss: 1703.0232\n",
      "Validation Loss: 1846.3655\n",
      "Epoch [1161/3000], Loss: 1641.5337\n",
      "Validation Loss: 1809.0860\n",
      "Epoch [1181/3000], Loss: 1590.2010\n",
      "Validation Loss: 1783.4273\n",
      "Epoch [1201/3000], Loss: 1508.4418\n",
      "Validation Loss: 1754.7206\n",
      "Epoch [1221/3000], Loss: 1456.9243\n",
      "Validation Loss: 1803.9475\n",
      "Epoch [1241/3000], Loss: 1382.9526\n",
      "Validation Loss: 1726.3079\n",
      "Epoch [1261/3000], Loss: 1327.9598\n",
      "Validation Loss: 1752.2208\n",
      "Epoch [1281/3000], Loss: 1264.9432\n",
      "Validation Loss: 1749.4813\n",
      "Epoch [1301/3000], Loss: 1208.5233\n",
      "Validation Loss: 1722.3929\n",
      "Epoch [1321/3000], Loss: 1154.0181\n",
      "Validation Loss: 1752.2193\n",
      "Epoch [1341/3000], Loss: 1098.5175\n",
      "Validation Loss: 1668.2685\n",
      "Epoch [1361/3000], Loss: 1059.7550\n",
      "Validation Loss: 1628.2516\n",
      "Epoch [1381/3000], Loss: 1007.9716\n",
      "Validation Loss: 1620.6774\n",
      "Epoch [1401/3000], Loss: 959.5939\n",
      "Validation Loss: 1552.1167\n",
      "Epoch [1421/3000], Loss: 917.7360\n",
      "Validation Loss: 1622.5925\n",
      "Epoch [1441/3000], Loss: 873.7701\n",
      "Validation Loss: 1596.4533\n",
      "Epoch [1461/3000], Loss: 840.7914\n",
      "Validation Loss: 1537.3166\n",
      "Epoch [1481/3000], Loss: 801.6425\n",
      "Validation Loss: 1487.8629\n",
      "Epoch [1501/3000], Loss: 763.0825\n",
      "Validation Loss: 1491.9417\n",
      "Epoch [1521/3000], Loss: 733.2447\n",
      "Validation Loss: 1402.8806\n",
      "Epoch [1541/3000], Loss: 705.4610\n",
      "Validation Loss: 1457.2901\n",
      "Epoch [1561/3000], Loss: 675.3153\n",
      "Validation Loss: 1477.9604\n",
      "Epoch [1581/3000], Loss: 650.1690\n",
      "Validation Loss: 1356.2142\n",
      "Epoch [1601/3000], Loss: 614.7118\n",
      "Validation Loss: 1500.7343\n",
      "Epoch [1621/3000], Loss: 584.6688\n",
      "Validation Loss: 1392.2238\n",
      "Epoch [1641/3000], Loss: 558.7824\n",
      "Validation Loss: 1267.8978\n",
      "Epoch [1661/3000], Loss: 530.1189\n",
      "Validation Loss: 1280.3630\n",
      "Epoch [1681/3000], Loss: 506.4901\n",
      "Validation Loss: 1286.7663\n",
      "Epoch [1701/3000], Loss: 482.2706\n",
      "Validation Loss: 1256.0040\n",
      "Epoch [1721/3000], Loss: 454.0097\n",
      "Validation Loss: 1337.2623\n",
      "Epoch [1741/3000], Loss: 432.4400\n",
      "Validation Loss: 1280.2363\n",
      "Epoch [1761/3000], Loss: 411.5991\n",
      "Validation Loss: 1245.2279\n",
      "Epoch [1781/3000], Loss: 391.7743\n",
      "Validation Loss: 1259.9864\n",
      "Epoch [1801/3000], Loss: 371.4370\n",
      "Validation Loss: 1211.6585\n",
      "Epoch [1821/3000], Loss: 354.0317\n",
      "Validation Loss: 1258.3115\n",
      "Epoch [1841/3000], Loss: 336.4569\n",
      "Validation Loss: 1209.8618\n",
      "Epoch [1861/3000], Loss: 320.7287\n",
      "Validation Loss: 1227.1706\n",
      "Epoch [1881/3000], Loss: 303.6738\n",
      "Validation Loss: 1230.2182\n",
      "Epoch [1901/3000], Loss: 288.0851\n",
      "Validation Loss: 1203.9362\n",
      "Epoch [1921/3000], Loss: 268.1029\n",
      "Validation Loss: 1215.8636\n",
      "Epoch [1941/3000], Loss: 279.2853\n",
      "Validation Loss: 1077.4629\n",
      "Epoch [1961/3000], Loss: 241.0585\n",
      "Validation Loss: 1083.1012\n",
      "Epoch [1981/3000], Loss: 225.2447\n",
      "Validation Loss: 1110.9508\n",
      "Epoch [2001/3000], Loss: 212.6628\n",
      "Validation Loss: 1089.5020\n",
      "Epoch [2021/3000], Loss: 198.9126\n",
      "Validation Loss: 1167.4131\n",
      "Epoch [2041/3000], Loss: 187.6950\n",
      "Validation Loss: 1167.6978\n",
      "Epoch [2061/3000], Loss: 181.6756\n",
      "Validation Loss: 1176.0750\n",
      "Epoch [2081/3000], Loss: 163.5785\n",
      "Validation Loss: 1095.3035\n",
      "Epoch [2101/3000], Loss: 154.8670\n",
      "Validation Loss: 1126.3965\n",
      "Epoch [2121/3000], Loss: 145.1346\n",
      "Validation Loss: 1131.2790\n",
      "Epoch [2141/3000], Loss: 136.3143\n",
      "Validation Loss: 1171.3353\n",
      "Epoch [2161/3000], Loss: 127.1648\n",
      "Validation Loss: 1122.7478\n",
      "Epoch [2181/3000], Loss: 119.8288\n",
      "Validation Loss: 1118.0140\n",
      "Epoch [2201/3000], Loss: 111.4897\n",
      "Validation Loss: 1072.1897\n",
      "Epoch [2221/3000], Loss: 103.9875\n",
      "Validation Loss: 1098.0280\n",
      "Epoch [2241/3000], Loss: 93.7031\n",
      "Validation Loss: 1040.5666\n",
      "Epoch [2261/3000], Loss: 83.9882\n",
      "Validation Loss: 1028.6990\n",
      "Epoch [2281/3000], Loss: 75.1871\n",
      "Validation Loss: 1104.6816\n",
      "Epoch [2301/3000], Loss: 68.5976\n",
      "Validation Loss: 1090.4116\n",
      "Epoch [2321/3000], Loss: 68.7461\n",
      "Validation Loss: 1195.9704\n",
      "Epoch [2341/3000], Loss: 57.6532\n",
      "Validation Loss: 1076.7693\n",
      "Epoch [2361/3000], Loss: 53.0120\n",
      "Validation Loss: 1125.8023\n",
      "Epoch [2381/3000], Loss: 48.0190\n",
      "Validation Loss: 1081.1897\n",
      "Epoch [2401/3000], Loss: 75.7021\n",
      "Validation Loss: 1085.3559\n",
      "Epoch [2421/3000], Loss: 40.0451\n",
      "Validation Loss: 1077.2779\n",
      "Epoch [2441/3000], Loss: 37.0273\n",
      "Validation Loss: 1096.0892\n",
      "Epoch [2461/3000], Loss: 33.8987\n",
      "Validation Loss: 1100.7051\n",
      "Epoch [2481/3000], Loss: 32.2057\n",
      "Validation Loss: 1095.5429\n",
      "Epoch [2501/3000], Loss: 28.1706\n",
      "Validation Loss: 1095.5095\n",
      "Epoch [2521/3000], Loss: 25.5860\n",
      "Validation Loss: 1052.4274\n",
      "Epoch [2541/3000], Loss: 23.6069\n",
      "Validation Loss: 1062.5673\n",
      "Epoch [2561/3000], Loss: 22.3188\n",
      "Validation Loss: 1113.4492\n",
      "Epoch [2581/3000], Loss: 19.8760\n",
      "Validation Loss: 1051.8620\n",
      "Epoch [2601/3000], Loss: 17.9513\n",
      "Validation Loss: 1076.4927\n",
      "Epoch [2621/3000], Loss: 16.6358\n",
      "Validation Loss: 1058.7482\n",
      "Epoch [2641/3000], Loss: 15.1365\n",
      "Validation Loss: 1082.5691\n",
      "Epoch [2661/3000], Loss: 13.0328\n",
      "Validation Loss: 1017.9491\n",
      "Epoch [2681/3000], Loss: 11.7826\n",
      "Validation Loss: 1033.3975\n",
      "Epoch [2701/3000], Loss: 11.2383\n",
      "Validation Loss: 1026.4764\n",
      "Epoch [2721/3000], Loss: 10.2748\n",
      "Validation Loss: 1034.2721\n",
      "Epoch [2741/3000], Loss: 9.7678\n",
      "Validation Loss: 1036.8804\n",
      "Epoch [2761/3000], Loss: 9.1249\n",
      "Validation Loss: 1043.6484\n",
      "Epoch [2781/3000], Loss: 8.4351\n",
      "Validation Loss: 1059.2732\n",
      "Epoch [2801/3000], Loss: 7.9410\n",
      "Validation Loss: 1067.6028\n",
      "Epoch [2821/3000], Loss: 7.3490\n",
      "Validation Loss: 1049.7157\n",
      "Epoch [2841/3000], Loss: 6.9155\n",
      "Validation Loss: 1056.7207\n",
      "Epoch [2861/3000], Loss: 6.4214\n",
      "Validation Loss: 1064.0152\n",
      "Epoch [2881/3000], Loss: 6.1256\n",
      "Validation Loss: 1060.6235\n",
      "Epoch [2901/3000], Loss: 5.8953\n",
      "Validation Loss: 1063.1368\n",
      "Epoch [2921/3000], Loss: 5.5354\n",
      "Validation Loss: 1060.1289\n",
      "Epoch [2941/3000], Loss: 5.3168\n",
      "Validation Loss: 1053.0290\n",
      "Epoch [2961/3000], Loss: 5.0100\n",
      "Validation Loss: 1066.6917\n",
      "Epoch [2981/3000], Loss: 4.8774\n",
      "Validation Loss: 1053.4915\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day074_plane0_Fall.mat\n",
      "(9517, 125)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9226.8867\n",
      "Validation Loss: 8274.3119\n",
      "Epoch [21/3000], Loss: 7905.4454\n",
      "Validation Loss: 7082.6323\n",
      "Epoch [41/3000], Loss: 7639.4302\n",
      "Validation Loss: 6844.0461\n",
      "Epoch [61/3000], Loss: 7413.4546\n",
      "Validation Loss: 6645.4449\n",
      "Epoch [81/3000], Loss: 7200.2077\n",
      "Validation Loss: 6460.6157\n",
      "Epoch [101/3000], Loss: 7008.4013\n",
      "Validation Loss: 6285.9152\n",
      "Epoch [121/3000], Loss: 6813.1355\n",
      "Validation Loss: 6122.1109\n",
      "Epoch [141/3000], Loss: 6635.2997\n",
      "Validation Loss: 5965.8932\n",
      "Epoch [161/3000], Loss: 6466.9894\n",
      "Validation Loss: 5816.5908\n",
      "Epoch [181/3000], Loss: 6302.7442\n",
      "Validation Loss: 5674.2282\n",
      "Epoch [201/3000], Loss: 6133.9423\n",
      "Validation Loss: 5537.5587\n",
      "Epoch [221/3000], Loss: 5992.4670\n",
      "Validation Loss: 5407.0573\n",
      "Epoch [241/3000], Loss: 5840.9197\n",
      "Validation Loss: 5282.3496\n",
      "Epoch [261/3000], Loss: 5699.3449\n",
      "Validation Loss: 5165.1981\n",
      "Epoch [281/3000], Loss: 5566.7606\n",
      "Validation Loss: 5054.6441\n",
      "Epoch [301/3000], Loss: 5440.6657\n",
      "Validation Loss: 4950.6267\n",
      "Epoch [321/3000], Loss: 5323.3962\n",
      "Validation Loss: 4853.1196\n",
      "Epoch [341/3000], Loss: 5206.8002\n",
      "Validation Loss: 4760.9974\n",
      "Epoch [361/3000], Loss: 5094.9558\n",
      "Validation Loss: 4675.6121\n",
      "Epoch [381/3000], Loss: 4998.1761\n",
      "Validation Loss: 4596.8852\n",
      "Epoch [401/3000], Loss: 4896.1639\n",
      "Validation Loss: 4523.4354\n",
      "Epoch [421/3000], Loss: 4813.2601\n",
      "Validation Loss: 4457.1848\n",
      "Epoch [441/3000], Loss: 4732.5884\n",
      "Validation Loss: 4397.3466\n",
      "Epoch [461/3000], Loss: 4660.5260\n",
      "Validation Loss: 4343.6393\n",
      "Epoch [481/3000], Loss: 4591.1958\n",
      "Validation Loss: 4296.0055\n",
      "Epoch [501/3000], Loss: 4527.3258\n",
      "Validation Loss: 4254.3765\n",
      "Epoch [521/3000], Loss: 4469.2849\n",
      "Validation Loss: 4217.8096\n",
      "Epoch [541/3000], Loss: 4414.4591\n",
      "Validation Loss: 4187.7673\n",
      "Epoch [561/3000], Loss: 4368.9829\n",
      "Validation Loss: 4163.3451\n",
      "Epoch [581/3000], Loss: 4331.8804\n",
      "Validation Loss: 4144.2640\n",
      "Epoch [601/3000], Loss: 4300.1834\n",
      "Validation Loss: 4130.2905\n",
      "Epoch [621/3000], Loss: 4269.2769\n",
      "Validation Loss: 4121.1276\n",
      "Epoch [641/3000], Loss: 3506.9572\n",
      "Validation Loss: 3185.6555\n",
      "Epoch [661/3000], Loss: 3130.0364\n",
      "Validation Loss: 2882.7955\n",
      "Epoch [681/3000], Loss: 2932.5395\n",
      "Validation Loss: 2752.0779\n",
      "Epoch [701/3000], Loss: 2786.3974\n",
      "Validation Loss: 2666.3507\n",
      "Epoch [721/3000], Loss: 2679.6872\n",
      "Validation Loss: 2587.3251\n",
      "Epoch [741/3000], Loss: 2522.8176\n",
      "Validation Loss: 2527.0970\n",
      "Epoch [761/3000], Loss: 2422.3292\n",
      "Validation Loss: 2458.2165\n",
      "Epoch [781/3000], Loss: 2310.2550\n",
      "Validation Loss: 2394.9529\n",
      "Epoch [801/3000], Loss: 2204.2641\n",
      "Validation Loss: 2344.8266\n",
      "Epoch [821/3000], Loss: 2105.5367\n",
      "Validation Loss: 2291.8182\n",
      "Epoch [841/3000], Loss: 2002.8871\n",
      "Validation Loss: 2243.3731\n",
      "Epoch [861/3000], Loss: 1904.7753\n",
      "Validation Loss: 2212.7357\n",
      "Epoch [881/3000], Loss: 1803.3034\n",
      "Validation Loss: 2287.8542\n",
      "Epoch [901/3000], Loss: 1719.0295\n",
      "Validation Loss: 2252.7636\n",
      "Epoch [921/3000], Loss: 1627.2179\n",
      "Validation Loss: 2296.9387\n",
      "Epoch [941/3000], Loss: 1543.6161\n",
      "Validation Loss: 2255.2324\n",
      "Epoch [961/3000], Loss: 1446.8284\n",
      "Validation Loss: 2258.6665\n",
      "Epoch [981/3000], Loss: 1363.0660\n",
      "Validation Loss: 2284.2048\n",
      "Epoch [1001/3000], Loss: 1285.4589\n",
      "Validation Loss: 2214.6281\n",
      "Epoch [1021/3000], Loss: 1214.5023\n",
      "Validation Loss: 2210.5766\n",
      "Epoch [1041/3000], Loss: 1143.4726\n",
      "Validation Loss: 2142.4592\n",
      "Epoch [1061/3000], Loss: 1081.8490\n",
      "Validation Loss: 2167.8559\n",
      "Epoch [1081/3000], Loss: 1001.9123\n",
      "Validation Loss: 2085.4364\n",
      "Epoch [1101/3000], Loss: 938.0219\n",
      "Validation Loss: 2062.5667\n",
      "Epoch [1121/3000], Loss: 880.0240\n",
      "Validation Loss: 2113.8650\n",
      "Epoch [1141/3000], Loss: 821.9040\n",
      "Validation Loss: 1965.4700\n",
      "Epoch [1161/3000], Loss: 780.6656\n",
      "Validation Loss: 1950.8110\n",
      "Epoch [1181/3000], Loss: 726.8258\n",
      "Validation Loss: 1912.2343\n",
      "Epoch [1201/3000], Loss: 674.5654\n",
      "Validation Loss: 1873.3584\n",
      "Epoch [1221/3000], Loss: 632.9752\n",
      "Validation Loss: 1860.3994\n",
      "Epoch [1241/3000], Loss: 596.0057\n",
      "Validation Loss: 1813.3597\n",
      "Epoch [1261/3000], Loss: 561.3643\n",
      "Validation Loss: 1828.2744\n",
      "Epoch [1281/3000], Loss: 528.1070\n",
      "Validation Loss: 1873.6703\n",
      "Epoch [1301/3000], Loss: 504.0705\n",
      "Validation Loss: 1835.0080\n",
      "Epoch [1321/3000], Loss: 469.6278\n",
      "Validation Loss: 1835.6932\n",
      "Epoch [1341/3000], Loss: 445.0118\n",
      "Validation Loss: 1845.0752\n",
      "Epoch [1361/3000], Loss: 441.6342\n",
      "Validation Loss: 1871.5218\n",
      "Epoch [1381/3000], Loss: 393.2703\n",
      "Validation Loss: 1874.7998\n",
      "Epoch [1401/3000], Loss: 374.2942\n",
      "Validation Loss: 1885.9766\n",
      "Epoch [1421/3000], Loss: 359.2370\n",
      "Validation Loss: 1871.3792\n",
      "Epoch [1441/3000], Loss: 347.5472\n",
      "Validation Loss: 1889.1842\n",
      "Epoch [1461/3000], Loss: 313.1900\n",
      "Validation Loss: 1844.0727\n",
      "Epoch [1481/3000], Loss: 295.1555\n",
      "Validation Loss: 1900.8387\n",
      "Epoch [1501/3000], Loss: 277.1262\n",
      "Validation Loss: 1939.3609\n",
      "Epoch [1521/3000], Loss: 244.6453\n",
      "Validation Loss: 1902.1887\n",
      "Epoch [1541/3000], Loss: 218.6144\n",
      "Validation Loss: 1962.4369\n",
      "Epoch [1561/3000], Loss: 199.5206\n",
      "Validation Loss: 1949.5062\n",
      "Epoch [1581/3000], Loss: 185.0496\n",
      "Validation Loss: 1908.3784\n",
      "Epoch [1601/3000], Loss: 169.4082\n",
      "Validation Loss: 1924.6283\n",
      "Epoch [1621/3000], Loss: 156.3036\n",
      "Validation Loss: 1912.2505\n",
      "Epoch [1641/3000], Loss: 145.4359\n",
      "Validation Loss: 1863.8625\n",
      "Epoch [1661/3000], Loss: 130.6086\n",
      "Validation Loss: 1914.5126\n",
      "Epoch [1681/3000], Loss: 123.6451\n",
      "Validation Loss: 1883.7521\n",
      "Epoch [1701/3000], Loss: 115.9891\n",
      "Validation Loss: 1799.5244\n",
      "Epoch [1721/3000], Loss: 111.2739\n",
      "Validation Loss: 1785.1996\n",
      "Epoch [1741/3000], Loss: 97.8413\n",
      "Validation Loss: 1782.4392\n",
      "Epoch [1761/3000], Loss: 93.3725\n",
      "Validation Loss: 1807.5268\n",
      "Epoch [1781/3000], Loss: 81.0321\n",
      "Validation Loss: 1824.2961\n",
      "Epoch [1801/3000], Loss: 72.7164\n",
      "Validation Loss: 1798.7743\n",
      "Epoch [1821/3000], Loss: 68.7475\n",
      "Validation Loss: 1751.2148\n",
      "Epoch [1841/3000], Loss: 63.8496\n",
      "Validation Loss: 1717.4037\n",
      "Epoch [1861/3000], Loss: 55.4390\n",
      "Validation Loss: 1716.5627\n",
      "Epoch [1881/3000], Loss: 52.0382\n",
      "Validation Loss: 1666.6475\n",
      "Epoch [1901/3000], Loss: 48.5866\n",
      "Validation Loss: 1653.8236\n",
      "Epoch [1921/3000], Loss: 63.6478\n",
      "Validation Loss: 1653.9414\n",
      "Epoch [1941/3000], Loss: 40.3106\n",
      "Validation Loss: 1659.7210\n",
      "Epoch [1961/3000], Loss: 79.5990\n",
      "Validation Loss: 1621.1858\n",
      "Epoch [1981/3000], Loss: 34.8780\n",
      "Validation Loss: 1604.7257\n",
      "Epoch [2001/3000], Loss: 32.7230\n",
      "Validation Loss: 1633.7756\n",
      "Epoch [2021/3000], Loss: 30.9968\n",
      "Validation Loss: 1621.7204\n",
      "Epoch [2041/3000], Loss: 28.6212\n",
      "Validation Loss: 1621.0785\n",
      "Epoch [2061/3000], Loss: 28.0599\n",
      "Validation Loss: 1641.1651\n",
      "Epoch [2081/3000], Loss: 25.4048\n",
      "Validation Loss: 1606.6584\n",
      "Epoch [2101/3000], Loss: 24.4135\n",
      "Validation Loss: 1633.4623\n",
      "Epoch [2121/3000], Loss: 23.0581\n",
      "Validation Loss: 1626.3865\n",
      "Epoch [2141/3000], Loss: 23.6015\n",
      "Validation Loss: 1669.1724\n",
      "Epoch [2161/3000], Loss: 20.4995\n",
      "Validation Loss: 1662.2964\n",
      "Epoch [2181/3000], Loss: 18.6352\n",
      "Validation Loss: 1603.8318\n",
      "Epoch [2201/3000], Loss: 17.9590\n",
      "Validation Loss: 1610.1597\n",
      "Epoch [2221/3000], Loss: 17.6268\n",
      "Validation Loss: 1624.9636\n",
      "Epoch [2241/3000], Loss: 16.7749\n",
      "Validation Loss: 1606.2014\n",
      "Epoch [2261/3000], Loss: 15.4244\n",
      "Validation Loss: 1609.2225\n",
      "Epoch [2281/3000], Loss: 15.0448\n",
      "Validation Loss: 1613.0993\n",
      "Epoch [2301/3000], Loss: 14.0906\n",
      "Validation Loss: 1628.9240\n",
      "Epoch [2321/3000], Loss: 13.7231\n",
      "Validation Loss: 1636.7715\n",
      "Epoch [2341/3000], Loss: 13.8754\n",
      "Validation Loss: 1589.2891\n",
      "Epoch [2361/3000], Loss: 12.1231\n",
      "Validation Loss: 1605.3924\n",
      "Epoch [2381/3000], Loss: 11.8499\n",
      "Validation Loss: 1606.0835\n",
      "Epoch [2401/3000], Loss: 11.0719\n",
      "Validation Loss: 1609.0035\n",
      "Epoch [2421/3000], Loss: 10.8843\n",
      "Validation Loss: 1622.0891\n",
      "Epoch [2441/3000], Loss: 10.3408\n",
      "Validation Loss: 1617.8276\n",
      "Epoch [2461/3000], Loss: 10.1520\n",
      "Validation Loss: 1580.6935\n",
      "Epoch [2481/3000], Loss: 9.1903\n",
      "Validation Loss: 1589.8373\n",
      "Epoch [2501/3000], Loss: 8.9220\n",
      "Validation Loss: 1602.4386\n",
      "Epoch [2521/3000], Loss: 9.1689\n",
      "Validation Loss: 1607.3675\n",
      "Epoch [2541/3000], Loss: 8.6053\n",
      "Validation Loss: 1606.6783\n",
      "Epoch [2561/3000], Loss: 8.0719\n",
      "Validation Loss: 1620.1680\n",
      "Epoch [2581/3000], Loss: 7.5464\n",
      "Validation Loss: 1570.3594\n",
      "Epoch [2601/3000], Loss: 7.2439\n",
      "Validation Loss: 1583.0743\n",
      "Epoch [2621/3000], Loss: 7.2079\n",
      "Validation Loss: 1586.5332\n",
      "Epoch [2641/3000], Loss: 6.9019\n",
      "Validation Loss: 1582.7799\n",
      "Epoch [2661/3000], Loss: 6.7650\n",
      "Validation Loss: 1589.0084\n",
      "Epoch [2681/3000], Loss: 6.6101\n",
      "Validation Loss: 1609.0393\n",
      "Epoch [2701/3000], Loss: 6.1493\n",
      "Validation Loss: 1587.1593\n",
      "Epoch [2721/3000], Loss: 6.1160\n",
      "Validation Loss: 1551.9780\n",
      "Epoch [2741/3000], Loss: 5.5108\n",
      "Validation Loss: 1568.8367\n",
      "Epoch [2761/3000], Loss: 5.3617\n",
      "Validation Loss: 1567.9282\n",
      "Epoch [2781/3000], Loss: 5.1297\n",
      "Validation Loss: 1575.1965\n",
      "Epoch [2801/3000], Loss: 5.1880\n",
      "Validation Loss: 1534.9662\n",
      "Epoch [2821/3000], Loss: 4.8744\n",
      "Validation Loss: 1544.3897\n",
      "Epoch [2841/3000], Loss: 4.8298\n",
      "Validation Loss: 1548.9057\n",
      "Epoch [2861/3000], Loss: 4.8800\n",
      "Validation Loss: 1540.0625\n",
      "Epoch [2881/3000], Loss: 4.8177\n",
      "Validation Loss: 1557.9803\n",
      "Epoch [2901/3000], Loss: 4.7404\n",
      "Validation Loss: 1556.1358\n",
      "Epoch [2921/3000], Loss: 16.6131\n",
      "Validation Loss: 1553.1480\n",
      "Epoch [2941/3000], Loss: 4.0762\n",
      "Validation Loss: 1516.2608\n",
      "Epoch [2961/3000], Loss: 3.8965\n",
      "Validation Loss: 1524.8174\n",
      "Epoch [2981/3000], Loss: 3.9420\n",
      "Validation Loss: 1528.9692\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day076_plane0_Fall.mat\n",
      "(14701, 102)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9772.4364\n",
      "Validation Loss: 8637.7989\n",
      "Epoch [21/3000], Loss: 8250.7150\n",
      "Validation Loss: 7263.0627\n",
      "Epoch [41/3000], Loss: 7884.1780\n",
      "Validation Loss: 6925.5173\n",
      "Epoch [61/3000], Loss: 7547.9200\n",
      "Validation Loss: 6633.7054\n",
      "Epoch [81/3000], Loss: 7227.0623\n",
      "Validation Loss: 6364.4683\n",
      "Epoch [101/3000], Loss: 6957.3653\n",
      "Validation Loss: 6113.4512\n",
      "Epoch [121/3000], Loss: 6687.3893\n",
      "Validation Loss: 5879.4707\n",
      "Epoch [141/3000], Loss: 6432.5872\n",
      "Validation Loss: 5661.6352\n",
      "Epoch [161/3000], Loss: 6184.0398\n",
      "Validation Loss: 5460.0185\n",
      "Epoch [181/3000], Loss: 5974.7280\n",
      "Validation Loss: 5274.1585\n",
      "Epoch [201/3000], Loss: 5766.1977\n",
      "Validation Loss: 5104.0444\n",
      "Epoch [221/3000], Loss: 5582.9066\n",
      "Validation Loss: 4949.6615\n",
      "Epoch [241/3000], Loss: 5409.0667\n",
      "Validation Loss: 4810.9131\n",
      "Epoch [261/3000], Loss: 5250.9379\n",
      "Validation Loss: 4687.3794\n",
      "Epoch [281/3000], Loss: 5108.0172\n",
      "Validation Loss: 4579.1549\n",
      "Epoch [301/3000], Loss: 4975.7677\n",
      "Validation Loss: 4485.8807\n",
      "Epoch [321/3000], Loss: 4862.6616\n",
      "Validation Loss: 4407.2995\n",
      "Epoch [341/3000], Loss: 4771.3279\n",
      "Validation Loss: 4343.0295\n",
      "Epoch [361/3000], Loss: 4688.4250\n",
      "Validation Loss: 4292.6242\n",
      "Epoch [381/3000], Loss: 4615.1687\n",
      "Validation Loss: 4255.5932\n",
      "Epoch [401/3000], Loss: 4563.8917\n",
      "Validation Loss: 4231.0677\n",
      "Epoch [421/3000], Loss: 4521.4186\n",
      "Validation Loss: 4217.8591\n",
      "Epoch [441/3000], Loss: 4476.3723\n",
      "Validation Loss: 4194.5830\n",
      "Epoch [461/3000], Loss: 3004.5304\n",
      "Validation Loss: 3001.6175\n",
      "Epoch [481/3000], Loss: 2763.0658\n",
      "Validation Loss: 3222.1387\n",
      "Epoch [501/3000], Loss: 2575.7845\n",
      "Validation Loss: 3123.3328\n",
      "Epoch [521/3000], Loss: 2413.0249\n",
      "Validation Loss: 3217.9631\n",
      "Epoch [541/3000], Loss: 2251.9541\n",
      "Validation Loss: 2993.0539\n",
      "Epoch [561/3000], Loss: 2105.9431\n",
      "Validation Loss: 3105.0452\n",
      "Epoch [581/3000], Loss: 1943.8747\n",
      "Validation Loss: 3118.1499\n",
      "Epoch [601/3000], Loss: 1795.8328\n",
      "Validation Loss: 3123.2515\n",
      "Epoch [621/3000], Loss: 1660.5986\n",
      "Validation Loss: 2918.3425\n",
      "Epoch [641/3000], Loss: 1537.8032\n",
      "Validation Loss: 3163.2535\n",
      "Epoch [661/3000], Loss: 1418.1058\n",
      "Validation Loss: 3029.8423\n",
      "Epoch [681/3000], Loss: 1303.7013\n",
      "Validation Loss: 2982.1833\n",
      "Epoch [701/3000], Loss: 1191.9909\n",
      "Validation Loss: 2785.6868\n",
      "Epoch [721/3000], Loss: 1095.9948\n",
      "Validation Loss: 2679.5119\n",
      "Epoch [741/3000], Loss: 999.0529\n",
      "Validation Loss: 2942.1373\n",
      "Epoch [761/3000], Loss: 920.3111\n",
      "Validation Loss: 2865.5934\n",
      "Epoch [781/3000], Loss: 835.3999\n",
      "Validation Loss: 2992.8251\n",
      "Epoch [801/3000], Loss: 768.5717\n",
      "Validation Loss: 2970.3512\n",
      "Epoch [821/3000], Loss: 702.3853\n",
      "Validation Loss: 3111.0143\n",
      "Epoch [841/3000], Loss: 627.2445\n",
      "Validation Loss: 2800.9255\n",
      "Epoch [861/3000], Loss: 586.5201\n",
      "Validation Loss: 2615.0778\n",
      "Epoch [881/3000], Loss: 527.6620\n",
      "Validation Loss: 2931.8474\n",
      "Epoch [901/3000], Loss: 485.9402\n",
      "Validation Loss: 2959.3248\n",
      "Epoch [921/3000], Loss: 451.4787\n",
      "Validation Loss: 2886.5111\n",
      "Epoch [941/3000], Loss: 424.6070\n",
      "Validation Loss: 2907.9633\n",
      "Epoch [961/3000], Loss: 399.9818\n",
      "Validation Loss: 2886.0298\n",
      "Epoch [981/3000], Loss: 341.8111\n",
      "Validation Loss: 2915.2894\n",
      "Epoch [1001/3000], Loss: 340.8623\n",
      "Validation Loss: 2864.7036\n",
      "Epoch [1021/3000], Loss: 288.3357\n",
      "Validation Loss: 2927.4484\n",
      "Epoch [1041/3000], Loss: 263.2854\n",
      "Validation Loss: 2822.9156\n",
      "Epoch [1061/3000], Loss: 233.3857\n",
      "Validation Loss: 2771.1610\n",
      "Epoch [1081/3000], Loss: 211.4655\n",
      "Validation Loss: 2876.9825\n",
      "Epoch [1101/3000], Loss: 193.5351\n",
      "Validation Loss: 2707.3916\n",
      "Epoch [1121/3000], Loss: 181.4055\n",
      "Validation Loss: 2821.4219\n",
      "Epoch [1141/3000], Loss: 162.3502\n",
      "Validation Loss: 2737.6069\n",
      "Epoch [1161/3000], Loss: 150.4611\n",
      "Validation Loss: 2751.1889\n",
      "Epoch [1181/3000], Loss: 137.0099\n",
      "Validation Loss: 2715.9072\n",
      "Epoch [1201/3000], Loss: 123.3678\n",
      "Validation Loss: 2730.0090\n",
      "Epoch [1221/3000], Loss: 111.8851\n",
      "Validation Loss: 2682.4489\n",
      "Epoch [1241/3000], Loss: 111.9625\n",
      "Validation Loss: 2643.3399\n",
      "Epoch [1261/3000], Loss: 101.6337\n",
      "Validation Loss: 2646.8580\n",
      "Epoch [1281/3000], Loss: 89.0079\n",
      "Validation Loss: 2662.3120\n",
      "Epoch [1301/3000], Loss: 81.5107\n",
      "Validation Loss: 2649.5263\n",
      "Epoch [1321/3000], Loss: 77.1779\n",
      "Validation Loss: 2638.2578\n",
      "Epoch [1341/3000], Loss: 72.7195\n",
      "Validation Loss: 2619.9703\n",
      "Epoch [1361/3000], Loss: 69.7062\n",
      "Validation Loss: 2644.0691\n",
      "Epoch [1381/3000], Loss: 64.6524\n",
      "Validation Loss: 2606.4518\n",
      "Epoch [1401/3000], Loss: 60.2704\n",
      "Validation Loss: 2643.9472\n",
      "Epoch [1421/3000], Loss: 55.6659\n",
      "Validation Loss: 2653.1651\n",
      "Epoch [1441/3000], Loss: 52.3617\n",
      "Validation Loss: 2657.6853\n",
      "Epoch [1461/3000], Loss: 50.4376\n",
      "Validation Loss: 2722.7670\n",
      "Epoch [1481/3000], Loss: 46.1312\n",
      "Validation Loss: 2690.5969\n",
      "Epoch [1501/3000], Loss: 41.9792\n",
      "Validation Loss: 2677.2011\n",
      "Epoch [1521/3000], Loss: 39.0465\n",
      "Validation Loss: 2697.7871\n",
      "Epoch [1541/3000], Loss: 39.0964\n",
      "Validation Loss: 2640.9135\n",
      "Epoch [1561/3000], Loss: 34.7852\n",
      "Validation Loss: 2654.9725\n",
      "Epoch [1581/3000], Loss: 50.7787\n",
      "Validation Loss: 2675.7038\n",
      "Epoch [1601/3000], Loss: 31.0825\n",
      "Validation Loss: 2633.9921\n",
      "Epoch [1621/3000], Loss: 28.3630\n",
      "Validation Loss: 2654.6273\n",
      "Epoch [1641/3000], Loss: 27.2346\n",
      "Validation Loss: 2654.5909\n",
      "Epoch [1661/3000], Loss: 25.9188\n",
      "Validation Loss: 2652.4009\n",
      "Epoch [1681/3000], Loss: 23.2597\n",
      "Validation Loss: 2635.5746\n",
      "Epoch [1701/3000], Loss: 22.1507\n",
      "Validation Loss: 2640.6748\n",
      "Epoch [1721/3000], Loss: 23.2178\n",
      "Validation Loss: 2586.7629\n",
      "Epoch [1741/3000], Loss: 19.2893\n",
      "Validation Loss: 2606.2404\n",
      "Epoch [1761/3000], Loss: 18.6392\n",
      "Validation Loss: 2579.6063\n",
      "Epoch [1781/3000], Loss: 17.0190\n",
      "Validation Loss: 2560.0972\n",
      "Epoch [1801/3000], Loss: 16.1565\n",
      "Validation Loss: 2573.3474\n",
      "Epoch [1821/3000], Loss: 15.8720\n",
      "Validation Loss: 2576.4133\n",
      "Epoch [1841/3000], Loss: 14.1415\n",
      "Validation Loss: 2533.5548\n",
      "Epoch [1861/3000], Loss: 13.2626\n",
      "Validation Loss: 2536.6093\n",
      "Epoch [1881/3000], Loss: 12.7021\n",
      "Validation Loss: 2538.4198\n",
      "Epoch [1901/3000], Loss: 11.9245\n",
      "Validation Loss: 2526.5932\n",
      "Epoch [1921/3000], Loss: 11.4181\n",
      "Validation Loss: 2490.2138\n",
      "Epoch [1941/3000], Loss: 10.3518\n",
      "Validation Loss: 2504.3962\n",
      "Epoch [1961/3000], Loss: 10.2105\n",
      "Validation Loss: 2478.6542\n",
      "Epoch [1981/3000], Loss: 13.5477\n",
      "Validation Loss: 2506.7350\n",
      "Epoch [2001/3000], Loss: 8.9954\n",
      "Validation Loss: 2464.5713\n",
      "Epoch [2021/3000], Loss: 8.9328\n",
      "Validation Loss: 2481.8918\n",
      "Epoch [2041/3000], Loss: 8.1100\n",
      "Validation Loss: 2447.7554\n",
      "Epoch [2061/3000], Loss: 9.0910\n",
      "Validation Loss: 2413.6252\n",
      "Epoch [2081/3000], Loss: 7.5729\n",
      "Validation Loss: 2427.1670\n",
      "Epoch [2101/3000], Loss: 7.4010\n",
      "Validation Loss: 2377.7656\n",
      "Epoch [2121/3000], Loss: 9.2301\n",
      "Validation Loss: 2436.3137\n",
      "Epoch [2141/3000], Loss: 6.6683\n",
      "Validation Loss: 2428.9727\n",
      "Epoch [2161/3000], Loss: 6.8284\n",
      "Validation Loss: 2430.9779\n",
      "Epoch [2181/3000], Loss: 7.4746\n",
      "Validation Loss: 2469.2699\n",
      "Epoch [2201/3000], Loss: 5.9339\n",
      "Validation Loss: 2392.5104\n",
      "Epoch [2221/3000], Loss: 6.3929\n",
      "Validation Loss: 2394.1946\n",
      "Epoch [2241/3000], Loss: 5.7472\n",
      "Validation Loss: 2411.2504\n",
      "Epoch [2261/3000], Loss: 5.0640\n",
      "Validation Loss: 2385.6841\n",
      "Epoch [2281/3000], Loss: 5.0151\n",
      "Validation Loss: 2403.3560\n",
      "Epoch [2301/3000], Loss: 4.9765\n",
      "Validation Loss: 2418.8555\n",
      "Epoch [2321/3000], Loss: 5.2630\n",
      "Validation Loss: 2405.1383\n",
      "Epoch [2341/3000], Loss: 4.4072\n",
      "Validation Loss: 2378.9831\n",
      "Epoch [2361/3000], Loss: 4.5646\n",
      "Validation Loss: 2375.0791\n",
      "Epoch [2381/3000], Loss: 4.3955\n",
      "Validation Loss: 2384.1642\n",
      "Epoch [2401/3000], Loss: 4.2520\n",
      "Validation Loss: 2383.8850\n",
      "Epoch [2421/3000], Loss: 3.8225\n",
      "Validation Loss: 2369.6234\n",
      "Epoch [2441/3000], Loss: 3.8271\n",
      "Validation Loss: 2386.8316\n",
      "Epoch [2461/3000], Loss: 4.0295\n",
      "Validation Loss: 2373.8393\n",
      "Epoch [2481/3000], Loss: 3.4983\n",
      "Validation Loss: 2392.4719\n",
      "Epoch [2501/3000], Loss: 3.3902\n",
      "Validation Loss: 2394.6658\n",
      "Epoch [2521/3000], Loss: 3.4432\n",
      "Validation Loss: 2400.2002\n",
      "Epoch [2541/3000], Loss: 32.5165\n",
      "Validation Loss: 2541.4476\n",
      "Epoch [2561/3000], Loss: 3.0913\n",
      "Validation Loss: 2375.4176\n",
      "Epoch [2581/3000], Loss: 3.0220\n",
      "Validation Loss: 2380.4262\n",
      "Epoch [2601/3000], Loss: 3.0540\n",
      "Validation Loss: 2397.3974\n",
      "Epoch [2621/3000], Loss: 2.9923\n",
      "Validation Loss: 2378.4666\n",
      "Epoch [2641/3000], Loss: 2.9130\n",
      "Validation Loss: 2378.6122\n",
      "Epoch [2661/3000], Loss: 2.7261\n",
      "Validation Loss: 2373.3717\n",
      "Epoch [2681/3000], Loss: 2.5079\n",
      "Validation Loss: 2380.3264\n",
      "Epoch [2701/3000], Loss: 2.5460\n",
      "Validation Loss: 2389.6764\n",
      "Epoch [2721/3000], Loss: 128.9029\n",
      "Validation Loss: 2456.8177\n",
      "Epoch [2741/3000], Loss: 2.3256\n",
      "Validation Loss: 2352.7498\n",
      "Epoch [2761/3000], Loss: 2.3072\n",
      "Validation Loss: 2358.6410\n",
      "Epoch [2781/3000], Loss: 2.2938\n",
      "Validation Loss: 2358.5176\n",
      "Epoch [2801/3000], Loss: 2.6399\n",
      "Validation Loss: 2372.5754\n",
      "Epoch [2821/3000], Loss: 2.2305\n",
      "Validation Loss: 2341.1793\n",
      "Epoch [2841/3000], Loss: 2.4310\n",
      "Validation Loss: 2364.1175\n",
      "Epoch [2861/3000], Loss: 2.1873\n",
      "Validation Loss: 2367.0442\n",
      "Epoch [2881/3000], Loss: 2.7628\n",
      "Validation Loss: 2346.3246\n",
      "Epoch [2901/3000], Loss: 3.3430\n",
      "Validation Loss: 2380.7566\n",
      "Epoch [2921/3000], Loss: 1.7860\n",
      "Validation Loss: 2368.2820\n",
      "Epoch [2941/3000], Loss: 1.7139\n",
      "Validation Loss: 2360.0672\n",
      "Epoch [2961/3000], Loss: 1.7568\n",
      "Validation Loss: 2402.1540\n",
      "Epoch [2981/3000], Loss: 1.8948\n",
      "Validation Loss: 2358.9791\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day081_plane0_Fall.mat\n",
      "(5200, 99)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7156.3677\n",
      "Validation Loss: 7634.1764\n",
      "Epoch [21/3000], Loss: 6232.4756\n",
      "Validation Loss: 6700.5453\n",
      "Epoch [41/3000], Loss: 6019.2202\n",
      "Validation Loss: 6494.4872\n",
      "Epoch [61/3000], Loss: 5909.6483\n",
      "Validation Loss: 6372.1663\n",
      "Epoch [81/3000], Loss: 5774.6280\n",
      "Validation Loss: 6265.5544\n",
      "Epoch [101/3000], Loss: 5699.5885\n",
      "Validation Loss: 6167.4019\n",
      "Epoch [121/3000], Loss: 5595.6351\n",
      "Validation Loss: 6074.2942\n",
      "Epoch [141/3000], Loss: 5528.9538\n",
      "Validation Loss: 5981.3201\n",
      "Epoch [161/3000], Loss: 5434.9375\n",
      "Validation Loss: 5894.2307\n",
      "Epoch [181/3000], Loss: 5334.0048\n",
      "Validation Loss: 5810.2599\n",
      "Epoch [201/3000], Loss: 5262.2591\n",
      "Validation Loss: 5728.8986\n",
      "Epoch [221/3000], Loss: 5163.5610\n",
      "Validation Loss: 5649.9854\n",
      "Epoch [241/3000], Loss: 5136.3509\n",
      "Validation Loss: 5573.1445\n",
      "Epoch [261/3000], Loss: 5034.1826\n",
      "Validation Loss: 5498.6108\n",
      "Epoch [281/3000], Loss: 4972.6813\n",
      "Validation Loss: 5426.0567\n",
      "Epoch [301/3000], Loss: 4904.0279\n",
      "Validation Loss: 5355.5409\n",
      "Epoch [321/3000], Loss: 4827.5648\n",
      "Validation Loss: 5285.6751\n",
      "Epoch [341/3000], Loss: 4782.4721\n",
      "Validation Loss: 5218.6761\n",
      "Epoch [361/3000], Loss: 4719.5630\n",
      "Validation Loss: 5153.7628\n",
      "Epoch [381/3000], Loss: 4656.1339\n",
      "Validation Loss: 5090.9500\n",
      "Epoch [401/3000], Loss: 4600.9735\n",
      "Validation Loss: 5030.0924\n",
      "Epoch [421/3000], Loss: 4530.4020\n",
      "Validation Loss: 4971.2288\n",
      "Epoch [441/3000], Loss: 4469.1964\n",
      "Validation Loss: 4914.2688\n",
      "Epoch [461/3000], Loss: 4434.4624\n",
      "Validation Loss: 4859.3146\n",
      "Epoch [481/3000], Loss: 4357.8964\n",
      "Validation Loss: 4806.2183\n",
      "Epoch [501/3000], Loss: 4320.3343\n",
      "Validation Loss: 4755.0676\n",
      "Epoch [521/3000], Loss: 4268.4307\n",
      "Validation Loss: 4705.8000\n",
      "Epoch [541/3000], Loss: 4225.9687\n",
      "Validation Loss: 4658.4916\n",
      "Epoch [561/3000], Loss: 4182.9951\n",
      "Validation Loss: 4613.0128\n",
      "Epoch [581/3000], Loss: 4129.5215\n",
      "Validation Loss: 4569.4101\n",
      "Epoch [601/3000], Loss: 4095.7395\n",
      "Validation Loss: 4527.6976\n",
      "Epoch [621/3000], Loss: 4066.0091\n",
      "Validation Loss: 4487.8249\n",
      "Epoch [641/3000], Loss: 4027.1589\n",
      "Validation Loss: 4449.8079\n",
      "Epoch [661/3000], Loss: 3989.7822\n",
      "Validation Loss: 4413.5796\n",
      "Epoch [681/3000], Loss: 3963.4194\n",
      "Validation Loss: 4379.2347\n",
      "Epoch [701/3000], Loss: 3921.9204\n",
      "Validation Loss: 4346.6567\n",
      "Epoch [721/3000], Loss: 3889.4297\n",
      "Validation Loss: 4315.9602\n",
      "Epoch [741/3000], Loss: 3871.7995\n",
      "Validation Loss: 4286.3618\n",
      "Epoch [761/3000], Loss: 3835.0293\n",
      "Validation Loss: 4258.9526\n",
      "Epoch [781/3000], Loss: 3814.0979\n",
      "Validation Loss: 4233.4478\n",
      "Epoch [801/3000], Loss: 3777.8893\n",
      "Validation Loss: 4209.7166\n",
      "Epoch [821/3000], Loss: 3770.0610\n",
      "Validation Loss: 4187.6778\n",
      "Epoch [841/3000], Loss: 3749.8072\n",
      "Validation Loss: 4167.3306\n",
      "Epoch [861/3000], Loss: 3744.7896\n",
      "Validation Loss: 4148.6071\n",
      "Epoch [881/3000], Loss: 3721.7630\n",
      "Validation Loss: 4131.5081\n",
      "Epoch [901/3000], Loss: 3715.3499\n",
      "Validation Loss: 4116.0169\n",
      "Epoch [921/3000], Loss: 3697.5021\n",
      "Validation Loss: 4102.0736\n",
      "Epoch [941/3000], Loss: 3686.7946\n",
      "Validation Loss: 4089.6703\n",
      "Epoch [961/3000], Loss: 3674.6946\n",
      "Validation Loss: 4078.6832\n",
      "Epoch [981/3000], Loss: 3662.4451\n",
      "Validation Loss: 4069.1511\n",
      "Epoch [1001/3000], Loss: 3658.1085\n",
      "Validation Loss: 4060.8152\n",
      "Epoch [1021/3000], Loss: 3648.3016\n",
      "Validation Loss: 4053.7109\n",
      "Epoch [1041/3000], Loss: 3656.5872\n",
      "Validation Loss: 4047.8280\n",
      "Epoch [1061/3000], Loss: 3650.3299\n",
      "Validation Loss: 4042.9655\n",
      "Epoch [1081/3000], Loss: 3634.7746\n",
      "Validation Loss: 4039.0523\n",
      "Epoch [1101/3000], Loss: 3633.8776\n",
      "Validation Loss: 4036.0017\n",
      "Epoch [1121/3000], Loss: 3637.2638\n",
      "Validation Loss: 4033.6002\n",
      "Epoch [1141/3000], Loss: 3636.9674\n",
      "Validation Loss: 4031.7730\n",
      "Epoch [1161/3000], Loss: 3608.0058\n",
      "Validation Loss: 3996.2036\n",
      "Epoch [1181/3000], Loss: 2929.0966\n",
      "Validation Loss: 3375.9312\n",
      "Epoch [1201/3000], Loss: 2631.8801\n",
      "Validation Loss: 3301.4242\n",
      "Epoch [1221/3000], Loss: 2526.0814\n",
      "Validation Loss: 3277.3240\n",
      "Epoch [1241/3000], Loss: 2450.3332\n",
      "Validation Loss: 3252.3341\n",
      "Epoch [1261/3000], Loss: 2395.8739\n",
      "Validation Loss: 3215.2087\n",
      "Epoch [1281/3000], Loss: 2333.2745\n",
      "Validation Loss: 3207.6251\n",
      "Epoch [1301/3000], Loss: 2270.9549\n",
      "Validation Loss: 3171.3607\n",
      "Epoch [1321/3000], Loss: 2223.3298\n",
      "Validation Loss: 3166.0337\n",
      "Epoch [1341/3000], Loss: 2171.8435\n",
      "Validation Loss: 3162.3077\n",
      "Epoch [1361/3000], Loss: 2121.8654\n",
      "Validation Loss: 3164.5231\n",
      "Epoch [1381/3000], Loss: 2093.6205\n",
      "Validation Loss: 3192.1069\n",
      "Epoch [1401/3000], Loss: 2034.2483\n",
      "Validation Loss: 3167.0708\n",
      "Epoch [1421/3000], Loss: 1996.9531\n",
      "Validation Loss: 3167.3959\n",
      "Epoch [1441/3000], Loss: 1953.8505\n",
      "Validation Loss: 3185.6288\n",
      "Epoch [1461/3000], Loss: 1919.9430\n",
      "Validation Loss: 3189.6404\n",
      "Epoch [1481/3000], Loss: 1881.5194\n",
      "Validation Loss: 3257.3450\n",
      "Epoch [1501/3000], Loss: 1828.7606\n",
      "Validation Loss: 3279.2058\n",
      "Epoch [1521/3000], Loss: 1787.9763\n",
      "Validation Loss: 3321.8934\n",
      "Epoch [1541/3000], Loss: 1741.7538\n",
      "Validation Loss: 3290.2706\n",
      "Epoch [1561/3000], Loss: 1700.8412\n",
      "Validation Loss: 3286.6811\n",
      "Epoch [1581/3000], Loss: 1669.9307\n",
      "Validation Loss: 3409.5617\n",
      "Epoch [1601/3000], Loss: 1631.9382\n",
      "Validation Loss: 3313.7043\n",
      "Epoch [1621/3000], Loss: 1588.1315\n",
      "Validation Loss: 3308.0188\n",
      "Epoch [1641/3000], Loss: 1560.2807\n",
      "Validation Loss: 3341.6785\n",
      "Epoch [1661/3000], Loss: 1523.6918\n",
      "Validation Loss: 3356.9287\n",
      "Epoch [1681/3000], Loss: 1487.9483\n",
      "Validation Loss: 3340.9917\n",
      "Epoch [1701/3000], Loss: 1463.7407\n",
      "Validation Loss: 3304.3402\n",
      "Epoch [1721/3000], Loss: 1431.1823\n",
      "Validation Loss: 3392.0092\n",
      "Epoch [1741/3000], Loss: 1412.3436\n",
      "Validation Loss: 3321.9452\n",
      "Epoch [1761/3000], Loss: 1377.2094\n",
      "Validation Loss: 3361.0272\n",
      "Epoch [1781/3000], Loss: 1355.0092\n",
      "Validation Loss: 3331.5965\n",
      "Epoch [1801/3000], Loss: 1337.4809\n",
      "Validation Loss: 3378.8104\n",
      "Epoch [1821/3000], Loss: 1292.8895\n",
      "Validation Loss: 3329.3823\n",
      "Epoch [1841/3000], Loss: 1266.3192\n",
      "Validation Loss: 3376.2397\n",
      "Epoch [1861/3000], Loss: 1227.0807\n",
      "Validation Loss: 3363.4770\n",
      "Epoch [1881/3000], Loss: 1227.7112\n",
      "Validation Loss: 3361.3133\n",
      "Epoch [1901/3000], Loss: 1193.6318\n",
      "Validation Loss: 3357.5477\n",
      "Epoch [1921/3000], Loss: 1164.3782\n",
      "Validation Loss: 3375.9362\n",
      "Epoch [1941/3000], Loss: 1170.9636\n",
      "Validation Loss: 3259.3783\n",
      "Epoch [1961/3000], Loss: 1126.2462\n",
      "Validation Loss: 3307.0452\n",
      "Epoch [1981/3000], Loss: 1097.2946\n",
      "Validation Loss: 3211.3365\n",
      "Epoch [2001/3000], Loss: 1070.4896\n",
      "Validation Loss: 3227.2968\n",
      "Epoch [2021/3000], Loss: 1047.8166\n",
      "Validation Loss: 3213.1626\n",
      "Epoch [2041/3000], Loss: 1044.2328\n",
      "Validation Loss: 3124.2941\n",
      "Epoch [2061/3000], Loss: 991.0985\n",
      "Validation Loss: 3188.1794\n",
      "Epoch [2081/3000], Loss: 978.1091\n",
      "Validation Loss: 3121.2659\n",
      "Epoch [2101/3000], Loss: 942.2910\n",
      "Validation Loss: 3111.2237\n",
      "Epoch [2121/3000], Loss: 912.0206\n",
      "Validation Loss: 3087.2266\n",
      "Epoch [2141/3000], Loss: 895.9861\n",
      "Validation Loss: 3086.6168\n",
      "Epoch [2161/3000], Loss: 875.6971\n",
      "Validation Loss: 2999.5141\n",
      "Epoch [2181/3000], Loss: 859.9464\n",
      "Validation Loss: 2981.0274\n",
      "Epoch [2201/3000], Loss: 834.6921\n",
      "Validation Loss: 2835.0213\n",
      "Epoch [2221/3000], Loss: 815.7862\n",
      "Validation Loss: 2857.1968\n",
      "Epoch [2241/3000], Loss: 793.7116\n",
      "Validation Loss: 2772.2858\n",
      "Epoch [2261/3000], Loss: 763.9867\n",
      "Validation Loss: 2733.4342\n",
      "Epoch [2281/3000], Loss: 719.9593\n",
      "Validation Loss: 2694.4266\n",
      "Epoch [2301/3000], Loss: 694.0704\n",
      "Validation Loss: 2625.5880\n",
      "Epoch [2321/3000], Loss: 675.4205\n",
      "Validation Loss: 2565.7103\n",
      "Epoch [2341/3000], Loss: 642.7143\n",
      "Validation Loss: 2531.2072\n",
      "Epoch [2361/3000], Loss: 630.5624\n",
      "Validation Loss: 2512.3379\n",
      "Epoch [2381/3000], Loss: 607.5732\n",
      "Validation Loss: 2490.6507\n",
      "Epoch [2401/3000], Loss: 584.5778\n",
      "Validation Loss: 2433.6072\n",
      "Epoch [2421/3000], Loss: 582.1344\n",
      "Validation Loss: 2410.2198\n",
      "Epoch [2441/3000], Loss: 535.6898\n",
      "Validation Loss: 2502.5448\n",
      "Epoch [2461/3000], Loss: 513.9666\n",
      "Validation Loss: 2445.9164\n",
      "Epoch [2481/3000], Loss: 474.9067\n",
      "Validation Loss: 2493.7414\n",
      "Epoch [2501/3000], Loss: 451.0036\n",
      "Validation Loss: 2484.2071\n",
      "Epoch [2521/3000], Loss: 424.1921\n",
      "Validation Loss: 2455.5117\n",
      "Epoch [2541/3000], Loss: 403.3490\n",
      "Validation Loss: 2495.6082\n",
      "Epoch [2561/3000], Loss: 374.4749\n",
      "Validation Loss: 2457.5005\n",
      "Epoch [2581/3000], Loss: 355.2653\n",
      "Validation Loss: 2418.4083\n",
      "Epoch [2601/3000], Loss: 326.2801\n",
      "Validation Loss: 2457.3111\n",
      "Epoch [2621/3000], Loss: 307.8502\n",
      "Validation Loss: 2448.7733\n",
      "Epoch [2641/3000], Loss: 285.9266\n",
      "Validation Loss: 2501.9543\n",
      "Epoch [2661/3000], Loss: 272.3053\n",
      "Validation Loss: 2502.2272\n",
      "Epoch [2681/3000], Loss: 260.5715\n",
      "Validation Loss: 2488.5408\n",
      "Epoch [2701/3000], Loss: 247.6190\n",
      "Validation Loss: 2452.1842\n",
      "Epoch [2721/3000], Loss: 244.8357\n",
      "Validation Loss: 2674.5861\n",
      "Epoch [2741/3000], Loss: 222.0041\n",
      "Validation Loss: 2524.4739\n",
      "Epoch [2761/3000], Loss: 215.3577\n",
      "Validation Loss: 2452.2975\n",
      "Epoch [2781/3000], Loss: 188.0135\n",
      "Validation Loss: 2434.2483\n",
      "Epoch [2801/3000], Loss: 178.1683\n",
      "Validation Loss: 2459.1806\n",
      "Epoch [2821/3000], Loss: 166.6680\n",
      "Validation Loss: 2463.6767\n",
      "Epoch [2841/3000], Loss: 158.1996\n",
      "Validation Loss: 2485.3638\n",
      "Epoch [2861/3000], Loss: 157.8344\n",
      "Validation Loss: 2355.0671\n",
      "Epoch [2881/3000], Loss: 143.6515\n",
      "Validation Loss: 2509.8804\n",
      "Epoch [2901/3000], Loss: 133.9604\n",
      "Validation Loss: 2489.2781\n",
      "Epoch [2921/3000], Loss: 131.7663\n",
      "Validation Loss: 2445.6446\n",
      "Epoch [2941/3000], Loss: 122.8917\n",
      "Validation Loss: 2440.0053\n",
      "Epoch [2961/3000], Loss: 116.3079\n",
      "Validation Loss: 2595.5942\n",
      "Epoch [2981/3000], Loss: 113.2359\n",
      "Validation Loss: 2458.1765\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day082_plane0_Fall.mat\n",
      "(4298, 63)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 5588.4101\n",
      "Validation Loss: 5114.6652\n",
      "Epoch [21/3000], Loss: 4952.1785\n",
      "Validation Loss: 4503.4286\n",
      "Epoch [41/3000], Loss: 4793.3046\n",
      "Validation Loss: 4308.6456\n",
      "Epoch [61/3000], Loss: 4625.0680\n",
      "Validation Loss: 4220.1148\n",
      "Epoch [81/3000], Loss: 4571.2714\n",
      "Validation Loss: 4149.3058\n",
      "Epoch [101/3000], Loss: 4518.8625\n",
      "Validation Loss: 4086.4354\n",
      "Epoch [121/3000], Loss: 4459.8728\n",
      "Validation Loss: 4028.5530\n",
      "Epoch [141/3000], Loss: 4424.5544\n",
      "Validation Loss: 3973.5093\n",
      "Epoch [161/3000], Loss: 4341.3275\n",
      "Validation Loss: 3920.3949\n",
      "Epoch [181/3000], Loss: 4241.0178\n",
      "Validation Loss: 3869.7198\n",
      "Epoch [201/3000], Loss: 4160.8523\n",
      "Validation Loss: 3820.8988\n",
      "Epoch [221/3000], Loss: 4154.3724\n",
      "Validation Loss: 3772.8702\n",
      "Epoch [241/3000], Loss: 4109.2699\n",
      "Validation Loss: 3726.0427\n",
      "Epoch [261/3000], Loss: 4010.7210\n",
      "Validation Loss: 3681.4867\n",
      "Epoch [281/3000], Loss: 4028.3444\n",
      "Validation Loss: 3638.3461\n",
      "Epoch [301/3000], Loss: 3968.9771\n",
      "Validation Loss: 3596.6223\n",
      "Epoch [321/3000], Loss: 3920.6706\n",
      "Validation Loss: 3556.2698\n",
      "Epoch [341/3000], Loss: 3870.6441\n",
      "Validation Loss: 3517.1526\n",
      "Epoch [361/3000], Loss: 3843.7032\n",
      "Validation Loss: 3479.2847\n",
      "Epoch [381/3000], Loss: 3815.1060\n",
      "Validation Loss: 3442.6323\n",
      "Epoch [401/3000], Loss: 3763.0024\n",
      "Validation Loss: 3407.2156\n",
      "Epoch [421/3000], Loss: 3749.7754\n",
      "Validation Loss: 3373.0302\n",
      "Epoch [441/3000], Loss: 3678.3236\n",
      "Validation Loss: 3340.2299\n",
      "Epoch [461/3000], Loss: 3648.2997\n",
      "Validation Loss: 3308.6304\n",
      "Epoch [481/3000], Loss: 3597.8273\n",
      "Validation Loss: 3278.1971\n",
      "Epoch [501/3000], Loss: 3602.1757\n",
      "Validation Loss: 3248.9181\n",
      "Epoch [521/3000], Loss: 3582.3595\n",
      "Validation Loss: 3220.7738\n",
      "Epoch [541/3000], Loss: 3547.7366\n",
      "Validation Loss: 3193.8768\n",
      "Epoch [561/3000], Loss: 3484.1829\n",
      "Validation Loss: 3168.1496\n",
      "Epoch [581/3000], Loss: 3463.2905\n",
      "Validation Loss: 3143.5184\n",
      "Epoch [601/3000], Loss: 3425.5719\n",
      "Validation Loss: 3119.9896\n",
      "Epoch [621/3000], Loss: 3380.7964\n",
      "Validation Loss: 3097.7405\n",
      "Epoch [641/3000], Loss: 3389.3921\n",
      "Validation Loss: 3076.6788\n",
      "Epoch [661/3000], Loss: 3386.3042\n",
      "Validation Loss: 3056.6204\n",
      "Epoch [681/3000], Loss: 3315.9405\n",
      "Validation Loss: 3037.6545\n",
      "Epoch [701/3000], Loss: 3339.9363\n",
      "Validation Loss: 3019.8838\n",
      "Epoch [721/3000], Loss: 3302.1014\n",
      "Validation Loss: 3003.0343\n",
      "Epoch [741/3000], Loss: 3295.7237\n",
      "Validation Loss: 2987.4793\n",
      "Epoch [761/3000], Loss: 3259.2524\n",
      "Validation Loss: 2972.9353\n",
      "Epoch [781/3000], Loss: 3257.5995\n",
      "Validation Loss: 2959.3430\n",
      "Epoch [801/3000], Loss: 3258.3851\n",
      "Validation Loss: 2946.8545\n",
      "Epoch [821/3000], Loss: 3223.4398\n",
      "Validation Loss: 2935.3766\n",
      "Epoch [841/3000], Loss: 3214.5862\n",
      "Validation Loss: 2924.8542\n",
      "Epoch [861/3000], Loss: 3229.4376\n",
      "Validation Loss: 2915.3756\n",
      "Epoch [881/3000], Loss: 3184.5231\n",
      "Validation Loss: 2906.8173\n",
      "Epoch [901/3000], Loss: 3190.2595\n",
      "Validation Loss: 2899.1849\n",
      "Epoch [921/3000], Loss: 3151.3350\n",
      "Validation Loss: 2892.4978\n",
      "Epoch [941/3000], Loss: 3123.8806\n",
      "Validation Loss: 2886.6495\n",
      "Epoch [961/3000], Loss: 3163.9913\n",
      "Validation Loss: 2881.6430\n",
      "Epoch [981/3000], Loss: 3131.0956\n",
      "Validation Loss: 2877.3513\n",
      "Epoch [1001/3000], Loss: 3111.5722\n",
      "Validation Loss: 2873.8567\n",
      "Epoch [1021/3000], Loss: 3125.2129\n",
      "Validation Loss: 2871.0841\n",
      "Epoch [1041/3000], Loss: 3122.2911\n",
      "Validation Loss: 2868.9133\n",
      "Epoch [1061/3000], Loss: 3140.6759\n",
      "Validation Loss: 2867.3117\n",
      "Epoch [1081/3000], Loss: 3110.7044\n",
      "Validation Loss: 2866.2412\n",
      "Epoch [1101/3000], Loss: 3113.2984\n",
      "Validation Loss: 2865.6396\n",
      "Epoch [1121/3000], Loss: 3097.5964\n",
      "Validation Loss: 2865.4203\n",
      "Epoch [1141/3000], Loss: 3057.6535\n",
      "Validation Loss: 2857.3697\n",
      "Epoch [1161/3000], Loss: 2494.5492\n",
      "Validation Loss: 2276.8134\n",
      "Epoch [1181/3000], Loss: 2385.9964\n",
      "Validation Loss: 2203.6204\n",
      "Epoch [1201/3000], Loss: 2323.6339\n",
      "Validation Loss: 2167.6814\n",
      "Epoch [1221/3000], Loss: 2261.9211\n",
      "Validation Loss: 2152.3101\n",
      "Epoch [1241/3000], Loss: 2189.7631\n",
      "Validation Loss: 2156.7043\n",
      "Epoch [1261/3000], Loss: 2171.1170\n",
      "Validation Loss: 2163.7179\n",
      "Epoch [1281/3000], Loss: 2077.7269\n",
      "Validation Loss: 2162.6932\n",
      "Epoch [1301/3000], Loss: 2066.4684\n",
      "Validation Loss: 2174.0104\n",
      "Epoch [1321/3000], Loss: 2030.7237\n",
      "Validation Loss: 2213.5798\n",
      "Epoch [1341/3000], Loss: 1992.8097\n",
      "Validation Loss: 2181.7469\n",
      "Epoch [1361/3000], Loss: 1949.5562\n",
      "Validation Loss: 2151.9054\n",
      "Epoch [1381/3000], Loss: 1892.4312\n",
      "Validation Loss: 2227.0617\n",
      "Epoch [1401/3000], Loss: 1902.9202\n",
      "Validation Loss: 2119.4240\n",
      "Epoch [1421/3000], Loss: 1862.5573\n",
      "Validation Loss: 2117.2467\n",
      "Epoch [1441/3000], Loss: 1817.6621\n",
      "Validation Loss: 2134.6406\n",
      "Epoch [1461/3000], Loss: 1768.1890\n",
      "Validation Loss: 2093.2367\n",
      "Epoch [1481/3000], Loss: 1778.8220\n",
      "Validation Loss: 2103.4266\n",
      "Epoch [1501/3000], Loss: 1746.5391\n",
      "Validation Loss: 2107.2142\n",
      "Epoch [1521/3000], Loss: 1706.9797\n",
      "Validation Loss: 2122.4684\n",
      "Epoch [1541/3000], Loss: 1690.5859\n",
      "Validation Loss: 2027.2209\n",
      "Epoch [1561/3000], Loss: 1660.8455\n",
      "Validation Loss: 2099.9924\n",
      "Epoch [1581/3000], Loss: 1628.5757\n",
      "Validation Loss: 2023.7695\n",
      "Epoch [1601/3000], Loss: 1580.3628\n",
      "Validation Loss: 1974.2298\n",
      "Epoch [1621/3000], Loss: 1562.5790\n",
      "Validation Loss: 1976.8432\n",
      "Epoch [1641/3000], Loss: 1547.2552\n",
      "Validation Loss: 1975.2257\n",
      "Epoch [1661/3000], Loss: 1536.6335\n",
      "Validation Loss: 1921.5403\n",
      "Epoch [1681/3000], Loss: 1518.8307\n",
      "Validation Loss: 1926.7733\n",
      "Epoch [1701/3000], Loss: 1489.2606\n",
      "Validation Loss: 1891.6148\n",
      "Epoch [1721/3000], Loss: 1439.5910\n",
      "Validation Loss: 1877.5953\n",
      "Epoch [1741/3000], Loss: 1411.3043\n",
      "Validation Loss: 1827.0676\n",
      "Epoch [1761/3000], Loss: 1400.7824\n",
      "Validation Loss: 1790.6073\n",
      "Epoch [1781/3000], Loss: 1388.1782\n",
      "Validation Loss: 1756.9851\n",
      "Epoch [1801/3000], Loss: 1351.5521\n",
      "Validation Loss: 1733.9046\n",
      "Epoch [1821/3000], Loss: 1332.7902\n",
      "Validation Loss: 1698.8196\n",
      "Epoch [1841/3000], Loss: 1312.1018\n",
      "Validation Loss: 1680.1849\n",
      "Epoch [1861/3000], Loss: 1283.5178\n",
      "Validation Loss: 1624.3465\n",
      "Epoch [1881/3000], Loss: 1274.6337\n",
      "Validation Loss: 1622.9215\n",
      "Epoch [1901/3000], Loss: 1242.4279\n",
      "Validation Loss: 1598.5336\n",
      "Epoch [1921/3000], Loss: 1203.3688\n",
      "Validation Loss: 1536.3628\n",
      "Epoch [1941/3000], Loss: 1195.2096\n",
      "Validation Loss: 1538.4990\n",
      "Epoch [1961/3000], Loss: 1147.4166\n",
      "Validation Loss: 1518.3968\n",
      "Epoch [1981/3000], Loss: 1112.4431\n",
      "Validation Loss: 1472.3478\n",
      "Epoch [2001/3000], Loss: 1105.7589\n",
      "Validation Loss: 1440.9282\n",
      "Epoch [2021/3000], Loss: 1085.1222\n",
      "Validation Loss: 1437.3894\n",
      "Epoch [2041/3000], Loss: 1064.4064\n",
      "Validation Loss: 1430.1637\n",
      "Epoch [2061/3000], Loss: 1039.0600\n",
      "Validation Loss: 1384.0943\n",
      "Epoch [2081/3000], Loss: 1023.7575\n",
      "Validation Loss: 1373.3950\n",
      "Epoch [2101/3000], Loss: 992.3089\n",
      "Validation Loss: 1344.9070\n",
      "Epoch [2121/3000], Loss: 969.7048\n",
      "Validation Loss: 1355.6940\n",
      "Epoch [2141/3000], Loss: 949.5394\n",
      "Validation Loss: 1318.4743\n",
      "Epoch [2161/3000], Loss: 932.5458\n",
      "Validation Loss: 1317.2945\n",
      "Epoch [2181/3000], Loss: 894.6463\n",
      "Validation Loss: 1283.3624\n",
      "Epoch [2201/3000], Loss: 871.4955\n",
      "Validation Loss: 1271.4953\n",
      "Epoch [2221/3000], Loss: 864.1432\n",
      "Validation Loss: 1258.7732\n",
      "Epoch [2241/3000], Loss: 850.7872\n",
      "Validation Loss: 1262.9136\n",
      "Epoch [2261/3000], Loss: 832.8094\n",
      "Validation Loss: 1205.4949\n",
      "Epoch [2281/3000], Loss: 817.0165\n",
      "Validation Loss: 1221.2210\n",
      "Epoch [2301/3000], Loss: 799.2580\n",
      "Validation Loss: 1232.4032\n",
      "Epoch [2321/3000], Loss: 768.3453\n",
      "Validation Loss: 1217.5289\n",
      "Epoch [2341/3000], Loss: 760.7956\n",
      "Validation Loss: 1178.8851\n",
      "Epoch [2361/3000], Loss: 739.7554\n",
      "Validation Loss: 1194.8684\n",
      "Epoch [2381/3000], Loss: 721.0520\n",
      "Validation Loss: 1177.4144\n",
      "Epoch [2401/3000], Loss: 701.3500\n",
      "Validation Loss: 1157.0076\n",
      "Epoch [2421/3000], Loss: 681.7352\n",
      "Validation Loss: 1137.5985\n",
      "Epoch [2441/3000], Loss: 666.4635\n",
      "Validation Loss: 1111.1243\n",
      "Epoch [2461/3000], Loss: 637.7557\n",
      "Validation Loss: 1143.2086\n",
      "Epoch [2481/3000], Loss: 615.5329\n",
      "Validation Loss: 1148.1447\n",
      "Epoch [2501/3000], Loss: 601.6278\n",
      "Validation Loss: 1114.0655\n",
      "Epoch [2521/3000], Loss: 592.9641\n",
      "Validation Loss: 1108.0085\n",
      "Epoch [2541/3000], Loss: 580.6219\n",
      "Validation Loss: 1094.6334\n",
      "Epoch [2561/3000], Loss: 548.7732\n",
      "Validation Loss: 1099.8043\n",
      "Epoch [2581/3000], Loss: 540.4558\n",
      "Validation Loss: 1085.1584\n",
      "Epoch [2601/3000], Loss: 521.2600\n",
      "Validation Loss: 1088.3817\n",
      "Epoch [2621/3000], Loss: 510.7881\n",
      "Validation Loss: 1077.5708\n",
      "Epoch [2641/3000], Loss: 492.2807\n",
      "Validation Loss: 1066.7224\n",
      "Epoch [2661/3000], Loss: 480.0682\n",
      "Validation Loss: 1064.0815\n",
      "Epoch [2681/3000], Loss: 468.5460\n",
      "Validation Loss: 1061.1206\n",
      "Epoch [2701/3000], Loss: 452.1372\n",
      "Validation Loss: 1053.9543\n",
      "Epoch [2721/3000], Loss: 437.3957\n",
      "Validation Loss: 1029.9654\n",
      "Epoch [2741/3000], Loss: 433.4184\n",
      "Validation Loss: 1040.0177\n",
      "Epoch [2761/3000], Loss: 409.7862\n",
      "Validation Loss: 1026.3397\n",
      "Epoch [2781/3000], Loss: 414.9635\n",
      "Validation Loss: 1005.1660\n",
      "Epoch [2801/3000], Loss: 384.7939\n",
      "Validation Loss: 1022.7594\n",
      "Epoch [2821/3000], Loss: 371.8099\n",
      "Validation Loss: 1015.5831\n",
      "Epoch [2841/3000], Loss: 361.7025\n",
      "Validation Loss: 1002.7410\n",
      "Epoch [2861/3000], Loss: 351.7317\n",
      "Validation Loss: 996.9940\n",
      "Epoch [2881/3000], Loss: 335.4745\n",
      "Validation Loss: 976.5355\n",
      "Epoch [2901/3000], Loss: 328.9563\n",
      "Validation Loss: 983.6265\n",
      "Epoch [2921/3000], Loss: 311.8282\n",
      "Validation Loss: 982.4964\n",
      "Epoch [2941/3000], Loss: 310.6989\n",
      "Validation Loss: 970.3374\n",
      "Epoch [2961/3000], Loss: 302.2625\n",
      "Validation Loss: 990.1096\n",
      "Epoch [2981/3000], Loss: 283.6684\n",
      "Validation Loss: 956.6291\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day083_plane0_Fall.mat\n",
      "(4373, 101)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6481.3760\n",
      "Validation Loss: 6203.6140\n",
      "Epoch [21/3000], Loss: 5707.5057\n",
      "Validation Loss: 5457.0050\n",
      "Epoch [41/3000], Loss: 5493.1337\n",
      "Validation Loss: 5260.0640\n",
      "Epoch [61/3000], Loss: 5391.7875\n",
      "Validation Loss: 5162.1889\n",
      "Epoch [81/3000], Loss: 5305.0273\n",
      "Validation Loss: 5081.6520\n",
      "Epoch [101/3000], Loss: 5228.0234\n",
      "Validation Loss: 5009.6313\n",
      "Epoch [121/3000], Loss: 5152.6778\n",
      "Validation Loss: 4940.7437\n",
      "Epoch [141/3000], Loss: 5091.8336\n",
      "Validation Loss: 4875.9047\n",
      "Epoch [161/3000], Loss: 5011.7631\n",
      "Validation Loss: 4813.8909\n",
      "Epoch [181/3000], Loss: 4962.4466\n",
      "Validation Loss: 4754.0534\n",
      "Epoch [201/3000], Loss: 4904.7775\n",
      "Validation Loss: 4696.1865\n",
      "Epoch [221/3000], Loss: 4838.1602\n",
      "Validation Loss: 4640.2021\n",
      "Epoch [241/3000], Loss: 4785.2018\n",
      "Validation Loss: 4585.8470\n",
      "Epoch [261/3000], Loss: 4715.2927\n",
      "Validation Loss: 4533.0577\n",
      "Epoch [281/3000], Loss: 4673.1766\n",
      "Validation Loss: 4481.8494\n",
      "Epoch [301/3000], Loss: 4614.8292\n",
      "Validation Loss: 4432.1455\n",
      "Epoch [321/3000], Loss: 4565.3537\n",
      "Validation Loss: 4383.8596\n",
      "Epoch [341/3000], Loss: 4512.4470\n",
      "Validation Loss: 4337.0123\n",
      "Epoch [361/3000], Loss: 4460.7744\n",
      "Validation Loss: 4291.6064\n",
      "Epoch [381/3000], Loss: 4427.8695\n",
      "Validation Loss: 4247.6062\n",
      "Epoch [401/3000], Loss: 4371.3543\n",
      "Validation Loss: 4204.9601\n",
      "Epoch [421/3000], Loss: 4336.5226\n",
      "Validation Loss: 4163.7356\n",
      "Epoch [441/3000], Loss: 4294.6465\n",
      "Validation Loss: 4123.7742\n",
      "Epoch [461/3000], Loss: 4251.5122\n",
      "Validation Loss: 4085.2373\n",
      "Epoch [481/3000], Loss: 4200.5734\n",
      "Validation Loss: 4048.0478\n",
      "Epoch [501/3000], Loss: 4171.5515\n",
      "Validation Loss: 4012.1821\n",
      "Epoch [521/3000], Loss: 4123.8376\n",
      "Validation Loss: 3977.6684\n",
      "Epoch [541/3000], Loss: 4095.7870\n",
      "Validation Loss: 3944.4517\n",
      "Epoch [561/3000], Loss: 4058.6046\n",
      "Validation Loss: 3912.5995\n",
      "Epoch [581/3000], Loss: 4027.0713\n",
      "Validation Loss: 3882.0687\n",
      "Epoch [601/3000], Loss: 3997.0546\n",
      "Validation Loss: 3852.8156\n",
      "Epoch [621/3000], Loss: 3963.5799\n",
      "Validation Loss: 3824.8378\n",
      "Epoch [641/3000], Loss: 3932.3563\n",
      "Validation Loss: 3798.1758\n",
      "Epoch [661/3000], Loss: 3905.6591\n",
      "Validation Loss: 3772.8075\n",
      "Epoch [681/3000], Loss: 3875.8517\n",
      "Validation Loss: 3748.7150\n",
      "Epoch [701/3000], Loss: 3856.9588\n",
      "Validation Loss: 3725.8713\n",
      "Epoch [721/3000], Loss: 3827.1408\n",
      "Validation Loss: 3704.2706\n",
      "Epoch [741/3000], Loss: 3809.6569\n",
      "Validation Loss: 3683.9034\n",
      "Epoch [761/3000], Loss: 3782.2547\n",
      "Validation Loss: 3664.7827\n",
      "Epoch [781/3000], Loss: 3760.8850\n",
      "Validation Loss: 3646.8583\n",
      "Epoch [801/3000], Loss: 3741.4777\n",
      "Validation Loss: 3630.1649\n",
      "Epoch [821/3000], Loss: 3716.7094\n",
      "Validation Loss: 3614.6557\n",
      "Epoch [841/3000], Loss: 3699.5565\n",
      "Validation Loss: 3600.2867\n",
      "Epoch [861/3000], Loss: 3687.5125\n",
      "Validation Loss: 3586.6337\n",
      "Epoch [881/3000], Loss: 3672.0888\n",
      "Validation Loss: 3574.5027\n",
      "Epoch [901/3000], Loss: 3662.5850\n",
      "Validation Loss: 3563.4987\n",
      "Epoch [921/3000], Loss: 3642.4794\n",
      "Validation Loss: 3553.5920\n",
      "Epoch [941/3000], Loss: 3637.8833\n",
      "Validation Loss: 3544.7223\n",
      "Epoch [961/3000], Loss: 3628.5293\n",
      "Validation Loss: 3536.9248\n",
      "Epoch [981/3000], Loss: 3621.2158\n",
      "Validation Loss: 3530.0815\n",
      "Epoch [1001/3000], Loss: 3613.7603\n",
      "Validation Loss: 3524.1634\n",
      "Epoch [1021/3000], Loss: 3605.0609\n",
      "Validation Loss: 3519.1402\n",
      "Epoch [1041/3000], Loss: 3595.0938\n",
      "Validation Loss: 3514.9734\n",
      "Epoch [1061/3000], Loss: 3585.2779\n",
      "Validation Loss: 3511.5792\n",
      "Epoch [1081/3000], Loss: 3587.3417\n",
      "Validation Loss: 3508.9053\n",
      "Epoch [1101/3000], Loss: 3578.7571\n",
      "Validation Loss: 3506.8636\n",
      "Epoch [1121/3000], Loss: 3578.9313\n",
      "Validation Loss: 3505.4186\n",
      "Epoch [1141/3000], Loss: 3575.5342\n",
      "Validation Loss: 3504.4699\n",
      "Epoch [1161/3000], Loss: 3575.2356\n",
      "Validation Loss: 3503.9217\n",
      "Epoch [1181/3000], Loss: 3571.9692\n",
      "Validation Loss: 3503.6980\n",
      "Epoch [1201/3000], Loss: 3573.4991\n",
      "Validation Loss: 3503.7247\n",
      "Epoch [1221/3000], Loss: 3570.7279\n",
      "Validation Loss: 3503.9260\n",
      "Epoch [1241/3000], Loss: 3567.2590\n",
      "Validation Loss: 3504.2375\n",
      "Epoch [1261/3000], Loss: 3572.6429\n",
      "Validation Loss: 3504.6039\n",
      "Epoch [1281/3000], Loss: 3572.2521\n",
      "Validation Loss: 3504.9817\n",
      "Epoch [1301/3000], Loss: 3563.9458\n",
      "Validation Loss: 3505.3483\n",
      "Epoch [1321/3000], Loss: 3572.6266\n",
      "Validation Loss: 3505.6927\n",
      "Epoch [1341/3000], Loss: 3571.7742\n",
      "Validation Loss: 3506.0042\n",
      "Epoch [1361/3000], Loss: 3564.4395\n",
      "Validation Loss: 3506.2635\n",
      "Epoch [1381/3000], Loss: 3566.6803\n",
      "Validation Loss: 3506.4596\n",
      "Epoch [1401/3000], Loss: 3571.9683\n",
      "Validation Loss: 3506.6315\n",
      "Epoch [1421/3000], Loss: 3569.4478\n",
      "Validation Loss: 3506.7876\n",
      "Epoch [1441/3000], Loss: 3568.3872\n",
      "Validation Loss: 3506.9179\n",
      "Epoch [1461/3000], Loss: 3569.0796\n",
      "Validation Loss: 3506.9920\n",
      "Epoch [1481/3000], Loss: 3570.5563\n",
      "Validation Loss: 3507.0617\n",
      "Epoch [1501/3000], Loss: 3570.8451\n",
      "Validation Loss: 3507.1156\n",
      "Epoch [1521/3000], Loss: 3569.7209\n",
      "Validation Loss: 3507.1830\n",
      "Epoch [1541/3000], Loss: 3567.1760\n",
      "Validation Loss: 3507.2154\n",
      "Epoch [1561/3000], Loss: 3563.5043\n",
      "Validation Loss: 3507.2455\n",
      "Epoch [1581/3000], Loss: 3569.4862\n",
      "Validation Loss: 3507.2744\n",
      "Epoch [1601/3000], Loss: 3571.9322\n",
      "Validation Loss: 3507.2893\n",
      "Epoch [1621/3000], Loss: 3441.9032\n",
      "Validation Loss: 3393.7689\n",
      "Epoch [1641/3000], Loss: 3060.9985\n",
      "Validation Loss: 3092.4465\n",
      "Epoch [1661/3000], Loss: 2581.7963\n",
      "Validation Loss: 2793.7326\n",
      "Epoch [1681/3000], Loss: 2429.1975\n",
      "Validation Loss: 2748.1350\n",
      "Epoch [1701/3000], Loss: 2361.8565\n",
      "Validation Loss: 2719.9525\n",
      "Epoch [1721/3000], Loss: 2293.1721\n",
      "Validation Loss: 2703.4629\n",
      "Epoch [1741/3000], Loss: 2241.4729\n",
      "Validation Loss: 2728.9247\n",
      "Epoch [1761/3000], Loss: 2193.2202\n",
      "Validation Loss: 2718.9727\n",
      "Epoch [1781/3000], Loss: 2146.3388\n",
      "Validation Loss: 2727.1072\n",
      "Epoch [1801/3000], Loss: 2103.3939\n",
      "Validation Loss: 2704.5229\n",
      "Epoch [1821/3000], Loss: 2069.9765\n",
      "Validation Loss: 2673.9101\n",
      "Epoch [1841/3000], Loss: 2019.5361\n",
      "Validation Loss: 2657.8797\n",
      "Epoch [1861/3000], Loss: 1979.7042\n",
      "Validation Loss: 2622.8201\n",
      "Epoch [1881/3000], Loss: 1938.6482\n",
      "Validation Loss: 2625.0338\n",
      "Epoch [1901/3000], Loss: 1901.7025\n",
      "Validation Loss: 2589.1184\n",
      "Epoch [1921/3000], Loss: 1863.0551\n",
      "Validation Loss: 2606.4788\n",
      "Epoch [1941/3000], Loss: 1826.2863\n",
      "Validation Loss: 2544.1149\n",
      "Epoch [1961/3000], Loss: 1784.5672\n",
      "Validation Loss: 2515.3134\n",
      "Epoch [1981/3000], Loss: 1751.9020\n",
      "Validation Loss: 2534.5879\n",
      "Epoch [2001/3000], Loss: 1719.8533\n",
      "Validation Loss: 2467.0878\n",
      "Epoch [2021/3000], Loss: 1672.7178\n",
      "Validation Loss: 2476.2658\n",
      "Epoch [2041/3000], Loss: 1645.4140\n",
      "Validation Loss: 2428.0120\n",
      "Epoch [2061/3000], Loss: 1606.6064\n",
      "Validation Loss: 2423.5927\n",
      "Epoch [2081/3000], Loss: 1571.6643\n",
      "Validation Loss: 2381.1484\n",
      "Epoch [2101/3000], Loss: 1537.8710\n",
      "Validation Loss: 2356.2323\n",
      "Epoch [2121/3000], Loss: 1508.7713\n",
      "Validation Loss: 2349.0974\n",
      "Epoch [2141/3000], Loss: 1476.2451\n",
      "Validation Loss: 2394.5469\n",
      "Epoch [2161/3000], Loss: 1441.4158\n",
      "Validation Loss: 2329.5380\n",
      "Epoch [2181/3000], Loss: 1411.0975\n",
      "Validation Loss: 2318.9277\n",
      "Epoch [2201/3000], Loss: 1378.6400\n",
      "Validation Loss: 2291.9815\n",
      "Epoch [2221/3000], Loss: 1347.7259\n",
      "Validation Loss: 2254.9576\n",
      "Epoch [2241/3000], Loss: 1319.5500\n",
      "Validation Loss: 2227.3566\n",
      "Epoch [2261/3000], Loss: 1287.3601\n",
      "Validation Loss: 2232.1987\n",
      "Epoch [2281/3000], Loss: 1269.4239\n",
      "Validation Loss: 2226.1058\n",
      "Epoch [2301/3000], Loss: 1232.3372\n",
      "Validation Loss: 2152.8777\n",
      "Epoch [2321/3000], Loss: 1202.6201\n",
      "Validation Loss: 2188.9052\n",
      "Epoch [2341/3000], Loss: 1171.1107\n",
      "Validation Loss: 2173.3580\n",
      "Epoch [2361/3000], Loss: 1150.0334\n",
      "Validation Loss: 2171.1009\n",
      "Epoch [2381/3000], Loss: 1130.4573\n",
      "Validation Loss: 2121.0052\n",
      "Epoch [2401/3000], Loss: 1090.5684\n",
      "Validation Loss: 2108.7492\n",
      "Epoch [2421/3000], Loss: 1063.3098\n",
      "Validation Loss: 2119.4182\n",
      "Epoch [2441/3000], Loss: 1035.3676\n",
      "Validation Loss: 2063.3159\n",
      "Epoch [2461/3000], Loss: 1016.5300\n",
      "Validation Loss: 2112.9918\n",
      "Epoch [2481/3000], Loss: 982.4399\n",
      "Validation Loss: 2034.8762\n",
      "Epoch [2501/3000], Loss: 955.7234\n",
      "Validation Loss: 1999.1308\n",
      "Epoch [2521/3000], Loss: 924.6375\n",
      "Validation Loss: 2016.8359\n",
      "Epoch [2541/3000], Loss: 896.9274\n",
      "Validation Loss: 2022.6312\n",
      "Epoch [2561/3000], Loss: 869.2767\n",
      "Validation Loss: 2026.5018\n",
      "Epoch [2581/3000], Loss: 842.2278\n",
      "Validation Loss: 2021.9698\n",
      "Epoch [2601/3000], Loss: 816.4117\n",
      "Validation Loss: 2030.8341\n",
      "Epoch [2621/3000], Loss: 796.7670\n",
      "Validation Loss: 2067.3975\n",
      "Epoch [2641/3000], Loss: 773.1730\n",
      "Validation Loss: 1973.3944\n",
      "Epoch [2661/3000], Loss: 748.9341\n",
      "Validation Loss: 1961.3519\n",
      "Epoch [2681/3000], Loss: 727.9241\n",
      "Validation Loss: 2020.4427\n",
      "Epoch [2701/3000], Loss: 699.7831\n",
      "Validation Loss: 1980.8691\n",
      "Epoch [2721/3000], Loss: 683.4695\n",
      "Validation Loss: 1986.1733\n",
      "Epoch [2741/3000], Loss: 654.9508\n",
      "Validation Loss: 1932.4970\n",
      "Epoch [2761/3000], Loss: 635.2684\n",
      "Validation Loss: 1935.6231\n",
      "Epoch [2781/3000], Loss: 615.7075\n",
      "Validation Loss: 1940.1427\n",
      "Epoch [2801/3000], Loss: 597.3419\n",
      "Validation Loss: 1927.4374\n",
      "Epoch [2821/3000], Loss: 577.6213\n",
      "Validation Loss: 1925.8973\n",
      "Epoch [2841/3000], Loss: 571.9321\n",
      "Validation Loss: 1943.1499\n",
      "Epoch [2861/3000], Loss: 543.4374\n",
      "Validation Loss: 1854.8155\n",
      "Epoch [2881/3000], Loss: 523.2258\n",
      "Validation Loss: 1875.0727\n",
      "Epoch [2901/3000], Loss: 508.8094\n",
      "Validation Loss: 1871.6588\n",
      "Epoch [2921/3000], Loss: 491.0019\n",
      "Validation Loss: 1858.5020\n",
      "Epoch [2941/3000], Loss: 478.0061\n",
      "Validation Loss: 1847.6613\n",
      "Epoch [2961/3000], Loss: 461.4706\n",
      "Validation Loss: 1846.4897\n",
      "Epoch [2981/3000], Loss: 444.7531\n",
      "Validation Loss: 1821.3257\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day084_plane0_Fall.mat\n",
      "(6334, 70)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6467.3165\n",
      "Validation Loss: 5512.3485\n",
      "Epoch [21/3000], Loss: 5645.8475\n",
      "Validation Loss: 4717.1966\n",
      "Epoch [41/3000], Loss: 5400.7662\n",
      "Validation Loss: 4548.8321\n",
      "Epoch [61/3000], Loss: 5318.2169\n",
      "Validation Loss: 4438.5730\n",
      "Epoch [81/3000], Loss: 5186.0935\n",
      "Validation Loss: 4340.9400\n",
      "Epoch [101/3000], Loss: 5083.9748\n",
      "Validation Loss: 4248.5115\n",
      "Epoch [121/3000], Loss: 4969.4529\n",
      "Validation Loss: 4160.9201\n",
      "Epoch [141/3000], Loss: 4851.6199\n",
      "Validation Loss: 4079.2367\n",
      "Epoch [161/3000], Loss: 4743.7564\n",
      "Validation Loss: 4000.8936\n",
      "Epoch [181/3000], Loss: 4701.0710\n",
      "Validation Loss: 3925.5466\n",
      "Epoch [201/3000], Loss: 4572.5607\n",
      "Validation Loss: 3853.5733\n",
      "Epoch [221/3000], Loss: 4472.6300\n",
      "Validation Loss: 3784.6602\n",
      "Epoch [241/3000], Loss: 4412.2652\n",
      "Validation Loss: 3718.6158\n",
      "Epoch [261/3000], Loss: 4372.8127\n",
      "Validation Loss: 3655.3549\n",
      "Epoch [281/3000], Loss: 4270.5745\n",
      "Validation Loss: 3594.9692\n",
      "Epoch [301/3000], Loss: 4190.0949\n",
      "Validation Loss: 3537.2823\n",
      "Epoch [321/3000], Loss: 4125.8910\n",
      "Validation Loss: 3482.2294\n",
      "Epoch [341/3000], Loss: 4060.2894\n",
      "Validation Loss: 3429.9552\n",
      "Epoch [361/3000], Loss: 4012.2172\n",
      "Validation Loss: 3380.2161\n",
      "Epoch [381/3000], Loss: 3944.7188\n",
      "Validation Loss: 3333.2874\n",
      "Epoch [401/3000], Loss: 3891.3882\n",
      "Validation Loss: 3288.9021\n",
      "Epoch [421/3000], Loss: 3822.9965\n",
      "Validation Loss: 3247.1143\n",
      "Epoch [441/3000], Loss: 3778.4178\n",
      "Validation Loss: 3208.0118\n",
      "Epoch [461/3000], Loss: 3734.2387\n",
      "Validation Loss: 3171.4649\n",
      "Epoch [481/3000], Loss: 3684.3347\n",
      "Validation Loss: 3137.4125\n",
      "Epoch [501/3000], Loss: 3623.1438\n",
      "Validation Loss: 3105.2952\n",
      "Epoch [521/3000], Loss: 3591.0969\n",
      "Validation Loss: 3076.2398\n",
      "Epoch [541/3000], Loss: 3552.4992\n",
      "Validation Loss: 3049.6046\n",
      "Epoch [561/3000], Loss: 3518.4474\n",
      "Validation Loss: 3025.5586\n",
      "Epoch [581/3000], Loss: 3471.3769\n",
      "Validation Loss: 3003.9038\n",
      "Epoch [601/3000], Loss: 3444.9560\n",
      "Validation Loss: 2984.5998\n",
      "Epoch [621/3000], Loss: 3398.4887\n",
      "Validation Loss: 2967.7554\n",
      "Epoch [641/3000], Loss: 3378.7902\n",
      "Validation Loss: 2953.1454\n",
      "Epoch [661/3000], Loss: 3374.3676\n",
      "Validation Loss: 2940.6997\n",
      "Epoch [681/3000], Loss: 3344.0772\n",
      "Validation Loss: 2930.2554\n",
      "Epoch [701/3000], Loss: 3295.8257\n",
      "Validation Loss: 2922.1861\n",
      "Epoch [721/3000], Loss: 3292.5697\n",
      "Validation Loss: 2916.1250\n",
      "Epoch [741/3000], Loss: 3268.6712\n",
      "Validation Loss: 2911.9319\n",
      "Epoch [761/3000], Loss: 3278.2781\n",
      "Validation Loss: 2909.5187\n",
      "Epoch [781/3000], Loss: 3240.2937\n",
      "Validation Loss: 2908.7375\n",
      "Epoch [801/3000], Loss: 3238.9737\n",
      "Validation Loss: 2909.4156\n",
      "Epoch [821/3000], Loss: 3223.6376\n",
      "Validation Loss: 2911.3256\n",
      "Epoch [841/3000], Loss: 3237.6109\n",
      "Validation Loss: 2914.2593\n",
      "Epoch [861/3000], Loss: 3205.0389\n",
      "Validation Loss: 2917.8910\n",
      "Epoch [881/3000], Loss: 3215.3856\n",
      "Validation Loss: 2921.9322\n",
      "Epoch [901/3000], Loss: 3216.0138\n",
      "Validation Loss: 2926.2589\n",
      "Epoch [921/3000], Loss: 3220.6020\n",
      "Validation Loss: 2930.4124\n",
      "Epoch [941/3000], Loss: 2537.7892\n",
      "Validation Loss: 2883.2823\n",
      "Epoch [961/3000], Loss: 2295.2326\n",
      "Validation Loss: 2544.4133\n",
      "Epoch [981/3000], Loss: 2190.2796\n",
      "Validation Loss: 2290.4009\n",
      "Epoch [1001/3000], Loss: 2106.4862\n",
      "Validation Loss: 2133.7497\n",
      "Epoch [1021/3000], Loss: 2031.7460\n",
      "Validation Loss: 2263.6216\n",
      "Epoch [1041/3000], Loss: 1962.4157\n",
      "Validation Loss: 2208.3962\n",
      "Epoch [1061/3000], Loss: 1911.7695\n",
      "Validation Loss: 2199.0947\n",
      "Epoch [1081/3000], Loss: 1846.8006\n",
      "Validation Loss: 2229.9713\n",
      "Epoch [1101/3000], Loss: 1798.9874\n",
      "Validation Loss: 2179.9866\n",
      "Epoch [1121/3000], Loss: 1745.9829\n",
      "Validation Loss: 2207.8390\n",
      "Epoch [1141/3000], Loss: 1709.0219\n",
      "Validation Loss: 2311.6201\n",
      "Epoch [1161/3000], Loss: 1661.6646\n",
      "Validation Loss: 2278.8495\n",
      "Epoch [1181/3000], Loss: 1621.7823\n",
      "Validation Loss: 2350.6440\n",
      "Epoch [1201/3000], Loss: 1576.3689\n",
      "Validation Loss: 2458.7150\n",
      "Epoch [1221/3000], Loss: 1534.2398\n",
      "Validation Loss: 2374.7937\n",
      "Epoch [1241/3000], Loss: 1512.1853\n",
      "Validation Loss: 2326.8056\n",
      "Epoch [1261/3000], Loss: 1463.1519\n",
      "Validation Loss: 2411.7159\n",
      "Epoch [1281/3000], Loss: 1437.1656\n",
      "Validation Loss: 2435.3862\n",
      "Epoch [1301/3000], Loss: 1404.8001\n",
      "Validation Loss: 2422.7880\n",
      "Epoch [1321/3000], Loss: 1388.0170\n",
      "Validation Loss: 2337.0317\n",
      "Epoch [1341/3000], Loss: 1325.9742\n",
      "Validation Loss: 2437.2399\n",
      "Epoch [1361/3000], Loss: 1307.4802\n",
      "Validation Loss: 2479.3855\n",
      "Epoch [1381/3000], Loss: 1281.4963\n",
      "Validation Loss: 2471.3820\n",
      "Epoch [1401/3000], Loss: 1246.7265\n",
      "Validation Loss: 2553.8850\n",
      "Epoch [1421/3000], Loss: 1218.5912\n",
      "Validation Loss: 2596.8305\n",
      "Epoch [1441/3000], Loss: 1185.0932\n",
      "Validation Loss: 2510.0316\n",
      "Epoch [1461/3000], Loss: 1156.4359\n",
      "Validation Loss: 2547.7868\n",
      "Epoch [1481/3000], Loss: 1133.5555\n",
      "Validation Loss: 2644.7528\n",
      "Epoch [1501/3000], Loss: 1105.5549\n",
      "Validation Loss: 2622.4482\n",
      "Epoch [1521/3000], Loss: 1065.3258\n",
      "Validation Loss: 2579.5840\n",
      "Epoch [1541/3000], Loss: 1033.6262\n",
      "Validation Loss: 2580.5587\n",
      "Epoch [1561/3000], Loss: 1018.5502\n",
      "Validation Loss: 2582.0013\n",
      "Epoch [1581/3000], Loss: 987.2159\n",
      "Validation Loss: 2643.1695\n",
      "Epoch [1601/3000], Loss: 965.1239\n",
      "Validation Loss: 2499.5950\n",
      "Epoch [1621/3000], Loss: 934.7870\n",
      "Validation Loss: 2636.0173\n",
      "Epoch [1641/3000], Loss: 905.5557\n",
      "Validation Loss: 2657.5931\n",
      "Epoch [1661/3000], Loss: 886.1081\n",
      "Validation Loss: 2678.1882\n",
      "Epoch [1681/3000], Loss: 847.4473\n",
      "Validation Loss: 2794.0018\n",
      "Epoch [1701/3000], Loss: 827.7891\n",
      "Validation Loss: 2695.9836\n",
      "Epoch [1721/3000], Loss: 810.7939\n",
      "Validation Loss: 2741.4608\n",
      "Epoch [1741/3000], Loss: 773.7365\n",
      "Validation Loss: 2767.2694\n",
      "Epoch [1761/3000], Loss: 758.1176\n",
      "Validation Loss: 2683.8116\n",
      "Epoch [1781/3000], Loss: 737.5564\n",
      "Validation Loss: 2728.0364\n",
      "Epoch [1801/3000], Loss: 717.5725\n",
      "Validation Loss: 2822.6677\n",
      "Epoch [1821/3000], Loss: 700.8180\n",
      "Validation Loss: 2810.4052\n",
      "Epoch [1841/3000], Loss: 678.9362\n",
      "Validation Loss: 2881.9271\n",
      "Epoch [1861/3000], Loss: 650.2879\n",
      "Validation Loss: 2792.5861\n",
      "Epoch [1881/3000], Loss: 634.6395\n",
      "Validation Loss: 2769.4435\n",
      "Epoch [1901/3000], Loss: 612.2811\n",
      "Validation Loss: 2764.8130\n",
      "Epoch [1921/3000], Loss: 584.7026\n",
      "Validation Loss: 2711.8460\n",
      "Epoch [1941/3000], Loss: 581.1146\n",
      "Validation Loss: 2809.3293\n",
      "Epoch [1961/3000], Loss: 552.9907\n",
      "Validation Loss: 2763.0913\n",
      "Epoch [1981/3000], Loss: 531.2057\n",
      "Validation Loss: 2740.6138\n",
      "Epoch [2001/3000], Loss: 518.9137\n",
      "Validation Loss: 2739.8341\n",
      "Epoch [2021/3000], Loss: 501.9025\n",
      "Validation Loss: 2718.8809\n",
      "Epoch [2041/3000], Loss: 482.5763\n",
      "Validation Loss: 2761.3809\n",
      "Epoch [2061/3000], Loss: 467.3990\n",
      "Validation Loss: 2739.1733\n",
      "Epoch [2081/3000], Loss: 438.8341\n",
      "Validation Loss: 2816.8999\n",
      "Epoch [2101/3000], Loss: 405.3957\n",
      "Validation Loss: 2794.1339\n",
      "Epoch [2121/3000], Loss: 382.3392\n",
      "Validation Loss: 2745.6999\n",
      "Epoch [2141/3000], Loss: 364.0496\n",
      "Validation Loss: 2759.3467\n",
      "Epoch [2161/3000], Loss: 351.9957\n",
      "Validation Loss: 2776.0349\n",
      "Epoch [2181/3000], Loss: 334.7030\n",
      "Validation Loss: 2770.5827\n",
      "Epoch [2201/3000], Loss: 307.2084\n",
      "Validation Loss: 2789.6578\n",
      "Epoch [2221/3000], Loss: 291.4861\n",
      "Validation Loss: 2767.2577\n",
      "Epoch [2241/3000], Loss: 285.6872\n",
      "Validation Loss: 2750.5621\n",
      "Epoch [2261/3000], Loss: 270.7434\n",
      "Validation Loss: 2699.1348\n",
      "Epoch [2281/3000], Loss: 258.5317\n",
      "Validation Loss: 2700.3159\n",
      "Epoch [2301/3000], Loss: 246.0869\n",
      "Validation Loss: 2737.3919\n",
      "Epoch [2321/3000], Loss: 234.7423\n",
      "Validation Loss: 2688.9817\n",
      "Epoch [2341/3000], Loss: 219.3951\n",
      "Validation Loss: 2732.9304\n",
      "Epoch [2361/3000], Loss: 216.5194\n",
      "Validation Loss: 2751.1392\n",
      "Epoch [2381/3000], Loss: 208.4395\n",
      "Validation Loss: 2757.7735\n",
      "Epoch [2401/3000], Loss: 198.8953\n",
      "Validation Loss: 2710.9365\n",
      "Epoch [2421/3000], Loss: 193.2121\n",
      "Validation Loss: 2679.0257\n",
      "Epoch [2441/3000], Loss: 176.6873\n",
      "Validation Loss: 2727.2064\n",
      "Epoch [2461/3000], Loss: 177.0803\n",
      "Validation Loss: 2716.8277\n",
      "Epoch [2481/3000], Loss: 166.6303\n",
      "Validation Loss: 2689.4138\n",
      "Epoch [2501/3000], Loss: 161.6740\n",
      "Validation Loss: 2757.0055\n",
      "Epoch [2521/3000], Loss: 156.7747\n",
      "Validation Loss: 2747.9888\n",
      "Epoch [2541/3000], Loss: 157.1680\n",
      "Validation Loss: 2753.9667\n",
      "Epoch [2561/3000], Loss: 150.7424\n",
      "Validation Loss: 2716.6922\n",
      "Epoch [2581/3000], Loss: 148.9035\n",
      "Validation Loss: 2710.4729\n",
      "Epoch [2601/3000], Loss: 143.5275\n",
      "Validation Loss: 2743.1780\n",
      "Epoch [2621/3000], Loss: 129.1113\n",
      "Validation Loss: 2743.1153\n",
      "Epoch [2641/3000], Loss: 126.7900\n",
      "Validation Loss: 2704.2434\n",
      "Epoch [2661/3000], Loss: 130.0770\n",
      "Validation Loss: 2775.8949\n",
      "Epoch [2681/3000], Loss: 195.9374\n",
      "Validation Loss: 2696.1675\n",
      "Epoch [2701/3000], Loss: 126.9787\n",
      "Validation Loss: 2764.5563\n",
      "Epoch [2721/3000], Loss: 120.4304\n",
      "Validation Loss: 2700.7877\n",
      "Epoch [2741/3000], Loss: 117.8695\n",
      "Validation Loss: 2697.4388\n",
      "Epoch [2761/3000], Loss: 111.9106\n",
      "Validation Loss: 2798.5702\n",
      "Epoch [2781/3000], Loss: 107.3500\n",
      "Validation Loss: 2735.8855\n",
      "Epoch [2801/3000], Loss: 112.3281\n",
      "Validation Loss: 2705.6553\n",
      "Epoch [2821/3000], Loss: 105.4918\n",
      "Validation Loss: 2774.5234\n",
      "Epoch [2841/3000], Loss: 95.8299\n",
      "Validation Loss: 2768.2637\n",
      "Epoch [2861/3000], Loss: 99.9864\n",
      "Validation Loss: 2878.7229\n",
      "Epoch [2881/3000], Loss: 85.4241\n",
      "Validation Loss: 2744.7447\n",
      "Epoch [2901/3000], Loss: 77.5147\n",
      "Validation Loss: 2827.5507\n",
      "Epoch [2921/3000], Loss: 67.0844\n",
      "Validation Loss: 2735.7957\n",
      "Epoch [2941/3000], Loss: 63.7353\n",
      "Validation Loss: 2787.6858\n",
      "Epoch [2961/3000], Loss: 66.2266\n",
      "Validation Loss: 2812.8464\n",
      "Epoch [2981/3000], Loss: 64.6319\n",
      "Validation Loss: 2813.4537\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day085_plane0_Fall.mat\n",
      "(2956, 95)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6005.1892\n",
      "Validation Loss: 5692.4615\n",
      "Epoch [21/3000], Loss: 5616.6695\n",
      "Validation Loss: 5350.6355\n",
      "Epoch [41/3000], Loss: 5208.7670\n",
      "Validation Loss: 4935.9929\n",
      "Epoch [61/3000], Loss: 5077.4288\n",
      "Validation Loss: 4832.4271\n",
      "Epoch [81/3000], Loss: 4997.2160\n",
      "Validation Loss: 4766.6223\n",
      "Epoch [101/3000], Loss: 4954.8140\n",
      "Validation Loss: 4713.5922\n",
      "Epoch [121/3000], Loss: 4813.9867\n",
      "Validation Loss: 4665.8051\n",
      "Epoch [141/3000], Loss: 4793.7154\n",
      "Validation Loss: 4620.7993\n",
      "Epoch [161/3000], Loss: 4798.8892\n",
      "Validation Loss: 4577.4023\n",
      "Epoch [181/3000], Loss: 4804.7994\n",
      "Validation Loss: 4536.1295\n",
      "Epoch [201/3000], Loss: 4655.6974\n",
      "Validation Loss: 4496.2866\n",
      "Epoch [221/3000], Loss: 4644.9145\n",
      "Validation Loss: 4457.5959\n",
      "Epoch [241/3000], Loss: 4605.4115\n",
      "Validation Loss: 4419.9085\n",
      "Epoch [261/3000], Loss: 4601.4380\n",
      "Validation Loss: 4382.6768\n",
      "Epoch [281/3000], Loss: 4455.1713\n",
      "Validation Loss: 4346.2653\n",
      "Epoch [301/3000], Loss: 4491.3035\n",
      "Validation Loss: 4310.8883\n",
      "Epoch [321/3000], Loss: 4433.8044\n",
      "Validation Loss: 4276.3086\n",
      "Epoch [341/3000], Loss: 4363.6673\n",
      "Validation Loss: 4242.5380\n",
      "Epoch [361/3000], Loss: 4362.3470\n",
      "Validation Loss: 4209.4802\n",
      "Epoch [381/3000], Loss: 4272.6464\n",
      "Validation Loss: 4176.9986\n",
      "Epoch [401/3000], Loss: 4317.7160\n",
      "Validation Loss: 4145.2435\n",
      "Epoch [421/3000], Loss: 4299.6025\n",
      "Validation Loss: 4114.0259\n",
      "Epoch [441/3000], Loss: 4234.4403\n",
      "Validation Loss: 4083.5046\n",
      "Epoch [461/3000], Loss: 4160.6530\n",
      "Validation Loss: 4053.5946\n",
      "Epoch [481/3000], Loss: 4145.6565\n",
      "Validation Loss: 4024.3193\n",
      "Epoch [501/3000], Loss: 4098.6723\n",
      "Validation Loss: 3995.6086\n",
      "Epoch [521/3000], Loss: 4069.3970\n",
      "Validation Loss: 3967.5292\n",
      "Epoch [541/3000], Loss: 4056.1448\n",
      "Validation Loss: 3939.9482\n",
      "Epoch [561/3000], Loss: 4056.2408\n",
      "Validation Loss: 3913.0610\n",
      "Epoch [581/3000], Loss: 3992.8027\n",
      "Validation Loss: 3886.7192\n",
      "Epoch [601/3000], Loss: 3887.7651\n",
      "Validation Loss: 3860.9532\n",
      "Epoch [621/3000], Loss: 3935.0347\n",
      "Validation Loss: 3835.7554\n",
      "Epoch [641/3000], Loss: 3875.8870\n",
      "Validation Loss: 3811.0823\n",
      "Epoch [661/3000], Loss: 3851.9184\n",
      "Validation Loss: 3787.0446\n",
      "Epoch [681/3000], Loss: 3847.6764\n",
      "Validation Loss: 3763.4723\n",
      "Epoch [701/3000], Loss: 3817.1311\n",
      "Validation Loss: 3740.4796\n",
      "Epoch [721/3000], Loss: 3809.5546\n",
      "Validation Loss: 3717.2755\n",
      "Epoch [741/3000], Loss: 3796.0060\n",
      "Validation Loss: 3695.1158\n",
      "Epoch [761/3000], Loss: 3726.8333\n",
      "Validation Loss: 3673.7460\n",
      "Epoch [781/3000], Loss: 3746.0010\n",
      "Validation Loss: 3652.9360\n",
      "Epoch [801/3000], Loss: 3718.9491\n",
      "Validation Loss: 3632.6784\n",
      "Epoch [821/3000], Loss: 3679.8607\n",
      "Validation Loss: 3612.9150\n",
      "Epoch [841/3000], Loss: 3629.0143\n",
      "Validation Loss: 3593.8069\n",
      "Epoch [861/3000], Loss: 3646.0705\n",
      "Validation Loss: 3575.2303\n",
      "Epoch [881/3000], Loss: 3613.2743\n",
      "Validation Loss: 3557.1257\n",
      "Epoch [901/3000], Loss: 3551.2079\n",
      "Validation Loss: 3539.6351\n",
      "Epoch [921/3000], Loss: 3548.3810\n",
      "Validation Loss: 3522.6577\n",
      "Epoch [941/3000], Loss: 3562.1021\n",
      "Validation Loss: 3506.2228\n",
      "Epoch [961/3000], Loss: 3525.2957\n",
      "Validation Loss: 3490.3631\n",
      "Epoch [981/3000], Loss: 3535.0904\n",
      "Validation Loss: 3475.0728\n",
      "Epoch [1001/3000], Loss: 3438.4490\n",
      "Validation Loss: 3460.2670\n",
      "Epoch [1021/3000], Loss: 3474.3843\n",
      "Validation Loss: 3445.9807\n",
      "Epoch [1041/3000], Loss: 3411.3544\n",
      "Validation Loss: 3432.1792\n",
      "Epoch [1061/3000], Loss: 3398.6815\n",
      "Validation Loss: 3418.9556\n",
      "Epoch [1081/3000], Loss: 3394.9677\n",
      "Validation Loss: 3405.8815\n",
      "Epoch [1101/3000], Loss: 3400.8673\n",
      "Validation Loss: 3393.6022\n",
      "Epoch [1121/3000], Loss: 3387.8024\n",
      "Validation Loss: 3381.3417\n",
      "Epoch [1141/3000], Loss: 3361.2611\n",
      "Validation Loss: 3370.0322\n",
      "Epoch [1161/3000], Loss: 3297.3820\n",
      "Validation Loss: 3359.3666\n",
      "Epoch [1181/3000], Loss: 3325.7851\n",
      "Validation Loss: 3349.1486\n",
      "Epoch [1201/3000], Loss: 3287.2114\n",
      "Validation Loss: 3339.4758\n",
      "Epoch [1221/3000], Loss: 3279.7447\n",
      "Validation Loss: 3330.3049\n",
      "Epoch [1241/3000], Loss: 3276.8426\n",
      "Validation Loss: 3321.6793\n",
      "Epoch [1261/3000], Loss: 3259.1216\n",
      "Validation Loss: 3313.4565\n",
      "Epoch [1281/3000], Loss: 3279.4750\n",
      "Validation Loss: 3305.8079\n",
      "Epoch [1301/3000], Loss: 3229.6992\n",
      "Validation Loss: 3298.6519\n",
      "Epoch [1321/3000], Loss: 3265.9960\n",
      "Validation Loss: 3291.9067\n",
      "Epoch [1341/3000], Loss: 3230.5698\n",
      "Validation Loss: 3285.6705\n",
      "Epoch [1361/3000], Loss: 3228.3113\n",
      "Validation Loss: 3279.8716\n",
      "Epoch [1381/3000], Loss: 3234.2737\n",
      "Validation Loss: 3274.5723\n",
      "Epoch [1401/3000], Loss: 3176.4317\n",
      "Validation Loss: 3269.6725\n",
      "Epoch [1421/3000], Loss: 3189.9414\n",
      "Validation Loss: 3265.2232\n",
      "Epoch [1441/3000], Loss: 3198.9826\n",
      "Validation Loss: 3261.2039\n",
      "Epoch [1461/3000], Loss: 3182.2894\n",
      "Validation Loss: 3257.5898\n",
      "Epoch [1481/3000], Loss: 3170.9046\n",
      "Validation Loss: 3254.3468\n",
      "Epoch [1501/3000], Loss: 3166.1641\n",
      "Validation Loss: 3251.4864\n",
      "Epoch [1521/3000], Loss: 3125.6104\n",
      "Validation Loss: 3249.0640\n",
      "Epoch [1541/3000], Loss: 3166.1517\n",
      "Validation Loss: 3246.9803\n",
      "Epoch [1561/3000], Loss: 3141.0255\n",
      "Validation Loss: 3245.2316\n",
      "Epoch [1581/3000], Loss: 3101.9806\n",
      "Validation Loss: 3243.8537\n",
      "Epoch [1601/3000], Loss: 3144.0366\n",
      "Validation Loss: 3242.7780\n",
      "Epoch [1621/3000], Loss: 3166.8962\n",
      "Validation Loss: 3241.9987\n",
      "Epoch [1641/3000], Loss: 3121.3303\n",
      "Validation Loss: 3241.5106\n",
      "Epoch [1661/3000], Loss: 3128.1415\n",
      "Validation Loss: 3241.2787\n",
      "Epoch [1681/3000], Loss: 3133.3054\n",
      "Validation Loss: 3241.2878\n",
      "Epoch [1701/3000], Loss: 3118.5403\n",
      "Validation Loss: 3241.5137\n",
      "Epoch [1721/3000], Loss: 3133.0504\n",
      "Validation Loss: 3241.9279\n",
      "Epoch [1741/3000], Loss: 3126.4648\n",
      "Validation Loss: 3242.4945\n",
      "Epoch [1761/3000], Loss: 3102.7890\n",
      "Validation Loss: 3243.2086\n",
      "Epoch [1781/3000], Loss: 3135.3482\n",
      "Validation Loss: 3244.0356\n",
      "Epoch [1801/3000], Loss: 3103.0593\n",
      "Validation Loss: 3244.9435\n",
      "Epoch [1821/3000], Loss: 3132.6314\n",
      "Validation Loss: 3245.9207\n",
      "Epoch [1841/3000], Loss: 3124.3528\n",
      "Validation Loss: 3246.8866\n",
      "Epoch [1861/3000], Loss: 2439.7307\n",
      "Validation Loss: 2585.9158\n",
      "Epoch [1881/3000], Loss: 2070.6222\n",
      "Validation Loss: 2233.1108\n",
      "Epoch [1901/3000], Loss: 2046.6182\n",
      "Validation Loss: 2179.4550\n",
      "Epoch [1921/3000], Loss: 2000.4170\n",
      "Validation Loss: 2137.8659\n",
      "Epoch [1941/3000], Loss: 1932.0936\n",
      "Validation Loss: 2110.1236\n",
      "Epoch [1961/3000], Loss: 1906.8129\n",
      "Validation Loss: 2081.8869\n",
      "Epoch [1981/3000], Loss: 1883.7376\n",
      "Validation Loss: 2058.2058\n",
      "Epoch [2001/3000], Loss: 1804.0846\n",
      "Validation Loss: 2032.9322\n",
      "Epoch [2021/3000], Loss: 1800.8297\n",
      "Validation Loss: 2009.0207\n",
      "Epoch [2041/3000], Loss: 1772.3866\n",
      "Validation Loss: 1991.8981\n",
      "Epoch [2061/3000], Loss: 1714.7065\n",
      "Validation Loss: 1968.8899\n",
      "Epoch [2081/3000], Loss: 1711.8202\n",
      "Validation Loss: 1950.7494\n",
      "Epoch [2101/3000], Loss: 1678.4442\n",
      "Validation Loss: 1934.9771\n",
      "Epoch [2121/3000], Loss: 1658.2926\n",
      "Validation Loss: 1916.0745\n",
      "Epoch [2141/3000], Loss: 1611.5416\n",
      "Validation Loss: 1896.2122\n",
      "Epoch [2161/3000], Loss: 1633.2644\n",
      "Validation Loss: 1880.9445\n",
      "Epoch [2181/3000], Loss: 1613.9290\n",
      "Validation Loss: 1862.6651\n",
      "Epoch [2201/3000], Loss: 1586.9468\n",
      "Validation Loss: 1855.5929\n",
      "Epoch [2221/3000], Loss: 1585.2676\n",
      "Validation Loss: 1841.5565\n",
      "Epoch [2241/3000], Loss: 1529.5396\n",
      "Validation Loss: 1821.4662\n",
      "Epoch [2261/3000], Loss: 1545.2834\n",
      "Validation Loss: 1820.1635\n",
      "Epoch [2281/3000], Loss: 1523.7843\n",
      "Validation Loss: 1795.5819\n",
      "Epoch [2301/3000], Loss: 1493.2732\n",
      "Validation Loss: 1772.3420\n",
      "Epoch [2321/3000], Loss: 1459.7050\n",
      "Validation Loss: 1754.1762\n",
      "Epoch [2341/3000], Loss: 1470.7599\n",
      "Validation Loss: 1717.3070\n",
      "Epoch [2361/3000], Loss: 1413.2104\n",
      "Validation Loss: 1706.8085\n",
      "Epoch [2381/3000], Loss: 1388.3954\n",
      "Validation Loss: 1685.6792\n",
      "Epoch [2401/3000], Loss: 1368.3405\n",
      "Validation Loss: 1674.4575\n",
      "Epoch [2421/3000], Loss: 1365.0757\n",
      "Validation Loss: 1672.9837\n",
      "Epoch [2441/3000], Loss: 1351.6626\n",
      "Validation Loss: 1640.8033\n",
      "Epoch [2461/3000], Loss: 1324.9756\n",
      "Validation Loss: 1629.0962\n",
      "Epoch [2481/3000], Loss: 1323.8146\n",
      "Validation Loss: 1634.7656\n",
      "Epoch [2501/3000], Loss: 1309.1949\n",
      "Validation Loss: 1603.8806\n",
      "Epoch [2521/3000], Loss: 1282.8398\n",
      "Validation Loss: 1589.8568\n",
      "Epoch [2541/3000], Loss: 1268.9707\n",
      "Validation Loss: 1581.2580\n",
      "Epoch [2561/3000], Loss: 1264.8256\n",
      "Validation Loss: 1567.7122\n",
      "Epoch [2581/3000], Loss: 1230.1779\n",
      "Validation Loss: 1564.3737\n",
      "Epoch [2601/3000], Loss: 1237.4064\n",
      "Validation Loss: 1549.1484\n",
      "Epoch [2621/3000], Loss: 1222.0885\n",
      "Validation Loss: 1533.3316\n",
      "Epoch [2641/3000], Loss: 1167.3972\n",
      "Validation Loss: 1529.7052\n",
      "Epoch [2661/3000], Loss: 1159.7001\n",
      "Validation Loss: 1520.8631\n",
      "Epoch [2681/3000], Loss: 1152.5334\n",
      "Validation Loss: 1542.0380\n",
      "Epoch [2701/3000], Loss: 1136.4401\n",
      "Validation Loss: 1492.0025\n",
      "Epoch [2721/3000], Loss: 1101.6770\n",
      "Validation Loss: 1485.7026\n",
      "Epoch [2741/3000], Loss: 1111.7409\n",
      "Validation Loss: 1460.6566\n",
      "Epoch [2761/3000], Loss: 1098.0662\n",
      "Validation Loss: 1454.6923\n",
      "Epoch [2781/3000], Loss: 1074.2875\n",
      "Validation Loss: 1445.1789\n",
      "Epoch [2801/3000], Loss: 1072.5619\n",
      "Validation Loss: 1442.7506\n",
      "Epoch [2821/3000], Loss: 1047.5167\n",
      "Validation Loss: 1432.5195\n",
      "Epoch [2841/3000], Loss: 1034.3742\n",
      "Validation Loss: 1422.5199\n",
      "Epoch [2861/3000], Loss: 1030.7755\n",
      "Validation Loss: 1418.1772\n",
      "Epoch [2881/3000], Loss: 1012.1321\n",
      "Validation Loss: 1412.7483\n",
      "Epoch [2901/3000], Loss: 991.5885\n",
      "Validation Loss: 1401.3947\n",
      "Epoch [2921/3000], Loss: 986.4408\n",
      "Validation Loss: 1391.4283\n",
      "Epoch [2941/3000], Loss: 968.5350\n",
      "Validation Loss: 1390.8168\n",
      "Epoch [2961/3000], Loss: 956.0135\n",
      "Validation Loss: 1375.9950\n",
      "Epoch [2981/3000], Loss: 960.6385\n",
      "Validation Loss: 1366.9129\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day086_plane0_Fall.mat\n",
      "(7932, 123)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8492.8117\n",
      "Validation Loss: 6502.7808\n",
      "Epoch [21/3000], Loss: 7322.5196\n",
      "Validation Loss: 5596.5761\n",
      "Epoch [41/3000], Loss: 7126.6484\n",
      "Validation Loss: 5415.7558\n",
      "Epoch [61/3000], Loss: 6921.1746\n",
      "Validation Loss: 5279.9906\n",
      "Epoch [81/3000], Loss: 6733.1052\n",
      "Validation Loss: 5157.4033\n",
      "Epoch [101/3000], Loss: 6620.2970\n",
      "Validation Loss: 5040.3249\n",
      "Epoch [121/3000], Loss: 6491.8227\n",
      "Validation Loss: 4931.2506\n",
      "Epoch [141/3000], Loss: 6335.2715\n",
      "Validation Loss: 4827.7877\n",
      "Epoch [161/3000], Loss: 6183.3027\n",
      "Validation Loss: 4729.4100\n",
      "Epoch [181/3000], Loss: 6081.3417\n",
      "Validation Loss: 4635.6070\n",
      "Epoch [201/3000], Loss: 5971.3601\n",
      "Validation Loss: 4546.3891\n",
      "Epoch [221/3000], Loss: 5812.7958\n",
      "Validation Loss: 4461.5455\n",
      "Epoch [241/3000], Loss: 5696.9401\n",
      "Validation Loss: 4380.2676\n",
      "Epoch [261/3000], Loss: 5574.2086\n",
      "Validation Loss: 4303.6307\n",
      "Epoch [281/3000], Loss: 5507.5394\n",
      "Validation Loss: 4231.5318\n",
      "Epoch [301/3000], Loss: 5360.8100\n",
      "Validation Loss: 4163.8374\n",
      "Epoch [321/3000], Loss: 5282.1291\n",
      "Validation Loss: 4100.3874\n",
      "Epoch [341/3000], Loss: 5179.0687\n",
      "Validation Loss: 4041.1515\n",
      "Epoch [361/3000], Loss: 5090.4310\n",
      "Validation Loss: 3986.0197\n",
      "Epoch [381/3000], Loss: 5008.5679\n",
      "Validation Loss: 3934.8914\n",
      "Epoch [401/3000], Loss: 4937.3689\n",
      "Validation Loss: 3887.6310\n",
      "Epoch [421/3000], Loss: 4863.0833\n",
      "Validation Loss: 3844.8952\n",
      "Epoch [441/3000], Loss: 4772.2370\n",
      "Validation Loss: 3806.3429\n",
      "Epoch [461/3000], Loss: 4686.8378\n",
      "Validation Loss: 3771.8549\n",
      "Epoch [481/3000], Loss: 4644.4623\n",
      "Validation Loss: 3740.9661\n",
      "Epoch [501/3000], Loss: 4578.2889\n",
      "Validation Loss: 3714.2142\n",
      "Epoch [521/3000], Loss: 4521.1371\n",
      "Validation Loss: 3691.5862\n",
      "Epoch [541/3000], Loss: 4469.7691\n",
      "Validation Loss: 3672.8821\n",
      "Epoch [561/3000], Loss: 4413.3184\n",
      "Validation Loss: 3657.9222\n",
      "Epoch [581/3000], Loss: 4391.6355\n",
      "Validation Loss: 3646.6208\n",
      "Epoch [601/3000], Loss: 4344.8805\n",
      "Validation Loss: 3638.9239\n",
      "Epoch [621/3000], Loss: 4303.0421\n",
      "Validation Loss: 3634.6834\n",
      "Epoch [641/3000], Loss: 4267.9067\n",
      "Validation Loss: 3633.7428\n",
      "Epoch [661/3000], Loss: 4224.0670\n",
      "Validation Loss: 3635.9217\n",
      "Epoch [681/3000], Loss: 4220.9776\n",
      "Validation Loss: 3641.0269\n",
      "Epoch [701/3000], Loss: 4185.8217\n",
      "Validation Loss: 3648.7339\n",
      "Epoch [721/3000], Loss: 4175.3648\n",
      "Validation Loss: 3658.7752\n",
      "Epoch [741/3000], Loss: 4164.0969\n",
      "Validation Loss: 3670.6572\n",
      "Epoch [761/3000], Loss: 4145.3388\n",
      "Validation Loss: 3683.9959\n",
      "Epoch [781/3000], Loss: 4135.5841\n",
      "Validation Loss: 3698.4328\n",
      "Epoch [801/3000], Loss: 4144.8006\n",
      "Validation Loss: 3713.2311\n",
      "Epoch [821/3000], Loss: 3313.3125\n",
      "Validation Loss: 2345.1805\n",
      "Epoch [841/3000], Loss: 2837.1172\n",
      "Validation Loss: 2152.7737\n",
      "Epoch [861/3000], Loss: 2669.1032\n",
      "Validation Loss: 2075.2831\n",
      "Epoch [881/3000], Loss: 2537.2021\n",
      "Validation Loss: 2012.4130\n",
      "Epoch [901/3000], Loss: 2431.0124\n",
      "Validation Loss: 1990.5055\n",
      "Epoch [921/3000], Loss: 2334.2448\n",
      "Validation Loss: 1926.1801\n",
      "Epoch [941/3000], Loss: 2242.2485\n",
      "Validation Loss: 1879.4617\n",
      "Epoch [961/3000], Loss: 2162.0701\n",
      "Validation Loss: 1826.5131\n",
      "Epoch [981/3000], Loss: 2077.0504\n",
      "Validation Loss: 1780.9602\n",
      "Epoch [1001/3000], Loss: 1990.1530\n",
      "Validation Loss: 1742.7996\n",
      "Epoch [1021/3000], Loss: 1910.9137\n",
      "Validation Loss: 1694.2026\n",
      "Epoch [1041/3000], Loss: 1827.3151\n",
      "Validation Loss: 1657.9155\n",
      "Epoch [1061/3000], Loss: 1744.7224\n",
      "Validation Loss: 1625.9038\n",
      "Epoch [1081/3000], Loss: 1679.7595\n",
      "Validation Loss: 1589.2657\n",
      "Epoch [1101/3000], Loss: 1598.7432\n",
      "Validation Loss: 1563.9771\n",
      "Epoch [1121/3000], Loss: 1538.8066\n",
      "Validation Loss: 1554.9186\n",
      "Epoch [1141/3000], Loss: 1472.4619\n",
      "Validation Loss: 1518.6925\n",
      "Epoch [1161/3000], Loss: 1404.8831\n",
      "Validation Loss: 1477.6650\n",
      "Epoch [1181/3000], Loss: 1344.7612\n",
      "Validation Loss: 1450.5179\n",
      "Epoch [1201/3000], Loss: 1288.1726\n",
      "Validation Loss: 1426.1537\n",
      "Epoch [1221/3000], Loss: 1232.6605\n",
      "Validation Loss: 1390.7759\n",
      "Epoch [1241/3000], Loss: 1175.6793\n",
      "Validation Loss: 1380.5879\n",
      "Epoch [1261/3000], Loss: 1110.2723\n",
      "Validation Loss: 1347.0753\n",
      "Epoch [1281/3000], Loss: 1070.8602\n",
      "Validation Loss: 1333.0056\n",
      "Epoch [1301/3000], Loss: 1019.6184\n",
      "Validation Loss: 1316.9787\n",
      "Epoch [1321/3000], Loss: 967.9938\n",
      "Validation Loss: 1292.5095\n",
      "Epoch [1341/3000], Loss: 919.8937\n",
      "Validation Loss: 1272.9681\n",
      "Epoch [1361/3000], Loss: 876.7945\n",
      "Validation Loss: 1254.6604\n",
      "Epoch [1381/3000], Loss: 831.7137\n",
      "Validation Loss: 1248.2459\n",
      "Epoch [1401/3000], Loss: 787.2771\n",
      "Validation Loss: 1229.6191\n",
      "Epoch [1421/3000], Loss: 745.8658\n",
      "Validation Loss: 1238.4971\n",
      "Epoch [1441/3000], Loss: 708.6250\n",
      "Validation Loss: 1212.1671\n",
      "Epoch [1461/3000], Loss: 676.4290\n",
      "Validation Loss: 1197.7780\n",
      "Epoch [1481/3000], Loss: 629.8719\n",
      "Validation Loss: 1190.8194\n",
      "Epoch [1501/3000], Loss: 625.1823\n",
      "Validation Loss: 1156.7515\n",
      "Epoch [1521/3000], Loss: 562.6277\n",
      "Validation Loss: 1183.6800\n",
      "Epoch [1541/3000], Loss: 532.0813\n",
      "Validation Loss: 1161.0879\n",
      "Epoch [1561/3000], Loss: 497.1069\n",
      "Validation Loss: 1162.4102\n",
      "Epoch [1581/3000], Loss: 464.0900\n",
      "Validation Loss: 1146.6371\n",
      "Epoch [1601/3000], Loss: 440.2477\n",
      "Validation Loss: 1141.8362\n",
      "Epoch [1621/3000], Loss: 413.4419\n",
      "Validation Loss: 1142.5074\n",
      "Epoch [1641/3000], Loss: 385.1750\n",
      "Validation Loss: 1151.2021\n",
      "Epoch [1661/3000], Loss: 364.7116\n",
      "Validation Loss: 1117.5828\n",
      "Epoch [1681/3000], Loss: 340.4357\n",
      "Validation Loss: 1098.8239\n",
      "Epoch [1701/3000], Loss: 328.9049\n",
      "Validation Loss: 1141.4947\n",
      "Epoch [1721/3000], Loss: 305.9000\n",
      "Validation Loss: 1129.9632\n",
      "Epoch [1741/3000], Loss: 289.5224\n",
      "Validation Loss: 1124.5519\n",
      "Epoch [1761/3000], Loss: 272.2686\n",
      "Validation Loss: 1064.1175\n",
      "Epoch [1781/3000], Loss: 259.0971\n",
      "Validation Loss: 1066.4581\n",
      "Epoch [1801/3000], Loss: 244.7540\n",
      "Validation Loss: 1111.9261\n",
      "Epoch [1821/3000], Loss: 235.5405\n",
      "Validation Loss: 1053.9753\n",
      "Epoch [1841/3000], Loss: 219.8827\n",
      "Validation Loss: 1113.6116\n",
      "Epoch [1861/3000], Loss: 209.3255\n",
      "Validation Loss: 1086.1506\n",
      "Epoch [1881/3000], Loss: 201.1628\n",
      "Validation Loss: 1084.3812\n",
      "Epoch [1901/3000], Loss: 197.8096\n",
      "Validation Loss: 1016.2448\n",
      "Epoch [1921/3000], Loss: 177.2580\n",
      "Validation Loss: 1102.5170\n",
      "Epoch [1941/3000], Loss: 162.3043\n",
      "Validation Loss: 1116.9148\n",
      "Epoch [1961/3000], Loss: 273.3672\n",
      "Validation Loss: 1024.0128\n",
      "Epoch [1981/3000], Loss: 149.3435\n",
      "Validation Loss: 1138.3788\n",
      "Epoch [2001/3000], Loss: 144.1174\n",
      "Validation Loss: 1115.2162\n",
      "Epoch [2021/3000], Loss: 112.6210\n",
      "Validation Loss: 1132.0255\n",
      "Epoch [2041/3000], Loss: 93.2025\n",
      "Validation Loss: 1049.6487\n",
      "Epoch [2061/3000], Loss: 83.9114\n",
      "Validation Loss: 1048.9130\n",
      "Epoch [2081/3000], Loss: 77.6524\n",
      "Validation Loss: 1059.2952\n",
      "Epoch [2101/3000], Loss: 74.1623\n",
      "Validation Loss: 1031.3569\n",
      "Epoch [2121/3000], Loss: 69.9987\n",
      "Validation Loss: 1017.2359\n",
      "Epoch [2141/3000], Loss: 66.4472\n",
      "Validation Loss: 975.3211\n",
      "Epoch [2161/3000], Loss: 63.5685\n",
      "Validation Loss: 955.2085\n",
      "Epoch [2181/3000], Loss: 55.7644\n",
      "Validation Loss: 1000.3429\n",
      "Epoch [2201/3000], Loss: 51.6256\n",
      "Validation Loss: 992.2870\n",
      "Epoch [2221/3000], Loss: 50.7558\n",
      "Validation Loss: 936.4364\n",
      "Epoch [2241/3000], Loss: 45.1207\n",
      "Validation Loss: 956.9259\n",
      "Epoch [2261/3000], Loss: 43.0716\n",
      "Validation Loss: 957.8036\n",
      "Epoch [2281/3000], Loss: 40.8509\n",
      "Validation Loss: 940.3317\n",
      "Epoch [2301/3000], Loss: 38.1588\n",
      "Validation Loss: 952.1594\n",
      "Epoch [2321/3000], Loss: 35.6742\n",
      "Validation Loss: 954.8184\n",
      "Epoch [2341/3000], Loss: 35.3106\n",
      "Validation Loss: 940.9955\n",
      "Epoch [2361/3000], Loss: 31.3482\n",
      "Validation Loss: 910.7546\n",
      "Epoch [2381/3000], Loss: 29.0857\n",
      "Validation Loss: 913.4086\n",
      "Epoch [2401/3000], Loss: 26.3595\n",
      "Validation Loss: 960.6437\n",
      "Epoch [2421/3000], Loss: 25.1492\n",
      "Validation Loss: 962.8978\n",
      "Epoch [2441/3000], Loss: 24.2886\n",
      "Validation Loss: 945.6511\n",
      "Epoch [2461/3000], Loss: 23.0199\n",
      "Validation Loss: 948.2125\n",
      "Epoch [2481/3000], Loss: 21.7014\n",
      "Validation Loss: 945.1308\n",
      "Epoch [2501/3000], Loss: 20.0004\n",
      "Validation Loss: 928.9206\n",
      "Epoch [2521/3000], Loss: 19.4989\n",
      "Validation Loss: 936.0905\n",
      "Epoch [2541/3000], Loss: 18.3990\n",
      "Validation Loss: 928.9016\n",
      "Epoch [2561/3000], Loss: 17.4537\n",
      "Validation Loss: 911.9989\n",
      "Epoch [2581/3000], Loss: 16.7478\n",
      "Validation Loss: 919.0263\n",
      "Epoch [2601/3000], Loss: 15.6994\n",
      "Validation Loss: 915.5512\n",
      "Epoch [2621/3000], Loss: 14.6651\n",
      "Validation Loss: 914.9097\n",
      "Epoch [2641/3000], Loss: 14.4252\n",
      "Validation Loss: 928.2085\n",
      "Epoch [2661/3000], Loss: 12.7842\n",
      "Validation Loss: 926.0468\n",
      "Epoch [2681/3000], Loss: 12.0816\n",
      "Validation Loss: 917.7869\n",
      "Epoch [2701/3000], Loss: 11.5003\n",
      "Validation Loss: 902.7886\n",
      "Epoch [2721/3000], Loss: 11.0828\n",
      "Validation Loss: 902.5329\n",
      "Epoch [2741/3000], Loss: 9.9371\n",
      "Validation Loss: 911.4866\n",
      "Epoch [2761/3000], Loss: 9.7223\n",
      "Validation Loss: 916.6800\n",
      "Epoch [2781/3000], Loss: 8.3664\n",
      "Validation Loss: 903.2347\n",
      "Epoch [2801/3000], Loss: 7.9443\n",
      "Validation Loss: 902.9045\n",
      "Epoch [2821/3000], Loss: 7.5013\n",
      "Validation Loss: 908.5827\n",
      "Epoch [2841/3000], Loss: 7.1312\n",
      "Validation Loss: 924.0306\n",
      "Epoch [2861/3000], Loss: 7.0051\n",
      "Validation Loss: 912.6931\n",
      "Epoch [2881/3000], Loss: 6.7472\n",
      "Validation Loss: 901.6774\n",
      "Epoch [2901/3000], Loss: 6.2568\n",
      "Validation Loss: 927.7274\n",
      "Epoch [2921/3000], Loss: 5.8633\n",
      "Validation Loss: 902.4130\n",
      "Epoch [2941/3000], Loss: 5.5449\n",
      "Validation Loss: 932.1929\n",
      "Epoch [2961/3000], Loss: 6.1114\n",
      "Validation Loss: 970.2984\n",
      "Epoch [2981/3000], Loss: 4.7208\n",
      "Validation Loss: 936.8124\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day087_plane0_Fall.mat\n",
      "(4407, 88)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6383.7150\n",
      "Validation Loss: 6189.2640\n",
      "Epoch [21/3000], Loss: 5515.5736\n",
      "Validation Loss: 5362.6231\n",
      "Epoch [41/3000], Loss: 5288.4274\n",
      "Validation Loss: 5130.0540\n",
      "Epoch [61/3000], Loss: 5174.2375\n",
      "Validation Loss: 5014.9757\n",
      "Epoch [81/3000], Loss: 5080.3440\n",
      "Validation Loss: 4921.2388\n",
      "Epoch [101/3000], Loss: 4972.3988\n",
      "Validation Loss: 4835.6929\n",
      "Epoch [121/3000], Loss: 4902.5068\n",
      "Validation Loss: 4754.4917\n",
      "Epoch [141/3000], Loss: 4814.0890\n",
      "Validation Loss: 4677.1430\n",
      "Epoch [161/3000], Loss: 4749.2212\n",
      "Validation Loss: 4602.6581\n",
      "Epoch [181/3000], Loss: 4674.3829\n",
      "Validation Loss: 4530.3923\n",
      "Epoch [201/3000], Loss: 4578.6909\n",
      "Validation Loss: 4459.6542\n",
      "Epoch [221/3000], Loss: 4529.6036\n",
      "Validation Loss: 4390.8642\n",
      "Epoch [241/3000], Loss: 4445.7812\n",
      "Validation Loss: 4323.9673\n",
      "Epoch [261/3000], Loss: 4409.1231\n",
      "Validation Loss: 4258.7319\n",
      "Epoch [281/3000], Loss: 4324.5652\n",
      "Validation Loss: 4195.1438\n",
      "Epoch [301/3000], Loss: 4255.3060\n",
      "Validation Loss: 4133.0057\n",
      "Epoch [321/3000], Loss: 4198.2965\n",
      "Validation Loss: 4072.4678\n",
      "Epoch [341/3000], Loss: 4125.8492\n",
      "Validation Loss: 4013.3647\n",
      "Epoch [361/3000], Loss: 4072.6757\n",
      "Validation Loss: 3955.6593\n",
      "Epoch [381/3000], Loss: 4025.7677\n",
      "Validation Loss: 3899.4669\n",
      "Epoch [401/3000], Loss: 3961.4445\n",
      "Validation Loss: 3844.6636\n",
      "Epoch [421/3000], Loss: 3897.0836\n",
      "Validation Loss: 3791.3004\n",
      "Epoch [441/3000], Loss: 3862.9869\n",
      "Validation Loss: 3739.2395\n",
      "Epoch [461/3000], Loss: 3801.5950\n",
      "Validation Loss: 3688.6057\n",
      "Epoch [481/3000], Loss: 3758.9819\n",
      "Validation Loss: 3639.3707\n",
      "Epoch [501/3000], Loss: 3691.2397\n",
      "Validation Loss: 3591.5429\n",
      "Epoch [521/3000], Loss: 3654.5436\n",
      "Validation Loss: 3545.0904\n",
      "Epoch [541/3000], Loss: 3587.9559\n",
      "Validation Loss: 3499.9801\n",
      "Epoch [561/3000], Loss: 3560.7458\n",
      "Validation Loss: 3456.2093\n",
      "Epoch [581/3000], Loss: 3521.0336\n",
      "Validation Loss: 3413.7933\n",
      "Epoch [601/3000], Loss: 3469.8778\n",
      "Validation Loss: 3372.7560\n",
      "Epoch [621/3000], Loss: 3428.0542\n",
      "Validation Loss: 3333.0875\n",
      "Epoch [641/3000], Loss: 3392.9197\n",
      "Validation Loss: 3294.6974\n",
      "Epoch [661/3000], Loss: 3342.0822\n",
      "Validation Loss: 3257.6539\n",
      "Epoch [681/3000], Loss: 3314.4474\n",
      "Validation Loss: 3222.0249\n",
      "Epoch [701/3000], Loss: 3274.9402\n",
      "Validation Loss: 3187.6972\n",
      "Epoch [721/3000], Loss: 3233.6988\n",
      "Validation Loss: 3154.6654\n",
      "Epoch [741/3000], Loss: 3205.4693\n",
      "Validation Loss: 3122.9945\n",
      "Epoch [761/3000], Loss: 3166.4556\n",
      "Validation Loss: 3092.6273\n",
      "Epoch [781/3000], Loss: 3139.8066\n",
      "Validation Loss: 3063.5893\n",
      "Epoch [801/3000], Loss: 3110.3890\n",
      "Validation Loss: 3035.8325\n",
      "Epoch [821/3000], Loss: 3086.4848\n",
      "Validation Loss: 3009.3317\n",
      "Epoch [841/3000], Loss: 3054.8621\n",
      "Validation Loss: 2984.0969\n",
      "Epoch [861/3000], Loss: 3020.7466\n",
      "Validation Loss: 2960.1009\n",
      "Epoch [881/3000], Loss: 3011.9122\n",
      "Validation Loss: 2937.4107\n",
      "Epoch [901/3000], Loss: 2985.9087\n",
      "Validation Loss: 2915.9925\n",
      "Epoch [921/3000], Loss: 2952.3799\n",
      "Validation Loss: 2895.8118\n",
      "Epoch [941/3000], Loss: 2938.6783\n",
      "Validation Loss: 2876.8776\n",
      "Epoch [961/3000], Loss: 2914.6340\n",
      "Validation Loss: 2859.1111\n",
      "Epoch [981/3000], Loss: 2898.7101\n",
      "Validation Loss: 2842.5923\n",
      "Epoch [1001/3000], Loss: 2873.2359\n",
      "Validation Loss: 2827.2284\n",
      "Epoch [1021/3000], Loss: 2856.6920\n",
      "Validation Loss: 2813.0636\n",
      "Epoch [1041/3000], Loss: 2850.6542\n",
      "Validation Loss: 2800.0106\n",
      "Epoch [1061/3000], Loss: 2845.3398\n",
      "Validation Loss: 2788.0664\n",
      "Epoch [1081/3000], Loss: 2827.2213\n",
      "Validation Loss: 2777.2260\n",
      "Epoch [1101/3000], Loss: 2807.8692\n",
      "Validation Loss: 2767.4875\n",
      "Epoch [1121/3000], Loss: 2797.4214\n",
      "Validation Loss: 2758.7444\n",
      "Epoch [1141/3000], Loss: 2792.1529\n",
      "Validation Loss: 2750.9958\n",
      "Epoch [1161/3000], Loss: 2790.9943\n",
      "Validation Loss: 2744.2395\n",
      "Epoch [1181/3000], Loss: 2770.5026\n",
      "Validation Loss: 2738.3833\n",
      "Epoch [1201/3000], Loss: 2769.9018\n",
      "Validation Loss: 2733.2056\n",
      "Epoch [1221/3000], Loss: 1985.0578\n",
      "Validation Loss: 1960.9108\n",
      "Epoch [1241/3000], Loss: 1844.2284\n",
      "Validation Loss: 1927.7950\n",
      "Epoch [1261/3000], Loss: 1751.7873\n",
      "Validation Loss: 1892.0081\n",
      "Epoch [1281/3000], Loss: 1690.7153\n",
      "Validation Loss: 1857.7482\n",
      "Epoch [1301/3000], Loss: 1633.8021\n",
      "Validation Loss: 1828.7027\n",
      "Epoch [1321/3000], Loss: 1586.9249\n",
      "Validation Loss: 1797.5457\n",
      "Epoch [1341/3000], Loss: 1537.9313\n",
      "Validation Loss: 1771.3218\n",
      "Epoch [1361/3000], Loss: 1490.4228\n",
      "Validation Loss: 1750.9181\n",
      "Epoch [1381/3000], Loss: 1451.6145\n",
      "Validation Loss: 1729.1641\n",
      "Epoch [1401/3000], Loss: 1419.7851\n",
      "Validation Loss: 1717.4427\n",
      "Epoch [1421/3000], Loss: 1384.1388\n",
      "Validation Loss: 1686.3327\n",
      "Epoch [1441/3000], Loss: 1364.0184\n",
      "Validation Loss: 1660.3779\n",
      "Epoch [1461/3000], Loss: 1314.2846\n",
      "Validation Loss: 1652.7453\n",
      "Epoch [1481/3000], Loss: 1280.6335\n",
      "Validation Loss: 1628.4392\n",
      "Epoch [1501/3000], Loss: 1240.9338\n",
      "Validation Loss: 1597.6841\n",
      "Epoch [1521/3000], Loss: 1221.9412\n",
      "Validation Loss: 1579.4790\n",
      "Epoch [1541/3000], Loss: 1178.5473\n",
      "Validation Loss: 1550.0580\n",
      "Epoch [1561/3000], Loss: 1147.1161\n",
      "Validation Loss: 1535.4360\n",
      "Epoch [1581/3000], Loss: 1119.6824\n",
      "Validation Loss: 1523.3449\n",
      "Epoch [1601/3000], Loss: 1086.9843\n",
      "Validation Loss: 1504.4221\n",
      "Epoch [1621/3000], Loss: 1065.4215\n",
      "Validation Loss: 1473.7179\n",
      "Epoch [1641/3000], Loss: 1032.4171\n",
      "Validation Loss: 1468.1645\n",
      "Epoch [1661/3000], Loss: 1001.4996\n",
      "Validation Loss: 1458.2599\n",
      "Epoch [1681/3000], Loss: 973.8201\n",
      "Validation Loss: 1458.7914\n",
      "Epoch [1701/3000], Loss: 943.1342\n",
      "Validation Loss: 1432.8553\n",
      "Epoch [1721/3000], Loss: 917.4225\n",
      "Validation Loss: 1435.2950\n",
      "Epoch [1741/3000], Loss: 885.5707\n",
      "Validation Loss: 1452.6910\n",
      "Epoch [1761/3000], Loss: 864.1324\n",
      "Validation Loss: 1412.9542\n",
      "Epoch [1781/3000], Loss: 833.8289\n",
      "Validation Loss: 1415.0296\n",
      "Epoch [1801/3000], Loss: 818.2932\n",
      "Validation Loss: 1377.4366\n",
      "Epoch [1821/3000], Loss: 789.6223\n",
      "Validation Loss: 1374.1362\n",
      "Epoch [1841/3000], Loss: 767.6397\n",
      "Validation Loss: 1349.9346\n",
      "Epoch [1861/3000], Loss: 751.1061\n",
      "Validation Loss: 1341.8502\n",
      "Epoch [1881/3000], Loss: 738.0584\n",
      "Validation Loss: 1338.2221\n",
      "Epoch [1901/3000], Loss: 708.8007\n",
      "Validation Loss: 1322.0226\n",
      "Epoch [1921/3000], Loss: 682.1756\n",
      "Validation Loss: 1315.2562\n",
      "Epoch [1941/3000], Loss: 665.0788\n",
      "Validation Loss: 1305.0274\n",
      "Epoch [1961/3000], Loss: 640.0724\n",
      "Validation Loss: 1275.9854\n",
      "Epoch [1981/3000], Loss: 623.6854\n",
      "Validation Loss: 1271.0950\n",
      "Epoch [2001/3000], Loss: 611.4812\n",
      "Validation Loss: 1270.4226\n",
      "Epoch [2021/3000], Loss: 593.6606\n",
      "Validation Loss: 1241.1764\n",
      "Epoch [2041/3000], Loss: 576.4109\n",
      "Validation Loss: 1238.8947\n",
      "Epoch [2061/3000], Loss: 563.5108\n",
      "Validation Loss: 1218.7649\n",
      "Epoch [2081/3000], Loss: 546.6228\n",
      "Validation Loss: 1215.0076\n",
      "Epoch [2101/3000], Loss: 532.3481\n",
      "Validation Loss: 1190.3985\n",
      "Epoch [2121/3000], Loss: 509.7285\n",
      "Validation Loss: 1196.1508\n",
      "Epoch [2141/3000], Loss: 495.8685\n",
      "Validation Loss: 1190.6055\n",
      "Epoch [2161/3000], Loss: 505.4674\n",
      "Validation Loss: 1270.8188\n",
      "Epoch [2181/3000], Loss: 483.1533\n",
      "Validation Loss: 1194.0213\n",
      "Epoch [2201/3000], Loss: 458.7557\n",
      "Validation Loss: 1181.4059\n",
      "Epoch [2221/3000], Loss: 446.6928\n",
      "Validation Loss: 1159.6466\n",
      "Epoch [2241/3000], Loss: 434.8395\n",
      "Validation Loss: 1155.5985\n",
      "Epoch [2261/3000], Loss: 425.8918\n",
      "Validation Loss: 1147.9712\n",
      "Epoch [2281/3000], Loss: 417.1594\n",
      "Validation Loss: 1145.7480\n",
      "Epoch [2301/3000], Loss: 402.4804\n",
      "Validation Loss: 1146.8811\n",
      "Epoch [2321/3000], Loss: 393.6094\n",
      "Validation Loss: 1143.1406\n",
      "Epoch [2341/3000], Loss: 385.9438\n",
      "Validation Loss: 1144.6975\n",
      "Epoch [2361/3000], Loss: 376.1820\n",
      "Validation Loss: 1150.7036\n",
      "Epoch [2381/3000], Loss: 365.8551\n",
      "Validation Loss: 1149.5692\n",
      "Epoch [2401/3000], Loss: 356.1985\n",
      "Validation Loss: 1155.6162\n",
      "Epoch [2421/3000], Loss: 366.3691\n",
      "Validation Loss: 1202.7186\n",
      "Epoch [2441/3000], Loss: 334.0149\n",
      "Validation Loss: 1163.5712\n",
      "Epoch [2461/3000], Loss: 326.1728\n",
      "Validation Loss: 1153.0421\n",
      "Epoch [2481/3000], Loss: 318.0909\n",
      "Validation Loss: 1168.7579\n",
      "Epoch [2501/3000], Loss: 312.7476\n",
      "Validation Loss: 1160.7298\n",
      "Epoch [2521/3000], Loss: 303.7737\n",
      "Validation Loss: 1167.6839\n",
      "Epoch [2541/3000], Loss: 292.5258\n",
      "Validation Loss: 1152.4085\n",
      "Epoch [2561/3000], Loss: 288.2847\n",
      "Validation Loss: 1152.9702\n",
      "Epoch [2581/3000], Loss: 279.6565\n",
      "Validation Loss: 1150.7718\n",
      "Epoch [2601/3000], Loss: 270.1345\n",
      "Validation Loss: 1160.0176\n",
      "Epoch [2621/3000], Loss: 265.1273\n",
      "Validation Loss: 1147.3088\n",
      "Epoch [2641/3000], Loss: 259.3364\n",
      "Validation Loss: 1157.9572\n",
      "Epoch [2661/3000], Loss: 251.3539\n",
      "Validation Loss: 1158.8303\n",
      "Epoch [2681/3000], Loss: 247.5319\n",
      "Validation Loss: 1159.7065\n",
      "Epoch [2701/3000], Loss: 238.8888\n",
      "Validation Loss: 1159.7347\n",
      "Epoch [2721/3000], Loss: 235.3482\n",
      "Validation Loss: 1153.6482\n",
      "Epoch [2741/3000], Loss: 231.4450\n",
      "Validation Loss: 1150.1690\n",
      "Epoch [2761/3000], Loss: 221.0071\n",
      "Validation Loss: 1165.9068\n",
      "Epoch [2781/3000], Loss: 216.5125\n",
      "Validation Loss: 1152.6997\n",
      "Epoch [2801/3000], Loss: 207.6269\n",
      "Validation Loss: 1148.2499\n",
      "Epoch [2821/3000], Loss: 197.4455\n",
      "Validation Loss: 1148.6817\n",
      "Epoch [2841/3000], Loss: 188.2317\n",
      "Validation Loss: 1141.1221\n",
      "Epoch [2861/3000], Loss: 182.1701\n",
      "Validation Loss: 1133.8733\n",
      "Epoch [2881/3000], Loss: 177.8178\n",
      "Validation Loss: 1129.8959\n",
      "Epoch [2901/3000], Loss: 170.2832\n",
      "Validation Loss: 1141.8734\n",
      "Epoch [2921/3000], Loss: 165.9933\n",
      "Validation Loss: 1106.7108\n",
      "Epoch [2941/3000], Loss: 156.5794\n",
      "Validation Loss: 1105.5618\n",
      "Epoch [2961/3000], Loss: 155.7964\n",
      "Validation Loss: 1114.0557\n",
      "Epoch [2981/3000], Loss: 151.2343\n",
      "Validation Loss: 1113.3238\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day088_plane0_Fall.mat\n",
      "(4617, 123)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9780.9535\n",
      "Validation Loss: 7022.6236\n",
      "Epoch [21/3000], Loss: 8739.1405\n",
      "Validation Loss: 6242.1684\n",
      "Epoch [41/3000], Loss: 8465.3791\n",
      "Validation Loss: 6027.9420\n",
      "Epoch [61/3000], Loss: 8298.1824\n",
      "Validation Loss: 5907.4189\n",
      "Epoch [81/3000], Loss: 8128.3350\n",
      "Validation Loss: 5817.9994\n",
      "Epoch [101/3000], Loss: 7985.0585\n",
      "Validation Loss: 5736.5259\n",
      "Epoch [121/3000], Loss: 7900.5520\n",
      "Validation Loss: 5660.7810\n",
      "Epoch [141/3000], Loss: 7814.3437\n",
      "Validation Loss: 5588.3842\n",
      "Epoch [161/3000], Loss: 7731.6534\n",
      "Validation Loss: 5513.5835\n",
      "Epoch [181/3000], Loss: 7627.9292\n",
      "Validation Loss: 5445.6405\n",
      "Epoch [201/3000], Loss: 7550.6824\n",
      "Validation Loss: 5379.8741\n",
      "Epoch [221/3000], Loss: 7382.3053\n",
      "Validation Loss: 5315.9485\n",
      "Epoch [241/3000], Loss: 7326.1462\n",
      "Validation Loss: 5251.6775\n",
      "Epoch [261/3000], Loss: 7223.7457\n",
      "Validation Loss: 5190.6532\n",
      "Epoch [281/3000], Loss: 7135.1831\n",
      "Validation Loss: 5131.2682\n",
      "Epoch [301/3000], Loss: 7017.0615\n",
      "Validation Loss: 5073.4856\n",
      "Epoch [321/3000], Loss: 6940.8616\n",
      "Validation Loss: 5017.1843\n",
      "Epoch [341/3000], Loss: 6905.0650\n",
      "Validation Loss: 4962.3664\n",
      "Epoch [361/3000], Loss: 6779.1919\n",
      "Validation Loss: 4908.9541\n",
      "Epoch [381/3000], Loss: 6686.3830\n",
      "Validation Loss: 4857.0840\n",
      "Epoch [401/3000], Loss: 6620.9640\n",
      "Validation Loss: 4806.6088\n",
      "Epoch [421/3000], Loss: 6568.3352\n",
      "Validation Loss: 4757.4959\n",
      "Epoch [441/3000], Loss: 6486.0258\n",
      "Validation Loss: 4709.7433\n",
      "Epoch [461/3000], Loss: 6355.2872\n",
      "Validation Loss: 4663.4020\n",
      "Epoch [481/3000], Loss: 6305.2528\n",
      "Validation Loss: 4618.4766\n",
      "Epoch [501/3000], Loss: 6209.6927\n",
      "Validation Loss: 4574.9906\n",
      "Epoch [521/3000], Loss: 6173.8633\n",
      "Validation Loss: 4532.7532\n",
      "Epoch [541/3000], Loss: 6062.0586\n",
      "Validation Loss: 4491.9685\n",
      "Epoch [561/3000], Loss: 6021.7234\n",
      "Validation Loss: 4452.5730\n",
      "Epoch [581/3000], Loss: 5912.7494\n",
      "Validation Loss: 4414.4008\n",
      "Epoch [601/3000], Loss: 5824.8348\n",
      "Validation Loss: 4376.9167\n",
      "Epoch [621/3000], Loss: 5809.7289\n",
      "Validation Loss: 4341.3458\n",
      "Epoch [641/3000], Loss: 5715.0070\n",
      "Validation Loss: 4307.1776\n",
      "Epoch [661/3000], Loss: 5639.4003\n",
      "Validation Loss: 4274.3267\n",
      "Epoch [681/3000], Loss: 5583.7033\n",
      "Validation Loss: 4242.9088\n",
      "Epoch [701/3000], Loss: 5551.4385\n",
      "Validation Loss: 4212.8592\n",
      "Epoch [721/3000], Loss: 5438.3834\n",
      "Validation Loss: 4184.1754\n",
      "Epoch [741/3000], Loss: 5406.6498\n",
      "Validation Loss: 4156.8062\n",
      "Epoch [761/3000], Loss: 5382.9283\n",
      "Validation Loss: 4130.8227\n",
      "Epoch [781/3000], Loss: 5293.0030\n",
      "Validation Loss: 4106.1554\n",
      "Epoch [801/3000], Loss: 5268.3485\n",
      "Validation Loss: 4082.8189\n",
      "Epoch [821/3000], Loss: 5214.8831\n",
      "Validation Loss: 4060.7908\n",
      "Epoch [841/3000], Loss: 5133.7618\n",
      "Validation Loss: 4040.0751\n",
      "Epoch [861/3000], Loss: 5068.6943\n",
      "Validation Loss: 4020.2691\n",
      "Epoch [881/3000], Loss: 5038.9502\n",
      "Validation Loss: 4002.0447\n",
      "Epoch [901/3000], Loss: 4982.4379\n",
      "Validation Loss: 3985.1727\n",
      "Epoch [921/3000], Loss: 4942.1014\n",
      "Validation Loss: 3969.6203\n",
      "Epoch [941/3000], Loss: 4929.2405\n",
      "Validation Loss: 3955.4053\n",
      "Epoch [961/3000], Loss: 4874.0679\n",
      "Validation Loss: 3942.5168\n",
      "Epoch [981/3000], Loss: 4822.4491\n",
      "Validation Loss: 3930.8996\n",
      "Epoch [1001/3000], Loss: 4789.7436\n",
      "Validation Loss: 3920.5504\n",
      "Epoch [1021/3000], Loss: 4757.7134\n",
      "Validation Loss: 3911.4788\n",
      "Epoch [1041/3000], Loss: 4684.3428\n",
      "Validation Loss: 3903.6381\n",
      "Epoch [1061/3000], Loss: 4676.1387\n",
      "Validation Loss: 3897.0107\n",
      "Epoch [1081/3000], Loss: 4639.2523\n",
      "Validation Loss: 3891.6395\n",
      "Epoch [1101/3000], Loss: 4591.2680\n",
      "Validation Loss: 3887.4790\n",
      "Epoch [1121/3000], Loss: 4579.3106\n",
      "Validation Loss: 3884.5218\n",
      "Epoch [1141/3000], Loss: 4529.9024\n",
      "Validation Loss: 3882.7523\n",
      "Epoch [1161/3000], Loss: 4515.1695\n",
      "Validation Loss: 3882.1628\n",
      "Epoch [1181/3000], Loss: 4485.7682\n",
      "Validation Loss: 3882.7279\n",
      "Epoch [1201/3000], Loss: 4449.2573\n",
      "Validation Loss: 3884.4382\n",
      "Epoch [1221/3000], Loss: 4434.6245\n",
      "Validation Loss: 3887.2646\n",
      "Epoch [1241/3000], Loss: 4397.7103\n",
      "Validation Loss: 3891.1872\n",
      "Epoch [1261/3000], Loss: 4386.4803\n",
      "Validation Loss: 3896.1966\n",
      "Epoch [1281/3000], Loss: 4364.7617\n",
      "Validation Loss: 3902.2122\n",
      "Epoch [1301/3000], Loss: 4332.8142\n",
      "Validation Loss: 3909.2794\n",
      "Epoch [1321/3000], Loss: 4319.2388\n",
      "Validation Loss: 3917.3323\n",
      "Epoch [1341/3000], Loss: 4300.1141\n",
      "Validation Loss: 3926.2715\n",
      "Epoch [1361/3000], Loss: 4278.8294\n",
      "Validation Loss: 3936.1648\n",
      "Epoch [1381/3000], Loss: 4274.4850\n",
      "Validation Loss: 3946.9671\n",
      "Epoch [1401/3000], Loss: 4243.7976\n",
      "Validation Loss: 3958.5422\n",
      "Epoch [1421/3000], Loss: 4232.9228\n",
      "Validation Loss: 3970.8823\n",
      "Epoch [1441/3000], Loss: 4229.0134\n",
      "Validation Loss: 3983.8326\n",
      "Epoch [1461/3000], Loss: 4177.4632\n",
      "Validation Loss: 3997.3928\n",
      "Epoch [1481/3000], Loss: 4188.5880\n",
      "Validation Loss: 4011.6713\n",
      "Epoch [1501/3000], Loss: 4199.6654\n",
      "Validation Loss: 4026.4843\n",
      "Epoch [1521/3000], Loss: 4169.9336\n",
      "Validation Loss: 4041.4597\n",
      "Epoch [1541/3000], Loss: 4171.9860\n",
      "Validation Loss: 4056.8778\n",
      "Epoch [1561/3000], Loss: 4161.8627\n",
      "Validation Loss: 4072.4203\n",
      "Epoch [1581/3000], Loss: 4159.6580\n",
      "Validation Loss: 4088.0245\n",
      "Epoch [1601/3000], Loss: 4130.4127\n",
      "Validation Loss: 4068.3223\n",
      "Epoch [1621/3000], Loss: 3798.9677\n",
      "Validation Loss: 3647.0700\n",
      "Epoch [1641/3000], Loss: 3170.7752\n",
      "Validation Loss: 2825.7800\n",
      "Epoch [1661/3000], Loss: 2462.4546\n",
      "Validation Loss: 2083.3580\n",
      "Epoch [1681/3000], Loss: 2302.6699\n",
      "Validation Loss: 2058.6031\n",
      "Epoch [1701/3000], Loss: 2190.4430\n",
      "Validation Loss: 2006.1111\n",
      "Epoch [1721/3000], Loss: 2089.7565\n",
      "Validation Loss: 1976.8795\n",
      "Epoch [1741/3000], Loss: 2048.1779\n",
      "Validation Loss: 1939.7152\n",
      "Epoch [1761/3000], Loss: 1964.1394\n",
      "Validation Loss: 1922.1609\n",
      "Epoch [1781/3000], Loss: 1904.4465\n",
      "Validation Loss: 1885.4377\n",
      "Epoch [1801/3000], Loss: 1873.4946\n",
      "Validation Loss: 1880.1958\n",
      "Epoch [1821/3000], Loss: 1801.7897\n",
      "Validation Loss: 1818.0103\n",
      "Epoch [1841/3000], Loss: 1765.1638\n",
      "Validation Loss: 1779.6218\n",
      "Epoch [1861/3000], Loss: 1713.1715\n",
      "Validation Loss: 1754.2605\n",
      "Epoch [1881/3000], Loss: 1667.3906\n",
      "Validation Loss: 1729.8596\n",
      "Epoch [1901/3000], Loss: 1614.0564\n",
      "Validation Loss: 1695.3867\n",
      "Epoch [1921/3000], Loss: 1595.9468\n",
      "Validation Loss: 1673.4023\n",
      "Epoch [1941/3000], Loss: 1549.9103\n",
      "Validation Loss: 1661.6709\n",
      "Epoch [1961/3000], Loss: 1508.7278\n",
      "Validation Loss: 1678.6592\n",
      "Epoch [1981/3000], Loss: 1468.1156\n",
      "Validation Loss: 1642.8272\n",
      "Epoch [2001/3000], Loss: 1423.7198\n",
      "Validation Loss: 1569.6979\n",
      "Epoch [2021/3000], Loss: 1402.1734\n",
      "Validation Loss: 1551.6858\n",
      "Epoch [2041/3000], Loss: 1338.5168\n",
      "Validation Loss: 1519.7612\n",
      "Epoch [2061/3000], Loss: 1313.3550\n",
      "Validation Loss: 1539.9160\n",
      "Epoch [2081/3000], Loss: 1263.9271\n",
      "Validation Loss: 1508.9710\n",
      "Epoch [2101/3000], Loss: 1253.4346\n",
      "Validation Loss: 1487.5673\n",
      "Epoch [2121/3000], Loss: 1215.6721\n",
      "Validation Loss: 1470.6278\n",
      "Epoch [2141/3000], Loss: 1171.2464\n",
      "Validation Loss: 1458.5326\n",
      "Epoch [2161/3000], Loss: 1146.3323\n",
      "Validation Loss: 1430.7083\n",
      "Epoch [2181/3000], Loss: 1114.8538\n",
      "Validation Loss: 1430.1490\n",
      "Epoch [2201/3000], Loss: 1095.2281\n",
      "Validation Loss: 1409.6020\n",
      "Epoch [2221/3000], Loss: 1060.1832\n",
      "Validation Loss: 1386.6634\n",
      "Epoch [2241/3000], Loss: 1028.2457\n",
      "Validation Loss: 1370.0114\n",
      "Epoch [2261/3000], Loss: 989.9152\n",
      "Validation Loss: 1365.0456\n",
      "Epoch [2281/3000], Loss: 976.5140\n",
      "Validation Loss: 1347.9971\n",
      "Epoch [2301/3000], Loss: 949.1609\n",
      "Validation Loss: 1348.1684\n",
      "Epoch [2321/3000], Loss: 917.7946\n",
      "Validation Loss: 1320.4290\n",
      "Epoch [2341/3000], Loss: 893.3356\n",
      "Validation Loss: 1318.6361\n",
      "Epoch [2361/3000], Loss: 859.7834\n",
      "Validation Loss: 1300.2740\n",
      "Epoch [2381/3000], Loss: 853.2029\n",
      "Validation Loss: 1291.3988\n",
      "Epoch [2401/3000], Loss: 820.0695\n",
      "Validation Loss: 1291.9641\n",
      "Epoch [2421/3000], Loss: 804.0558\n",
      "Validation Loss: 1271.6303\n",
      "Epoch [2441/3000], Loss: 791.1632\n",
      "Validation Loss: 1266.7002\n",
      "Epoch [2461/3000], Loss: 747.9924\n",
      "Validation Loss: 1257.2346\n",
      "Epoch [2481/3000], Loss: 736.3097\n",
      "Validation Loss: 1250.0368\n",
      "Epoch [2501/3000], Loss: 712.1925\n",
      "Validation Loss: 1273.9214\n",
      "Epoch [2521/3000], Loss: 690.5418\n",
      "Validation Loss: 1287.4167\n",
      "Epoch [2541/3000], Loss: 670.0093\n",
      "Validation Loss: 1279.2450\n",
      "Epoch [2561/3000], Loss: 650.0701\n",
      "Validation Loss: 1256.3070\n",
      "Epoch [2581/3000], Loss: 626.2860\n",
      "Validation Loss: 1247.1344\n",
      "Epoch [2601/3000], Loss: 610.3095\n",
      "Validation Loss: 1242.4922\n",
      "Epoch [2621/3000], Loss: 590.1790\n",
      "Validation Loss: 1231.8175\n",
      "Epoch [2641/3000], Loss: 562.8239\n",
      "Validation Loss: 1221.1982\n",
      "Epoch [2661/3000], Loss: 552.8816\n",
      "Validation Loss: 1214.1189\n",
      "Epoch [2681/3000], Loss: 529.0309\n",
      "Validation Loss: 1195.9319\n",
      "Epoch [2701/3000], Loss: 510.6562\n",
      "Validation Loss: 1191.4720\n",
      "Epoch [2721/3000], Loss: 502.3508\n",
      "Validation Loss: 1200.3376\n",
      "Epoch [2741/3000], Loss: 485.0936\n",
      "Validation Loss: 1170.3663\n",
      "Epoch [2761/3000], Loss: 464.4368\n",
      "Validation Loss: 1163.9632\n",
      "Epoch [2781/3000], Loss: 442.4151\n",
      "Validation Loss: 1153.0006\n",
      "Epoch [2801/3000], Loss: 431.6244\n",
      "Validation Loss: 1155.3346\n",
      "Epoch [2821/3000], Loss: 417.6083\n",
      "Validation Loss: 1148.0490\n",
      "Epoch [2841/3000], Loss: 399.2283\n",
      "Validation Loss: 1146.1306\n",
      "Epoch [2861/3000], Loss: 386.7547\n",
      "Validation Loss: 1154.7265\n",
      "Epoch [2881/3000], Loss: 371.8211\n",
      "Validation Loss: 1127.2656\n",
      "Epoch [2901/3000], Loss: 348.8592\n",
      "Validation Loss: 1084.2276\n",
      "Epoch [2921/3000], Loss: 326.2682\n",
      "Validation Loss: 1100.9765\n",
      "Epoch [2941/3000], Loss: 320.8786\n",
      "Validation Loss: 1112.2650\n",
      "Epoch [2961/3000], Loss: 298.9793\n",
      "Validation Loss: 1101.5625\n",
      "Epoch [2981/3000], Loss: 286.8939\n",
      "Validation Loss: 1084.2967\n",
      "Y:\\analysis\\fmats\\e200\\days\\e200_day089_plane0_Fall.mat\n",
      "(5365, 127)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6488.3042\n",
      "Validation Loss: 5713.8665\n",
      "Epoch [21/3000], Loss: 5556.3316\n",
      "Validation Loss: 4878.6550\n",
      "Epoch [41/3000], Loss: 5343.4608\n",
      "Validation Loss: 4692.6747\n",
      "Epoch [61/3000], Loss: 5189.1972\n",
      "Validation Loss: 4579.7163\n",
      "Epoch [81/3000], Loss: 5074.1553\n",
      "Validation Loss: 4481.7054\n",
      "Epoch [101/3000], Loss: 5012.7243\n",
      "Validation Loss: 4390.8650\n",
      "Epoch [121/3000], Loss: 4893.1059\n",
      "Validation Loss: 4304.8169\n",
      "Epoch [141/3000], Loss: 4785.6714\n",
      "Validation Loss: 4222.4757\n",
      "Epoch [161/3000], Loss: 4686.7135\n",
      "Validation Loss: 4143.0549\n",
      "Epoch [181/3000], Loss: 4608.8623\n",
      "Validation Loss: 4066.2370\n",
      "Epoch [201/3000], Loss: 4510.8884\n",
      "Validation Loss: 3991.9025\n",
      "Epoch [221/3000], Loss: 4429.9498\n",
      "Validation Loss: 3919.8005\n",
      "Epoch [241/3000], Loss: 4395.2987\n",
      "Validation Loss: 3848.9519\n",
      "Epoch [261/3000], Loss: 4279.3003\n",
      "Validation Loss: 3780.5747\n",
      "Epoch [281/3000], Loss: 4190.0399\n",
      "Validation Loss: 3714.6022\n",
      "Epoch [301/3000], Loss: 4122.7828\n",
      "Validation Loss: 3650.6451\n",
      "Epoch [321/3000], Loss: 4040.3019\n",
      "Validation Loss: 3588.5718\n",
      "Epoch [341/3000], Loss: 3941.7654\n",
      "Validation Loss: 3528.5504\n",
      "Epoch [361/3000], Loss: 3917.8454\n",
      "Validation Loss: 3470.6112\n",
      "Epoch [381/3000], Loss: 3843.1807\n",
      "Validation Loss: 3414.4905\n",
      "Epoch [401/3000], Loss: 3769.8673\n",
      "Validation Loss: 3360.3628\n",
      "Epoch [421/3000], Loss: 3687.9999\n",
      "Validation Loss: 3307.2972\n",
      "Epoch [441/3000], Loss: 3630.9187\n",
      "Validation Loss: 3256.5826\n",
      "Epoch [461/3000], Loss: 3593.2548\n",
      "Validation Loss: 3207.9014\n",
      "Epoch [481/3000], Loss: 3505.7941\n",
      "Validation Loss: 3161.1696\n",
      "Epoch [501/3000], Loss: 3460.5643\n",
      "Validation Loss: 3116.4234\n",
      "Epoch [521/3000], Loss: 3422.0099\n",
      "Validation Loss: 3073.5626\n",
      "Epoch [541/3000], Loss: 3353.0969\n",
      "Validation Loss: 3032.5632\n",
      "Epoch [561/3000], Loss: 3310.5930\n",
      "Validation Loss: 2993.4563\n",
      "Epoch [581/3000], Loss: 3262.7606\n",
      "Validation Loss: 2956.2089\n",
      "Epoch [601/3000], Loss: 3210.2721\n",
      "Validation Loss: 2920.8066\n",
      "Epoch [621/3000], Loss: 3182.7860\n",
      "Validation Loss: 2887.2807\n",
      "Epoch [641/3000], Loss: 3112.0954\n",
      "Validation Loss: 2855.5471\n",
      "Epoch [661/3000], Loss: 3081.3878\n",
      "Validation Loss: 2825.6546\n",
      "Epoch [681/3000], Loss: 3038.6368\n",
      "Validation Loss: 2797.5940\n",
      "Epoch [701/3000], Loss: 3009.8525\n",
      "Validation Loss: 2770.8707\n",
      "Epoch [721/3000], Loss: 2952.2632\n",
      "Validation Loss: 2746.2141\n",
      "Epoch [741/3000], Loss: 2961.9513\n",
      "Validation Loss: 2723.4002\n",
      "Epoch [761/3000], Loss: 2889.6937\n",
      "Validation Loss: 2702.3978\n",
      "Epoch [781/3000], Loss: 2878.5814\n",
      "Validation Loss: 2683.1526\n",
      "Epoch [801/3000], Loss: 2828.0242\n",
      "Validation Loss: 2665.5912\n",
      "Epoch [821/3000], Loss: 2792.7445\n",
      "Validation Loss: 2649.7753\n",
      "Epoch [841/3000], Loss: 2794.3178\n",
      "Validation Loss: 2635.5791\n",
      "Epoch [861/3000], Loss: 2769.8556\n",
      "Validation Loss: 2622.9992\n",
      "Epoch [881/3000], Loss: 2736.0395\n",
      "Validation Loss: 2612.0230\n",
      "Epoch [901/3000], Loss: 2727.0228\n",
      "Validation Loss: 2602.6018\n",
      "Epoch [921/3000], Loss: 2704.1301\n",
      "Validation Loss: 2594.7187\n",
      "Epoch [941/3000], Loss: 2696.3768\n",
      "Validation Loss: 2588.3083\n",
      "Epoch [961/3000], Loss: 2675.3296\n",
      "Validation Loss: 2583.3334\n",
      "Epoch [981/3000], Loss: 2645.8936\n",
      "Validation Loss: 2579.6962\n",
      "Epoch [1001/3000], Loss: 2649.1545\n",
      "Validation Loss: 2577.3285\n",
      "Epoch [1021/3000], Loss: 2633.2486\n",
      "Validation Loss: 2576.1538\n",
      "Epoch [1041/3000], Loss: 2623.5925\n",
      "Validation Loss: 2576.0742\n",
      "Epoch [1061/3000], Loss: 2625.0907\n",
      "Validation Loss: 2576.9918\n",
      "Epoch [1081/3000], Loss: 1699.7884\n",
      "Validation Loss: 1673.0352\n",
      "Epoch [1101/3000], Loss: 1573.2719\n",
      "Validation Loss: 1594.3318\n",
      "Epoch [1121/3000], Loss: 1468.5441\n",
      "Validation Loss: 1490.2358\n",
      "Epoch [1141/3000], Loss: 1440.4371\n",
      "Validation Loss: 1473.2520\n",
      "Epoch [1161/3000], Loss: 1380.1702\n",
      "Validation Loss: 1440.2922\n",
      "Epoch [1181/3000], Loss: 1352.7123\n",
      "Validation Loss: 1316.7654\n",
      "Epoch [1201/3000], Loss: 1277.3995\n",
      "Validation Loss: 1305.8982\n",
      "Epoch [1221/3000], Loss: 1232.2523\n",
      "Validation Loss: 1252.9403\n",
      "Epoch [1241/3000], Loss: 1184.2771\n",
      "Validation Loss: 1216.8751\n",
      "Epoch [1261/3000], Loss: 1141.6517\n",
      "Validation Loss: 1169.4314\n",
      "Epoch [1281/3000], Loss: 1114.8324\n",
      "Validation Loss: 1128.1194\n",
      "Epoch [1301/3000], Loss: 1081.0936\n",
      "Validation Loss: 1079.3066\n",
      "Epoch [1321/3000], Loss: 1038.2335\n",
      "Validation Loss: 1161.3328\n",
      "Epoch [1341/3000], Loss: 1017.2614\n",
      "Validation Loss: 1069.5378\n",
      "Epoch [1361/3000], Loss: 966.6153\n",
      "Validation Loss: 1004.7634\n",
      "Epoch [1381/3000], Loss: 917.4554\n",
      "Validation Loss: 990.0657\n",
      "Epoch [1401/3000], Loss: 889.3207\n",
      "Validation Loss: 969.8656\n",
      "Epoch [1421/3000], Loss: 864.5941\n",
      "Validation Loss: 951.1645\n",
      "Epoch [1441/3000], Loss: 826.4526\n",
      "Validation Loss: 918.1715\n",
      "Epoch [1461/3000], Loss: 809.7565\n",
      "Validation Loss: 894.6864\n",
      "Epoch [1481/3000], Loss: 782.9144\n",
      "Validation Loss: 884.5809\n",
      "Epoch [1501/3000], Loss: 744.1480\n",
      "Validation Loss: 863.3689\n",
      "Epoch [1521/3000], Loss: 718.1304\n",
      "Validation Loss: 858.2174\n",
      "Epoch [1541/3000], Loss: 701.8488\n",
      "Validation Loss: 818.3623\n",
      "Epoch [1561/3000], Loss: 667.2988\n",
      "Validation Loss: 815.0088\n",
      "Epoch [1581/3000], Loss: 640.6051\n",
      "Validation Loss: 786.3708\n",
      "Epoch [1601/3000], Loss: 624.4037\n",
      "Validation Loss: 775.6281\n",
      "Epoch [1621/3000], Loss: 584.5018\n",
      "Validation Loss: 755.2311\n",
      "Epoch [1641/3000], Loss: 573.3001\n",
      "Validation Loss: 741.2341\n",
      "Epoch [1661/3000], Loss: 552.9752\n",
      "Validation Loss: 727.4197\n",
      "Epoch [1681/3000], Loss: 529.8761\n",
      "Validation Loss: 720.0793\n",
      "Epoch [1701/3000], Loss: 513.4580\n",
      "Validation Loss: 705.3555\n",
      "Epoch [1721/3000], Loss: 499.4897\n",
      "Validation Loss: 678.6958\n",
      "Epoch [1741/3000], Loss: 473.3270\n",
      "Validation Loss: 674.2220\n",
      "Epoch [1761/3000], Loss: 459.5303\n",
      "Validation Loss: 658.7654\n",
      "Epoch [1781/3000], Loss: 447.6528\n",
      "Validation Loss: 650.7774\n",
      "Epoch [1801/3000], Loss: 424.6617\n",
      "Validation Loss: 633.2372\n",
      "Epoch [1821/3000], Loss: 408.1491\n",
      "Validation Loss: 625.1267\n",
      "Epoch [1841/3000], Loss: 395.4179\n",
      "Validation Loss: 621.0585\n",
      "Epoch [1861/3000], Loss: 367.5870\n",
      "Validation Loss: 620.2081\n",
      "Epoch [1881/3000], Loss: 366.1163\n",
      "Validation Loss: 625.9612\n",
      "Epoch [1901/3000], Loss: 344.6379\n",
      "Validation Loss: 602.8745\n",
      "Epoch [1921/3000], Loss: 332.8558\n",
      "Validation Loss: 607.9090\n",
      "Epoch [1941/3000], Loss: 328.6351\n",
      "Validation Loss: 610.7523\n",
      "Epoch [1961/3000], Loss: 311.8263\n",
      "Validation Loss: 602.8713\n",
      "Epoch [1981/3000], Loss: 299.7408\n",
      "Validation Loss: 596.7541\n",
      "Epoch [2001/3000], Loss: 283.8058\n",
      "Validation Loss: 568.0629\n",
      "Epoch [2021/3000], Loss: 275.7748\n",
      "Validation Loss: 547.6343\n",
      "Epoch [2041/3000], Loss: 263.1937\n",
      "Validation Loss: 552.1597\n",
      "Epoch [2061/3000], Loss: 251.9827\n",
      "Validation Loss: 551.7777\n",
      "Epoch [2081/3000], Loss: 245.1966\n",
      "Validation Loss: 545.0142\n",
      "Epoch [2101/3000], Loss: 235.7135\n",
      "Validation Loss: 539.5285\n",
      "Epoch [2121/3000], Loss: 229.6502\n",
      "Validation Loss: 533.2711\n",
      "Epoch [2141/3000], Loss: 216.7339\n",
      "Validation Loss: 548.6203\n",
      "Epoch [2161/3000], Loss: 207.6896\n",
      "Validation Loss: 530.1156\n",
      "Epoch [2181/3000], Loss: 203.9548\n",
      "Validation Loss: 541.8463\n",
      "Epoch [2201/3000], Loss: 194.0940\n",
      "Validation Loss: 530.3451\n",
      "Epoch [2221/3000], Loss: 187.7728\n",
      "Validation Loss: 569.0309\n",
      "Epoch [2241/3000], Loss: 183.3623\n",
      "Validation Loss: 582.9514\n",
      "Epoch [2261/3000], Loss: 173.8196\n",
      "Validation Loss: 554.6948\n",
      "Epoch [2281/3000], Loss: 164.9369\n",
      "Validation Loss: 575.2821\n",
      "Epoch [2301/3000], Loss: 157.2076\n",
      "Validation Loss: 560.1068\n",
      "Epoch [2321/3000], Loss: 154.5091\n",
      "Validation Loss: 570.0911\n",
      "Epoch [2341/3000], Loss: 144.6689\n",
      "Validation Loss: 572.5852\n",
      "Epoch [2361/3000], Loss: 142.9107\n",
      "Validation Loss: 568.3202\n",
      "Epoch [2381/3000], Loss: 139.0967\n",
      "Validation Loss: 563.6682\n",
      "Epoch [2401/3000], Loss: 132.4707\n",
      "Validation Loss: 585.3619\n",
      "Epoch [2421/3000], Loss: 125.2664\n",
      "Validation Loss: 556.0796\n",
      "Epoch [2441/3000], Loss: 120.0151\n",
      "Validation Loss: 538.9871\n",
      "Epoch [2461/3000], Loss: 114.5123\n",
      "Validation Loss: 562.4908\n",
      "Epoch [2481/3000], Loss: 112.3262\n",
      "Validation Loss: 552.3229\n",
      "Epoch [2501/3000], Loss: 110.5405\n",
      "Validation Loss: 540.3003\n",
      "Epoch [2521/3000], Loss: 105.8693\n",
      "Validation Loss: 546.4172\n",
      "Epoch [2541/3000], Loss: 101.1300\n",
      "Validation Loss: 539.7494\n",
      "Epoch [2561/3000], Loss: 98.3131\n",
      "Validation Loss: 547.1715\n",
      "Epoch [2581/3000], Loss: 92.9216\n",
      "Validation Loss: 533.1372\n",
      "Epoch [2601/3000], Loss: 92.2740\n",
      "Validation Loss: 535.1096\n",
      "Epoch [2621/3000], Loss: 88.5359\n",
      "Validation Loss: 530.7693\n",
      "Epoch [2641/3000], Loss: 85.9698\n",
      "Validation Loss: 535.1758\n",
      "Epoch [2661/3000], Loss: 82.8066\n",
      "Validation Loss: 541.3676\n",
      "Epoch [2681/3000], Loss: 77.5863\n",
      "Validation Loss: 535.2440\n",
      "Epoch [2701/3000], Loss: 77.1563\n",
      "Validation Loss: 520.6766\n",
      "Epoch [2721/3000], Loss: 74.7539\n",
      "Validation Loss: 534.9141\n",
      "Epoch [2741/3000], Loss: 71.2732\n",
      "Validation Loss: 517.0245\n",
      "Epoch [2761/3000], Loss: 66.9802\n",
      "Validation Loss: 506.2637\n",
      "Epoch [2781/3000], Loss: 65.5708\n",
      "Validation Loss: 481.9963\n",
      "Epoch [2801/3000], Loss: 61.2388\n",
      "Validation Loss: 509.7637\n",
      "Epoch [2821/3000], Loss: 59.8289\n",
      "Validation Loss: 519.3287\n",
      "Epoch [2841/3000], Loss: 54.7897\n",
      "Validation Loss: 457.7329\n",
      "Epoch [2861/3000], Loss: 53.1091\n",
      "Validation Loss: 405.8837\n",
      "Epoch [2881/3000], Loss: 48.7233\n",
      "Validation Loss: 412.3947\n",
      "Epoch [2901/3000], Loss: 45.0177\n",
      "Validation Loss: 410.9204\n",
      "Epoch [2921/3000], Loss: 43.3945\n",
      "Validation Loss: 421.6666\n",
      "Epoch [2941/3000], Loss: 41.8054\n",
      "Validation Loss: 415.5647\n",
      "Epoch [2961/3000], Loss: 39.6052\n",
      "Validation Loss: 422.3038\n",
      "Epoch [2981/3000], Loss: 36.1062\n",
      "Validation Loss: 435.2597\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day052_plane0_Fall.mat\n",
      "(10078, 910)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9185.4121\n",
      "Validation Loss: 8042.4830\n",
      "Epoch [21/3000], Loss: 7643.3870\n",
      "Validation Loss: 6762.1035\n",
      "Epoch [41/3000], Loss: 7312.5454\n",
      "Validation Loss: 6489.7854\n",
      "Epoch [61/3000], Loss: 7049.8852\n",
      "Validation Loss: 6267.4719\n",
      "Epoch [81/3000], Loss: 6793.8028\n",
      "Validation Loss: 6061.7540\n",
      "Epoch [101/3000], Loss: 6553.4373\n",
      "Validation Loss: 5864.7845\n",
      "Epoch [121/3000], Loss: 6304.4201\n",
      "Validation Loss: 5676.6852\n",
      "Epoch [141/3000], Loss: 6082.0454\n",
      "Validation Loss: 5498.3676\n",
      "Epoch [161/3000], Loss: 5880.4308\n",
      "Validation Loss: 5328.2526\n",
      "Epoch [181/3000], Loss: 5665.7147\n",
      "Validation Loss: 5165.9168\n",
      "Epoch [201/3000], Loss: 5466.2027\n",
      "Validation Loss: 5011.3525\n",
      "Epoch [221/3000], Loss: 5278.6834\n",
      "Validation Loss: 4864.3136\n",
      "Epoch [241/3000], Loss: 5089.3686\n",
      "Validation Loss: 4724.7672\n",
      "Epoch [261/3000], Loss: 4919.9178\n",
      "Validation Loss: 4592.7481\n",
      "Epoch [281/3000], Loss: 4750.6014\n",
      "Validation Loss: 4468.1360\n",
      "Epoch [301/3000], Loss: 4586.7110\n",
      "Validation Loss: 4350.9680\n",
      "Epoch [321/3000], Loss: 4429.0437\n",
      "Validation Loss: 4241.1796\n",
      "Epoch [341/3000], Loss: 4283.3594\n",
      "Validation Loss: 4138.7344\n",
      "Epoch [361/3000], Loss: 4145.8959\n",
      "Validation Loss: 4043.5972\n",
      "Epoch [381/3000], Loss: 4012.7931\n",
      "Validation Loss: 3955.7338\n",
      "Epoch [401/3000], Loss: 3888.4672\n",
      "Validation Loss: 3875.0396\n",
      "Epoch [421/3000], Loss: 3769.3014\n",
      "Validation Loss: 3801.5982\n",
      "Epoch [441/3000], Loss: 3666.1916\n",
      "Validation Loss: 3735.2195\n",
      "Epoch [461/3000], Loss: 2965.1675\n",
      "Validation Loss: 2979.5736\n",
      "Epoch [481/3000], Loss: 2793.9766\n",
      "Validation Loss: 2859.5644\n",
      "Epoch [501/3000], Loss: 2643.4267\n",
      "Validation Loss: 2741.0908\n",
      "Epoch [521/3000], Loss: 2501.2107\n",
      "Validation Loss: 2629.6179\n",
      "Epoch [541/3000], Loss: 2369.9347\n",
      "Validation Loss: 2523.3418\n",
      "Epoch [561/3000], Loss: 2239.3389\n",
      "Validation Loss: 2417.1714\n",
      "Epoch [581/3000], Loss: 2130.0249\n",
      "Validation Loss: 2318.1060\n",
      "Epoch [601/3000], Loss: 2004.1790\n",
      "Validation Loss: 2231.7009\n",
      "Epoch [621/3000], Loss: 1886.6358\n",
      "Validation Loss: 2133.9273\n",
      "Epoch [641/3000], Loss: 1780.4246\n",
      "Validation Loss: 2041.9695\n",
      "Epoch [661/3000], Loss: 1675.7703\n",
      "Validation Loss: 1956.7048\n",
      "Epoch [681/3000], Loss: 1573.3572\n",
      "Validation Loss: 1874.6427\n",
      "Epoch [701/3000], Loss: 1486.3106\n",
      "Validation Loss: 1796.0860\n",
      "Epoch [721/3000], Loss: 1384.0538\n",
      "Validation Loss: 1736.4839\n",
      "Epoch [741/3000], Loss: 1299.3561\n",
      "Validation Loss: 1660.3391\n",
      "Epoch [761/3000], Loss: 1215.2694\n",
      "Validation Loss: 1587.0012\n",
      "Epoch [781/3000], Loss: 1133.6584\n",
      "Validation Loss: 1518.8173\n",
      "Epoch [801/3000], Loss: 1058.4048\n",
      "Validation Loss: 1458.9420\n",
      "Epoch [821/3000], Loss: 989.4033\n",
      "Validation Loss: 1398.2087\n",
      "Epoch [841/3000], Loss: 919.7577\n",
      "Validation Loss: 1341.6831\n",
      "Epoch [861/3000], Loss: 852.3598\n",
      "Validation Loss: 1286.7790\n",
      "Epoch [881/3000], Loss: 788.4241\n",
      "Validation Loss: 1222.8331\n",
      "Epoch [901/3000], Loss: 730.2877\n",
      "Validation Loss: 1175.4748\n",
      "Epoch [921/3000], Loss: 675.7816\n",
      "Validation Loss: 1120.6212\n",
      "Epoch [941/3000], Loss: 622.8714\n",
      "Validation Loss: 1067.2723\n",
      "Epoch [961/3000], Loss: 571.7344\n",
      "Validation Loss: 1018.3323\n",
      "Epoch [981/3000], Loss: 528.4667\n",
      "Validation Loss: 973.1517\n",
      "Epoch [1001/3000], Loss: 481.8665\n",
      "Validation Loss: 930.5285\n",
      "Epoch [1021/3000], Loss: 442.8201\n",
      "Validation Loss: 888.6142\n",
      "Epoch [1041/3000], Loss: 405.9830\n",
      "Validation Loss: 851.2883\n",
      "Epoch [1061/3000], Loss: 373.4405\n",
      "Validation Loss: 821.3930\n",
      "Epoch [1081/3000], Loss: 340.6422\n",
      "Validation Loss: 791.0481\n",
      "Epoch [1101/3000], Loss: 313.0393\n",
      "Validation Loss: 769.0135\n",
      "Epoch [1121/3000], Loss: 287.9306\n",
      "Validation Loss: 749.6928\n",
      "Epoch [1141/3000], Loss: 263.3886\n",
      "Validation Loss: 719.0449\n",
      "Epoch [1161/3000], Loss: 242.6202\n",
      "Validation Loss: 696.0476\n",
      "Epoch [1181/3000], Loss: 224.6387\n",
      "Validation Loss: 678.0119\n",
      "Epoch [1201/3000], Loss: 203.0818\n",
      "Validation Loss: 668.0423\n",
      "Epoch [1221/3000], Loss: 186.1799\n",
      "Validation Loss: 662.6865\n",
      "Epoch [1241/3000], Loss: 169.8115\n",
      "Validation Loss: 654.7299\n",
      "Epoch [1261/3000], Loss: 153.0194\n",
      "Validation Loss: 646.4824\n",
      "Epoch [1281/3000], Loss: 138.7244\n",
      "Validation Loss: 645.3003\n",
      "Epoch [1301/3000], Loss: 124.8965\n",
      "Validation Loss: 633.5039\n",
      "Epoch [1321/3000], Loss: 111.6554\n",
      "Validation Loss: 623.3156\n",
      "Epoch [1341/3000], Loss: 100.2674\n",
      "Validation Loss: 617.7459\n",
      "Epoch [1361/3000], Loss: 88.6759\n",
      "Validation Loss: 619.3772\n",
      "Epoch [1381/3000], Loss: 79.3699\n",
      "Validation Loss: 622.3788\n",
      "Epoch [1401/3000], Loss: 70.2192\n",
      "Validation Loss: 628.9754\n",
      "Epoch [1421/3000], Loss: 61.7816\n",
      "Validation Loss: 632.0484\n",
      "Epoch [1441/3000], Loss: 54.3437\n",
      "Validation Loss: 588.5090\n",
      "Epoch [1461/3000], Loss: 47.5718\n",
      "Validation Loss: 586.1425\n",
      "Epoch [1481/3000], Loss: 41.1770\n",
      "Validation Loss: 584.1921\n",
      "Epoch [1501/3000], Loss: 35.7714\n",
      "Validation Loss: 586.1911\n",
      "Epoch [1521/3000], Loss: 30.4702\n",
      "Validation Loss: 593.2252\n",
      "Epoch [1541/3000], Loss: 26.0930\n",
      "Validation Loss: 601.9794\n",
      "Epoch [1561/3000], Loss: 22.1237\n",
      "Validation Loss: 608.2445\n",
      "Epoch [1581/3000], Loss: 18.5049\n",
      "Validation Loss: 608.8175\n",
      "Epoch [1601/3000], Loss: 15.4395\n",
      "Validation Loss: 613.2522\n",
      "Epoch [1621/3000], Loss: 12.7470\n",
      "Validation Loss: 617.4738\n",
      "Epoch [1641/3000], Loss: 10.3187\n",
      "Validation Loss: 616.9628\n",
      "Epoch [1661/3000], Loss: 8.2837\n",
      "Validation Loss: 614.3309\n",
      "Epoch [1681/3000], Loss: 6.6154\n",
      "Validation Loss: 613.3063\n",
      "Epoch [1701/3000], Loss: 5.1106\n",
      "Validation Loss: 613.5491\n",
      "Epoch [1721/3000], Loss: 3.9380\n",
      "Validation Loss: 612.0173\n",
      "Epoch [1741/3000], Loss: 2.9805\n",
      "Validation Loss: 609.7300\n",
      "Epoch [1761/3000], Loss: 2.1713\n",
      "Validation Loss: 604.7042\n",
      "Epoch [1781/3000], Loss: 1.5671\n",
      "Validation Loss: 608.2545\n",
      "Epoch [1801/3000], Loss: 1.0942\n",
      "Validation Loss: 606.9963\n",
      "Epoch [1821/3000], Loss: 0.7296\n",
      "Validation Loss: 602.6104\n",
      "Epoch [1841/3000], Loss: 0.4737\n",
      "Validation Loss: 600.3631\n",
      "Epoch [1861/3000], Loss: 0.2966\n",
      "Validation Loss: 601.7016\n",
      "Epoch [1881/3000], Loss: 0.1695\n",
      "Validation Loss: 603.1681\n",
      "Epoch [1901/3000], Loss: 0.1033\n",
      "Validation Loss: 606.8844\n",
      "Epoch [1921/3000], Loss: 0.0591\n",
      "Validation Loss: 600.9354\n",
      "Epoch [1941/3000], Loss: 0.1488\n",
      "Validation Loss: 535.7745\n",
      "Epoch [1961/3000], Loss: 0.0666\n",
      "Validation Loss: 543.4602\n",
      "Epoch [1981/3000], Loss: 0.0470\n",
      "Validation Loss: 547.5815\n",
      "Epoch [2001/3000], Loss: 0.0375\n",
      "Validation Loss: 550.9841\n",
      "Epoch [2021/3000], Loss: 0.0313\n",
      "Validation Loss: 553.8292\n",
      "Epoch [2041/3000], Loss: 0.0272\n",
      "Validation Loss: 556.7648\n",
      "Epoch [2061/3000], Loss: 0.0241\n",
      "Validation Loss: 559.2820\n",
      "Epoch [2081/3000], Loss: 0.0228\n",
      "Validation Loss: 562.3131\n",
      "Epoch [2101/3000], Loss: 0.0216\n",
      "Validation Loss: 566.1179\n",
      "Epoch [2121/3000], Loss: 0.0208\n",
      "Validation Loss: 567.7800\n",
      "Epoch [2141/3000], Loss: 0.0203\n",
      "Validation Loss: 570.0316\n",
      "Epoch [2161/3000], Loss: 0.0190\n",
      "Validation Loss: 572.7367\n",
      "Epoch [2181/3000], Loss: 0.0183\n",
      "Validation Loss: 576.1636\n",
      "Epoch [2201/3000], Loss: 0.0182\n",
      "Validation Loss: 577.4686\n",
      "Epoch [2221/3000], Loss: 0.0176\n",
      "Validation Loss: 578.2422\n",
      "Epoch [2241/3000], Loss: 0.0164\n",
      "Validation Loss: 578.3568\n",
      "Epoch [2261/3000], Loss: 0.0169\n",
      "Validation Loss: 579.1805\n",
      "Epoch [2281/3000], Loss: 0.0159\n",
      "Validation Loss: 580.4684\n",
      "Epoch [2301/3000], Loss: 0.0142\n",
      "Validation Loss: 579.5857\n",
      "Epoch [2321/3000], Loss: 0.0138\n",
      "Validation Loss: 584.8210\n",
      "Epoch [2341/3000], Loss: 0.0160\n",
      "Validation Loss: 582.1129\n",
      "Epoch [2361/3000], Loss: 0.0108\n",
      "Validation Loss: 585.6334\n",
      "Epoch [2381/3000], Loss: 0.0132\n",
      "Validation Loss: 585.3477\n",
      "Epoch [2401/3000], Loss: 0.0114\n",
      "Validation Loss: 583.7303\n",
      "Epoch [2421/3000], Loss: 0.0104\n",
      "Validation Loss: 583.0071\n",
      "Epoch [2441/3000], Loss: 0.0116\n",
      "Validation Loss: 584.4643\n",
      "Epoch [2461/3000], Loss: 0.0090\n",
      "Validation Loss: 585.2664\n",
      "Epoch [2481/3000], Loss: 0.0105\n",
      "Validation Loss: 583.3681\n",
      "Epoch [2501/3000], Loss: 0.0081\n",
      "Validation Loss: 586.6838\n",
      "Epoch [2521/3000], Loss: 0.0072\n",
      "Validation Loss: 590.4863\n",
      "Epoch [2541/3000], Loss: 0.0093\n",
      "Validation Loss: 588.8625\n",
      "Epoch [2561/3000], Loss: 0.0060\n",
      "Validation Loss: 588.4122\n",
      "Epoch [2581/3000], Loss: 0.0068\n",
      "Validation Loss: 587.4581\n",
      "Epoch [2601/3000], Loss: 0.0091\n",
      "Validation Loss: 588.5480\n",
      "Epoch [2621/3000], Loss: 0.0074\n",
      "Validation Loss: 588.8900\n",
      "Epoch [2641/3000], Loss: 0.0064\n",
      "Validation Loss: 585.6517\n",
      "Epoch [2661/3000], Loss: 0.0064\n",
      "Validation Loss: 586.3702\n",
      "Epoch [2681/3000], Loss: 0.0055\n",
      "Validation Loss: 582.8485\n",
      "Epoch [2701/3000], Loss: 0.0086\n",
      "Validation Loss: 586.1401\n",
      "Epoch [2721/3000], Loss: 0.0071\n",
      "Validation Loss: 582.8922\n",
      "Epoch [2741/3000], Loss: 0.0051\n",
      "Validation Loss: 583.5950\n",
      "Epoch [2761/3000], Loss: 0.0061\n",
      "Validation Loss: 584.7166\n",
      "Epoch [2781/3000], Loss: 0.0069\n",
      "Validation Loss: 582.2464\n",
      "Epoch [2801/3000], Loss: 0.0124\n",
      "Validation Loss: 584.8583\n",
      "Epoch [2821/3000], Loss: 0.0051\n",
      "Validation Loss: 581.7944\n",
      "Epoch [2841/3000], Loss: 0.0046\n",
      "Validation Loss: 581.5268\n",
      "Epoch [2861/3000], Loss: 0.0048\n",
      "Validation Loss: 584.0858\n",
      "Epoch [2881/3000], Loss: 0.0049\n",
      "Validation Loss: 581.3740\n",
      "Epoch [2901/3000], Loss: 0.0038\n",
      "Validation Loss: 582.5729\n",
      "Epoch [2921/3000], Loss: 0.0046\n",
      "Validation Loss: 582.3617\n",
      "Epoch [2941/3000], Loss: 0.0047\n",
      "Validation Loss: 579.4122\n",
      "Epoch [2961/3000], Loss: 0.0045\n",
      "Validation Loss: 579.9963\n",
      "Epoch [2981/3000], Loss: 0.0062\n",
      "Validation Loss: 574.5363\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day053_plane0_Fall.mat\n",
      "(12343, 834)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8771.8010\n",
      "Validation Loss: 13010.1272\n",
      "Epoch [21/3000], Loss: 7254.9728\n",
      "Validation Loss: 11063.0708\n",
      "Epoch [41/3000], Loss: 6879.9520\n",
      "Validation Loss: 10581.0843\n",
      "Epoch [61/3000], Loss: 6558.6641\n",
      "Validation Loss: 10154.5940\n",
      "Epoch [81/3000], Loss: 6266.2508\n",
      "Validation Loss: 9760.0062\n",
      "Epoch [101/3000], Loss: 5992.9390\n",
      "Validation Loss: 9382.5712\n",
      "Epoch [121/3000], Loss: 5728.2714\n",
      "Validation Loss: 9018.6042\n",
      "Epoch [141/3000], Loss: 5474.9390\n",
      "Validation Loss: 8667.5127\n",
      "Epoch [161/3000], Loss: 5239.7226\n",
      "Validation Loss: 8328.4214\n",
      "Epoch [181/3000], Loss: 5003.0507\n",
      "Validation Loss: 8001.4186\n",
      "Epoch [201/3000], Loss: 4793.0751\n",
      "Validation Loss: 7686.1287\n",
      "Epoch [221/3000], Loss: 4590.2004\n",
      "Validation Loss: 7382.5253\n",
      "Epoch [241/3000], Loss: 4393.3126\n",
      "Validation Loss: 7090.6490\n",
      "Epoch [261/3000], Loss: 4204.4766\n",
      "Validation Loss: 6810.4976\n",
      "Epoch [281/3000], Loss: 3692.8155\n",
      "Validation Loss: 6561.3289\n",
      "Epoch [301/3000], Loss: 3463.6791\n",
      "Validation Loss: 6500.9194\n",
      "Epoch [321/3000], Loss: 3257.2171\n",
      "Validation Loss: 6139.8738\n",
      "Epoch [341/3000], Loss: 3065.5613\n",
      "Validation Loss: 5784.9634\n",
      "Epoch [361/3000], Loss: 2878.8214\n",
      "Validation Loss: 5757.8750\n",
      "Epoch [381/3000], Loss: 2702.0182\n",
      "Validation Loss: 5587.6073\n",
      "Epoch [401/3000], Loss: 2533.7456\n",
      "Validation Loss: 5333.6637\n",
      "Epoch [421/3000], Loss: 2372.1415\n",
      "Validation Loss: 5138.9760\n",
      "Epoch [441/3000], Loss: 2219.4364\n",
      "Validation Loss: 4878.2999\n",
      "Epoch [461/3000], Loss: 2075.6803\n",
      "Validation Loss: 4679.1838\n",
      "Epoch [481/3000], Loss: 1935.8807\n",
      "Validation Loss: 4469.6219\n",
      "Epoch [501/3000], Loss: 1808.8527\n",
      "Validation Loss: 3854.0626\n",
      "Epoch [521/3000], Loss: 1681.0900\n",
      "Validation Loss: 4049.4243\n",
      "Epoch [541/3000], Loss: 1559.9754\n",
      "Validation Loss: 3779.5774\n",
      "Epoch [561/3000], Loss: 1449.8061\n",
      "Validation Loss: 3656.2263\n",
      "Epoch [581/3000], Loss: 1343.4824\n",
      "Validation Loss: 3401.2753\n",
      "Epoch [601/3000], Loss: 1241.7255\n",
      "Validation Loss: 3210.0858\n",
      "Epoch [621/3000], Loss: 1148.0538\n",
      "Validation Loss: 3147.7547\n",
      "Epoch [641/3000], Loss: 1057.0342\n",
      "Validation Loss: 2981.0451\n",
      "Epoch [661/3000], Loss: 975.8836\n",
      "Validation Loss: 2873.2331\n",
      "Epoch [681/3000], Loss: 897.8433\n",
      "Validation Loss: 2758.0455\n",
      "Epoch [701/3000], Loss: 826.3139\n",
      "Validation Loss: 2655.5876\n",
      "Epoch [721/3000], Loss: 761.3520\n",
      "Validation Loss: 2662.5322\n",
      "Epoch [741/3000], Loss: 697.6931\n",
      "Validation Loss: 2555.9817\n",
      "Epoch [761/3000], Loss: 640.0885\n",
      "Validation Loss: 2488.5067\n",
      "Epoch [781/3000], Loss: 585.3613\n",
      "Validation Loss: 2458.3491\n",
      "Epoch [801/3000], Loss: 534.8160\n",
      "Validation Loss: 2450.8982\n",
      "Epoch [821/3000], Loss: 487.1277\n",
      "Validation Loss: 2386.6775\n",
      "Epoch [841/3000], Loss: 442.1606\n",
      "Validation Loss: 2329.6146\n",
      "Epoch [861/3000], Loss: 400.6824\n",
      "Validation Loss: 2356.5683\n",
      "Epoch [881/3000], Loss: 364.1573\n",
      "Validation Loss: 2366.7176\n",
      "Epoch [901/3000], Loss: 329.5703\n",
      "Validation Loss: 2308.4852\n",
      "Epoch [921/3000], Loss: 297.5479\n",
      "Validation Loss: 2247.5481\n",
      "Epoch [941/3000], Loss: 268.3116\n",
      "Validation Loss: 2193.7693\n",
      "Epoch [961/3000], Loss: 241.4078\n",
      "Validation Loss: 2119.8169\n",
      "Epoch [981/3000], Loss: 214.7262\n",
      "Validation Loss: 2059.4231\n",
      "Epoch [1001/3000], Loss: 193.5639\n",
      "Validation Loss: 1966.2895\n",
      "Epoch [1021/3000], Loss: 171.8443\n",
      "Validation Loss: 1942.0631\n",
      "Epoch [1041/3000], Loss: 153.4698\n",
      "Validation Loss: 1908.6551\n",
      "Epoch [1061/3000], Loss: 135.9019\n",
      "Validation Loss: 1832.0072\n",
      "Epoch [1081/3000], Loss: 119.4222\n",
      "Validation Loss: 1776.7137\n",
      "Epoch [1101/3000], Loss: 104.2490\n",
      "Validation Loss: 1747.3824\n",
      "Epoch [1121/3000], Loss: 90.9578\n",
      "Validation Loss: 1803.6080\n",
      "Epoch [1141/3000], Loss: 78.1002\n",
      "Validation Loss: 1776.6862\n",
      "Epoch [1161/3000], Loss: 66.7653\n",
      "Validation Loss: 1758.5869\n",
      "Epoch [1181/3000], Loss: 56.4478\n",
      "Validation Loss: 1718.9524\n",
      "Epoch [1201/3000], Loss: 47.2462\n",
      "Validation Loss: 1701.3926\n",
      "Epoch [1221/3000], Loss: 39.2667\n",
      "Validation Loss: 1675.3401\n",
      "Epoch [1241/3000], Loss: 32.2014\n",
      "Validation Loss: 1702.7542\n",
      "Epoch [1261/3000], Loss: 26.6221\n",
      "Validation Loss: 1669.2083\n",
      "Epoch [1281/3000], Loss: 21.6936\n",
      "Validation Loss: 1676.2818\n",
      "Epoch [1301/3000], Loss: 17.3425\n",
      "Validation Loss: 1707.7168\n",
      "Epoch [1321/3000], Loss: 13.7854\n",
      "Validation Loss: 1727.5003\n",
      "Epoch [1341/3000], Loss: 10.6473\n",
      "Validation Loss: 1703.7212\n",
      "Epoch [1361/3000], Loss: 8.0676\n",
      "Validation Loss: 1737.3573\n",
      "Epoch [1381/3000], Loss: 5.9207\n",
      "Validation Loss: 1745.0211\n",
      "Epoch [1401/3000], Loss: 4.2264\n",
      "Validation Loss: 1719.7205\n",
      "Epoch [1421/3000], Loss: 2.9210\n",
      "Validation Loss: 1724.8852\n",
      "Epoch [1441/3000], Loss: 1.9260\n",
      "Validation Loss: 1685.1486\n",
      "Epoch [1461/3000], Loss: 1.1923\n",
      "Validation Loss: 1679.8429\n",
      "Epoch [1481/3000], Loss: 0.6856\n",
      "Validation Loss: 1679.9486\n",
      "Epoch [1501/3000], Loss: 0.3605\n",
      "Validation Loss: 1677.9754\n",
      "Epoch [1521/3000], Loss: 0.1885\n",
      "Validation Loss: 1657.8820\n",
      "Epoch [1541/3000], Loss: 0.0961\n",
      "Validation Loss: 1675.6482\n",
      "Epoch [1561/3000], Loss: 0.0557\n",
      "Validation Loss: 1678.4114\n",
      "Epoch [1581/3000], Loss: 0.0412\n",
      "Validation Loss: 1669.1500\n",
      "Epoch [1601/3000], Loss: 0.0782\n",
      "Validation Loss: 1749.0451\n",
      "Epoch [1621/3000], Loss: 0.0417\n",
      "Validation Loss: 1741.2582\n",
      "Epoch [1641/3000], Loss: 0.0323\n",
      "Validation Loss: 1737.0811\n",
      "Epoch [1661/3000], Loss: 0.0282\n",
      "Validation Loss: 1728.7401\n",
      "Epoch [1681/3000], Loss: 0.0262\n",
      "Validation Loss: 1727.9073\n",
      "Epoch [1701/3000], Loss: 0.0246\n",
      "Validation Loss: 1718.8368\n",
      "Epoch [1721/3000], Loss: 0.0230\n",
      "Validation Loss: 1717.4796\n",
      "Epoch [1741/3000], Loss: 0.0243\n",
      "Validation Loss: 1703.8318\n",
      "Epoch [1761/3000], Loss: 0.0235\n",
      "Validation Loss: 1714.4319\n",
      "Epoch [1781/3000], Loss: 0.0207\n",
      "Validation Loss: 1699.8409\n",
      "Epoch [1801/3000], Loss: 0.0219\n",
      "Validation Loss: 1698.0749\n",
      "Epoch [1821/3000], Loss: 0.0205\n",
      "Validation Loss: 1690.9819\n",
      "Epoch [1841/3000], Loss: 0.0243\n",
      "Validation Loss: 1683.1552\n",
      "Epoch [1861/3000], Loss: 0.0183\n",
      "Validation Loss: 1689.8480\n",
      "Epoch [1881/3000], Loss: 0.2283\n",
      "Validation Loss: 1616.7876\n",
      "Epoch [1901/3000], Loss: 0.0135\n",
      "Validation Loss: 1668.9377\n",
      "Epoch [1921/3000], Loss: 0.0135\n",
      "Validation Loss: 1671.2898\n",
      "Epoch [1941/3000], Loss: 0.0151\n",
      "Validation Loss: 1668.5858\n",
      "Epoch [1961/3000], Loss: 0.0159\n",
      "Validation Loss: 1664.3398\n",
      "Epoch [1981/3000], Loss: 0.0160\n",
      "Validation Loss: 1663.5766\n",
      "Epoch [2001/3000], Loss: 0.0158\n",
      "Validation Loss: 1659.0549\n",
      "Epoch [2021/3000], Loss: 0.0134\n",
      "Validation Loss: 1664.9740\n",
      "Epoch [2041/3000], Loss: 0.0149\n",
      "Validation Loss: 1659.9659\n",
      "Epoch [2061/3000], Loss: 0.0144\n",
      "Validation Loss: 1656.7835\n",
      "Epoch [2081/3000], Loss: 0.0125\n",
      "Validation Loss: 1646.5944\n",
      "Epoch [2101/3000], Loss: 0.0131\n",
      "Validation Loss: 1655.4019\n",
      "Epoch [2121/3000], Loss: 0.0154\n",
      "Validation Loss: 1641.6585\n",
      "Epoch [2141/3000], Loss: 0.0125\n",
      "Validation Loss: 1649.8285\n",
      "Epoch [2161/3000], Loss: 0.0107\n",
      "Validation Loss: 1647.1286\n",
      "Epoch [2181/3000], Loss: 0.0125\n",
      "Validation Loss: 1648.5838\n",
      "Epoch [2201/3000], Loss: 0.0096\n",
      "Validation Loss: 1654.2462\n",
      "Epoch [2221/3000], Loss: 0.0105\n",
      "Validation Loss: 1654.9077\n",
      "Epoch [2241/3000], Loss: 0.0094\n",
      "Validation Loss: 1653.9724\n",
      "Epoch [2261/3000], Loss: 0.0121\n",
      "Validation Loss: 1644.9846\n",
      "Epoch [2281/3000], Loss: 0.0084\n",
      "Validation Loss: 1643.7964\n",
      "Epoch [2301/3000], Loss: 0.0097\n",
      "Validation Loss: 1641.9586\n",
      "Epoch [2321/3000], Loss: 0.0080\n",
      "Validation Loss: 1641.5243\n",
      "Epoch [2341/3000], Loss: 0.0085\n",
      "Validation Loss: 1650.7565\n",
      "Epoch [2361/3000], Loss: 0.0073\n",
      "Validation Loss: 1640.0281\n",
      "Epoch [2381/3000], Loss: 0.0073\n",
      "Validation Loss: 1650.9777\n",
      "Epoch [2401/3000], Loss: 0.0092\n",
      "Validation Loss: 1645.9116\n",
      "Epoch [2421/3000], Loss: 0.0065\n",
      "Validation Loss: 1654.5787\n",
      "Epoch [2441/3000], Loss: 0.0071\n",
      "Validation Loss: 1642.7988\n",
      "Epoch [2461/3000], Loss: 0.0068\n",
      "Validation Loss: 1641.8812\n",
      "Epoch [2481/3000], Loss: 0.0059\n",
      "Validation Loss: 1642.0201\n",
      "Epoch [2501/3000], Loss: 0.0072\n",
      "Validation Loss: 1634.5490\n",
      "Epoch [2521/3000], Loss: 0.0076\n",
      "Validation Loss: 1639.6989\n",
      "Epoch [2541/3000], Loss: 0.0051\n",
      "Validation Loss: 1634.4480\n",
      "Epoch [2561/3000], Loss: 0.0053\n",
      "Validation Loss: 1632.8772\n",
      "Epoch [2581/3000], Loss: 0.0067\n",
      "Validation Loss: 1643.7645\n",
      "Epoch [2601/3000], Loss: 0.0059\n",
      "Validation Loss: 1636.4896\n",
      "Epoch [2621/3000], Loss: 0.0057\n",
      "Validation Loss: 1626.6529\n",
      "Epoch [2641/3000], Loss: 0.0067\n",
      "Validation Loss: 1631.7613\n",
      "Epoch [2661/3000], Loss: 0.0044\n",
      "Validation Loss: 1637.3442\n",
      "Epoch [2681/3000], Loss: 0.0054\n",
      "Validation Loss: 1632.8600\n",
      "Epoch [2701/3000], Loss: 0.0054\n",
      "Validation Loss: 1645.1867\n",
      "Epoch [2721/3000], Loss: 0.0049\n",
      "Validation Loss: 1645.7012\n",
      "Epoch [2741/3000], Loss: 0.0071\n",
      "Validation Loss: 1639.6081\n",
      "Epoch [2761/3000], Loss: 0.0060\n",
      "Validation Loss: 1645.3026\n",
      "Epoch [2781/3000], Loss: 0.0080\n",
      "Validation Loss: 1646.5764\n",
      "Epoch [2801/3000], Loss: 0.0045\n",
      "Validation Loss: 1631.7395\n",
      "Epoch [2821/3000], Loss: 0.0083\n",
      "Validation Loss: 1629.9944\n",
      "Epoch [2841/3000], Loss: 0.0048\n",
      "Validation Loss: 1637.7456\n",
      "Epoch [2861/3000], Loss: 0.0037\n",
      "Validation Loss: 1637.1670\n",
      "Epoch [2881/3000], Loss: 0.0035\n",
      "Validation Loss: 1632.2973\n",
      "Epoch [2901/3000], Loss: 0.0049\n",
      "Validation Loss: 1640.5982\n",
      "Epoch [2921/3000], Loss: 0.0046\n",
      "Validation Loss: 1656.2130\n",
      "Epoch [2941/3000], Loss: 0.0041\n",
      "Validation Loss: 1634.1142\n",
      "Epoch [2961/3000], Loss: 0.0049\n",
      "Validation Loss: 1636.5340\n",
      "Epoch [2981/3000], Loss: 0.0040\n",
      "Validation Loss: 1641.5489\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day054_plane0_Fall.mat\n",
      "(7112, 868)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7929.5664\n",
      "Validation Loss: 5471.2099\n",
      "Epoch [21/3000], Loss: 6840.2129\n",
      "Validation Loss: 4639.2123\n",
      "Epoch [41/3000], Loss: 6560.7177\n",
      "Validation Loss: 4468.2026\n",
      "Epoch [61/3000], Loss: 6409.7886\n",
      "Validation Loss: 4343.0425\n",
      "Epoch [81/3000], Loss: 6229.5444\n",
      "Validation Loss: 4231.6904\n",
      "Epoch [101/3000], Loss: 6090.8217\n",
      "Validation Loss: 4127.9539\n",
      "Epoch [121/3000], Loss: 5946.0534\n",
      "Validation Loss: 4029.8203\n",
      "Epoch [141/3000], Loss: 5823.7325\n",
      "Validation Loss: 3936.4896\n",
      "Epoch [161/3000], Loss: 5675.1123\n",
      "Validation Loss: 3847.2842\n",
      "Epoch [181/3000], Loss: 5576.6846\n",
      "Validation Loss: 3762.2399\n",
      "Epoch [201/3000], Loss: 5458.1460\n",
      "Validation Loss: 3681.0331\n",
      "Epoch [221/3000], Loss: 5330.7449\n",
      "Validation Loss: 3603.5293\n",
      "Epoch [241/3000], Loss: 5195.8332\n",
      "Validation Loss: 3529.7782\n",
      "Epoch [261/3000], Loss: 5081.5079\n",
      "Validation Loss: 3459.5447\n",
      "Epoch [281/3000], Loss: 4978.1280\n",
      "Validation Loss: 3392.8528\n",
      "Epoch [301/3000], Loss: 4875.9079\n",
      "Validation Loss: 3329.8041\n",
      "Epoch [321/3000], Loss: 4775.8234\n",
      "Validation Loss: 3270.3312\n",
      "Epoch [341/3000], Loss: 4695.3850\n",
      "Validation Loss: 3214.2769\n",
      "Epoch [361/3000], Loss: 4598.3964\n",
      "Validation Loss: 3161.7332\n",
      "Epoch [381/3000], Loss: 4510.6128\n",
      "Validation Loss: 3112.7437\n",
      "Epoch [401/3000], Loss: 4413.9613\n",
      "Validation Loss: 3067.1639\n",
      "Epoch [421/3000], Loss: 4347.2840\n",
      "Validation Loss: 3024.9395\n",
      "Epoch [441/3000], Loss: 4279.4807\n",
      "Validation Loss: 2986.1515\n",
      "Epoch [461/3000], Loss: 4189.5789\n",
      "Validation Loss: 2950.8356\n",
      "Epoch [481/3000], Loss: 4116.4426\n",
      "Validation Loss: 2918.8440\n",
      "Epoch [501/3000], Loss: 4046.9925\n",
      "Validation Loss: 2868.9045\n",
      "Epoch [521/3000], Loss: 3462.7665\n",
      "Validation Loss: 2363.1928\n",
      "Epoch [541/3000], Loss: 3350.1254\n",
      "Validation Loss: 2281.4891\n",
      "Epoch [561/3000], Loss: 3238.8029\n",
      "Validation Loss: 2215.8608\n",
      "Epoch [581/3000], Loss: 3136.1113\n",
      "Validation Loss: 2151.4815\n",
      "Epoch [601/3000], Loss: 3039.2821\n",
      "Validation Loss: 2083.2553\n",
      "Epoch [621/3000], Loss: 2945.9245\n",
      "Validation Loss: 2028.1303\n",
      "Epoch [641/3000], Loss: 2872.9022\n",
      "Validation Loss: 1977.3383\n",
      "Epoch [661/3000], Loss: 2767.9424\n",
      "Validation Loss: 1929.9893\n",
      "Epoch [681/3000], Loss: 2682.2772\n",
      "Validation Loss: 1884.0552\n",
      "Epoch [701/3000], Loss: 2607.7706\n",
      "Validation Loss: 1838.0755\n",
      "Epoch [721/3000], Loss: 2529.8816\n",
      "Validation Loss: 1796.5474\n",
      "Epoch [741/3000], Loss: 2447.8210\n",
      "Validation Loss: 1755.3424\n",
      "Epoch [761/3000], Loss: 2373.4341\n",
      "Validation Loss: 1717.3154\n",
      "Epoch [781/3000], Loss: 2281.1779\n",
      "Validation Loss: 1677.8014\n",
      "Epoch [801/3000], Loss: 2222.3310\n",
      "Validation Loss: 1645.0761\n",
      "Epoch [821/3000], Loss: 2148.8078\n",
      "Validation Loss: 1610.5096\n",
      "Epoch [841/3000], Loss: 2094.3533\n",
      "Validation Loss: 1662.5428\n",
      "Epoch [861/3000], Loss: 2016.5684\n",
      "Validation Loss: 1502.7214\n",
      "Epoch [881/3000], Loss: 1943.8974\n",
      "Validation Loss: 1472.6108\n",
      "Epoch [901/3000], Loss: 1874.1253\n",
      "Validation Loss: 1444.2946\n",
      "Epoch [921/3000], Loss: 1805.1343\n",
      "Validation Loss: 1416.4783\n",
      "Epoch [941/3000], Loss: 1744.0567\n",
      "Validation Loss: 1389.0401\n",
      "Epoch [961/3000], Loss: 1691.9143\n",
      "Validation Loss: 1364.6332\n",
      "Epoch [981/3000], Loss: 1627.6532\n",
      "Validation Loss: 1339.9356\n",
      "Epoch [1001/3000], Loss: 1572.4191\n",
      "Validation Loss: 1318.8472\n",
      "Epoch [1021/3000], Loss: 1512.1419\n",
      "Validation Loss: 1298.1713\n",
      "Epoch [1041/3000], Loss: 1465.7290\n",
      "Validation Loss: 1258.6679\n",
      "Epoch [1061/3000], Loss: 1418.8954\n",
      "Validation Loss: 1241.5703\n",
      "Epoch [1081/3000], Loss: 1356.0896\n",
      "Validation Loss: 1224.2582\n",
      "Epoch [1101/3000], Loss: 1304.7397\n",
      "Validation Loss: 1139.4198\n",
      "Epoch [1121/3000], Loss: 1255.9528\n",
      "Validation Loss: 1182.9911\n",
      "Epoch [1141/3000], Loss: 1204.0159\n",
      "Validation Loss: 1166.5097\n",
      "Epoch [1161/3000], Loss: 1154.4640\n",
      "Validation Loss: 1148.8125\n",
      "Epoch [1181/3000], Loss: 1116.3923\n",
      "Validation Loss: 1133.2465\n",
      "Epoch [1201/3000], Loss: 1071.0548\n",
      "Validation Loss: 1120.7782\n",
      "Epoch [1221/3000], Loss: 1028.0135\n",
      "Validation Loss: 1104.0411\n",
      "Epoch [1241/3000], Loss: 977.6646\n",
      "Validation Loss: 1089.9120\n",
      "Epoch [1261/3000], Loss: 944.8728\n",
      "Validation Loss: 1077.4934\n",
      "Epoch [1281/3000], Loss: 899.6792\n",
      "Validation Loss: 1067.6255\n",
      "Epoch [1301/3000], Loss: 866.7827\n",
      "Validation Loss: 1044.8590\n",
      "Epoch [1321/3000], Loss: 829.3969\n",
      "Validation Loss: 1005.3223\n",
      "Epoch [1341/3000], Loss: 790.6986\n",
      "Validation Loss: 991.4406\n",
      "Epoch [1361/3000], Loss: 759.9725\n",
      "Validation Loss: 988.4117\n",
      "Epoch [1381/3000], Loss: 726.6288\n",
      "Validation Loss: 976.6594\n",
      "Epoch [1401/3000], Loss: 692.5433\n",
      "Validation Loss: 936.4958\n",
      "Epoch [1421/3000], Loss: 662.0122\n",
      "Validation Loss: 933.0549\n",
      "Epoch [1441/3000], Loss: 627.3564\n",
      "Validation Loss: 930.2442\n",
      "Epoch [1461/3000], Loss: 602.8723\n",
      "Validation Loss: 925.9948\n",
      "Epoch [1481/3000], Loss: 568.9250\n",
      "Validation Loss: 924.3430\n",
      "Epoch [1501/3000], Loss: 541.7062\n",
      "Validation Loss: 922.1225\n",
      "Epoch [1521/3000], Loss: 516.1955\n",
      "Validation Loss: 917.2945\n",
      "Epoch [1541/3000], Loss: 492.0441\n",
      "Validation Loss: 919.9215\n",
      "Epoch [1561/3000], Loss: 468.9203\n",
      "Validation Loss: 917.9978\n",
      "Epoch [1581/3000], Loss: 440.4849\n",
      "Validation Loss: 921.1597\n",
      "Epoch [1601/3000], Loss: 415.5198\n",
      "Validation Loss: 918.4355\n",
      "Epoch [1621/3000], Loss: 396.0713\n",
      "Validation Loss: 915.9483\n",
      "Epoch [1641/3000], Loss: 374.9149\n",
      "Validation Loss: 918.8214\n",
      "Epoch [1661/3000], Loss: 352.8681\n",
      "Validation Loss: 920.0278\n",
      "Epoch [1681/3000], Loss: 332.8629\n",
      "Validation Loss: 932.4778\n",
      "Epoch [1701/3000], Loss: 313.1256\n",
      "Validation Loss: 936.7485\n",
      "Epoch [1721/3000], Loss: 295.8242\n",
      "Validation Loss: 936.4282\n",
      "Epoch [1741/3000], Loss: 274.6382\n",
      "Validation Loss: 942.0227\n",
      "Epoch [1761/3000], Loss: 256.9651\n",
      "Validation Loss: 959.9803\n",
      "Epoch [1781/3000], Loss: 240.9735\n",
      "Validation Loss: 939.3964\n",
      "Epoch [1801/3000], Loss: 227.8389\n",
      "Validation Loss: 965.0522\n",
      "Epoch [1821/3000], Loss: 213.2990\n",
      "Validation Loss: 965.4568\n",
      "Epoch [1841/3000], Loss: 197.3069\n",
      "Validation Loss: 974.0544\n",
      "Epoch [1861/3000], Loss: 184.0273\n",
      "Validation Loss: 978.9718\n",
      "Epoch [1881/3000], Loss: 171.6993\n",
      "Validation Loss: 882.0247\n",
      "Epoch [1901/3000], Loss: 158.5222\n",
      "Validation Loss: 918.2569\n",
      "Epoch [1921/3000], Loss: 148.7927\n",
      "Validation Loss: 932.4358\n",
      "Epoch [1941/3000], Loss: 137.3423\n",
      "Validation Loss: 944.0147\n",
      "Epoch [1961/3000], Loss: 126.7867\n",
      "Validation Loss: 956.0460\n",
      "Epoch [1981/3000], Loss: 116.9370\n",
      "Validation Loss: 971.3524\n",
      "Epoch [2001/3000], Loss: 106.6976\n",
      "Validation Loss: 987.8276\n",
      "Epoch [2021/3000], Loss: 97.6604\n",
      "Validation Loss: 1005.4044\n",
      "Epoch [2041/3000], Loss: 88.8871\n",
      "Validation Loss: 1017.3815\n",
      "Epoch [2061/3000], Loss: 81.8251\n",
      "Validation Loss: 1029.4254\n",
      "Epoch [2081/3000], Loss: 73.8269\n",
      "Validation Loss: 1045.9337\n",
      "Epoch [2101/3000], Loss: 67.9446\n",
      "Validation Loss: 1066.6296\n",
      "Epoch [2121/3000], Loss: 60.6051\n",
      "Validation Loss: 1083.1980\n",
      "Epoch [2141/3000], Loss: 54.1517\n",
      "Validation Loss: 1099.8468\n",
      "Epoch [2161/3000], Loss: 48.8653\n",
      "Validation Loss: 1110.1308\n",
      "Epoch [2181/3000], Loss: 44.0779\n",
      "Validation Loss: 1117.1043\n",
      "Epoch [2201/3000], Loss: 39.6187\n",
      "Validation Loss: 1130.8901\n",
      "Epoch [2221/3000], Loss: 34.9931\n",
      "Validation Loss: 1139.8146\n",
      "Epoch [2241/3000], Loss: 30.7324\n",
      "Validation Loss: 1154.4380\n",
      "Epoch [2261/3000], Loss: 27.4218\n",
      "Validation Loss: 1165.0211\n",
      "Epoch [2281/3000], Loss: 23.9622\n",
      "Validation Loss: 1173.4582\n",
      "Epoch [2301/3000], Loss: 20.6904\n",
      "Validation Loss: 1182.0424\n",
      "Epoch [2321/3000], Loss: 18.0496\n",
      "Validation Loss: 1190.4817\n",
      "Epoch [2341/3000], Loss: 15.5021\n",
      "Validation Loss: 1205.8128\n",
      "Epoch [2361/3000], Loss: 13.3521\n",
      "Validation Loss: 1219.2830\n",
      "Epoch [2381/3000], Loss: 11.3734\n",
      "Validation Loss: 1226.6107\n",
      "Epoch [2401/3000], Loss: 9.6438\n",
      "Validation Loss: 1237.0839\n",
      "Epoch [2421/3000], Loss: 8.1435\n",
      "Validation Loss: 1232.2365\n",
      "Epoch [2441/3000], Loss: 6.8293\n",
      "Validation Loss: 1274.1660\n",
      "Epoch [2461/3000], Loss: 5.5748\n",
      "Validation Loss: 1262.8227\n",
      "Epoch [2481/3000], Loss: 4.7879\n",
      "Validation Loss: 1231.9118\n",
      "Epoch [2501/3000], Loss: 3.8472\n",
      "Validation Loss: 1246.0106\n",
      "Epoch [2521/3000], Loss: 3.1733\n",
      "Validation Loss: 1261.2785\n",
      "Epoch [2541/3000], Loss: 2.5304\n",
      "Validation Loss: 1275.7841\n",
      "Epoch [2561/3000], Loss: 2.0331\n",
      "Validation Loss: 1290.5110\n",
      "Epoch [2581/3000], Loss: 1.6538\n",
      "Validation Loss: 1307.9173\n",
      "Epoch [2601/3000], Loss: 1.2318\n",
      "Validation Loss: 1319.7958\n",
      "Epoch [2621/3000], Loss: 0.9360\n",
      "Validation Loss: 1329.8882\n",
      "Epoch [2641/3000], Loss: 0.6855\n",
      "Validation Loss: 1336.3158\n",
      "Epoch [2661/3000], Loss: 0.4856\n",
      "Validation Loss: 1345.6198\n",
      "Epoch [2681/3000], Loss: 0.3439\n",
      "Validation Loss: 1358.0918\n",
      "Epoch [2701/3000], Loss: 0.2321\n",
      "Validation Loss: 1363.1045\n",
      "Epoch [2721/3000], Loss: 0.1633\n",
      "Validation Loss: 1367.9115\n",
      "Epoch [2741/3000], Loss: 0.1123\n",
      "Validation Loss: 1366.6643\n",
      "Epoch [2761/3000], Loss: 0.0802\n",
      "Validation Loss: 1374.5109\n",
      "Epoch [2781/3000], Loss: 0.0571\n",
      "Validation Loss: 1368.0083\n",
      "Epoch [2801/3000], Loss: 0.0489\n",
      "Validation Loss: 1374.8855\n",
      "Epoch [2821/3000], Loss: 0.0363\n",
      "Validation Loss: 1360.4153\n",
      "Epoch [2841/3000], Loss: 0.0303\n",
      "Validation Loss: 1363.1588\n",
      "Epoch [2861/3000], Loss: 0.0261\n",
      "Validation Loss: 1349.0032\n",
      "Epoch [2881/3000], Loss: 0.0252\n",
      "Validation Loss: 1350.4467\n",
      "Epoch [2901/3000], Loss: 0.0238\n",
      "Validation Loss: 1343.5771\n",
      "Epoch [2921/3000], Loss: 0.0183\n",
      "Validation Loss: 1341.6040\n",
      "Epoch [2941/3000], Loss: 0.0178\n",
      "Validation Loss: 1342.0174\n",
      "Epoch [2961/3000], Loss: 0.0179\n",
      "Validation Loss: 1333.4519\n",
      "Epoch [2981/3000], Loss: 0.0157\n",
      "Validation Loss: 1337.9494\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day055_plane0_Fall.mat\n",
      "(5210, 982)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6866.7165\n",
      "Validation Loss: 5772.3861\n",
      "Epoch [21/3000], Loss: 5907.2914\n",
      "Validation Loss: 4901.7107\n",
      "Epoch [41/3000], Loss: 5673.0976\n",
      "Validation Loss: 4696.8169\n",
      "Epoch [61/3000], Loss: 5529.4693\n",
      "Validation Loss: 4573.5434\n",
      "Epoch [81/3000], Loss: 5410.2041\n",
      "Validation Loss: 4468.7550\n",
      "Epoch [101/3000], Loss: 5306.9490\n",
      "Validation Loss: 4373.3890\n",
      "Epoch [121/3000], Loss: 5199.7805\n",
      "Validation Loss: 4283.1401\n",
      "Epoch [141/3000], Loss: 5094.4486\n",
      "Validation Loss: 4196.6769\n",
      "Epoch [161/3000], Loss: 4996.4346\n",
      "Validation Loss: 4113.1723\n",
      "Epoch [181/3000], Loss: 4915.3357\n",
      "Validation Loss: 4032.4019\n",
      "Epoch [201/3000], Loss: 4828.3623\n",
      "Validation Loss: 3954.2187\n",
      "Epoch [221/3000], Loss: 4736.7180\n",
      "Validation Loss: 3878.2693\n",
      "Epoch [241/3000], Loss: 4619.5190\n",
      "Validation Loss: 3804.4853\n",
      "Epoch [261/3000], Loss: 4583.5351\n",
      "Validation Loss: 3732.9807\n",
      "Epoch [281/3000], Loss: 4483.6534\n",
      "Validation Loss: 3663.4282\n",
      "Epoch [301/3000], Loss: 4415.0120\n",
      "Validation Loss: 3595.8871\n",
      "Epoch [321/3000], Loss: 4322.4998\n",
      "Validation Loss: 3530.2990\n",
      "Epoch [341/3000], Loss: 4268.9454\n",
      "Validation Loss: 3466.7532\n",
      "Epoch [361/3000], Loss: 4193.8243\n",
      "Validation Loss: 3405.1886\n",
      "Epoch [381/3000], Loss: 4126.1514\n",
      "Validation Loss: 3345.4832\n",
      "Epoch [401/3000], Loss: 4045.1495\n",
      "Validation Loss: 3287.8386\n",
      "Epoch [421/3000], Loss: 3985.0042\n",
      "Validation Loss: 3232.1032\n",
      "Epoch [441/3000], Loss: 3920.5005\n",
      "Validation Loss: 3178.2064\n",
      "Epoch [461/3000], Loss: 3870.3049\n",
      "Validation Loss: 3126.2672\n",
      "Epoch [481/3000], Loss: 3792.4233\n",
      "Validation Loss: 3076.2039\n",
      "Epoch [501/3000], Loss: 3757.1531\n",
      "Validation Loss: 3028.0819\n",
      "Epoch [521/3000], Loss: 3683.6425\n",
      "Validation Loss: 2981.8043\n",
      "Epoch [541/3000], Loss: 3627.6000\n",
      "Validation Loss: 2937.4375\n",
      "Epoch [561/3000], Loss: 3578.7946\n",
      "Validation Loss: 2894.6318\n",
      "Epoch [581/3000], Loss: 3510.1095\n",
      "Validation Loss: 2853.3202\n",
      "Epoch [601/3000], Loss: 3476.6009\n",
      "Validation Loss: 2814.3222\n",
      "Epoch [621/3000], Loss: 3425.1162\n",
      "Validation Loss: 2777.2200\n",
      "Epoch [641/3000], Loss: 3387.0964\n",
      "Validation Loss: 2742.0599\n",
      "Epoch [661/3000], Loss: 3331.5468\n",
      "Validation Loss: 2708.7275\n",
      "Epoch [681/3000], Loss: 3285.4610\n",
      "Validation Loss: 2677.2135\n",
      "Epoch [701/3000], Loss: 3247.2054\n",
      "Validation Loss: 2647.5029\n",
      "Epoch [721/3000], Loss: 3200.4322\n",
      "Validation Loss: 2619.6068\n",
      "Epoch [741/3000], Loss: 3174.1581\n",
      "Validation Loss: 2593.5484\n",
      "Epoch [761/3000], Loss: 3147.8065\n",
      "Validation Loss: 2569.1970\n",
      "Epoch [781/3000], Loss: 3112.8577\n",
      "Validation Loss: 2546.6167\n",
      "Epoch [801/3000], Loss: 3084.2676\n",
      "Validation Loss: 2525.7940\n",
      "Epoch [821/3000], Loss: 3057.8738\n",
      "Validation Loss: 2506.6493\n",
      "Epoch [841/3000], Loss: 3021.5899\n",
      "Validation Loss: 2488.7985\n",
      "Epoch [861/3000], Loss: 2308.5142\n",
      "Validation Loss: 1772.1417\n",
      "Epoch [881/3000], Loss: 2193.1930\n",
      "Validation Loss: 1706.9396\n",
      "Epoch [901/3000], Loss: 2118.2047\n",
      "Validation Loss: 1662.3308\n",
      "Epoch [921/3000], Loss: 2054.9985\n",
      "Validation Loss: 1606.1913\n",
      "Epoch [941/3000], Loss: 1993.3349\n",
      "Validation Loss: 1559.1735\n",
      "Epoch [961/3000], Loss: 1936.8968\n",
      "Validation Loss: 1515.7610\n",
      "Epoch [981/3000], Loss: 1896.8458\n",
      "Validation Loss: 1470.9980\n",
      "Epoch [1001/3000], Loss: 1833.5896\n",
      "Validation Loss: 1430.7264\n",
      "Epoch [1021/3000], Loss: 1793.9898\n",
      "Validation Loss: 1390.3179\n",
      "Epoch [1041/3000], Loss: 1732.7701\n",
      "Validation Loss: 1351.9895\n",
      "Epoch [1061/3000], Loss: 1685.5793\n",
      "Validation Loss: 1315.7966\n",
      "Epoch [1081/3000], Loss: 1649.1622\n",
      "Validation Loss: 1279.6929\n",
      "Epoch [1101/3000], Loss: 1607.9980\n",
      "Validation Loss: 1245.0024\n",
      "Epoch [1121/3000], Loss: 1553.3794\n",
      "Validation Loss: 1211.2424\n",
      "Epoch [1141/3000], Loss: 1513.6651\n",
      "Validation Loss: 1179.4014\n",
      "Epoch [1161/3000], Loss: 1472.5008\n",
      "Validation Loss: 1146.9415\n",
      "Epoch [1181/3000], Loss: 1430.1343\n",
      "Validation Loss: 1118.6967\n",
      "Epoch [1201/3000], Loss: 1396.7265\n",
      "Validation Loss: 1088.4159\n",
      "Epoch [1221/3000], Loss: 1351.1168\n",
      "Validation Loss: 1059.1704\n",
      "Epoch [1241/3000], Loss: 1315.1950\n",
      "Validation Loss: 1030.9724\n",
      "Epoch [1261/3000], Loss: 1273.4045\n",
      "Validation Loss: 1004.4310\n",
      "Epoch [1281/3000], Loss: 1245.0509\n",
      "Validation Loss: 977.8406\n",
      "Epoch [1301/3000], Loss: 1198.5965\n",
      "Validation Loss: 952.1307\n",
      "Epoch [1321/3000], Loss: 1174.7002\n",
      "Validation Loss: 944.7801\n",
      "Epoch [1341/3000], Loss: 1133.9800\n",
      "Validation Loss: 904.0604\n",
      "Epoch [1361/3000], Loss: 1103.4024\n",
      "Validation Loss: 882.2502\n",
      "Epoch [1381/3000], Loss: 1070.3217\n",
      "Validation Loss: 859.4750\n",
      "Epoch [1401/3000], Loss: 1041.5436\n",
      "Validation Loss: 838.1629\n",
      "Epoch [1421/3000], Loss: 1010.8878\n",
      "Validation Loss: 818.3953\n",
      "Epoch [1441/3000], Loss: 983.3391\n",
      "Validation Loss: 797.7133\n",
      "Epoch [1461/3000], Loss: 954.7028\n",
      "Validation Loss: 785.7524\n",
      "Epoch [1481/3000], Loss: 928.8724\n",
      "Validation Loss: 761.0231\n",
      "Epoch [1501/3000], Loss: 895.1053\n",
      "Validation Loss: 742.6607\n",
      "Epoch [1521/3000], Loss: 875.6966\n",
      "Validation Loss: 725.1675\n",
      "Epoch [1541/3000], Loss: 850.0475\n",
      "Validation Loss: 708.4277\n",
      "Epoch [1561/3000], Loss: 829.9594\n",
      "Validation Loss: 691.7228\n",
      "Epoch [1581/3000], Loss: 799.6885\n",
      "Validation Loss: 675.8403\n",
      "Epoch [1601/3000], Loss: 775.0982\n",
      "Validation Loss: 659.8545\n",
      "Epoch [1621/3000], Loss: 755.7930\n",
      "Validation Loss: 645.1546\n",
      "Epoch [1641/3000], Loss: 725.1462\n",
      "Validation Loss: 630.1133\n",
      "Epoch [1661/3000], Loss: 700.4052\n",
      "Validation Loss: 615.8233\n",
      "Epoch [1681/3000], Loss: 677.1157\n",
      "Validation Loss: 601.9104\n",
      "Epoch [1701/3000], Loss: 661.3002\n",
      "Validation Loss: 588.0567\n",
      "Epoch [1721/3000], Loss: 640.4600\n",
      "Validation Loss: 574.7333\n",
      "Epoch [1741/3000], Loss: 615.4317\n",
      "Validation Loss: 561.5468\n",
      "Epoch [1761/3000], Loss: 598.6132\n",
      "Validation Loss: 548.6645\n",
      "Epoch [1781/3000], Loss: 582.1851\n",
      "Validation Loss: 536.3256\n",
      "Epoch [1801/3000], Loss: 561.5282\n",
      "Validation Loss: 523.7922\n",
      "Epoch [1821/3000], Loss: 542.2809\n",
      "Validation Loss: 511.8070\n",
      "Epoch [1841/3000], Loss: 522.1838\n",
      "Validation Loss: 499.7032\n",
      "Epoch [1861/3000], Loss: 500.7432\n",
      "Validation Loss: 488.9329\n",
      "Epoch [1881/3000], Loss: 488.4810\n",
      "Validation Loss: 477.5124\n",
      "Epoch [1901/3000], Loss: 466.4612\n",
      "Validation Loss: 467.5428\n",
      "Epoch [1921/3000], Loss: 453.3705\n",
      "Validation Loss: 456.5441\n",
      "Epoch [1941/3000], Loss: 438.6068\n",
      "Validation Loss: 445.9289\n",
      "Epoch [1961/3000], Loss: 421.0324\n",
      "Validation Loss: 436.5685\n",
      "Epoch [1981/3000], Loss: 404.9898\n",
      "Validation Loss: 426.7940\n",
      "Epoch [2001/3000], Loss: 392.9281\n",
      "Validation Loss: 417.6685\n",
      "Epoch [2021/3000], Loss: 376.7631\n",
      "Validation Loss: 408.6495\n",
      "Epoch [2041/3000], Loss: 367.3331\n",
      "Validation Loss: 400.4140\n",
      "Epoch [2061/3000], Loss: 352.6600\n",
      "Validation Loss: 391.7154\n",
      "Epoch [2081/3000], Loss: 336.6949\n",
      "Validation Loss: 384.1003\n",
      "Epoch [2101/3000], Loss: 324.4875\n",
      "Validation Loss: 375.9815\n",
      "Epoch [2121/3000], Loss: 312.9753\n",
      "Validation Loss: 368.0406\n",
      "Epoch [2141/3000], Loss: 302.1446\n",
      "Validation Loss: 362.5178\n",
      "Epoch [2161/3000], Loss: 291.6238\n",
      "Validation Loss: 353.3318\n",
      "Epoch [2181/3000], Loss: 276.1190\n",
      "Validation Loss: 345.2921\n",
      "Epoch [2201/3000], Loss: 266.0759\n",
      "Validation Loss: 338.8351\n",
      "Epoch [2221/3000], Loss: 254.8411\n",
      "Validation Loss: 331.0003\n",
      "Epoch [2241/3000], Loss: 244.7993\n",
      "Validation Loss: 325.0110\n",
      "Epoch [2261/3000], Loss: 234.2921\n",
      "Validation Loss: 317.4738\n",
      "Epoch [2281/3000], Loss: 223.7640\n",
      "Validation Loss: 311.1652\n",
      "Epoch [2301/3000], Loss: 217.1114\n",
      "Validation Loss: 305.7106\n",
      "Epoch [2321/3000], Loss: 206.2303\n",
      "Validation Loss: 298.8119\n",
      "Epoch [2341/3000], Loss: 197.1563\n",
      "Validation Loss: 294.3408\n",
      "Epoch [2361/3000], Loss: 187.2668\n",
      "Validation Loss: 286.8154\n",
      "Epoch [2381/3000], Loss: 178.2442\n",
      "Validation Loss: 281.1888\n",
      "Epoch [2401/3000], Loss: 172.4455\n",
      "Validation Loss: 274.7902\n",
      "Epoch [2421/3000], Loss: 164.1805\n",
      "Validation Loss: 266.4834\n",
      "Epoch [2441/3000], Loss: 153.9638\n",
      "Validation Loss: 266.1639\n",
      "Epoch [2461/3000], Loss: 149.2985\n",
      "Validation Loss: 260.5659\n",
      "Epoch [2481/3000], Loss: 141.6794\n",
      "Validation Loss: 254.9628\n",
      "Epoch [2501/3000], Loss: 135.3846\n",
      "Validation Loss: 249.7128\n",
      "Epoch [2521/3000], Loss: 127.8121\n",
      "Validation Loss: 244.7177\n",
      "Epoch [2541/3000], Loss: 119.4752\n",
      "Validation Loss: 240.3851\n",
      "Epoch [2561/3000], Loss: 116.0343\n",
      "Validation Loss: 235.4142\n",
      "Epoch [2581/3000], Loss: 109.2008\n",
      "Validation Loss: 231.6300\n",
      "Epoch [2601/3000], Loss: 104.1473\n",
      "Validation Loss: 227.1588\n",
      "Epoch [2621/3000], Loss: 99.0936\n",
      "Validation Loss: 223.1644\n",
      "Epoch [2641/3000], Loss: 93.0746\n",
      "Validation Loss: 219.9837\n",
      "Epoch [2661/3000], Loss: 87.6159\n",
      "Validation Loss: 215.9921\n",
      "Epoch [2681/3000], Loss: 83.4456\n",
      "Validation Loss: 213.9044\n",
      "Epoch [2701/3000], Loss: 78.1369\n",
      "Validation Loss: 210.8759\n",
      "Epoch [2721/3000], Loss: 73.2447\n",
      "Validation Loss: 207.7084\n",
      "Epoch [2741/3000], Loss: 67.2899\n",
      "Validation Loss: 203.4141\n",
      "Epoch [2761/3000], Loss: 65.2800\n",
      "Validation Loss: 199.9808\n",
      "Epoch [2781/3000], Loss: 60.2712\n",
      "Validation Loss: 197.4218\n",
      "Epoch [2801/3000], Loss: 56.8426\n",
      "Validation Loss: 194.3731\n",
      "Epoch [2821/3000], Loss: 52.9266\n",
      "Validation Loss: 192.8088\n",
      "Epoch [2841/3000], Loss: 49.8051\n",
      "Validation Loss: 190.1459\n",
      "Epoch [2861/3000], Loss: 47.0109\n",
      "Validation Loss: 187.6587\n",
      "Epoch [2881/3000], Loss: 43.8346\n",
      "Validation Loss: 186.1398\n",
      "Epoch [2901/3000], Loss: 40.4736\n",
      "Validation Loss: 182.9100\n",
      "Epoch [2921/3000], Loss: 38.0447\n",
      "Validation Loss: 181.2365\n",
      "Epoch [2941/3000], Loss: 35.0621\n",
      "Validation Loss: 179.0895\n",
      "Epoch [2961/3000], Loss: 32.3816\n",
      "Validation Loss: 176.8143\n",
      "Epoch [2981/3000], Loss: 30.0443\n",
      "Validation Loss: 175.4872\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day056_plane0_Fall.mat\n",
      "(4425, 763)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6955.2204\n",
      "Validation Loss: 5816.0512\n",
      "Epoch [21/3000], Loss: 6151.9725\n",
      "Validation Loss: 5085.6000\n",
      "Epoch [41/3000], Loss: 5920.3238\n",
      "Validation Loss: 4904.8163\n",
      "Epoch [61/3000], Loss: 5820.0206\n",
      "Validation Loss: 4808.3206\n",
      "Epoch [81/3000], Loss: 5703.3758\n",
      "Validation Loss: 4730.4390\n",
      "Epoch [101/3000], Loss: 5591.8245\n",
      "Validation Loss: 4659.8657\n",
      "Epoch [121/3000], Loss: 5559.0041\n",
      "Validation Loss: 4591.3917\n",
      "Epoch [141/3000], Loss: 5471.6809\n",
      "Validation Loss: 4527.8696\n",
      "Epoch [161/3000], Loss: 5389.8552\n",
      "Validation Loss: 4467.0353\n",
      "Epoch [181/3000], Loss: 5311.9364\n",
      "Validation Loss: 4408.5358\n",
      "Epoch [201/3000], Loss: 5247.5034\n",
      "Validation Loss: 4351.9553\n",
      "Epoch [221/3000], Loss: 5183.0146\n",
      "Validation Loss: 4297.1825\n",
      "Epoch [241/3000], Loss: 5131.6183\n",
      "Validation Loss: 4244.1325\n",
      "Epoch [261/3000], Loss: 5076.7658\n",
      "Validation Loss: 4192.7161\n",
      "Epoch [281/3000], Loss: 4994.0974\n",
      "Validation Loss: 4142.8423\n",
      "Epoch [301/3000], Loss: 4955.2049\n",
      "Validation Loss: 4094.5340\n",
      "Epoch [321/3000], Loss: 4908.2240\n",
      "Validation Loss: 4047.6623\n",
      "Epoch [341/3000], Loss: 4851.5744\n",
      "Validation Loss: 4002.2222\n",
      "Epoch [361/3000], Loss: 4779.7759\n",
      "Validation Loss: 3958.2903\n",
      "Epoch [381/3000], Loss: 4703.7478\n",
      "Validation Loss: 3915.7125\n",
      "Epoch [401/3000], Loss: 4677.9667\n",
      "Validation Loss: 3874.5714\n",
      "Epoch [421/3000], Loss: 4630.5039\n",
      "Validation Loss: 3834.8141\n",
      "Epoch [441/3000], Loss: 4558.4782\n",
      "Validation Loss: 3796.4154\n",
      "Epoch [461/3000], Loss: 4518.2651\n",
      "Validation Loss: 3759.4231\n",
      "Epoch [481/3000], Loss: 4469.5455\n",
      "Validation Loss: 3723.7853\n",
      "Epoch [501/3000], Loss: 4419.5776\n",
      "Validation Loss: 3689.5067\n",
      "Epoch [521/3000], Loss: 4362.4246\n",
      "Validation Loss: 3656.6130\n",
      "Epoch [541/3000], Loss: 4341.5114\n",
      "Validation Loss: 3625.0481\n",
      "Epoch [561/3000], Loss: 4287.1776\n",
      "Validation Loss: 3594.8135\n",
      "Epoch [581/3000], Loss: 4256.6095\n",
      "Validation Loss: 3566.0043\n",
      "Epoch [601/3000], Loss: 4203.8032\n",
      "Validation Loss: 3538.4305\n",
      "Epoch [621/3000], Loss: 4176.2711\n",
      "Validation Loss: 3512.1976\n",
      "Epoch [641/3000], Loss: 4125.3342\n",
      "Validation Loss: 3487.2701\n",
      "Epoch [661/3000], Loss: 4116.3555\n",
      "Validation Loss: 3463.6572\n",
      "Epoch [681/3000], Loss: 4062.3339\n",
      "Validation Loss: 3441.4186\n",
      "Epoch [701/3000], Loss: 4045.9238\n",
      "Validation Loss: 3420.4029\n",
      "Epoch [721/3000], Loss: 4001.5405\n",
      "Validation Loss: 3400.6665\n",
      "Epoch [741/3000], Loss: 3969.4942\n",
      "Validation Loss: 3382.2486\n",
      "Epoch [761/3000], Loss: 3951.6313\n",
      "Validation Loss: 3365.0073\n",
      "Epoch [781/3000], Loss: 3909.4519\n",
      "Validation Loss: 3349.0107\n",
      "Epoch [801/3000], Loss: 3887.5079\n",
      "Validation Loss: 3334.2720\n",
      "Epoch [821/3000], Loss: 3880.7482\n",
      "Validation Loss: 3320.7617\n",
      "Epoch [841/3000], Loss: 3838.2810\n",
      "Validation Loss: 3308.4442\n",
      "Epoch [861/3000], Loss: 3825.3915\n",
      "Validation Loss: 3297.2810\n",
      "Epoch [881/3000], Loss: 3821.8782\n",
      "Validation Loss: 3287.2909\n",
      "Epoch [901/3000], Loss: 3772.2610\n",
      "Validation Loss: 3278.4585\n",
      "Epoch [921/3000], Loss: 3769.9380\n",
      "Validation Loss: 3270.7131\n",
      "Epoch [941/3000], Loss: 3762.6129\n",
      "Validation Loss: 3264.0953\n",
      "Epoch [961/3000], Loss: 3743.9327\n",
      "Validation Loss: 3258.5361\n",
      "Epoch [981/3000], Loss: 3718.3898\n",
      "Validation Loss: 3254.0133\n",
      "Epoch [1001/3000], Loss: 3709.7636\n",
      "Validation Loss: 3250.5011\n",
      "Epoch [1021/3000], Loss: 3714.2518\n",
      "Validation Loss: 3247.9034\n",
      "Epoch [1041/3000], Loss: 3690.6642\n",
      "Validation Loss: 3246.2284\n",
      "Epoch [1061/3000], Loss: 3668.3874\n",
      "Validation Loss: 3245.4248\n",
      "Epoch [1081/3000], Loss: 3672.2822\n",
      "Validation Loss: 3245.4309\n",
      "Epoch [1101/3000], Loss: 3653.7370\n",
      "Validation Loss: 3246.1925\n",
      "Epoch [1121/3000], Loss: 3608.1743\n",
      "Validation Loss: 3195.3267\n",
      "Epoch [1141/3000], Loss: 2546.5023\n",
      "Validation Loss: 2236.2757\n",
      "Epoch [1161/3000], Loss: 2434.9295\n",
      "Validation Loss: 2219.9999\n",
      "Epoch [1181/3000], Loss: 2368.4290\n",
      "Validation Loss: 2227.2682\n",
      "Epoch [1201/3000], Loss: 2307.5804\n",
      "Validation Loss: 2192.2003\n",
      "Epoch [1221/3000], Loss: 2265.6100\n",
      "Validation Loss: 2168.0650\n",
      "Epoch [1241/3000], Loss: 2202.7585\n",
      "Validation Loss: 2142.7624\n",
      "Epoch [1261/3000], Loss: 2169.8294\n",
      "Validation Loss: 2102.1331\n",
      "Epoch [1281/3000], Loss: 2117.8950\n",
      "Validation Loss: 2077.1815\n",
      "Epoch [1301/3000], Loss: 2073.1912\n",
      "Validation Loss: 2045.1932\n",
      "Epoch [1321/3000], Loss: 2022.8726\n",
      "Validation Loss: 2017.8954\n",
      "Epoch [1341/3000], Loss: 1995.7575\n",
      "Validation Loss: 1987.1129\n",
      "Epoch [1361/3000], Loss: 1939.4379\n",
      "Validation Loss: 1949.7699\n",
      "Epoch [1381/3000], Loss: 1904.9803\n",
      "Validation Loss: 1915.0160\n",
      "Epoch [1401/3000], Loss: 1867.1938\n",
      "Validation Loss: 1890.5759\n",
      "Epoch [1421/3000], Loss: 1838.0843\n",
      "Validation Loss: 1850.6566\n",
      "Epoch [1441/3000], Loss: 1787.5263\n",
      "Validation Loss: 1832.0508\n",
      "Epoch [1461/3000], Loss: 1760.9273\n",
      "Validation Loss: 1813.3971\n",
      "Epoch [1481/3000], Loss: 1713.8581\n",
      "Validation Loss: 1771.9788\n",
      "Epoch [1501/3000], Loss: 1665.2199\n",
      "Validation Loss: 1744.9770\n",
      "Epoch [1521/3000], Loss: 1628.6041\n",
      "Validation Loss: 1758.3365\n",
      "Epoch [1541/3000], Loss: 1604.3693\n",
      "Validation Loss: 1723.3293\n",
      "Epoch [1561/3000], Loss: 1556.6822\n",
      "Validation Loss: 1693.3148\n",
      "Epoch [1581/3000], Loss: 1522.9113\n",
      "Validation Loss: 1666.2021\n",
      "Epoch [1601/3000], Loss: 1497.8331\n",
      "Validation Loss: 1640.2975\n",
      "Epoch [1621/3000], Loss: 1464.6960\n",
      "Validation Loss: 1615.2751\n",
      "Epoch [1641/3000], Loss: 1436.9229\n",
      "Validation Loss: 1589.4229\n",
      "Epoch [1661/3000], Loss: 1397.8623\n",
      "Validation Loss: 1567.3706\n",
      "Epoch [1681/3000], Loss: 1360.9250\n",
      "Validation Loss: 1545.4277\n",
      "Epoch [1701/3000], Loss: 1317.5343\n",
      "Validation Loss: 1520.3852\n",
      "Epoch [1721/3000], Loss: 1303.0919\n",
      "Validation Loss: 1497.4645\n",
      "Epoch [1741/3000], Loss: 1269.8082\n",
      "Validation Loss: 1474.1243\n",
      "Epoch [1761/3000], Loss: 1244.8678\n",
      "Validation Loss: 1453.2656\n",
      "Epoch [1781/3000], Loss: 1206.4182\n",
      "Validation Loss: 1429.9957\n",
      "Epoch [1801/3000], Loss: 1177.9579\n",
      "Validation Loss: 1410.9382\n",
      "Epoch [1821/3000], Loss: 1159.6437\n",
      "Validation Loss: 1389.8603\n",
      "Epoch [1841/3000], Loss: 1128.1656\n",
      "Validation Loss: 1369.9512\n",
      "Epoch [1861/3000], Loss: 1099.2205\n",
      "Validation Loss: 1375.4413\n",
      "Epoch [1881/3000], Loss: 1070.8150\n",
      "Validation Loss: 1339.9545\n",
      "Epoch [1901/3000], Loss: 1042.7030\n",
      "Validation Loss: 1319.7203\n",
      "Epoch [1921/3000], Loss: 1018.3650\n",
      "Validation Loss: 1301.5002\n",
      "Epoch [1941/3000], Loss: 989.2445\n",
      "Validation Loss: 1284.3919\n",
      "Epoch [1961/3000], Loss: 972.8151\n",
      "Validation Loss: 1266.3728\n",
      "Epoch [1981/3000], Loss: 937.9106\n",
      "Validation Loss: 1249.0269\n",
      "Epoch [2001/3000], Loss: 917.1931\n",
      "Validation Loss: 1230.6235\n",
      "Epoch [2021/3000], Loss: 894.3334\n",
      "Validation Loss: 1212.9916\n",
      "Epoch [2041/3000], Loss: 868.4523\n",
      "Validation Loss: 1195.3602\n",
      "Epoch [2061/3000], Loss: 836.4998\n",
      "Validation Loss: 1178.3182\n",
      "Epoch [2081/3000], Loss: 820.3685\n",
      "Validation Loss: 1163.1789\n",
      "Epoch [2101/3000], Loss: 801.0072\n",
      "Validation Loss: 1145.5597\n",
      "Epoch [2121/3000], Loss: 777.4255\n",
      "Validation Loss: 1128.4554\n",
      "Epoch [2141/3000], Loss: 759.2128\n",
      "Validation Loss: 1114.0875\n",
      "Epoch [2161/3000], Loss: 731.2979\n",
      "Validation Loss: 1097.2372\n",
      "Epoch [2181/3000], Loss: 709.8902\n",
      "Validation Loss: 1082.0679\n",
      "Epoch [2201/3000], Loss: 695.1219\n",
      "Validation Loss: 1074.8358\n",
      "Epoch [2221/3000], Loss: 678.8068\n",
      "Validation Loss: 1052.7491\n",
      "Epoch [2241/3000], Loss: 657.0699\n",
      "Validation Loss: 1040.1260\n",
      "Epoch [2261/3000], Loss: 633.8592\n",
      "Validation Loss: 1020.8160\n",
      "Epoch [2281/3000], Loss: 621.4171\n",
      "Validation Loss: 1009.2441\n",
      "Epoch [2301/3000], Loss: 601.4734\n",
      "Validation Loss: 993.7149\n",
      "Epoch [2321/3000], Loss: 581.7285\n",
      "Validation Loss: 982.7739\n",
      "Epoch [2341/3000], Loss: 565.0484\n",
      "Validation Loss: 965.4895\n",
      "Epoch [2361/3000], Loss: 545.6739\n",
      "Validation Loss: 951.4060\n",
      "Epoch [2381/3000], Loss: 533.6776\n",
      "Validation Loss: 970.4394\n",
      "Epoch [2401/3000], Loss: 516.4521\n",
      "Validation Loss: 951.7019\n",
      "Epoch [2421/3000], Loss: 496.2867\n",
      "Validation Loss: 918.9044\n",
      "Epoch [2441/3000], Loss: 485.1502\n",
      "Validation Loss: 894.4424\n",
      "Epoch [2461/3000], Loss: 464.1351\n",
      "Validation Loss: 885.5646\n",
      "Epoch [2481/3000], Loss: 451.7678\n",
      "Validation Loss: 877.7480\n",
      "Epoch [2501/3000], Loss: 438.2938\n",
      "Validation Loss: 863.9979\n",
      "Epoch [2521/3000], Loss: 425.1960\n",
      "Validation Loss: 854.8973\n",
      "Epoch [2541/3000], Loss: 407.4858\n",
      "Validation Loss: 845.1443\n",
      "Epoch [2561/3000], Loss: 398.2950\n",
      "Validation Loss: 842.9650\n",
      "Epoch [2581/3000], Loss: 383.9933\n",
      "Validation Loss: 826.3483\n",
      "Epoch [2601/3000], Loss: 369.3920\n",
      "Validation Loss: 821.3853\n",
      "Epoch [2621/3000], Loss: 358.8876\n",
      "Validation Loss: 809.9021\n",
      "Epoch [2641/3000], Loss: 340.0473\n",
      "Validation Loss: 821.1088\n",
      "Epoch [2661/3000], Loss: 331.9510\n",
      "Validation Loss: 806.0401\n",
      "Epoch [2681/3000], Loss: 318.8527\n",
      "Validation Loss: 796.4541\n",
      "Epoch [2701/3000], Loss: 307.6136\n",
      "Validation Loss: 787.3253\n",
      "Epoch [2721/3000], Loss: 295.4635\n",
      "Validation Loss: 777.9422\n",
      "Epoch [2741/3000], Loss: 284.9272\n",
      "Validation Loss: 770.8030\n",
      "Epoch [2761/3000], Loss: 277.9473\n",
      "Validation Loss: 757.8031\n",
      "Epoch [2781/3000], Loss: 265.1721\n",
      "Validation Loss: 749.5479\n",
      "Epoch [2801/3000], Loss: 255.3657\n",
      "Validation Loss: 742.0382\n",
      "Epoch [2821/3000], Loss: 247.6108\n",
      "Validation Loss: 734.5916\n",
      "Epoch [2841/3000], Loss: 236.1675\n",
      "Validation Loss: 726.0286\n",
      "Epoch [2861/3000], Loss: 227.7184\n",
      "Validation Loss: 719.1903\n",
      "Epoch [2881/3000], Loss: 215.6531\n",
      "Validation Loss: 713.1061\n",
      "Epoch [2901/3000], Loss: 206.7424\n",
      "Validation Loss: 704.0337\n",
      "Epoch [2921/3000], Loss: 203.5104\n",
      "Validation Loss: 697.7782\n",
      "Epoch [2941/3000], Loss: 192.5643\n",
      "Validation Loss: 690.0139\n",
      "Epoch [2961/3000], Loss: 185.3147\n",
      "Validation Loss: 681.3870\n",
      "Epoch [2981/3000], Loss: 177.6494\n",
      "Validation Loss: 679.2566\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day057_plane0_Fall.mat\n",
      "(6803, 1024)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7286.4650\n",
      "Validation Loss: 7372.4592\n",
      "Epoch [21/3000], Loss: 6184.6420\n",
      "Validation Loss: 6246.7945\n",
      "Epoch [41/3000], Loss: 5942.2496\n",
      "Validation Loss: 6022.6389\n",
      "Epoch [61/3000], Loss: 5791.1677\n",
      "Validation Loss: 5854.7612\n",
      "Epoch [81/3000], Loss: 5657.9778\n",
      "Validation Loss: 5703.0308\n",
      "Epoch [101/3000], Loss: 5521.3092\n",
      "Validation Loss: 5560.0212\n",
      "Epoch [121/3000], Loss: 5377.3964\n",
      "Validation Loss: 5423.2522\n",
      "Epoch [141/3000], Loss: 5245.6903\n",
      "Validation Loss: 5291.3761\n",
      "Epoch [161/3000], Loss: 5112.9217\n",
      "Validation Loss: 5163.8248\n",
      "Epoch [181/3000], Loss: 4995.8398\n",
      "Validation Loss: 5040.2511\n",
      "Epoch [201/3000], Loss: 4878.2397\n",
      "Validation Loss: 4920.4361\n",
      "Epoch [221/3000], Loss: 4751.7045\n",
      "Validation Loss: 4804.1881\n",
      "Epoch [241/3000], Loss: 4643.8892\n",
      "Validation Loss: 4691.4659\n",
      "Epoch [261/3000], Loss: 4532.2431\n",
      "Validation Loss: 4582.0089\n",
      "Epoch [281/3000], Loss: 4447.5577\n",
      "Validation Loss: 4476.0626\n",
      "Epoch [301/3000], Loss: 4345.1413\n",
      "Validation Loss: 4373.4660\n",
      "Epoch [321/3000], Loss: 4242.3641\n",
      "Validation Loss: 4274.1717\n",
      "Epoch [341/3000], Loss: 4159.5003\n",
      "Validation Loss: 4178.1573\n",
      "Epoch [361/3000], Loss: 4069.1565\n",
      "Validation Loss: 4085.4313\n",
      "Epoch [381/3000], Loss: 3976.9766\n",
      "Validation Loss: 3996.0389\n",
      "Epoch [401/3000], Loss: 3886.7198\n",
      "Validation Loss: 3909.9367\n",
      "Epoch [421/3000], Loss: 3796.4047\n",
      "Validation Loss: 3826.6110\n",
      "Epoch [441/3000], Loss: 3721.9004\n",
      "Validation Loss: 3745.9980\n",
      "Epoch [461/3000], Loss: 3656.7694\n",
      "Validation Loss: 3669.3295\n",
      "Epoch [481/3000], Loss: 3581.4787\n",
      "Validation Loss: 3595.9019\n",
      "Epoch [501/3000], Loss: 3504.4117\n",
      "Validation Loss: 3525.8984\n",
      "Epoch [521/3000], Loss: 3457.8002\n",
      "Validation Loss: 3458.8488\n",
      "Epoch [541/3000], Loss: 3388.0421\n",
      "Validation Loss: 3395.2820\n",
      "Epoch [561/3000], Loss: 3330.8718\n",
      "Validation Loss: 3334.8080\n",
      "Epoch [581/3000], Loss: 3286.9919\n",
      "Validation Loss: 3277.6232\n",
      "Epoch [601/3000], Loss: 3231.1293\n",
      "Validation Loss: 3223.5516\n",
      "Epoch [621/3000], Loss: 3179.9161\n",
      "Validation Loss: 3172.5011\n",
      "Epoch [641/3000], Loss: 3133.2997\n",
      "Validation Loss: 3124.6258\n",
      "Epoch [661/3000], Loss: 3079.8263\n",
      "Validation Loss: 3079.8402\n",
      "Epoch [681/3000], Loss: 3050.4039\n",
      "Validation Loss: 3038.2537\n",
      "Epoch [701/3000], Loss: 3016.2863\n",
      "Validation Loss: 2999.5277\n",
      "Epoch [721/3000], Loss: 2987.2032\n",
      "Validation Loss: 2963.8990\n",
      "Epoch [741/3000], Loss: 2956.7261\n",
      "Validation Loss: 2931.0855\n",
      "Epoch [761/3000], Loss: 2921.4339\n",
      "Validation Loss: 2901.2957\n",
      "Epoch [781/3000], Loss: 2896.5275\n",
      "Validation Loss: 2874.3756\n",
      "Epoch [801/3000], Loss: 2869.8651\n",
      "Validation Loss: 2850.2814\n",
      "Epoch [821/3000], Loss: 2860.9738\n",
      "Validation Loss: 2829.0221\n",
      "Epoch [841/3000], Loss: 2841.4297\n",
      "Validation Loss: 2810.2135\n",
      "Epoch [861/3000], Loss: 2830.2660\n",
      "Validation Loss: 2793.9531\n",
      "Epoch [881/3000], Loss: 1745.8896\n",
      "Validation Loss: 1790.2084\n",
      "Epoch [901/3000], Loss: 1637.3118\n",
      "Validation Loss: 1697.7593\n",
      "Epoch [921/3000], Loss: 1548.6165\n",
      "Validation Loss: 1629.4184\n",
      "Epoch [941/3000], Loss: 1491.6625\n",
      "Validation Loss: 1568.1724\n",
      "Epoch [961/3000], Loss: 1432.4736\n",
      "Validation Loss: 1507.1259\n",
      "Epoch [981/3000], Loss: 1361.9498\n",
      "Validation Loss: 1452.7725\n",
      "Epoch [1001/3000], Loss: 1307.2467\n",
      "Validation Loss: 1401.7266\n",
      "Epoch [1021/3000], Loss: 1265.8633\n",
      "Validation Loss: 1353.0533\n",
      "Epoch [1041/3000], Loss: 1214.8720\n",
      "Validation Loss: 1306.6384\n",
      "Epoch [1061/3000], Loss: 1168.8213\n",
      "Validation Loss: 1281.0193\n",
      "Epoch [1081/3000], Loss: 1127.6292\n",
      "Validation Loss: 1217.4688\n",
      "Epoch [1101/3000], Loss: 1069.2134\n",
      "Validation Loss: 1176.3087\n",
      "Epoch [1121/3000], Loss: 1035.0046\n",
      "Validation Loss: 1135.8874\n",
      "Epoch [1141/3000], Loss: 990.4278\n",
      "Validation Loss: 1097.3477\n",
      "Epoch [1161/3000], Loss: 956.6185\n",
      "Validation Loss: 1060.2666\n",
      "Epoch [1181/3000], Loss: 919.1989\n",
      "Validation Loss: 1026.6914\n",
      "Epoch [1201/3000], Loss: 880.0518\n",
      "Validation Loss: 997.4366\n",
      "Epoch [1221/3000], Loss: 839.5550\n",
      "Validation Loss: 964.8449\n",
      "Epoch [1241/3000], Loss: 810.1802\n",
      "Validation Loss: 934.0681\n",
      "Epoch [1261/3000], Loss: 776.0009\n",
      "Validation Loss: 905.1780\n",
      "Epoch [1281/3000], Loss: 740.1591\n",
      "Validation Loss: 875.3535\n",
      "Epoch [1301/3000], Loss: 708.9542\n",
      "Validation Loss: 845.6233\n",
      "Epoch [1321/3000], Loss: 680.0562\n",
      "Validation Loss: 808.5601\n",
      "Epoch [1341/3000], Loss: 654.0110\n",
      "Validation Loss: 790.5465\n",
      "Epoch [1361/3000], Loss: 629.2228\n",
      "Validation Loss: 766.8607\n",
      "Epoch [1381/3000], Loss: 602.0812\n",
      "Validation Loss: 743.7797\n",
      "Epoch [1401/3000], Loss: 577.7974\n",
      "Validation Loss: 722.5498\n",
      "Epoch [1421/3000], Loss: 550.4900\n",
      "Validation Loss: 702.6893\n",
      "Epoch [1441/3000], Loss: 530.9808\n",
      "Validation Loss: 683.4944\n",
      "Epoch [1461/3000], Loss: 505.6268\n",
      "Validation Loss: 666.3477\n",
      "Epoch [1481/3000], Loss: 484.6043\n",
      "Validation Loss: 652.1167\n",
      "Epoch [1501/3000], Loss: 462.2325\n",
      "Validation Loss: 635.6513\n",
      "Epoch [1521/3000], Loss: 442.7162\n",
      "Validation Loss: 624.0610\n",
      "Epoch [1541/3000], Loss: 422.5670\n",
      "Validation Loss: 610.8728\n",
      "Epoch [1561/3000], Loss: 407.3825\n",
      "Validation Loss: 601.3522\n",
      "Epoch [1581/3000], Loss: 386.8969\n",
      "Validation Loss: 580.0021\n",
      "Epoch [1601/3000], Loss: 371.3275\n",
      "Validation Loss: 580.0094\n",
      "Epoch [1621/3000], Loss: 350.3618\n",
      "Validation Loss: 566.0195\n",
      "Epoch [1641/3000], Loss: 331.0365\n",
      "Validation Loss: 550.2939\n",
      "Epoch [1661/3000], Loss: 322.6711\n",
      "Validation Loss: 539.2121\n",
      "Epoch [1681/3000], Loss: 302.6909\n",
      "Validation Loss: 529.8401\n",
      "Epoch [1701/3000], Loss: 290.2322\n",
      "Validation Loss: 508.4512\n",
      "Epoch [1721/3000], Loss: 274.8700\n",
      "Validation Loss: 499.5389\n",
      "Epoch [1741/3000], Loss: 263.2588\n",
      "Validation Loss: 491.6356\n",
      "Epoch [1761/3000], Loss: 246.2182\n",
      "Validation Loss: 483.7073\n",
      "Epoch [1781/3000], Loss: 234.5991\n",
      "Validation Loss: 477.7710\n",
      "Epoch [1801/3000], Loss: 222.0116\n",
      "Validation Loss: 472.3678\n",
      "Epoch [1821/3000], Loss: 206.9509\n",
      "Validation Loss: 468.2773\n",
      "Epoch [1841/3000], Loss: 197.5164\n",
      "Validation Loss: 462.0678\n",
      "Epoch [1861/3000], Loss: 185.5374\n",
      "Validation Loss: 456.1038\n",
      "Epoch [1881/3000], Loss: 175.0631\n",
      "Validation Loss: 445.5832\n",
      "Epoch [1901/3000], Loss: 164.3378\n",
      "Validation Loss: 440.6352\n",
      "Epoch [1921/3000], Loss: 154.0838\n",
      "Validation Loss: 434.4662\n",
      "Epoch [1941/3000], Loss: 144.8402\n",
      "Validation Loss: 428.3133\n",
      "Epoch [1961/3000], Loss: 134.3674\n",
      "Validation Loss: 422.8635\n",
      "Epoch [1981/3000], Loss: 126.3237\n",
      "Validation Loss: 418.0037\n",
      "Epoch [2001/3000], Loss: 118.9895\n",
      "Validation Loss: 409.4891\n",
      "Epoch [2021/3000], Loss: 110.6250\n",
      "Validation Loss: 406.7697\n",
      "Epoch [2041/3000], Loss: 103.0105\n",
      "Validation Loss: 402.3089\n",
      "Epoch [2061/3000], Loss: 96.4796\n",
      "Validation Loss: 398.1561\n",
      "Epoch [2081/3000], Loss: 87.7573\n",
      "Validation Loss: 394.6015\n",
      "Epoch [2101/3000], Loss: 82.3005\n",
      "Validation Loss: 377.5643\n",
      "Epoch [2121/3000], Loss: 76.5485\n",
      "Validation Loss: 375.8987\n",
      "Epoch [2141/3000], Loss: 70.1870\n",
      "Validation Loss: 374.7170\n",
      "Epoch [2161/3000], Loss: 65.7287\n",
      "Validation Loss: 373.9771\n",
      "Epoch [2181/3000], Loss: 60.1757\n",
      "Validation Loss: 374.4682\n",
      "Epoch [2201/3000], Loss: 54.7758\n",
      "Validation Loss: 374.6915\n",
      "Epoch [2221/3000], Loss: 50.1533\n",
      "Validation Loss: 375.4008\n",
      "Epoch [2241/3000], Loss: 45.9028\n",
      "Validation Loss: 374.3549\n",
      "Epoch [2261/3000], Loss: 41.4907\n",
      "Validation Loss: 373.3751\n",
      "Epoch [2281/3000], Loss: 37.4818\n",
      "Validation Loss: 371.2886\n",
      "Epoch [2301/3000], Loss: 34.1286\n",
      "Validation Loss: 369.3643\n",
      "Epoch [2321/3000], Loss: 31.0220\n",
      "Validation Loss: 367.5520\n",
      "Epoch [2341/3000], Loss: 27.9846\n",
      "Validation Loss: 363.2188\n",
      "Epoch [2361/3000], Loss: 24.8990\n",
      "Validation Loss: 353.8932\n",
      "Epoch [2381/3000], Loss: 22.3263\n",
      "Validation Loss: 359.1287\n",
      "Epoch [2401/3000], Loss: 19.5477\n",
      "Validation Loss: 357.3369\n",
      "Epoch [2421/3000], Loss: 17.4959\n",
      "Validation Loss: 355.9361\n",
      "Epoch [2441/3000], Loss: 15.1919\n",
      "Validation Loss: 356.3208\n",
      "Epoch [2461/3000], Loss: 13.3833\n",
      "Validation Loss: 355.2919\n",
      "Epoch [2481/3000], Loss: 11.6865\n",
      "Validation Loss: 355.1204\n",
      "Epoch [2501/3000], Loss: 10.2284\n",
      "Validation Loss: 355.3623\n",
      "Epoch [2521/3000], Loss: 8.8155\n",
      "Validation Loss: 355.9679\n",
      "Epoch [2541/3000], Loss: 7.6023\n",
      "Validation Loss: 352.8010\n",
      "Epoch [2561/3000], Loss: 6.4503\n",
      "Validation Loss: 354.6093\n",
      "Epoch [2581/3000], Loss: 5.4848\n",
      "Validation Loss: 351.4622\n",
      "Epoch [2601/3000], Loss: 4.5954\n",
      "Validation Loss: 351.4510\n",
      "Epoch [2621/3000], Loss: 3.7018\n",
      "Validation Loss: 352.3106\n",
      "Epoch [2641/3000], Loss: 3.1316\n",
      "Validation Loss: 352.4641\n",
      "Epoch [2661/3000], Loss: 2.4905\n",
      "Validation Loss: 356.2355\n",
      "Epoch [2681/3000], Loss: 2.0019\n",
      "Validation Loss: 355.6266\n",
      "Epoch [2701/3000], Loss: 1.5521\n",
      "Validation Loss: 356.9336\n",
      "Epoch [2721/3000], Loss: 1.2172\n",
      "Validation Loss: 357.5482\n",
      "Epoch [2741/3000], Loss: 0.9187\n",
      "Validation Loss: 363.0268\n",
      "Epoch [2761/3000], Loss: 0.6837\n",
      "Validation Loss: 364.2311\n",
      "Epoch [2781/3000], Loss: 0.4972\n",
      "Validation Loss: 360.6552\n",
      "Epoch [2801/3000], Loss: 0.3525\n",
      "Validation Loss: 363.1960\n",
      "Epoch [2821/3000], Loss: 0.2352\n",
      "Validation Loss: 365.1055\n",
      "Epoch [2841/3000], Loss: 0.1611\n",
      "Validation Loss: 367.5665\n",
      "Epoch [2861/3000], Loss: 0.1069\n",
      "Validation Loss: 369.7088\n",
      "Epoch [2881/3000], Loss: 0.0678\n",
      "Validation Loss: 370.4971\n",
      "Epoch [2901/3000], Loss: 0.0467\n",
      "Validation Loss: 369.4636\n",
      "Epoch [2921/3000], Loss: 0.0302\n",
      "Validation Loss: 367.4596\n",
      "Epoch [2941/3000], Loss: 0.0237\n",
      "Validation Loss: 367.1383\n",
      "Epoch [2961/3000], Loss: 0.0205\n",
      "Validation Loss: 360.1505\n",
      "Epoch [2981/3000], Loss: 0.0174\n",
      "Validation Loss: 366.0071\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day058_plane0_Fall.mat\n",
      "(6454, 918)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8126.5970\n",
      "Validation Loss: 8867.1823\n",
      "Epoch [21/3000], Loss: 7030.3496\n",
      "Validation Loss: 7658.0502\n",
      "Epoch [41/3000], Loss: 6778.9194\n",
      "Validation Loss: 7400.7332\n",
      "Epoch [61/3000], Loss: 6617.8139\n",
      "Validation Loss: 7219.4368\n",
      "Epoch [81/3000], Loss: 6483.8707\n",
      "Validation Loss: 7054.7036\n",
      "Epoch [101/3000], Loss: 6345.0705\n",
      "Validation Loss: 6900.8443\n",
      "Epoch [121/3000], Loss: 6205.9465\n",
      "Validation Loss: 6753.7125\n",
      "Epoch [141/3000], Loss: 6070.4057\n",
      "Validation Loss: 6611.6531\n",
      "Epoch [161/3000], Loss: 5949.2065\n",
      "Validation Loss: 6473.9049\n",
      "Epoch [181/3000], Loss: 5838.1609\n",
      "Validation Loss: 6337.0518\n",
      "Epoch [201/3000], Loss: 5708.4129\n",
      "Validation Loss: 6205.5935\n",
      "Epoch [221/3000], Loss: 5592.8731\n",
      "Validation Loss: 6078.1030\n",
      "Epoch [241/3000], Loss: 5489.7421\n",
      "Validation Loss: 5954.0763\n",
      "Epoch [261/3000], Loss: 5362.6517\n",
      "Validation Loss: 5833.2383\n",
      "Epoch [281/3000], Loss: 5275.7049\n",
      "Validation Loss: 5715.8136\n",
      "Epoch [301/3000], Loss: 5169.8927\n",
      "Validation Loss: 5601.4140\n",
      "Epoch [321/3000], Loss: 5088.4728\n",
      "Validation Loss: 5490.2224\n",
      "Epoch [341/3000], Loss: 4974.8288\n",
      "Validation Loss: 5382.2003\n",
      "Epoch [361/3000], Loss: 4883.6145\n",
      "Validation Loss: 5277.2287\n",
      "Epoch [381/3000], Loss: 4807.3451\n",
      "Validation Loss: 5175.3822\n",
      "Epoch [401/3000], Loss: 4728.7067\n",
      "Validation Loss: 5076.6163\n",
      "Epoch [421/3000], Loss: 4626.3863\n",
      "Validation Loss: 4980.9247\n",
      "Epoch [441/3000], Loss: 4553.4653\n",
      "Validation Loss: 4888.2842\n",
      "Epoch [461/3000], Loss: 4481.0094\n",
      "Validation Loss: 4798.8247\n",
      "Epoch [481/3000], Loss: 4413.4317\n",
      "Validation Loss: 4712.3790\n",
      "Epoch [501/3000], Loss: 4339.2477\n",
      "Validation Loss: 4628.9904\n",
      "Epoch [521/3000], Loss: 4269.0905\n",
      "Validation Loss: 4548.5821\n",
      "Epoch [541/3000], Loss: 4213.4327\n",
      "Validation Loss: 4471.1778\n",
      "Epoch [561/3000], Loss: 4151.0301\n",
      "Validation Loss: 4396.8345\n",
      "Epoch [581/3000], Loss: 4092.9342\n",
      "Validation Loss: 4325.5366\n",
      "Epoch [601/3000], Loss: 4028.2528\n",
      "Validation Loss: 4257.1898\n",
      "Epoch [621/3000], Loss: 3984.9553\n",
      "Validation Loss: 4191.9855\n",
      "Epoch [641/3000], Loss: 3928.9289\n",
      "Validation Loss: 4129.5633\n",
      "Epoch [661/3000], Loss: 3894.9858\n",
      "Validation Loss: 4070.1439\n",
      "Epoch [681/3000], Loss: 3853.3373\n",
      "Validation Loss: 4013.7173\n",
      "Epoch [701/3000], Loss: 3807.8036\n",
      "Validation Loss: 3960.2152\n",
      "Epoch [721/3000], Loss: 3763.8973\n",
      "Validation Loss: 3909.7001\n",
      "Epoch [741/3000], Loss: 3733.4523\n",
      "Validation Loss: 3862.0619\n",
      "Epoch [761/3000], Loss: 2778.0920\n",
      "Validation Loss: 3264.3200\n",
      "Epoch [781/3000], Loss: 2656.9123\n",
      "Validation Loss: 3245.8063\n",
      "Epoch [801/3000], Loss: 2566.2118\n",
      "Validation Loss: 3198.2726\n",
      "Epoch [821/3000], Loss: 2475.0437\n",
      "Validation Loss: 3114.8962\n",
      "Epoch [841/3000], Loss: 2397.3331\n",
      "Validation Loss: 3079.3270\n",
      "Epoch [861/3000], Loss: 2322.7592\n",
      "Validation Loss: 3002.8205\n",
      "Epoch [881/3000], Loss: 2252.5926\n",
      "Validation Loss: 2926.5087\n",
      "Epoch [901/3000], Loss: 2179.8813\n",
      "Validation Loss: 2858.4976\n",
      "Epoch [921/3000], Loss: 2110.6815\n",
      "Validation Loss: 2791.1912\n",
      "Epoch [941/3000], Loss: 2046.7051\n",
      "Validation Loss: 2721.4003\n",
      "Epoch [961/3000], Loss: 1980.8415\n",
      "Validation Loss: 2649.7447\n",
      "Epoch [981/3000], Loss: 1911.6284\n",
      "Validation Loss: 2583.0472\n",
      "Epoch [1001/3000], Loss: 1850.8130\n",
      "Validation Loss: 2507.5342\n",
      "Epoch [1021/3000], Loss: 1792.2231\n",
      "Validation Loss: 2451.3600\n",
      "Epoch [1041/3000], Loss: 1736.6454\n",
      "Validation Loss: 2428.7304\n",
      "Epoch [1061/3000], Loss: 1670.6376\n",
      "Validation Loss: 2331.2671\n",
      "Epoch [1081/3000], Loss: 1610.9896\n",
      "Validation Loss: 2270.7305\n",
      "Epoch [1101/3000], Loss: 1560.8635\n",
      "Validation Loss: 2213.2506\n",
      "Epoch [1121/3000], Loss: 1504.9776\n",
      "Validation Loss: 2157.9359\n",
      "Epoch [1141/3000], Loss: 1452.0215\n",
      "Validation Loss: 2101.4512\n",
      "Epoch [1161/3000], Loss: 1396.0082\n",
      "Validation Loss: 2049.3196\n",
      "Epoch [1181/3000], Loss: 1350.3104\n",
      "Validation Loss: 2009.9104\n",
      "Epoch [1201/3000], Loss: 1297.1876\n",
      "Validation Loss: 1951.0573\n",
      "Epoch [1221/3000], Loss: 1252.1796\n",
      "Validation Loss: 1904.3445\n",
      "Epoch [1241/3000], Loss: 1204.0463\n",
      "Validation Loss: 1862.3174\n",
      "Epoch [1261/3000], Loss: 1156.7110\n",
      "Validation Loss: 1819.3679\n",
      "Epoch [1281/3000], Loss: 1115.6000\n",
      "Validation Loss: 1771.9234\n",
      "Epoch [1301/3000], Loss: 1071.8902\n",
      "Validation Loss: 1734.2172\n",
      "Epoch [1321/3000], Loss: 1029.9672\n",
      "Validation Loss: 1691.2829\n",
      "Epoch [1341/3000], Loss: 986.6174\n",
      "Validation Loss: 1653.2761\n",
      "Epoch [1361/3000], Loss: 947.7562\n",
      "Validation Loss: 1610.5267\n",
      "Epoch [1381/3000], Loss: 907.7643\n",
      "Validation Loss: 1568.4870\n",
      "Epoch [1401/3000], Loss: 870.5586\n",
      "Validation Loss: 1558.6622\n",
      "Epoch [1421/3000], Loss: 832.6133\n",
      "Validation Loss: 1523.8863\n",
      "Epoch [1441/3000], Loss: 801.7361\n",
      "Validation Loss: 1490.9116\n",
      "Epoch [1461/3000], Loss: 768.6348\n",
      "Validation Loss: 1460.1275\n",
      "Epoch [1481/3000], Loss: 732.0965\n",
      "Validation Loss: 1428.9654\n",
      "Epoch [1501/3000], Loss: 706.2814\n",
      "Validation Loss: 1398.0796\n",
      "Epoch [1521/3000], Loss: 669.1567\n",
      "Validation Loss: 1365.9722\n",
      "Epoch [1541/3000], Loss: 640.5658\n",
      "Validation Loss: 1334.5322\n",
      "Epoch [1561/3000], Loss: 613.5108\n",
      "Validation Loss: 1303.4018\n",
      "Epoch [1581/3000], Loss: 583.0600\n",
      "Validation Loss: 1277.0465\n",
      "Epoch [1601/3000], Loss: 557.9361\n",
      "Validation Loss: 1248.6055\n",
      "Epoch [1621/3000], Loss: 529.1450\n",
      "Validation Loss: 1224.0587\n",
      "Epoch [1641/3000], Loss: 505.0592\n",
      "Validation Loss: 1199.5445\n",
      "Epoch [1661/3000], Loss: 478.5282\n",
      "Validation Loss: 1180.0301\n",
      "Epoch [1681/3000], Loss: 456.7509\n",
      "Validation Loss: 1154.2850\n",
      "Epoch [1701/3000], Loss: 434.4202\n",
      "Validation Loss: 1133.9536\n",
      "Epoch [1721/3000], Loss: 411.3068\n",
      "Validation Loss: 1111.4618\n",
      "Epoch [1741/3000], Loss: 391.6472\n",
      "Validation Loss: 1092.9462\n",
      "Epoch [1761/3000], Loss: 371.1812\n",
      "Validation Loss: 1068.2719\n",
      "Epoch [1781/3000], Loss: 351.0303\n",
      "Validation Loss: 1053.8019\n",
      "Epoch [1801/3000], Loss: 333.6480\n",
      "Validation Loss: 1032.9905\n",
      "Epoch [1821/3000], Loss: 314.7685\n",
      "Validation Loss: 1027.9014\n",
      "Epoch [1841/3000], Loss: 306.9423\n",
      "Validation Loss: 1057.2753\n",
      "Epoch [1861/3000], Loss: 281.2563\n",
      "Validation Loss: 1010.5645\n",
      "Epoch [1881/3000], Loss: 264.6818\n",
      "Validation Loss: 995.5944\n",
      "Epoch [1901/3000], Loss: 249.3778\n",
      "Validation Loss: 980.2745\n",
      "Epoch [1921/3000], Loss: 233.8822\n",
      "Validation Loss: 963.8356\n",
      "Epoch [1941/3000], Loss: 219.9575\n",
      "Validation Loss: 946.0046\n",
      "Epoch [1961/3000], Loss: 206.6262\n",
      "Validation Loss: 929.0596\n",
      "Epoch [1981/3000], Loss: 193.9326\n",
      "Validation Loss: 914.1777\n",
      "Epoch [2001/3000], Loss: 180.7163\n",
      "Validation Loss: 901.0952\n",
      "Epoch [2021/3000], Loss: 169.8389\n",
      "Validation Loss: 889.4470\n",
      "Epoch [2041/3000], Loss: 158.1180\n",
      "Validation Loss: 879.3018\n",
      "Epoch [2061/3000], Loss: 147.7248\n",
      "Validation Loss: 866.5128\n",
      "Epoch [2081/3000], Loss: 135.8095\n",
      "Validation Loss: 859.4100\n",
      "Epoch [2101/3000], Loss: 127.8081\n",
      "Validation Loss: 849.3482\n",
      "Epoch [2121/3000], Loss: 118.7949\n",
      "Validation Loss: 839.0939\n",
      "Epoch [2141/3000], Loss: 109.7284\n",
      "Validation Loss: 832.6270\n",
      "Epoch [2161/3000], Loss: 101.0162\n",
      "Validation Loss: 825.5221\n",
      "Epoch [2181/3000], Loss: 93.6277\n",
      "Validation Loss: 824.6338\n",
      "Epoch [2201/3000], Loss: 87.0571\n",
      "Validation Loss: 816.9518\n",
      "Epoch [2221/3000], Loss: 79.6365\n",
      "Validation Loss: 809.4950\n",
      "Epoch [2241/3000], Loss: 73.3624\n",
      "Validation Loss: 807.1775\n",
      "Epoch [2261/3000], Loss: 67.1904\n",
      "Validation Loss: 801.0551\n",
      "Epoch [2281/3000], Loss: 61.6038\n",
      "Validation Loss: 799.6965\n",
      "Epoch [2301/3000], Loss: 56.1687\n",
      "Validation Loss: 796.4390\n",
      "Epoch [2321/3000], Loss: 51.0972\n",
      "Validation Loss: 792.4765\n",
      "Epoch [2341/3000], Loss: 46.6780\n",
      "Validation Loss: 791.2434\n",
      "Epoch [2361/3000], Loss: 42.1080\n",
      "Validation Loss: 791.6486\n",
      "Epoch [2381/3000], Loss: 38.3191\n",
      "Validation Loss: 790.6790\n",
      "Epoch [2401/3000], Loss: 34.5397\n",
      "Validation Loss: 790.8826\n",
      "Epoch [2421/3000], Loss: 30.9941\n",
      "Validation Loss: 788.9922\n",
      "Epoch [2441/3000], Loss: 27.7461\n",
      "Validation Loss: 787.3356\n",
      "Epoch [2461/3000], Loss: 24.6439\n",
      "Validation Loss: 788.6456\n",
      "Epoch [2481/3000], Loss: 21.7902\n",
      "Validation Loss: 786.5207\n",
      "Epoch [2501/3000], Loss: 19.5678\n",
      "Validation Loss: 833.9979\n",
      "Epoch [2521/3000], Loss: 17.2747\n",
      "Validation Loss: 827.4214\n",
      "Epoch [2541/3000], Loss: 15.2413\n",
      "Validation Loss: 823.9041\n",
      "Epoch [2561/3000], Loss: 13.3434\n",
      "Validation Loss: 820.0831\n",
      "Epoch [2581/3000], Loss: 11.6518\n",
      "Validation Loss: 816.9487\n",
      "Epoch [2601/3000], Loss: 10.2115\n",
      "Validation Loss: 813.9575\n",
      "Epoch [2621/3000], Loss: 8.7693\n",
      "Validation Loss: 811.6171\n",
      "Epoch [2641/3000], Loss: 7.4983\n",
      "Validation Loss: 809.3339\n",
      "Epoch [2661/3000], Loss: 6.3865\n",
      "Validation Loss: 804.8995\n",
      "Epoch [2681/3000], Loss: 5.3589\n",
      "Validation Loss: 801.3683\n",
      "Epoch [2701/3000], Loss: 4.4633\n",
      "Validation Loss: 798.6531\n",
      "Epoch [2721/3000], Loss: 3.6340\n",
      "Validation Loss: 793.5830\n",
      "Epoch [2741/3000], Loss: 2.9921\n",
      "Validation Loss: 792.7043\n",
      "Epoch [2761/3000], Loss: 2.4051\n",
      "Validation Loss: 790.9393\n",
      "Epoch [2781/3000], Loss: 1.8802\n",
      "Validation Loss: 787.5572\n",
      "Epoch [2801/3000], Loss: 1.5067\n",
      "Validation Loss: 787.6063\n",
      "Epoch [2821/3000], Loss: 1.1592\n",
      "Validation Loss: 784.4093\n",
      "Epoch [2841/3000], Loss: 0.8827\n",
      "Validation Loss: 781.7532\n",
      "Epoch [2861/3000], Loss: 0.6647\n",
      "Validation Loss: 779.8512\n",
      "Epoch [2881/3000], Loss: 0.4938\n",
      "Validation Loss: 778.2179\n",
      "Epoch [2901/3000], Loss: 0.3450\n",
      "Validation Loss: 777.9474\n",
      "Epoch [2921/3000], Loss: 0.2352\n",
      "Validation Loss: 778.6377\n",
      "Epoch [2941/3000], Loss: 31.1382\n",
      "Validation Loss: 743.2410\n",
      "Epoch [2961/3000], Loss: 0.1425\n",
      "Validation Loss: 796.8114\n",
      "Epoch [2981/3000], Loss: 0.1113\n",
      "Validation Loss: 794.2874\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day059_plane0_Fall.mat\n",
      "(6621, 966)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8531.3092\n",
      "Validation Loss: 9128.9039\n",
      "Epoch [21/3000], Loss: 7410.5237\n",
      "Validation Loss: 7920.2623\n",
      "Epoch [41/3000], Loss: 7152.8719\n",
      "Validation Loss: 7657.6654\n",
      "Epoch [61/3000], Loss: 6989.5889\n",
      "Validation Loss: 7467.8000\n",
      "Epoch [81/3000], Loss: 6808.0672\n",
      "Validation Loss: 7296.8738\n",
      "Epoch [101/3000], Loss: 6632.2229\n",
      "Validation Loss: 7135.6200\n",
      "Epoch [121/3000], Loss: 6503.0556\n",
      "Validation Loss: 6980.7091\n",
      "Epoch [141/3000], Loss: 6379.9492\n",
      "Validation Loss: 6830.8829\n",
      "Epoch [161/3000], Loss: 6215.2241\n",
      "Validation Loss: 6685.2770\n",
      "Epoch [181/3000], Loss: 6081.8333\n",
      "Validation Loss: 6543.6518\n",
      "Epoch [201/3000], Loss: 5959.7792\n",
      "Validation Loss: 6405.5036\n",
      "Epoch [221/3000], Loss: 5856.3076\n",
      "Validation Loss: 6270.8231\n",
      "Epoch [241/3000], Loss: 5741.7478\n",
      "Validation Loss: 6137.0881\n",
      "Epoch [261/3000], Loss: 5589.7871\n",
      "Validation Loss: 6007.8544\n",
      "Epoch [281/3000], Loss: 5524.2084\n",
      "Validation Loss: 5882.3123\n",
      "Epoch [301/3000], Loss: 5377.0019\n",
      "Validation Loss: 5760.0949\n",
      "Epoch [321/3000], Loss: 5251.9068\n",
      "Validation Loss: 5641.1926\n",
      "Epoch [341/3000], Loss: 5169.1560\n",
      "Validation Loss: 5525.2185\n",
      "Epoch [361/3000], Loss: 5054.4489\n",
      "Validation Loss: 5412.4631\n",
      "Epoch [381/3000], Loss: 4951.0362\n",
      "Validation Loss: 5302.8620\n",
      "Epoch [401/3000], Loss: 4868.9446\n",
      "Validation Loss: 5196.4039\n",
      "Epoch [421/3000], Loss: 4771.6728\n",
      "Validation Loss: 5092.8945\n",
      "Epoch [441/3000], Loss: 4698.8863\n",
      "Validation Loss: 4992.5242\n",
      "Epoch [461/3000], Loss: 4574.0921\n",
      "Validation Loss: 4895.3403\n",
      "Epoch [481/3000], Loss: 4498.3378\n",
      "Validation Loss: 4801.1982\n",
      "Epoch [501/3000], Loss: 4409.6809\n",
      "Validation Loss: 4710.1101\n",
      "Epoch [521/3000], Loss: 4346.4975\n",
      "Validation Loss: 4622.0955\n",
      "Epoch [541/3000], Loss: 4270.8404\n",
      "Validation Loss: 4537.0293\n",
      "Epoch [561/3000], Loss: 4186.6170\n",
      "Validation Loss: 4455.0090\n",
      "Epoch [581/3000], Loss: 4111.5513\n",
      "Validation Loss: 4376.1003\n",
      "Epoch [601/3000], Loss: 4057.7752\n",
      "Validation Loss: 4300.0878\n",
      "Epoch [621/3000], Loss: 3995.4611\n",
      "Validation Loss: 4227.1821\n",
      "Epoch [641/3000], Loss: 3937.1773\n",
      "Validation Loss: 4157.2759\n",
      "Epoch [661/3000], Loss: 3901.4565\n",
      "Validation Loss: 4090.3499\n",
      "Epoch [681/3000], Loss: 3822.3869\n",
      "Validation Loss: 4026.4551\n",
      "Epoch [701/3000], Loss: 3774.7537\n",
      "Validation Loss: 3965.4518\n",
      "Epoch [721/3000], Loss: 3717.8509\n",
      "Validation Loss: 3907.3953\n",
      "Epoch [741/3000], Loss: 3671.9523\n",
      "Validation Loss: 3852.2603\n",
      "Epoch [761/3000], Loss: 3623.9950\n",
      "Validation Loss: 3799.9679\n",
      "Epoch [781/3000], Loss: 3601.9135\n",
      "Validation Loss: 3750.7506\n",
      "Epoch [801/3000], Loss: 3554.6930\n",
      "Validation Loss: 3704.4653\n",
      "Epoch [821/3000], Loss: 3540.7864\n",
      "Validation Loss: 3660.9275\n",
      "Epoch [841/3000], Loss: 3486.5680\n",
      "Validation Loss: 3620.2332\n",
      "Epoch [861/3000], Loss: 3462.0272\n",
      "Validation Loss: 3582.3315\n",
      "Epoch [881/3000], Loss: 3440.9039\n",
      "Validation Loss: 3547.3654\n",
      "Epoch [901/3000], Loss: 3414.9479\n",
      "Validation Loss: 3515.0981\n",
      "Epoch [921/3000], Loss: 2278.8517\n",
      "Validation Loss: 2746.4001\n",
      "Epoch [941/3000], Loss: 2164.9314\n",
      "Validation Loss: 2722.5907\n",
      "Epoch [961/3000], Loss: 2066.9607\n",
      "Validation Loss: 2686.6546\n",
      "Epoch [981/3000], Loss: 1990.6917\n",
      "Validation Loss: 2635.5574\n",
      "Epoch [1001/3000], Loss: 1921.8292\n",
      "Validation Loss: 2582.1963\n",
      "Epoch [1021/3000], Loss: 1850.2793\n",
      "Validation Loss: 2516.9836\n",
      "Epoch [1041/3000], Loss: 1789.4068\n",
      "Validation Loss: 2460.8127\n",
      "Epoch [1061/3000], Loss: 1717.8576\n",
      "Validation Loss: 2396.5385\n",
      "Epoch [1081/3000], Loss: 1664.7041\n",
      "Validation Loss: 2333.1806\n",
      "Epoch [1101/3000], Loss: 1598.7711\n",
      "Validation Loss: 2276.9228\n",
      "Epoch [1121/3000], Loss: 1540.7882\n",
      "Validation Loss: 2215.3825\n",
      "Epoch [1141/3000], Loss: 1479.4676\n",
      "Validation Loss: 2158.1962\n",
      "Epoch [1161/3000], Loss: 1434.5341\n",
      "Validation Loss: 2113.8170\n",
      "Epoch [1181/3000], Loss: 1362.7951\n",
      "Validation Loss: 2047.9648\n",
      "Epoch [1201/3000], Loss: 1321.4189\n",
      "Validation Loss: 2000.7467\n",
      "Epoch [1221/3000], Loss: 1276.4015\n",
      "Validation Loss: 1943.4719\n",
      "Epoch [1241/3000], Loss: 1227.1129\n",
      "Validation Loss: 1898.8703\n",
      "Epoch [1261/3000], Loss: 1185.3112\n",
      "Validation Loss: 1880.1136\n",
      "Epoch [1281/3000], Loss: 1132.0638\n",
      "Validation Loss: 1832.7004\n",
      "Epoch [1301/3000], Loss: 1092.1462\n",
      "Validation Loss: 1787.0526\n",
      "Epoch [1321/3000], Loss: 1047.8129\n",
      "Validation Loss: 1743.6881\n",
      "Epoch [1341/3000], Loss: 1009.1590\n",
      "Validation Loss: 1702.9516\n",
      "Epoch [1361/3000], Loss: 965.9118\n",
      "Validation Loss: 1663.5368\n",
      "Epoch [1381/3000], Loss: 930.1284\n",
      "Validation Loss: 1623.7557\n",
      "Epoch [1401/3000], Loss: 888.8882\n",
      "Validation Loss: 1591.5430\n",
      "Epoch [1421/3000], Loss: 851.7053\n",
      "Validation Loss: 1557.9747\n",
      "Epoch [1441/3000], Loss: 819.3859\n",
      "Validation Loss: 1523.0629\n",
      "Epoch [1461/3000], Loss: 790.9964\n",
      "Validation Loss: 1487.9557\n",
      "Epoch [1481/3000], Loss: 750.2073\n",
      "Validation Loss: 1453.5424\n",
      "Epoch [1501/3000], Loss: 713.7426\n",
      "Validation Loss: 1421.0465\n",
      "Epoch [1521/3000], Loss: 683.9904\n",
      "Validation Loss: 1390.0348\n",
      "Epoch [1541/3000], Loss: 651.6735\n",
      "Validation Loss: 1359.3559\n",
      "Epoch [1561/3000], Loss: 622.2025\n",
      "Validation Loss: 1319.3914\n",
      "Epoch [1581/3000], Loss: 587.8108\n",
      "Validation Loss: 1302.4568\n",
      "Epoch [1601/3000], Loss: 562.7135\n",
      "Validation Loss: 1271.8826\n",
      "Epoch [1621/3000], Loss: 538.1216\n",
      "Validation Loss: 1241.3573\n",
      "Epoch [1641/3000], Loss: 519.0682\n",
      "Validation Loss: 1222.6993\n",
      "Epoch [1661/3000], Loss: 484.8557\n",
      "Validation Loss: 1195.8380\n",
      "Epoch [1681/3000], Loss: 467.5679\n",
      "Validation Loss: 1194.4244\n",
      "Epoch [1701/3000], Loss: 441.6984\n",
      "Validation Loss: 1172.7445\n",
      "Epoch [1721/3000], Loss: 417.6859\n",
      "Validation Loss: 1148.9400\n",
      "Epoch [1741/3000], Loss: 396.7229\n",
      "Validation Loss: 1123.1326\n",
      "Epoch [1761/3000], Loss: 376.6878\n",
      "Validation Loss: 1098.9944\n",
      "Epoch [1781/3000], Loss: 356.7659\n",
      "Validation Loss: 1077.0913\n",
      "Epoch [1801/3000], Loss: 332.7801\n",
      "Validation Loss: 1056.5286\n",
      "Epoch [1821/3000], Loss: 319.5104\n",
      "Validation Loss: 1035.6772\n",
      "Epoch [1841/3000], Loss: 299.8486\n",
      "Validation Loss: 1016.5395\n",
      "Epoch [1861/3000], Loss: 284.0918\n",
      "Validation Loss: 1000.3534\n",
      "Epoch [1881/3000], Loss: 266.0206\n",
      "Validation Loss: 985.0439\n",
      "Epoch [1901/3000], Loss: 248.2075\n",
      "Validation Loss: 969.6371\n",
      "Epoch [1921/3000], Loss: 236.4831\n",
      "Validation Loss: 956.0278\n",
      "Epoch [1941/3000], Loss: 222.0603\n",
      "Validation Loss: 947.7753\n",
      "Epoch [1961/3000], Loss: 210.3448\n",
      "Validation Loss: 930.9425\n",
      "Epoch [1981/3000], Loss: 198.6727\n",
      "Validation Loss: 921.2729\n",
      "Epoch [2001/3000], Loss: 184.3367\n",
      "Validation Loss: 916.0623\n",
      "Epoch [2021/3000], Loss: 173.8358\n",
      "Validation Loss: 951.0552\n",
      "Epoch [2041/3000], Loss: 163.5978\n",
      "Validation Loss: 937.2071\n",
      "Epoch [2061/3000], Loss: 153.9724\n",
      "Validation Loss: 923.9352\n",
      "Epoch [2081/3000], Loss: 143.2697\n",
      "Validation Loss: 913.1725\n",
      "Epoch [2101/3000], Loss: 131.7524\n",
      "Validation Loss: 903.4882\n",
      "Epoch [2121/3000], Loss: 126.1064\n",
      "Validation Loss: 892.6161\n",
      "Epoch [2141/3000], Loss: 117.5576\n",
      "Validation Loss: 884.0399\n",
      "Epoch [2161/3000], Loss: 108.1351\n",
      "Validation Loss: 873.7937\n",
      "Epoch [2181/3000], Loss: 99.9964\n",
      "Validation Loss: 867.1996\n",
      "Epoch [2201/3000], Loss: 91.8440\n",
      "Validation Loss: 857.7259\n",
      "Epoch [2221/3000], Loss: 85.3992\n",
      "Validation Loss: 851.0201\n",
      "Epoch [2241/3000], Loss: 79.2659\n",
      "Validation Loss: 842.2880\n",
      "Epoch [2261/3000], Loss: 72.3313\n",
      "Validation Loss: 835.7458\n",
      "Epoch [2281/3000], Loss: 66.4143\n",
      "Validation Loss: 825.9634\n",
      "Epoch [2301/3000], Loss: 60.3948\n",
      "Validation Loss: 816.5171\n",
      "Epoch [2321/3000], Loss: 55.0347\n",
      "Validation Loss: 815.3216\n",
      "Epoch [2341/3000], Loss: 50.4981\n",
      "Validation Loss: 808.2499\n",
      "Epoch [2361/3000], Loss: 45.1454\n",
      "Validation Loss: 818.7682\n",
      "Epoch [2381/3000], Loss: 40.7014\n",
      "Validation Loss: 806.0011\n",
      "Epoch [2401/3000], Loss: 36.7519\n",
      "Validation Loss: 799.5572\n",
      "Epoch [2421/3000], Loss: 33.2905\n",
      "Validation Loss: 832.1584\n",
      "Epoch [2441/3000], Loss: 29.4104\n",
      "Validation Loss: 837.7535\n",
      "Epoch [2461/3000], Loss: 26.4185\n",
      "Validation Loss: 832.4813\n",
      "Epoch [2481/3000], Loss: 23.7730\n",
      "Validation Loss: 826.7390\n",
      "Epoch [2501/3000], Loss: 20.3064\n",
      "Validation Loss: 820.2673\n",
      "Epoch [2521/3000], Loss: 18.3171\n",
      "Validation Loss: 813.7937\n",
      "Epoch [2541/3000], Loss: 15.8716\n",
      "Validation Loss: 809.4901\n",
      "Epoch [2561/3000], Loss: 13.5548\n",
      "Validation Loss: 805.0998\n",
      "Epoch [2581/3000], Loss: 11.6200\n",
      "Validation Loss: 800.5902\n",
      "Epoch [2601/3000], Loss: 10.2591\n",
      "Validation Loss: 800.6328\n",
      "Epoch [2621/3000], Loss: 8.6805\n",
      "Validation Loss: 791.4446\n",
      "Epoch [2641/3000], Loss: 7.2356\n",
      "Validation Loss: 790.8029\n",
      "Epoch [2661/3000], Loss: 6.1012\n",
      "Validation Loss: 788.5025\n",
      "Epoch [2681/3000], Loss: 5.1656\n",
      "Validation Loss: 784.7934\n",
      "Epoch [2701/3000], Loss: 4.3798\n",
      "Validation Loss: 782.2192\n",
      "Epoch [2721/3000], Loss: 3.6771\n",
      "Validation Loss: 778.0272\n",
      "Epoch [2741/3000], Loss: 2.9812\n",
      "Validation Loss: 777.9062\n",
      "Epoch [2761/3000], Loss: 2.4531\n",
      "Validation Loss: 772.2254\n",
      "Epoch [2781/3000], Loss: 1.9897\n",
      "Validation Loss: 772.0543\n",
      "Epoch [2801/3000], Loss: 1.6038\n",
      "Validation Loss: 765.4471\n",
      "Epoch [2821/3000], Loss: 1.2172\n",
      "Validation Loss: 762.8882\n",
      "Epoch [2841/3000], Loss: 0.9414\n",
      "Validation Loss: 761.8723\n",
      "Epoch [2861/3000], Loss: 0.7251\n",
      "Validation Loss: 764.8542\n",
      "Epoch [2881/3000], Loss: 0.5335\n",
      "Validation Loss: 759.0917\n",
      "Epoch [2901/3000], Loss: 0.3974\n",
      "Validation Loss: 765.1913\n",
      "Epoch [2921/3000], Loss: 0.2798\n",
      "Validation Loss: 759.6688\n",
      "Epoch [2941/3000], Loss: 0.2013\n",
      "Validation Loss: 755.7674\n",
      "Epoch [2961/3000], Loss: 0.1371\n",
      "Validation Loss: 791.3638\n",
      "Epoch [2981/3000], Loss: 0.0944\n",
      "Validation Loss: 754.9226\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day060_plane0_Fall.mat\n",
      "(5575, 942)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6254.3513\n",
      "Validation Loss: 5037.4804\n",
      "Epoch [21/3000], Loss: 5410.2995\n",
      "Validation Loss: 4293.8145\n",
      "Epoch [41/3000], Loss: 5245.6154\n",
      "Validation Loss: 4128.5869\n",
      "Epoch [61/3000], Loss: 5139.3926\n",
      "Validation Loss: 4029.2763\n",
      "Epoch [81/3000], Loss: 5012.4951\n",
      "Validation Loss: 3939.3417\n",
      "Epoch [101/3000], Loss: 4885.7317\n",
      "Validation Loss: 3860.0766\n",
      "Epoch [121/3000], Loss: 4811.9204\n",
      "Validation Loss: 3785.4526\n",
      "Epoch [141/3000], Loss: 4739.5982\n",
      "Validation Loss: 3714.6865\n",
      "Epoch [161/3000], Loss: 4641.2318\n",
      "Validation Loss: 3647.1047\n",
      "Epoch [181/3000], Loss: 4582.7801\n",
      "Validation Loss: 3582.2626\n",
      "Epoch [201/3000], Loss: 4489.1930\n",
      "Validation Loss: 3520.0219\n",
      "Epoch [221/3000], Loss: 4416.1896\n",
      "Validation Loss: 3460.1866\n",
      "Epoch [241/3000], Loss: 4352.0626\n",
      "Validation Loss: 3402.7003\n",
      "Epoch [261/3000], Loss: 4329.5718\n",
      "Validation Loss: 3347.3924\n",
      "Epoch [281/3000], Loss: 4237.3563\n",
      "Validation Loss: 3294.3000\n",
      "Epoch [301/3000], Loss: 4131.4745\n",
      "Validation Loss: 3243.4815\n",
      "Epoch [321/3000], Loss: 4096.9497\n",
      "Validation Loss: 3194.9191\n",
      "Epoch [341/3000], Loss: 4015.4966\n",
      "Validation Loss: 3148.2838\n",
      "Epoch [361/3000], Loss: 3951.7999\n",
      "Validation Loss: 3103.9088\n",
      "Epoch [381/3000], Loss: 3888.2444\n",
      "Validation Loss: 3061.6330\n",
      "Epoch [401/3000], Loss: 3859.1760\n",
      "Validation Loss: 3021.4841\n",
      "Epoch [421/3000], Loss: 3825.7565\n",
      "Validation Loss: 2983.3301\n",
      "Epoch [441/3000], Loss: 3764.1212\n",
      "Validation Loss: 2947.2188\n",
      "Epoch [461/3000], Loss: 3702.3734\n",
      "Validation Loss: 2913.1447\n",
      "Epoch [481/3000], Loss: 3676.4747\n",
      "Validation Loss: 2881.1973\n",
      "Epoch [501/3000], Loss: 3633.2111\n",
      "Validation Loss: 2851.1278\n",
      "Epoch [521/3000], Loss: 3585.5655\n",
      "Validation Loss: 2823.1540\n",
      "Epoch [541/3000], Loss: 3557.5466\n",
      "Validation Loss: 2797.1184\n",
      "Epoch [561/3000], Loss: 3510.9873\n",
      "Validation Loss: 2773.1095\n",
      "Epoch [581/3000], Loss: 3467.8760\n",
      "Validation Loss: 2751.0105\n",
      "Epoch [601/3000], Loss: 3450.3849\n",
      "Validation Loss: 2730.8077\n",
      "Epoch [621/3000], Loss: 3437.8449\n",
      "Validation Loss: 2712.5006\n",
      "Epoch [641/3000], Loss: 3378.2750\n",
      "Validation Loss: 2695.9907\n",
      "Epoch [661/3000], Loss: 3356.9703\n",
      "Validation Loss: 2681.3492\n",
      "Epoch [681/3000], Loss: 3306.1070\n",
      "Validation Loss: 2668.5270\n",
      "Epoch [701/3000], Loss: 3300.8087\n",
      "Validation Loss: 2657.4483\n",
      "Epoch [721/3000], Loss: 3308.3757\n",
      "Validation Loss: 2648.0884\n",
      "Epoch [741/3000], Loss: 3286.1239\n",
      "Validation Loss: 2640.3318\n",
      "Epoch [761/3000], Loss: 3274.7741\n",
      "Validation Loss: 2634.1946\n",
      "Epoch [781/3000], Loss: 3236.4557\n",
      "Validation Loss: 2629.6177\n",
      "Epoch [801/3000], Loss: 3231.8539\n",
      "Validation Loss: 2626.5100\n",
      "Epoch [821/3000], Loss: 3193.4300\n",
      "Validation Loss: 2624.7507\n",
      "Epoch [841/3000], Loss: 3205.5024\n",
      "Validation Loss: 2624.2475\n",
      "Epoch [861/3000], Loss: 3187.1299\n",
      "Validation Loss: 2616.9629\n",
      "Epoch [881/3000], Loss: 2218.8915\n",
      "Validation Loss: 1665.6992\n",
      "Epoch [901/3000], Loss: 2119.7150\n",
      "Validation Loss: 1606.3606\n",
      "Epoch [921/3000], Loss: 2062.1737\n",
      "Validation Loss: 1561.7143\n",
      "Epoch [941/3000], Loss: 2007.0551\n",
      "Validation Loss: 1518.2175\n",
      "Epoch [961/3000], Loss: 1976.0666\n",
      "Validation Loss: 1480.0051\n",
      "Epoch [981/3000], Loss: 1912.2275\n",
      "Validation Loss: 1444.1322\n",
      "Epoch [1001/3000], Loss: 1846.6304\n",
      "Validation Loss: 1409.9235\n",
      "Epoch [1021/3000], Loss: 1821.8090\n",
      "Validation Loss: 1377.0589\n",
      "Epoch [1041/3000], Loss: 1780.0093\n",
      "Validation Loss: 1345.7078\n",
      "Epoch [1061/3000], Loss: 1731.6875\n",
      "Validation Loss: 1315.4496\n",
      "Epoch [1081/3000], Loss: 1669.5663\n",
      "Validation Loss: 1286.1723\n",
      "Epoch [1101/3000], Loss: 1639.6426\n",
      "Validation Loss: 1257.0765\n",
      "Epoch [1121/3000], Loss: 1600.9675\n",
      "Validation Loss: 1225.9514\n",
      "Epoch [1141/3000], Loss: 1566.5227\n",
      "Validation Loss: 1200.3943\n",
      "Epoch [1161/3000], Loss: 1505.5055\n",
      "Validation Loss: 1168.7202\n",
      "Epoch [1181/3000], Loss: 1484.7469\n",
      "Validation Loss: 1140.7140\n",
      "Epoch [1201/3000], Loss: 1429.3028\n",
      "Validation Loss: 1114.1020\n",
      "Epoch [1221/3000], Loss: 1398.6385\n",
      "Validation Loss: 1087.8994\n",
      "Epoch [1241/3000], Loss: 1357.1876\n",
      "Validation Loss: 1062.3740\n",
      "Epoch [1261/3000], Loss: 1329.9857\n",
      "Validation Loss: 1037.2587\n",
      "Epoch [1281/3000], Loss: 1271.5843\n",
      "Validation Loss: 1012.4917\n",
      "Epoch [1301/3000], Loss: 1245.8588\n",
      "Validation Loss: 987.8983\n",
      "Epoch [1321/3000], Loss: 1212.1028\n",
      "Validation Loss: 964.1341\n",
      "Epoch [1341/3000], Loss: 1188.6218\n",
      "Validation Loss: 939.6102\n",
      "Epoch [1361/3000], Loss: 1137.3747\n",
      "Validation Loss: 916.4812\n",
      "Epoch [1381/3000], Loss: 1107.7904\n",
      "Validation Loss: 893.0963\n",
      "Epoch [1401/3000], Loss: 1087.5080\n",
      "Validation Loss: 871.4512\n",
      "Epoch [1421/3000], Loss: 1051.9195\n",
      "Validation Loss: 849.5927\n",
      "Epoch [1441/3000], Loss: 1010.1089\n",
      "Validation Loss: 828.9215\n",
      "Epoch [1461/3000], Loss: 990.9487\n",
      "Validation Loss: 808.0437\n",
      "Epoch [1481/3000], Loss: 966.1319\n",
      "Validation Loss: 788.5837\n",
      "Epoch [1501/3000], Loss: 931.4254\n",
      "Validation Loss: 765.7282\n",
      "Epoch [1521/3000], Loss: 899.5185\n",
      "Validation Loss: 745.2297\n",
      "Epoch [1541/3000], Loss: 878.6843\n",
      "Validation Loss: 726.0398\n",
      "Epoch [1561/3000], Loss: 849.1133\n",
      "Validation Loss: 707.1257\n",
      "Epoch [1581/3000], Loss: 830.7094\n",
      "Validation Loss: 685.2316\n",
      "Epoch [1601/3000], Loss: 800.0578\n",
      "Validation Loss: 667.5901\n",
      "Epoch [1621/3000], Loss: 775.7032\n",
      "Validation Loss: 649.8400\n",
      "Epoch [1641/3000], Loss: 748.3507\n",
      "Validation Loss: 631.0556\n",
      "Epoch [1661/3000], Loss: 726.5438\n",
      "Validation Loss: 611.5845\n",
      "Epoch [1681/3000], Loss: 704.1268\n",
      "Validation Loss: 595.7877\n",
      "Epoch [1701/3000], Loss: 673.4230\n",
      "Validation Loss: 579.1336\n",
      "Epoch [1721/3000], Loss: 659.5507\n",
      "Validation Loss: 564.6050\n",
      "Epoch [1741/3000], Loss: 632.6524\n",
      "Validation Loss: 547.4520\n",
      "Epoch [1761/3000], Loss: 615.5402\n",
      "Validation Loss: 528.0693\n",
      "Epoch [1781/3000], Loss: 585.3186\n",
      "Validation Loss: 514.1564\n",
      "Epoch [1801/3000], Loss: 564.5659\n",
      "Validation Loss: 500.5867\n",
      "Epoch [1821/3000], Loss: 543.0988\n",
      "Validation Loss: 487.3523\n",
      "Epoch [1841/3000], Loss: 529.9842\n",
      "Validation Loss: 474.8335\n",
      "Epoch [1861/3000], Loss: 515.7148\n",
      "Validation Loss: 462.3022\n",
      "Epoch [1881/3000], Loss: 493.2090\n",
      "Validation Loss: 449.0403\n",
      "Epoch [1901/3000], Loss: 473.1003\n",
      "Validation Loss: 436.8454\n",
      "Epoch [1921/3000], Loss: 458.3300\n",
      "Validation Loss: 424.4052\n",
      "Epoch [1941/3000], Loss: 441.0735\n",
      "Validation Loss: 412.4631\n",
      "Epoch [1961/3000], Loss: 422.6088\n",
      "Validation Loss: 401.0220\n",
      "Epoch [1981/3000], Loss: 406.7981\n",
      "Validation Loss: 390.3667\n",
      "Epoch [2001/3000], Loss: 387.6406\n",
      "Validation Loss: 379.7548\n",
      "Epoch [2021/3000], Loss: 374.1928\n",
      "Validation Loss: 369.5837\n",
      "Epoch [2041/3000], Loss: 362.7426\n",
      "Validation Loss: 361.1049\n",
      "Epoch [2061/3000], Loss: 347.1966\n",
      "Validation Loss: 351.4928\n",
      "Epoch [2081/3000], Loss: 331.8756\n",
      "Validation Loss: 342.8838\n",
      "Epoch [2101/3000], Loss: 318.6362\n",
      "Validation Loss: 333.6857\n",
      "Epoch [2121/3000], Loss: 305.6423\n",
      "Validation Loss: 326.7095\n",
      "Epoch [2141/3000], Loss: 290.5841\n",
      "Validation Loss: 319.3624\n",
      "Epoch [2161/3000], Loss: 281.7292\n",
      "Validation Loss: 308.2650\n",
      "Epoch [2181/3000], Loss: 268.2079\n",
      "Validation Loss: 304.2530\n",
      "Epoch [2201/3000], Loss: 253.5371\n",
      "Validation Loss: 296.9475\n",
      "Epoch [2221/3000], Loss: 244.2066\n",
      "Validation Loss: 292.5552\n",
      "Epoch [2241/3000], Loss: 233.4663\n",
      "Validation Loss: 283.3146\n",
      "Epoch [2261/3000], Loss: 221.7074\n",
      "Validation Loss: 277.0798\n",
      "Epoch [2281/3000], Loss: 211.7940\n",
      "Validation Loss: 270.8870\n",
      "Epoch [2301/3000], Loss: 198.7359\n",
      "Validation Loss: 264.7108\n",
      "Epoch [2321/3000], Loss: 192.6280\n",
      "Validation Loss: 255.3752\n",
      "Epoch [2341/3000], Loss: 177.1134\n",
      "Validation Loss: 250.5629\n",
      "Epoch [2361/3000], Loss: 170.4606\n",
      "Validation Loss: 244.1084\n",
      "Epoch [2381/3000], Loss: 163.9050\n",
      "Validation Loss: 238.9710\n",
      "Epoch [2401/3000], Loss: 156.1014\n",
      "Validation Loss: 233.3049\n",
      "Epoch [2421/3000], Loss: 146.4062\n",
      "Validation Loss: 227.5389\n",
      "Epoch [2441/3000], Loss: 139.2034\n",
      "Validation Loss: 223.7805\n",
      "Epoch [2461/3000], Loss: 131.1345\n",
      "Validation Loss: 218.2343\n",
      "Epoch [2481/3000], Loss: 124.4307\n",
      "Validation Loss: 215.0500\n",
      "Epoch [2501/3000], Loss: 117.7070\n",
      "Validation Loss: 210.3649\n",
      "Epoch [2521/3000], Loss: 109.8747\n",
      "Validation Loss: 208.5579\n",
      "Epoch [2541/3000], Loss: 104.0650\n",
      "Validation Loss: 203.5864\n",
      "Epoch [2561/3000], Loss: 97.6412\n",
      "Validation Loss: 198.8566\n",
      "Epoch [2581/3000], Loss: 92.1253\n",
      "Validation Loss: 196.8120\n",
      "Epoch [2601/3000], Loss: 86.3935\n",
      "Validation Loss: 192.9521\n",
      "Epoch [2621/3000], Loss: 78.7126\n",
      "Validation Loss: 187.6913\n",
      "Epoch [2641/3000], Loss: 76.3344\n",
      "Validation Loss: 182.7738\n",
      "Epoch [2661/3000], Loss: 71.5202\n",
      "Validation Loss: 185.7212\n",
      "Epoch [2681/3000], Loss: 65.8730\n",
      "Validation Loss: 180.9355\n",
      "Epoch [2701/3000], Loss: 60.9353\n",
      "Validation Loss: 180.7462\n",
      "Epoch [2721/3000], Loss: 55.5043\n",
      "Validation Loss: 175.8782\n",
      "Epoch [2741/3000], Loss: 53.2575\n",
      "Validation Loss: 171.8208\n",
      "Epoch [2761/3000], Loss: 49.4834\n",
      "Validation Loss: 170.4178\n",
      "Epoch [2781/3000], Loss: 45.7778\n",
      "Validation Loss: 175.2560\n",
      "Epoch [2801/3000], Loss: 42.8581\n",
      "Validation Loss: 170.9183\n",
      "Epoch [2821/3000], Loss: 38.8597\n",
      "Validation Loss: 168.6200\n",
      "Epoch [2841/3000], Loss: 35.4542\n",
      "Validation Loss: 167.0035\n",
      "Epoch [2861/3000], Loss: 33.2794\n",
      "Validation Loss: 160.3199\n",
      "Epoch [2881/3000], Loss: 29.9974\n",
      "Validation Loss: 165.3951\n",
      "Epoch [2901/3000], Loss: 27.9102\n",
      "Validation Loss: 165.3174\n",
      "Epoch [2921/3000], Loss: 25.5533\n",
      "Validation Loss: 164.9414\n",
      "Epoch [2941/3000], Loss: 22.6799\n",
      "Validation Loss: 171.3149\n",
      "Epoch [2961/3000], Loss: 20.9068\n",
      "Validation Loss: 164.7959\n",
      "Epoch [2981/3000], Loss: 18.8880\n",
      "Validation Loss: 170.0063\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day061_plane0_Fall.mat\n",
      "(7602, 813)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8112.5532\n",
      "Validation Loss: 8427.9585\n",
      "Epoch [21/3000], Loss: 6880.5768\n",
      "Validation Loss: 7193.8598\n",
      "Epoch [41/3000], Loss: 6614.8799\n",
      "Validation Loss: 6928.2787\n",
      "Epoch [61/3000], Loss: 6441.4960\n",
      "Validation Loss: 6728.5957\n",
      "Epoch [81/3000], Loss: 6257.8827\n",
      "Validation Loss: 6545.0106\n",
      "Epoch [101/3000], Loss: 6095.9878\n",
      "Validation Loss: 6371.5315\n",
      "Epoch [121/3000], Loss: 5941.6230\n",
      "Validation Loss: 6205.4349\n",
      "Epoch [141/3000], Loss: 5802.7401\n",
      "Validation Loss: 6045.0828\n",
      "Epoch [161/3000], Loss: 5642.5142\n",
      "Validation Loss: 5890.1744\n",
      "Epoch [181/3000], Loss: 5508.8206\n",
      "Validation Loss: 5739.9773\n",
      "Epoch [201/3000], Loss: 5345.0073\n",
      "Validation Loss: 5594.5235\n",
      "Epoch [221/3000], Loss: 5225.6485\n",
      "Validation Loss: 5453.4178\n",
      "Epoch [241/3000], Loss: 5115.5474\n",
      "Validation Loss: 5316.5955\n",
      "Epoch [261/3000], Loss: 4988.0656\n",
      "Validation Loss: 5184.1083\n",
      "Epoch [281/3000], Loss: 4859.9324\n",
      "Validation Loss: 5055.8956\n",
      "Epoch [301/3000], Loss: 4726.1228\n",
      "Validation Loss: 4931.8452\n",
      "Epoch [321/3000], Loss: 4607.3604\n",
      "Validation Loss: 4812.0602\n",
      "Epoch [341/3000], Loss: 4508.6223\n",
      "Validation Loss: 4696.4970\n",
      "Epoch [361/3000], Loss: 4399.7643\n",
      "Validation Loss: 4585.0002\n",
      "Epoch [381/3000], Loss: 4300.9451\n",
      "Validation Loss: 4477.9217\n",
      "Epoch [401/3000], Loss: 4226.9278\n",
      "Validation Loss: 4374.7183\n",
      "Epoch [421/3000], Loss: 4129.6928\n",
      "Validation Loss: 4275.7594\n",
      "Epoch [441/3000], Loss: 4029.5540\n",
      "Validation Loss: 4180.9956\n",
      "Epoch [461/3000], Loss: 3951.0854\n",
      "Validation Loss: 4090.2496\n",
      "Epoch [481/3000], Loss: 3880.1034\n",
      "Validation Loss: 4003.5260\n",
      "Epoch [501/3000], Loss: 3802.5456\n",
      "Validation Loss: 3920.9480\n",
      "Epoch [521/3000], Loss: 3729.2372\n",
      "Validation Loss: 3842.4117\n",
      "Epoch [541/3000], Loss: 3651.7954\n",
      "Validation Loss: 3768.0026\n",
      "Epoch [561/3000], Loss: 3600.2375\n",
      "Validation Loss: 3697.5905\n",
      "Epoch [581/3000], Loss: 3541.0144\n",
      "Validation Loss: 3631.1065\n",
      "Epoch [601/3000], Loss: 3488.7099\n",
      "Validation Loss: 3568.6822\n",
      "Epoch [621/3000], Loss: 3433.8265\n",
      "Validation Loss: 3510.0991\n",
      "Epoch [641/3000], Loss: 3386.0675\n",
      "Validation Loss: 3455.4325\n",
      "Epoch [661/3000], Loss: 3340.0269\n",
      "Validation Loss: 3404.7067\n",
      "Epoch [681/3000], Loss: 3289.1551\n",
      "Validation Loss: 3357.8326\n",
      "Epoch [701/3000], Loss: 3265.9167\n",
      "Validation Loss: 3314.7498\n",
      "Epoch [721/3000], Loss: 3239.0583\n",
      "Validation Loss: 3275.4223\n",
      "Epoch [741/3000], Loss: 3201.7960\n",
      "Validation Loss: 3239.6531\n",
      "Epoch [761/3000], Loss: 3181.8948\n",
      "Validation Loss: 3207.5962\n",
      "Epoch [781/3000], Loss: 3009.7958\n",
      "Validation Loss: 2994.1023\n",
      "Epoch [801/3000], Loss: 1922.0375\n",
      "Validation Loss: 2016.0501\n",
      "Epoch [821/3000], Loss: 1832.3751\n",
      "Validation Loss: 1913.1042\n",
      "Epoch [841/3000], Loss: 1731.1696\n",
      "Validation Loss: 1842.0866\n",
      "Epoch [861/3000], Loss: 1657.1601\n",
      "Validation Loss: 1763.6934\n",
      "Epoch [881/3000], Loss: 1580.4152\n",
      "Validation Loss: 1689.0611\n",
      "Epoch [901/3000], Loss: 1512.8734\n",
      "Validation Loss: 1618.6406\n",
      "Epoch [921/3000], Loss: 1444.3912\n",
      "Validation Loss: 1550.5604\n",
      "Epoch [941/3000], Loss: 1384.0905\n",
      "Validation Loss: 1484.4653\n",
      "Epoch [961/3000], Loss: 1311.9382\n",
      "Validation Loss: 1421.1303\n",
      "Epoch [981/3000], Loss: 1254.6714\n",
      "Validation Loss: 1358.9844\n",
      "Epoch [1001/3000], Loss: 1196.8649\n",
      "Validation Loss: 1299.9092\n",
      "Epoch [1021/3000], Loss: 1140.1321\n",
      "Validation Loss: 1240.1809\n",
      "Epoch [1041/3000], Loss: 1092.4096\n",
      "Validation Loss: 1185.0854\n",
      "Epoch [1061/3000], Loss: 1038.6008\n",
      "Validation Loss: 1130.8899\n",
      "Epoch [1081/3000], Loss: 992.7089\n",
      "Validation Loss: 1076.9500\n",
      "Epoch [1101/3000], Loss: 938.2075\n",
      "Validation Loss: 1026.6509\n",
      "Epoch [1121/3000], Loss: 884.3454\n",
      "Validation Loss: 983.4048\n",
      "Epoch [1141/3000], Loss: 849.2764\n",
      "Validation Loss: 940.2662\n",
      "Epoch [1161/3000], Loss: 803.6032\n",
      "Validation Loss: 896.0188\n",
      "Epoch [1181/3000], Loss: 756.8441\n",
      "Validation Loss: 853.4114\n",
      "Epoch [1201/3000], Loss: 718.0395\n",
      "Validation Loss: 812.1536\n",
      "Epoch [1221/3000], Loss: 686.0770\n",
      "Validation Loss: 773.2180\n",
      "Epoch [1241/3000], Loss: 643.8606\n",
      "Validation Loss: 737.6694\n",
      "Epoch [1261/3000], Loss: 607.1484\n",
      "Validation Loss: 703.6074\n",
      "Epoch [1281/3000], Loss: 573.5382\n",
      "Validation Loss: 671.3233\n",
      "Epoch [1301/3000], Loss: 546.9356\n",
      "Validation Loss: 638.5501\n",
      "Epoch [1321/3000], Loss: 508.9382\n",
      "Validation Loss: 607.6396\n",
      "Epoch [1341/3000], Loss: 478.3809\n",
      "Validation Loss: 579.3131\n",
      "Epoch [1361/3000], Loss: 450.9404\n",
      "Validation Loss: 553.6313\n",
      "Epoch [1381/3000], Loss: 422.8028\n",
      "Validation Loss: 527.5161\n",
      "Epoch [1401/3000], Loss: 397.7129\n",
      "Validation Loss: 502.8251\n",
      "Epoch [1421/3000], Loss: 374.4671\n",
      "Validation Loss: 480.9354\n",
      "Epoch [1441/3000], Loss: 348.9729\n",
      "Validation Loss: 457.6452\n",
      "Epoch [1461/3000], Loss: 330.1250\n",
      "Validation Loss: 438.0077\n",
      "Epoch [1481/3000], Loss: 308.9023\n",
      "Validation Loss: 419.2518\n",
      "Epoch [1501/3000], Loss: 286.3199\n",
      "Validation Loss: 401.1701\n",
      "Epoch [1521/3000], Loss: 268.3973\n",
      "Validation Loss: 384.7743\n",
      "Epoch [1541/3000], Loss: 250.3989\n",
      "Validation Loss: 368.6901\n",
      "Epoch [1561/3000], Loss: 233.7884\n",
      "Validation Loss: 352.9374\n",
      "Epoch [1581/3000], Loss: 218.6829\n",
      "Validation Loss: 339.1025\n",
      "Epoch [1601/3000], Loss: 201.6641\n",
      "Validation Loss: 329.7668\n",
      "Epoch [1621/3000], Loss: 188.0747\n",
      "Validation Loss: 321.2536\n",
      "Epoch [1641/3000], Loss: 177.0253\n",
      "Validation Loss: 311.0111\n",
      "Epoch [1661/3000], Loss: 163.7010\n",
      "Validation Loss: 302.3262\n",
      "Epoch [1681/3000], Loss: 151.6094\n",
      "Validation Loss: 294.0647\n",
      "Epoch [1701/3000], Loss: 140.9327\n",
      "Validation Loss: 287.4121\n",
      "Epoch [1721/3000], Loss: 131.9515\n",
      "Validation Loss: 280.2860\n",
      "Epoch [1741/3000], Loss: 121.0588\n",
      "Validation Loss: 274.9341\n",
      "Epoch [1761/3000], Loss: 113.0537\n",
      "Validation Loss: 268.8260\n",
      "Epoch [1781/3000], Loss: 105.1088\n",
      "Validation Loss: 265.2950\n",
      "Epoch [1801/3000], Loss: 96.3527\n",
      "Validation Loss: 261.8183\n",
      "Epoch [1821/3000], Loss: 90.1516\n",
      "Validation Loss: 258.0685\n",
      "Epoch [1841/3000], Loss: 83.3493\n",
      "Validation Loss: 248.6793\n",
      "Epoch [1861/3000], Loss: 77.8629\n",
      "Validation Loss: 249.7171\n",
      "Epoch [1881/3000], Loss: 71.5818\n",
      "Validation Loss: 249.6835\n",
      "Epoch [1901/3000], Loss: 66.4330\n",
      "Validation Loss: 249.7722\n",
      "Epoch [1921/3000], Loss: 61.8274\n",
      "Validation Loss: 250.9259\n",
      "Epoch [1941/3000], Loss: 56.4315\n",
      "Validation Loss: 252.3539\n",
      "Epoch [1961/3000], Loss: 51.3355\n",
      "Validation Loss: 252.9768\n",
      "Epoch [1981/3000], Loss: 46.8684\n",
      "Validation Loss: 251.3407\n",
      "Epoch [2001/3000], Loss: 42.9310\n",
      "Validation Loss: 252.2930\n",
      "Epoch [2021/3000], Loss: 38.7316\n",
      "Validation Loss: 252.2445\n",
      "Epoch [2041/3000], Loss: 35.1422\n",
      "Validation Loss: 253.8603\n",
      "Epoch [2061/3000], Loss: 31.2983\n",
      "Validation Loss: 254.6247\n",
      "Epoch [2081/3000], Loss: 28.0856\n",
      "Validation Loss: 253.3168\n",
      "Epoch [2101/3000], Loss: 24.8304\n",
      "Validation Loss: 256.3984\n",
      "Epoch [2121/3000], Loss: 21.5590\n",
      "Validation Loss: 258.5135\n",
      "Epoch [2141/3000], Loss: 19.0805\n",
      "Validation Loss: 260.3332\n",
      "Epoch [2161/3000], Loss: 16.6244\n",
      "Validation Loss: 260.6608\n",
      "Epoch [2181/3000], Loss: 14.5076\n",
      "Validation Loss: 260.7146\n",
      "Epoch [2201/3000], Loss: 12.5568\n",
      "Validation Loss: 262.6602\n",
      "Epoch [2221/3000], Loss: 10.7400\n",
      "Validation Loss: 262.4035\n",
      "Epoch [2241/3000], Loss: 9.1356\n",
      "Validation Loss: 263.1355\n",
      "Epoch [2261/3000], Loss: 7.8200\n",
      "Validation Loss: 261.5224\n",
      "Epoch [2281/3000], Loss: 6.4993\n",
      "Validation Loss: 259.0866\n",
      "Epoch [2301/3000], Loss: 5.3825\n",
      "Validation Loss: 260.3964\n",
      "Epoch [2321/3000], Loss: 4.4650\n",
      "Validation Loss: 260.9953\n",
      "Epoch [2341/3000], Loss: 25.1333\n",
      "Validation Loss: 217.6731\n",
      "Epoch [2361/3000], Loss: 3.0631\n",
      "Validation Loss: 231.8220\n",
      "Epoch [2381/3000], Loss: 2.4649\n",
      "Validation Loss: 235.7276\n",
      "Epoch [2401/3000], Loss: 1.9982\n",
      "Validation Loss: 238.7869\n",
      "Epoch [2421/3000], Loss: 1.5557\n",
      "Validation Loss: 241.9260\n",
      "Epoch [2441/3000], Loss: 1.2431\n",
      "Validation Loss: 244.1411\n",
      "Epoch [2461/3000], Loss: 0.9558\n",
      "Validation Loss: 245.5053\n",
      "Epoch [2481/3000], Loss: 0.7272\n",
      "Validation Loss: 247.7357\n",
      "Epoch [2501/3000], Loss: 0.5252\n",
      "Validation Loss: 248.4147\n",
      "Epoch [2521/3000], Loss: 0.3791\n",
      "Validation Loss: 247.8662\n",
      "Epoch [2541/3000], Loss: 0.2655\n",
      "Validation Loss: 247.9120\n",
      "Epoch [2561/3000], Loss: 0.1836\n",
      "Validation Loss: 247.5910\n",
      "Epoch [2581/3000], Loss: 0.1219\n",
      "Validation Loss: 247.2299\n",
      "Epoch [2601/3000], Loss: 0.0921\n",
      "Validation Loss: 248.8552\n",
      "Epoch [2621/3000], Loss: 0.0794\n",
      "Validation Loss: 245.8561\n",
      "Epoch [2641/3000], Loss: 0.0486\n",
      "Validation Loss: 246.4700\n",
      "Epoch [2661/3000], Loss: 0.0436\n",
      "Validation Loss: 247.1259\n",
      "Epoch [2681/3000], Loss: 0.0345\n",
      "Validation Loss: 248.1042\n",
      "Epoch [2701/3000], Loss: 0.0340\n",
      "Validation Loss: 247.3919\n",
      "Epoch [2721/3000], Loss: 0.0297\n",
      "Validation Loss: 247.7774\n",
      "Epoch [2741/3000], Loss: 0.0256\n",
      "Validation Loss: 247.3147\n",
      "Epoch [2761/3000], Loss: 0.0234\n",
      "Validation Loss: 242.9391\n",
      "Epoch [2781/3000], Loss: 0.0251\n",
      "Validation Loss: 244.6362\n",
      "Epoch [2801/3000], Loss: 0.0220\n",
      "Validation Loss: 242.2598\n",
      "Epoch [2821/3000], Loss: 0.0211\n",
      "Validation Loss: 243.7180\n",
      "Epoch [2841/3000], Loss: 0.0191\n",
      "Validation Loss: 242.6652\n",
      "Epoch [2861/3000], Loss: 0.0205\n",
      "Validation Loss: 241.2719\n",
      "Epoch [2881/3000], Loss: 0.0218\n",
      "Validation Loss: 239.6626\n",
      "Epoch [2901/3000], Loss: 0.0167\n",
      "Validation Loss: 241.4875\n",
      "Epoch [2921/3000], Loss: 0.0211\n",
      "Validation Loss: 241.1699\n",
      "Epoch [2941/3000], Loss: 0.0149\n",
      "Validation Loss: 244.6488\n",
      "Epoch [2961/3000], Loss: 0.0195\n",
      "Validation Loss: 242.7806\n",
      "Epoch [2981/3000], Loss: 0.0157\n",
      "Validation Loss: 245.9870\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day062_plane0_Fall.mat\n",
      "(4466, 1056)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6488.1184\n",
      "Validation Loss: 5653.9175\n",
      "Epoch [21/3000], Loss: 5597.6354\n",
      "Validation Loss: 4861.1514\n",
      "Epoch [41/3000], Loss: 5374.4189\n",
      "Validation Loss: 4657.4692\n",
      "Epoch [61/3000], Loss: 5242.5149\n",
      "Validation Loss: 4545.3538\n",
      "Epoch [81/3000], Loss: 5156.3166\n",
      "Validation Loss: 4456.1708\n",
      "Epoch [101/3000], Loss: 5040.8324\n",
      "Validation Loss: 4374.8355\n",
      "Epoch [121/3000], Loss: 4976.2492\n",
      "Validation Loss: 4297.0713\n",
      "Epoch [141/3000], Loss: 4897.8237\n",
      "Validation Loss: 4222.8690\n",
      "Epoch [161/3000], Loss: 4811.1133\n",
      "Validation Loss: 4151.4452\n",
      "Epoch [181/3000], Loss: 4716.1698\n",
      "Validation Loss: 4082.5014\n",
      "Epoch [201/3000], Loss: 4639.5114\n",
      "Validation Loss: 4015.7239\n",
      "Epoch [221/3000], Loss: 4581.5254\n",
      "Validation Loss: 3950.8671\n",
      "Epoch [241/3000], Loss: 4512.9629\n",
      "Validation Loss: 3887.6124\n",
      "Epoch [261/3000], Loss: 4415.7570\n",
      "Validation Loss: 3826.1308\n",
      "Epoch [281/3000], Loss: 4349.6410\n",
      "Validation Loss: 3766.2342\n",
      "Epoch [301/3000], Loss: 4284.6343\n",
      "Validation Loss: 3707.7881\n",
      "Epoch [321/3000], Loss: 4192.6661\n",
      "Validation Loss: 3650.9271\n",
      "Epoch [341/3000], Loss: 4157.1415\n",
      "Validation Loss: 3595.5031\n",
      "Epoch [361/3000], Loss: 4060.9440\n",
      "Validation Loss: 3541.5415\n",
      "Epoch [381/3000], Loss: 4011.8245\n",
      "Validation Loss: 3489.0244\n",
      "Epoch [401/3000], Loss: 3981.1952\n",
      "Validation Loss: 3437.9630\n",
      "Epoch [421/3000], Loss: 3901.7085\n",
      "Validation Loss: 3388.2122\n",
      "Epoch [441/3000], Loss: 3857.5912\n",
      "Validation Loss: 3339.9500\n",
      "Epoch [461/3000], Loss: 3776.4039\n",
      "Validation Loss: 3293.0515\n",
      "Epoch [481/3000], Loss: 3717.3703\n",
      "Validation Loss: 3247.5655\n",
      "Epoch [501/3000], Loss: 3672.0617\n",
      "Validation Loss: 3203.4877\n",
      "Epoch [521/3000], Loss: 3629.5277\n",
      "Validation Loss: 3160.7175\n",
      "Epoch [541/3000], Loss: 3574.0390\n",
      "Validation Loss: 3119.3572\n",
      "Epoch [561/3000], Loss: 3520.1003\n",
      "Validation Loss: 3079.3516\n",
      "Epoch [581/3000], Loss: 3466.9758\n",
      "Validation Loss: 3040.7340\n",
      "Epoch [601/3000], Loss: 3415.7211\n",
      "Validation Loss: 3003.4915\n",
      "Epoch [621/3000], Loss: 3380.3463\n",
      "Validation Loss: 2967.5400\n",
      "Epoch [641/3000], Loss: 3336.6545\n",
      "Validation Loss: 2933.0215\n",
      "Epoch [661/3000], Loss: 3283.2930\n",
      "Validation Loss: 2899.7749\n",
      "Epoch [681/3000], Loss: 3251.1421\n",
      "Validation Loss: 2867.8469\n",
      "Epoch [701/3000], Loss: 3206.1307\n",
      "Validation Loss: 2837.3038\n",
      "Epoch [721/3000], Loss: 3171.1640\n",
      "Validation Loss: 2808.0759\n",
      "Epoch [741/3000], Loss: 3141.4640\n",
      "Validation Loss: 2780.2006\n",
      "Epoch [761/3000], Loss: 3096.4894\n",
      "Validation Loss: 2753.6247\n",
      "Epoch [781/3000], Loss: 3067.6158\n",
      "Validation Loss: 2728.3223\n",
      "Epoch [801/3000], Loss: 3026.8802\n",
      "Validation Loss: 2704.3966\n",
      "Epoch [821/3000], Loss: 2981.6596\n",
      "Validation Loss: 2681.6655\n",
      "Epoch [841/3000], Loss: 2960.6090\n",
      "Validation Loss: 2660.2823\n",
      "Epoch [861/3000], Loss: 2936.4937\n",
      "Validation Loss: 2640.1086\n",
      "Epoch [881/3000], Loss: 2892.9069\n",
      "Validation Loss: 2621.2594\n",
      "Epoch [901/3000], Loss: 2876.2269\n",
      "Validation Loss: 2603.6218\n",
      "Epoch [921/3000], Loss: 2844.7739\n",
      "Validation Loss: 2587.2046\n",
      "Epoch [941/3000], Loss: 2817.1798\n",
      "Validation Loss: 2572.0643\n",
      "Epoch [961/3000], Loss: 2795.9025\n",
      "Validation Loss: 2558.0909\n",
      "Epoch [981/3000], Loss: 2762.7062\n",
      "Validation Loss: 2545.3324\n",
      "Epoch [1001/3000], Loss: 2728.7942\n",
      "Validation Loss: 2533.7382\n",
      "Epoch [1021/3000], Loss: 2739.3367\n",
      "Validation Loss: 2523.3441\n",
      "Epoch [1041/3000], Loss: 2707.1858\n",
      "Validation Loss: 2514.0663\n",
      "Epoch [1061/3000], Loss: 2712.8388\n",
      "Validation Loss: 2505.8838\n",
      "Epoch [1081/3000], Loss: 2693.8621\n",
      "Validation Loss: 2498.8061\n",
      "Epoch [1101/3000], Loss: 2673.8173\n",
      "Validation Loss: 2492.7872\n",
      "Epoch [1121/3000], Loss: 2653.5684\n",
      "Validation Loss: 2487.7963\n",
      "Epoch [1141/3000], Loss: 2638.4740\n",
      "Validation Loss: 2483.8235\n",
      "Epoch [1161/3000], Loss: 2636.5605\n",
      "Validation Loss: 2480.7944\n",
      "Epoch [1181/3000], Loss: 2628.5200\n",
      "Validation Loss: 2478.6686\n",
      "Epoch [1201/3000], Loss: 1802.9943\n",
      "Validation Loss: 1533.8088\n",
      "Epoch [1221/3000], Loss: 1664.2293\n",
      "Validation Loss: 1409.7566\n",
      "Epoch [1241/3000], Loss: 1586.7227\n",
      "Validation Loss: 1362.0372\n",
      "Epoch [1261/3000], Loss: 1554.9427\n",
      "Validation Loss: 1322.6648\n",
      "Epoch [1281/3000], Loss: 1508.3694\n",
      "Validation Loss: 1286.5113\n",
      "Epoch [1301/3000], Loss: 1451.7455\n",
      "Validation Loss: 1252.3656\n",
      "Epoch [1321/3000], Loss: 1418.3759\n",
      "Validation Loss: 1220.5245\n",
      "Epoch [1341/3000], Loss: 1388.9503\n",
      "Validation Loss: 1189.8275\n",
      "Epoch [1361/3000], Loss: 1355.8554\n",
      "Validation Loss: 1160.2983\n",
      "Epoch [1381/3000], Loss: 1316.0471\n",
      "Validation Loss: 1131.8437\n",
      "Epoch [1401/3000], Loss: 1282.2709\n",
      "Validation Loss: 1104.2554\n",
      "Epoch [1421/3000], Loss: 1236.5175\n",
      "Validation Loss: 1077.3758\n",
      "Epoch [1441/3000], Loss: 1217.2869\n",
      "Validation Loss: 1051.3795\n",
      "Epoch [1461/3000], Loss: 1193.8438\n",
      "Validation Loss: 1026.4312\n",
      "Epoch [1481/3000], Loss: 1162.6463\n",
      "Validation Loss: 1002.0870\n",
      "Epoch [1501/3000], Loss: 1134.2525\n",
      "Validation Loss: 978.3888\n",
      "Epoch [1521/3000], Loss: 1104.0534\n",
      "Validation Loss: 955.6865\n",
      "Epoch [1541/3000], Loss: 1077.4682\n",
      "Validation Loss: 932.7435\n",
      "Epoch [1561/3000], Loss: 1040.8502\n",
      "Validation Loss: 912.4438\n",
      "Epoch [1581/3000], Loss: 1005.2130\n",
      "Validation Loss: 892.2735\n",
      "Epoch [1601/3000], Loss: 989.6983\n",
      "Validation Loss: 871.7749\n",
      "Epoch [1621/3000], Loss: 971.0633\n",
      "Validation Loss: 852.5536\n",
      "Epoch [1641/3000], Loss: 929.5948\n",
      "Validation Loss: 833.2254\n",
      "Epoch [1661/3000], Loss: 907.8750\n",
      "Validation Loss: 814.6743\n",
      "Epoch [1681/3000], Loss: 898.3655\n",
      "Validation Loss: 797.5753\n",
      "Epoch [1701/3000], Loss: 864.1665\n",
      "Validation Loss: 780.0377\n",
      "Epoch [1721/3000], Loss: 850.4812\n",
      "Validation Loss: 764.4287\n",
      "Epoch [1741/3000], Loss: 821.9879\n",
      "Validation Loss: 747.9631\n",
      "Epoch [1761/3000], Loss: 799.8824\n",
      "Validation Loss: 732.4446\n",
      "Epoch [1781/3000], Loss: 778.6366\n",
      "Validation Loss: 718.1415\n",
      "Epoch [1801/3000], Loss: 758.8989\n",
      "Validation Loss: 699.8893\n",
      "Epoch [1821/3000], Loss: 740.6782\n",
      "Validation Loss: 687.8814\n",
      "Epoch [1841/3000], Loss: 717.7420\n",
      "Validation Loss: 676.6995\n",
      "Epoch [1861/3000], Loss: 693.5741\n",
      "Validation Loss: 660.4447\n",
      "Epoch [1881/3000], Loss: 678.8217\n",
      "Validation Loss: 651.2847\n",
      "Epoch [1901/3000], Loss: 662.6296\n",
      "Validation Loss: 639.9846\n",
      "Epoch [1921/3000], Loss: 647.8032\n",
      "Validation Loss: 626.4138\n",
      "Epoch [1941/3000], Loss: 624.3953\n",
      "Validation Loss: 616.1259\n",
      "Epoch [1961/3000], Loss: 605.0734\n",
      "Validation Loss: 605.6888\n",
      "Epoch [1981/3000], Loss: 594.1055\n",
      "Validation Loss: 595.6177\n",
      "Epoch [2001/3000], Loss: 572.1390\n",
      "Validation Loss: 585.8310\n",
      "Epoch [2021/3000], Loss: 561.5718\n",
      "Validation Loss: 594.6668\n",
      "Epoch [2041/3000], Loss: 535.6239\n",
      "Validation Loss: 557.1180\n",
      "Epoch [2061/3000], Loss: 520.5863\n",
      "Validation Loss: 549.3576\n",
      "Epoch [2081/3000], Loss: 514.5483\n",
      "Validation Loss: 541.5683\n",
      "Epoch [2101/3000], Loss: 487.4548\n",
      "Validation Loss: 534.4941\n",
      "Epoch [2121/3000], Loss: 472.3576\n",
      "Validation Loss: 528.0223\n",
      "Epoch [2141/3000], Loss: 465.0307\n",
      "Validation Loss: 521.6578\n",
      "Epoch [2161/3000], Loss: 458.0790\n",
      "Validation Loss: 515.1825\n",
      "Epoch [2181/3000], Loss: 436.4023\n",
      "Validation Loss: 509.3813\n",
      "Epoch [2201/3000], Loss: 426.3634\n",
      "Validation Loss: 502.2256\n",
      "Epoch [2221/3000], Loss: 411.0454\n",
      "Validation Loss: 495.8153\n",
      "Epoch [2241/3000], Loss: 404.6543\n",
      "Validation Loss: 490.3126\n",
      "Epoch [2261/3000], Loss: 396.8699\n",
      "Validation Loss: 484.7533\n",
      "Epoch [2281/3000], Loss: 376.5761\n",
      "Validation Loss: 479.1318\n",
      "Epoch [2301/3000], Loss: 368.4638\n",
      "Validation Loss: 474.3979\n",
      "Epoch [2321/3000], Loss: 359.2831\n",
      "Validation Loss: 469.6700\n",
      "Epoch [2341/3000], Loss: 346.9448\n",
      "Validation Loss: 462.7032\n",
      "Epoch [2361/3000], Loss: 336.3383\n",
      "Validation Loss: 456.4341\n",
      "Epoch [2381/3000], Loss: 321.5451\n",
      "Validation Loss: 452.8459\n",
      "Epoch [2401/3000], Loss: 316.0873\n",
      "Validation Loss: 449.0551\n",
      "Epoch [2421/3000], Loss: 305.3398\n",
      "Validation Loss: 440.1909\n",
      "Epoch [2441/3000], Loss: 295.3569\n",
      "Validation Loss: 443.5937\n",
      "Epoch [2461/3000], Loss: 287.8506\n",
      "Validation Loss: 440.0032\n",
      "Epoch [2481/3000], Loss: 278.5789\n",
      "Validation Loss: 433.8615\n",
      "Epoch [2501/3000], Loss: 271.2818\n",
      "Validation Loss: 432.7730\n",
      "Epoch [2521/3000], Loss: 258.2892\n",
      "Validation Loss: 424.8673\n",
      "Epoch [2541/3000], Loss: 250.5620\n",
      "Validation Loss: 424.2018\n",
      "Epoch [2561/3000], Loss: 240.3400\n",
      "Validation Loss: 422.0401\n",
      "Epoch [2581/3000], Loss: 234.7279\n",
      "Validation Loss: 415.9033\n",
      "Epoch [2601/3000], Loss: 230.4919\n",
      "Validation Loss: 409.2537\n",
      "Epoch [2621/3000], Loss: 217.4215\n",
      "Validation Loss: 406.5353\n",
      "Epoch [2641/3000], Loss: 210.8448\n",
      "Validation Loss: 401.3819\n",
      "Epoch [2661/3000], Loss: 203.0071\n",
      "Validation Loss: 398.6464\n",
      "Epoch [2681/3000], Loss: 195.3786\n",
      "Validation Loss: 397.6576\n",
      "Epoch [2701/3000], Loss: 188.4277\n",
      "Validation Loss: 394.7916\n",
      "Epoch [2721/3000], Loss: 182.3924\n",
      "Validation Loss: 391.6582\n",
      "Epoch [2741/3000], Loss: 176.2176\n",
      "Validation Loss: 388.6520\n",
      "Epoch [2761/3000], Loss: 166.6641\n",
      "Validation Loss: 381.5429\n",
      "Epoch [2781/3000], Loss: 163.0993\n",
      "Validation Loss: 383.1380\n",
      "Epoch [2801/3000], Loss: 156.6740\n",
      "Validation Loss: 379.9821\n",
      "Epoch [2821/3000], Loss: 150.7421\n",
      "Validation Loss: 376.6242\n",
      "Epoch [2841/3000], Loss: 146.7499\n",
      "Validation Loss: 375.4715\n",
      "Epoch [2861/3000], Loss: 140.6271\n",
      "Validation Loss: 371.2154\n",
      "Epoch [2881/3000], Loss: 135.2714\n",
      "Validation Loss: 369.6685\n",
      "Epoch [2901/3000], Loss: 128.9728\n",
      "Validation Loss: 369.6948\n",
      "Epoch [2921/3000], Loss: 125.1465\n",
      "Validation Loss: 366.5472\n",
      "Epoch [2941/3000], Loss: 120.0282\n",
      "Validation Loss: 366.8028\n",
      "Epoch [2961/3000], Loss: 114.0488\n",
      "Validation Loss: 368.8017\n",
      "Epoch [2981/3000], Loss: 109.2884\n",
      "Validation Loss: 366.9023\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day063_plane0_Fall.mat\n",
      "(5928, 886)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7481.6503\n",
      "Validation Loss: 6662.6818\n",
      "Epoch [21/3000], Loss: 6363.7262\n",
      "Validation Loss: 5664.2856\n",
      "Epoch [41/3000], Loss: 6111.9966\n",
      "Validation Loss: 5445.4417\n",
      "Epoch [61/3000], Loss: 5936.0290\n",
      "Validation Loss: 5301.3035\n",
      "Epoch [81/3000], Loss: 5799.6409\n",
      "Validation Loss: 5171.6769\n",
      "Epoch [101/3000], Loss: 5652.7436\n",
      "Validation Loss: 5053.7615\n",
      "Epoch [121/3000], Loss: 5538.8975\n",
      "Validation Loss: 4941.4314\n",
      "Epoch [141/3000], Loss: 5400.1434\n",
      "Validation Loss: 4833.5092\n",
      "Epoch [161/3000], Loss: 5288.7903\n",
      "Validation Loss: 4729.2823\n",
      "Epoch [181/3000], Loss: 5162.0393\n",
      "Validation Loss: 4627.1799\n",
      "Epoch [201/3000], Loss: 5050.7630\n",
      "Validation Loss: 4528.5506\n",
      "Epoch [221/3000], Loss: 4940.7145\n",
      "Validation Loss: 4433.1275\n",
      "Epoch [241/3000], Loss: 4832.0846\n",
      "Validation Loss: 4340.6550\n",
      "Epoch [261/3000], Loss: 4725.6280\n",
      "Validation Loss: 4251.0121\n",
      "Epoch [281/3000], Loss: 4622.5259\n",
      "Validation Loss: 4164.0548\n",
      "Epoch [301/3000], Loss: 4513.4438\n",
      "Validation Loss: 4079.8279\n",
      "Epoch [321/3000], Loss: 4421.1704\n",
      "Validation Loss: 3998.2880\n",
      "Epoch [341/3000], Loss: 4331.2043\n",
      "Validation Loss: 3919.3374\n",
      "Epoch [361/3000], Loss: 4233.1940\n",
      "Validation Loss: 3843.0441\n",
      "Epoch [381/3000], Loss: 4144.2432\n",
      "Validation Loss: 3769.3226\n",
      "Epoch [401/3000], Loss: 4060.9866\n",
      "Validation Loss: 3698.2532\n",
      "Epoch [421/3000], Loss: 3973.9486\n",
      "Validation Loss: 3629.7843\n",
      "Epoch [441/3000], Loss: 3890.4927\n",
      "Validation Loss: 3563.8516\n",
      "Epoch [461/3000], Loss: 3809.3940\n",
      "Validation Loss: 3500.5530\n",
      "Epoch [481/3000], Loss: 3739.3052\n",
      "Validation Loss: 3439.7601\n",
      "Epoch [501/3000], Loss: 3668.0124\n",
      "Validation Loss: 3381.5484\n",
      "Epoch [521/3000], Loss: 3590.8176\n",
      "Validation Loss: 3325.8629\n",
      "Epoch [541/3000], Loss: 3516.1492\n",
      "Validation Loss: 3272.7463\n",
      "Epoch [561/3000], Loss: 3451.1029\n",
      "Validation Loss: 3222.1216\n",
      "Epoch [581/3000], Loss: 3392.2140\n",
      "Validation Loss: 3174.0286\n",
      "Epoch [601/3000], Loss: 3324.7045\n",
      "Validation Loss: 3128.4125\n",
      "Epoch [621/3000], Loss: 3264.1655\n",
      "Validation Loss: 3085.3004\n",
      "Epoch [641/3000], Loss: 3219.4013\n",
      "Validation Loss: 3044.6649\n",
      "Epoch [661/3000], Loss: 3160.9516\n",
      "Validation Loss: 3006.5112\n",
      "Epoch [681/3000], Loss: 3108.6579\n",
      "Validation Loss: 2970.7864\n",
      "Epoch [701/3000], Loss: 3060.6524\n",
      "Validation Loss: 2937.5115\n",
      "Epoch [721/3000], Loss: 3020.6046\n",
      "Validation Loss: 2906.6079\n",
      "Epoch [741/3000], Loss: 2972.4834\n",
      "Validation Loss: 2878.0815\n",
      "Epoch [761/3000], Loss: 2930.4914\n",
      "Validation Loss: 2851.9233\n",
      "Epoch [781/3000], Loss: 2892.1414\n",
      "Validation Loss: 2828.0857\n",
      "Epoch [801/3000], Loss: 2856.0958\n",
      "Validation Loss: 2806.5383\n",
      "Epoch [821/3000], Loss: 2819.8712\n",
      "Validation Loss: 2787.2974\n",
      "Epoch [841/3000], Loss: 2791.4795\n",
      "Validation Loss: 2770.2760\n",
      "Epoch [861/3000], Loss: 2757.2497\n",
      "Validation Loss: 2755.4378\n",
      "Epoch [881/3000], Loss: 2729.5668\n",
      "Validation Loss: 2742.7350\n",
      "Epoch [901/3000], Loss: 2707.6028\n",
      "Validation Loss: 2732.1340\n",
      "Epoch [921/3000], Loss: 2684.0785\n",
      "Validation Loss: 2723.5561\n",
      "Epoch [941/3000], Loss: 2663.6839\n",
      "Validation Loss: 2716.9359\n",
      "Epoch [961/3000], Loss: 2646.7868\n",
      "Validation Loss: 2712.1888\n",
      "Epoch [981/3000], Loss: 2633.6018\n",
      "Validation Loss: 2709.2213\n",
      "Epoch [1001/3000], Loss: 2596.3165\n",
      "Validation Loss: 2675.9181\n",
      "Epoch [1021/3000], Loss: 1556.5098\n",
      "Validation Loss: 1569.0721\n",
      "Epoch [1041/3000], Loss: 1472.2431\n",
      "Validation Loss: 1495.2934\n",
      "Epoch [1061/3000], Loss: 1411.1213\n",
      "Validation Loss: 1452.8255\n",
      "Epoch [1081/3000], Loss: 1350.9197\n",
      "Validation Loss: 1419.9994\n",
      "Epoch [1101/3000], Loss: 1300.8309\n",
      "Validation Loss: 1376.5817\n",
      "Epoch [1121/3000], Loss: 1248.8878\n",
      "Validation Loss: 1338.9511\n",
      "Epoch [1141/3000], Loss: 1200.6495\n",
      "Validation Loss: 1307.8428\n",
      "Epoch [1161/3000], Loss: 1150.7489\n",
      "Validation Loss: 1269.5185\n",
      "Epoch [1181/3000], Loss: 1110.7271\n",
      "Validation Loss: 1238.6085\n",
      "Epoch [1201/3000], Loss: 1066.3745\n",
      "Validation Loss: 1208.8429\n",
      "Epoch [1221/3000], Loss: 1024.3888\n",
      "Validation Loss: 1178.6000\n",
      "Epoch [1241/3000], Loss: 985.6401\n",
      "Validation Loss: 1149.0442\n",
      "Epoch [1261/3000], Loss: 949.1110\n",
      "Validation Loss: 1117.0100\n",
      "Epoch [1281/3000], Loss: 910.6709\n",
      "Validation Loss: 1088.0668\n",
      "Epoch [1301/3000], Loss: 873.8088\n",
      "Validation Loss: 1061.9170\n",
      "Epoch [1321/3000], Loss: 841.1969\n",
      "Validation Loss: 1039.7541\n",
      "Epoch [1341/3000], Loss: 807.4674\n",
      "Validation Loss: 1013.2518\n",
      "Epoch [1361/3000], Loss: 775.6407\n",
      "Validation Loss: 987.0410\n",
      "Epoch [1381/3000], Loss: 746.5929\n",
      "Validation Loss: 967.5957\n",
      "Epoch [1401/3000], Loss: 710.9946\n",
      "Validation Loss: 985.2152\n",
      "Epoch [1421/3000], Loss: 680.4175\n",
      "Validation Loss: 934.8393\n",
      "Epoch [1441/3000], Loss: 656.5408\n",
      "Validation Loss: 912.4869\n",
      "Epoch [1461/3000], Loss: 629.0562\n",
      "Validation Loss: 891.6514\n",
      "Epoch [1481/3000], Loss: 604.3008\n",
      "Validation Loss: 882.9429\n",
      "Epoch [1501/3000], Loss: 578.7375\n",
      "Validation Loss: 864.9811\n",
      "Epoch [1521/3000], Loss: 552.8989\n",
      "Validation Loss: 847.7743\n",
      "Epoch [1541/3000], Loss: 531.1439\n",
      "Validation Loss: 830.1587\n",
      "Epoch [1561/3000], Loss: 511.0976\n",
      "Validation Loss: 816.5259\n",
      "Epoch [1581/3000], Loss: 487.8992\n",
      "Validation Loss: 804.2280\n",
      "Epoch [1601/3000], Loss: 467.1624\n",
      "Validation Loss: 791.9835\n",
      "Epoch [1621/3000], Loss: 447.8428\n",
      "Validation Loss: 779.7135\n",
      "Epoch [1641/3000], Loss: 429.3427\n",
      "Validation Loss: 766.1383\n",
      "Epoch [1661/3000], Loss: 410.9059\n",
      "Validation Loss: 754.4059\n",
      "Epoch [1681/3000], Loss: 391.9468\n",
      "Validation Loss: 741.6455\n",
      "Epoch [1701/3000], Loss: 374.7430\n",
      "Validation Loss: 736.5937\n",
      "Epoch [1721/3000], Loss: 358.1057\n",
      "Validation Loss: 723.8510\n",
      "Epoch [1741/3000], Loss: 341.5065\n",
      "Validation Loss: 723.5675\n",
      "Epoch [1761/3000], Loss: 326.4581\n",
      "Validation Loss: 719.3755\n",
      "Epoch [1781/3000], Loss: 310.4862\n",
      "Validation Loss: 713.9188\n",
      "Epoch [1801/3000], Loss: 295.7470\n",
      "Validation Loss: 700.1106\n",
      "Epoch [1821/3000], Loss: 282.8832\n",
      "Validation Loss: 699.8426\n",
      "Epoch [1841/3000], Loss: 269.8778\n",
      "Validation Loss: 694.1459\n",
      "Epoch [1861/3000], Loss: 256.4064\n",
      "Validation Loss: 680.4176\n",
      "Epoch [1881/3000], Loss: 245.2067\n",
      "Validation Loss: 669.8798\n",
      "Epoch [1901/3000], Loss: 232.0143\n",
      "Validation Loss: 662.0504\n",
      "Epoch [1921/3000], Loss: 220.6729\n",
      "Validation Loss: 656.1027\n",
      "Epoch [1941/3000], Loss: 209.9972\n",
      "Validation Loss: 651.1197\n",
      "Epoch [1961/3000], Loss: 198.8587\n",
      "Validation Loss: 649.8221\n",
      "Epoch [1981/3000], Loss: 188.3183\n",
      "Validation Loss: 649.7745\n",
      "Epoch [2001/3000], Loss: 178.9669\n",
      "Validation Loss: 646.0174\n",
      "Epoch [2021/3000], Loss: 167.7838\n",
      "Validation Loss: 641.2595\n",
      "Epoch [2041/3000], Loss: 160.0202\n",
      "Validation Loss: 640.3568\n",
      "Epoch [2061/3000], Loss: 151.6609\n",
      "Validation Loss: 637.2754\n",
      "Epoch [2081/3000], Loss: 142.1558\n",
      "Validation Loss: 637.8472\n",
      "Epoch [2101/3000], Loss: 136.2302\n",
      "Validation Loss: 638.5115\n",
      "Epoch [2121/3000], Loss: 128.8206\n",
      "Validation Loss: 638.8357\n",
      "Epoch [2141/3000], Loss: 121.9057\n",
      "Validation Loss: 640.3297\n",
      "Epoch [2161/3000], Loss: 115.2255\n",
      "Validation Loss: 637.5828\n",
      "Epoch [2181/3000], Loss: 109.4978\n",
      "Validation Loss: 635.5104\n",
      "Epoch [2201/3000], Loss: 104.4103\n",
      "Validation Loss: 615.7237\n",
      "Epoch [2221/3000], Loss: 98.5212\n",
      "Validation Loss: 607.1654\n",
      "Epoch [2241/3000], Loss: 92.7825\n",
      "Validation Loss: 604.6615\n",
      "Epoch [2261/3000], Loss: 86.9716\n",
      "Validation Loss: 605.4679\n",
      "Epoch [2281/3000], Loss: 82.4993\n",
      "Validation Loss: 602.5483\n",
      "Epoch [2301/3000], Loss: 77.6032\n",
      "Validation Loss: 600.1542\n",
      "Epoch [2321/3000], Loss: 72.5893\n",
      "Validation Loss: 590.5986\n",
      "Epoch [2341/3000], Loss: 68.2617\n",
      "Validation Loss: 589.0236\n",
      "Epoch [2361/3000], Loss: 63.6738\n",
      "Validation Loss: 594.1809\n",
      "Epoch [2381/3000], Loss: 67.9849\n",
      "Validation Loss: 580.4594\n",
      "Epoch [2401/3000], Loss: 56.1216\n",
      "Validation Loss: 620.4286\n",
      "Epoch [2421/3000], Loss: 52.4064\n",
      "Validation Loss: 615.4664\n",
      "Epoch [2441/3000], Loss: 48.1506\n",
      "Validation Loss: 612.6420\n",
      "Epoch [2461/3000], Loss: 45.1639\n",
      "Validation Loss: 612.8086\n",
      "Epoch [2481/3000], Loss: 41.8615\n",
      "Validation Loss: 612.7622\n",
      "Epoch [2501/3000], Loss: 39.1150\n",
      "Validation Loss: 611.6219\n",
      "Epoch [2521/3000], Loss: 36.1725\n",
      "Validation Loss: 611.4420\n",
      "Epoch [2541/3000], Loss: 33.6368\n",
      "Validation Loss: 615.4796\n",
      "Epoch [2561/3000], Loss: 30.9316\n",
      "Validation Loss: 617.9033\n",
      "Epoch [2581/3000], Loss: 28.5370\n",
      "Validation Loss: 621.6016\n",
      "Epoch [2601/3000], Loss: 26.0995\n",
      "Validation Loss: 625.6902\n",
      "Epoch [2621/3000], Loss: 23.9968\n",
      "Validation Loss: 628.3162\n",
      "Epoch [2641/3000], Loss: 21.7675\n",
      "Validation Loss: 635.4008\n",
      "Epoch [2661/3000], Loss: 19.8405\n",
      "Validation Loss: 637.9735\n",
      "Epoch [2681/3000], Loss: 18.1341\n",
      "Validation Loss: 639.1278\n",
      "Epoch [2701/3000], Loss: 16.3085\n",
      "Validation Loss: 634.0061\n",
      "Epoch [2721/3000], Loss: 14.7778\n",
      "Validation Loss: 641.3295\n",
      "Epoch [2741/3000], Loss: 13.2569\n",
      "Validation Loss: 642.6434\n",
      "Epoch [2761/3000], Loss: 11.8354\n",
      "Validation Loss: 639.6927\n",
      "Epoch [2781/3000], Loss: 10.6339\n",
      "Validation Loss: 640.2478\n",
      "Epoch [2801/3000], Loss: 9.4995\n",
      "Validation Loss: 640.6878\n",
      "Epoch [2821/3000], Loss: 8.3399\n",
      "Validation Loss: 631.7161\n",
      "Epoch [2841/3000], Loss: 7.3460\n",
      "Validation Loss: 640.2247\n",
      "Epoch [2861/3000], Loss: 6.5266\n",
      "Validation Loss: 641.3609\n",
      "Epoch [2881/3000], Loss: 5.6536\n",
      "Validation Loss: 642.5153\n",
      "Epoch [2901/3000], Loss: 4.9413\n",
      "Validation Loss: 641.2235\n",
      "Epoch [2921/3000], Loss: 4.2639\n",
      "Validation Loss: 643.2539\n",
      "Epoch [2941/3000], Loss: 3.6085\n",
      "Validation Loss: 642.9996\n",
      "Epoch [2961/3000], Loss: 3.0741\n",
      "Validation Loss: 631.9558\n",
      "Epoch [2981/3000], Loss: 2.5653\n",
      "Validation Loss: 640.3369\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day064_plane0_Fall.mat\n",
      "(7292, 784)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7974.4373\n",
      "Validation Loss: 7152.2425\n",
      "Epoch [21/3000], Loss: 6766.7257\n",
      "Validation Loss: 6032.9289\n",
      "Epoch [41/3000], Loss: 6527.3489\n",
      "Validation Loss: 5813.7841\n",
      "Epoch [61/3000], Loss: 6371.0280\n",
      "Validation Loss: 5642.9680\n",
      "Epoch [81/3000], Loss: 6184.5115\n",
      "Validation Loss: 5489.8404\n",
      "Epoch [101/3000], Loss: 6037.5720\n",
      "Validation Loss: 5345.5514\n",
      "Epoch [121/3000], Loss: 5878.8912\n",
      "Validation Loss: 5207.7371\n",
      "Epoch [141/3000], Loss: 5723.5363\n",
      "Validation Loss: 5075.2411\n",
      "Epoch [161/3000], Loss: 5596.2356\n",
      "Validation Loss: 4947.4712\n",
      "Epoch [181/3000], Loss: 5468.4450\n",
      "Validation Loss: 4824.0757\n",
      "Epoch [201/3000], Loss: 5340.2685\n",
      "Validation Loss: 4704.8399\n",
      "Epoch [221/3000], Loss: 5202.3965\n",
      "Validation Loss: 4588.9713\n",
      "Epoch [241/3000], Loss: 5086.3448\n",
      "Validation Loss: 4476.7943\n",
      "Epoch [261/3000], Loss: 4975.8717\n",
      "Validation Loss: 4368.9651\n",
      "Epoch [281/3000], Loss: 4861.3779\n",
      "Validation Loss: 4265.2313\n",
      "Epoch [301/3000], Loss: 4740.0642\n",
      "Validation Loss: 4165.2760\n",
      "Epoch [321/3000], Loss: 4620.2318\n",
      "Validation Loss: 4069.3406\n",
      "Epoch [341/3000], Loss: 4533.0793\n",
      "Validation Loss: 3977.1773\n",
      "Epoch [361/3000], Loss: 4413.2916\n",
      "Validation Loss: 3888.8838\n",
      "Epoch [381/3000], Loss: 4336.2062\n",
      "Validation Loss: 3804.3412\n",
      "Epoch [401/3000], Loss: 4252.9926\n",
      "Validation Loss: 3723.5355\n",
      "Epoch [421/3000], Loss: 4170.8709\n",
      "Validation Loss: 3646.6116\n",
      "Epoch [441/3000], Loss: 4056.2567\n",
      "Validation Loss: 3573.4118\n",
      "Epoch [461/3000], Loss: 3982.9409\n",
      "Validation Loss: 3503.9278\n",
      "Epoch [481/3000], Loss: 3908.4439\n",
      "Validation Loss: 3438.1663\n",
      "Epoch [501/3000], Loss: 3838.1088\n",
      "Validation Loss: 3376.1130\n",
      "Epoch [521/3000], Loss: 3757.3137\n",
      "Validation Loss: 3317.8364\n",
      "Epoch [541/3000], Loss: 3696.9699\n",
      "Validation Loss: 3262.8808\n",
      "Epoch [561/3000], Loss: 3628.9754\n",
      "Validation Loss: 3211.0214\n",
      "Epoch [581/3000], Loss: 3576.4659\n",
      "Validation Loss: 3163.3247\n",
      "Epoch [601/3000], Loss: 3529.9333\n",
      "Validation Loss: 3119.4039\n",
      "Epoch [621/3000], Loss: 3474.9155\n",
      "Validation Loss: 3078.9809\n",
      "Epoch [641/3000], Loss: 3431.6843\n",
      "Validation Loss: 3042.0853\n",
      "Epoch [661/3000], Loss: 3385.8777\n",
      "Validation Loss: 3008.6447\n",
      "Epoch [681/3000], Loss: 2578.7530\n",
      "Validation Loss: 2243.0952\n",
      "Epoch [701/3000], Loss: 2404.9048\n",
      "Validation Loss: 2103.9656\n",
      "Epoch [721/3000], Loss: 2306.5430\n",
      "Validation Loss: 2027.2543\n",
      "Epoch [741/3000], Loss: 2205.1348\n",
      "Validation Loss: 1958.4244\n",
      "Epoch [761/3000], Loss: 2124.0512\n",
      "Validation Loss: 1884.8605\n",
      "Epoch [781/3000], Loss: 2053.0339\n",
      "Validation Loss: 1819.9424\n",
      "Epoch [801/3000], Loss: 1969.7024\n",
      "Validation Loss: 1753.6910\n",
      "Epoch [821/3000], Loss: 1884.2459\n",
      "Validation Loss: 1691.7047\n",
      "Epoch [841/3000], Loss: 1806.4059\n",
      "Validation Loss: 1633.6453\n",
      "Epoch [861/3000], Loss: 1756.4963\n",
      "Validation Loss: 1573.4870\n",
      "Epoch [881/3000], Loss: 1672.0676\n",
      "Validation Loss: 1538.4860\n",
      "Epoch [901/3000], Loss: 1614.1545\n",
      "Validation Loss: 1468.0340\n",
      "Epoch [921/3000], Loss: 1552.7594\n",
      "Validation Loss: 1413.2937\n",
      "Epoch [941/3000], Loss: 1485.4182\n",
      "Validation Loss: 1361.5961\n",
      "Epoch [961/3000], Loss: 1418.3501\n",
      "Validation Loss: 1314.0190\n",
      "Epoch [981/3000], Loss: 1367.7524\n",
      "Validation Loss: 1267.5074\n",
      "Epoch [1001/3000], Loss: 1310.0375\n",
      "Validation Loss: 1221.6397\n",
      "Epoch [1021/3000], Loss: 1246.3643\n",
      "Validation Loss: 1173.1674\n",
      "Epoch [1041/3000], Loss: 1199.8504\n",
      "Validation Loss: 1126.3513\n",
      "Epoch [1061/3000], Loss: 1150.0086\n",
      "Validation Loss: 1088.6033\n",
      "Epoch [1081/3000], Loss: 1096.6302\n",
      "Validation Loss: 1047.1038\n",
      "Epoch [1101/3000], Loss: 1049.8608\n",
      "Validation Loss: 1009.3401\n",
      "Epoch [1121/3000], Loss: 1011.0023\n",
      "Validation Loss: 979.7680\n",
      "Epoch [1141/3000], Loss: 962.1241\n",
      "Validation Loss: 946.6611\n",
      "Epoch [1161/3000], Loss: 917.9731\n",
      "Validation Loss: 915.9888\n",
      "Epoch [1181/3000], Loss: 869.8468\n",
      "Validation Loss: 879.7137\n",
      "Epoch [1201/3000], Loss: 830.5545\n",
      "Validation Loss: 856.7896\n",
      "Epoch [1221/3000], Loss: 793.7758\n",
      "Validation Loss: 824.0939\n",
      "Epoch [1241/3000], Loss: 759.0662\n",
      "Validation Loss: 797.1387\n",
      "Epoch [1261/3000], Loss: 722.7009\n",
      "Validation Loss: 772.6540\n",
      "Epoch [1281/3000], Loss: 691.2542\n",
      "Validation Loss: 752.3472\n",
      "Epoch [1301/3000], Loss: 651.9304\n",
      "Validation Loss: 727.5503\n",
      "Epoch [1321/3000], Loss: 619.8672\n",
      "Validation Loss: 709.2023\n",
      "Epoch [1341/3000], Loss: 591.6866\n",
      "Validation Loss: 692.3750\n",
      "Epoch [1361/3000], Loss: 557.3915\n",
      "Validation Loss: 675.3597\n",
      "Epoch [1381/3000], Loss: 532.9153\n",
      "Validation Loss: 657.4523\n",
      "Epoch [1401/3000], Loss: 505.7365\n",
      "Validation Loss: 641.8917\n",
      "Epoch [1421/3000], Loss: 477.6553\n",
      "Validation Loss: 624.3833\n",
      "Epoch [1441/3000], Loss: 456.2356\n",
      "Validation Loss: 609.2745\n",
      "Epoch [1461/3000], Loss: 431.6442\n",
      "Validation Loss: 580.3342\n",
      "Epoch [1481/3000], Loss: 407.5699\n",
      "Validation Loss: 571.6832\n",
      "Epoch [1501/3000], Loss: 386.3163\n",
      "Validation Loss: 559.2068\n",
      "Epoch [1521/3000], Loss: 363.8949\n",
      "Validation Loss: 553.8689\n",
      "Epoch [1541/3000], Loss: 344.3062\n",
      "Validation Loss: 544.5379\n",
      "Epoch [1561/3000], Loss: 325.7348\n",
      "Validation Loss: 529.1988\n",
      "Epoch [1581/3000], Loss: 308.9452\n",
      "Validation Loss: 508.6184\n",
      "Epoch [1601/3000], Loss: 292.2255\n",
      "Validation Loss: 491.0372\n",
      "Epoch [1621/3000], Loss: 274.9828\n",
      "Validation Loss: 472.8737\n",
      "Epoch [1641/3000], Loss: 259.0767\n",
      "Validation Loss: 469.8264\n",
      "Epoch [1661/3000], Loss: 244.2840\n",
      "Validation Loss: 462.6354\n",
      "Epoch [1681/3000], Loss: 228.8946\n",
      "Validation Loss: 453.4927\n",
      "Epoch [1701/3000], Loss: 216.0285\n",
      "Validation Loss: 449.9565\n",
      "Epoch [1721/3000], Loss: 236.1273\n",
      "Validation Loss: 518.8258\n",
      "Epoch [1741/3000], Loss: 190.6261\n",
      "Validation Loss: 443.7967\n",
      "Epoch [1761/3000], Loss: 178.8057\n",
      "Validation Loss: 438.0733\n",
      "Epoch [1781/3000], Loss: 168.3179\n",
      "Validation Loss: 433.2136\n",
      "Epoch [1801/3000], Loss: 154.9543\n",
      "Validation Loss: 427.3547\n",
      "Epoch [1821/3000], Loss: 146.7859\n",
      "Validation Loss: 418.9219\n",
      "Epoch [1841/3000], Loss: 136.5023\n",
      "Validation Loss: 410.3942\n",
      "Epoch [1861/3000], Loss: 126.1960\n",
      "Validation Loss: 403.2798\n",
      "Epoch [1881/3000], Loss: 117.1995\n",
      "Validation Loss: 397.4134\n",
      "Epoch [1901/3000], Loss: 108.7296\n",
      "Validation Loss: 391.1879\n",
      "Epoch [1921/3000], Loss: 99.7856\n",
      "Validation Loss: 383.8159\n",
      "Epoch [1941/3000], Loss: 91.6339\n",
      "Validation Loss: 378.0377\n",
      "Epoch [1961/3000], Loss: 84.2243\n",
      "Validation Loss: 363.9435\n",
      "Epoch [1981/3000], Loss: 76.6616\n",
      "Validation Loss: 357.1367\n",
      "Epoch [2001/3000], Loss: 70.5169\n",
      "Validation Loss: 341.5878\n",
      "Epoch [2021/3000], Loss: 63.7480\n",
      "Validation Loss: 335.4469\n",
      "Epoch [2041/3000], Loss: 58.0817\n",
      "Validation Loss: 335.7804\n",
      "Epoch [2061/3000], Loss: 52.7051\n",
      "Validation Loss: 328.7378\n",
      "Epoch [2081/3000], Loss: 47.2960\n",
      "Validation Loss: 323.5755\n",
      "Epoch [2101/3000], Loss: 42.8653\n",
      "Validation Loss: 321.7552\n",
      "Epoch [2121/3000], Loss: 38.5384\n",
      "Validation Loss: 313.1471\n",
      "Epoch [2141/3000], Loss: 34.5586\n",
      "Validation Loss: 312.4000\n",
      "Epoch [2161/3000], Loss: 31.3257\n",
      "Validation Loss: 278.8811\n",
      "Epoch [2181/3000], Loss: 24.8237\n",
      "Validation Loss: 350.0172\n",
      "Epoch [2201/3000], Loss: 21.8261\n",
      "Validation Loss: 341.8890\n",
      "Epoch [2221/3000], Loss: 18.7424\n",
      "Validation Loss: 337.0942\n",
      "Epoch [2241/3000], Loss: 16.3211\n",
      "Validation Loss: 332.4040\n",
      "Epoch [2261/3000], Loss: 14.3224\n",
      "Validation Loss: 328.7310\n",
      "Epoch [2281/3000], Loss: 12.1934\n",
      "Validation Loss: 326.5952\n",
      "Epoch [2301/3000], Loss: 10.4929\n",
      "Validation Loss: 325.2620\n",
      "Epoch [2321/3000], Loss: 9.0660\n",
      "Validation Loss: 325.5756\n",
      "Epoch [2341/3000], Loss: 7.7284\n",
      "Validation Loss: 323.6398\n",
      "Epoch [2361/3000], Loss: 6.4383\n",
      "Validation Loss: 319.7696\n",
      "Epoch [2381/3000], Loss: 5.3264\n",
      "Validation Loss: 318.9626\n",
      "Epoch [2401/3000], Loss: 4.3829\n",
      "Validation Loss: 313.9654\n",
      "Epoch [2421/3000], Loss: 3.5128\n",
      "Validation Loss: 315.1801\n",
      "Epoch [2441/3000], Loss: 2.8255\n",
      "Validation Loss: 306.9511\n",
      "Epoch [2461/3000], Loss: 2.2156\n",
      "Validation Loss: 303.2587\n",
      "Epoch [2481/3000], Loss: 1.7241\n",
      "Validation Loss: 300.8458\n",
      "Epoch [2501/3000], Loss: 1.3421\n",
      "Validation Loss: 302.9449\n",
      "Epoch [2521/3000], Loss: 1.0072\n",
      "Validation Loss: 299.1713\n",
      "Epoch [2541/3000], Loss: 0.7459\n",
      "Validation Loss: 302.0076\n",
      "Epoch [2561/3000], Loss: 0.5211\n",
      "Validation Loss: 302.5555\n",
      "Epoch [2581/3000], Loss: 0.3812\n",
      "Validation Loss: 300.6543\n",
      "Epoch [2601/3000], Loss: 0.2629\n",
      "Validation Loss: 304.9322\n",
      "Epoch [2621/3000], Loss: 0.1909\n",
      "Validation Loss: 306.3564\n",
      "Epoch [2641/3000], Loss: 0.1362\n",
      "Validation Loss: 309.0922\n",
      "Epoch [2661/3000], Loss: 0.0959\n",
      "Validation Loss: 314.7810\n",
      "Epoch [2681/3000], Loss: 0.0716\n",
      "Validation Loss: 312.8441\n",
      "Epoch [2701/3000], Loss: 0.0590\n",
      "Validation Loss: 315.9059\n",
      "Epoch [2721/3000], Loss: 0.0479\n",
      "Validation Loss: 314.1430\n",
      "Epoch [2741/3000], Loss: 0.0435\n",
      "Validation Loss: 313.7418\n",
      "Epoch [2761/3000], Loss: 0.0369\n",
      "Validation Loss: 316.0630\n",
      "Epoch [2781/3000], Loss: 0.0383\n",
      "Validation Loss: 315.4056\n",
      "Epoch [2801/3000], Loss: 0.0311\n",
      "Validation Loss: 315.9286\n",
      "Epoch [2821/3000], Loss: 0.0304\n",
      "Validation Loss: 313.5606\n",
      "Epoch [2841/3000], Loss: 0.0304\n",
      "Validation Loss: 314.6309\n",
      "Epoch [2861/3000], Loss: 0.0283\n",
      "Validation Loss: 317.2891\n",
      "Epoch [2881/3000], Loss: 0.0269\n",
      "Validation Loss: 319.9531\n",
      "Epoch [2901/3000], Loss: 0.0275\n",
      "Validation Loss: 328.1178\n",
      "Epoch [2921/3000], Loss: 0.0253\n",
      "Validation Loss: 328.0852\n",
      "Epoch [2941/3000], Loss: 0.0222\n",
      "Validation Loss: 330.8198\n",
      "Epoch [2961/3000], Loss: 0.0230\n",
      "Validation Loss: 331.9806\n",
      "Epoch [2981/3000], Loss: 0.0203\n",
      "Validation Loss: 333.8704\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day065_plane0_Fall.mat\n",
      "(4453, 713)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8305.5921\n",
      "Validation Loss: 9152.4114\n",
      "Epoch [21/3000], Loss: 7225.1108\n",
      "Validation Loss: 8032.1904\n",
      "Epoch [41/3000], Loss: 6940.1126\n",
      "Validation Loss: 7733.6766\n",
      "Epoch [61/3000], Loss: 6756.5622\n",
      "Validation Loss: 7575.9631\n",
      "Epoch [81/3000], Loss: 6661.1610\n",
      "Validation Loss: 7446.0556\n",
      "Epoch [101/3000], Loss: 6554.2804\n",
      "Validation Loss: 7326.6350\n",
      "Epoch [121/3000], Loss: 6446.2485\n",
      "Validation Loss: 7213.0687\n",
      "Epoch [141/3000], Loss: 6352.2291\n",
      "Validation Loss: 7102.7261\n",
      "Epoch [161/3000], Loss: 6220.1567\n",
      "Validation Loss: 6995.3993\n",
      "Epoch [181/3000], Loss: 6156.0518\n",
      "Validation Loss: 6891.3268\n",
      "Epoch [201/3000], Loss: 6021.0380\n",
      "Validation Loss: 6789.6492\n",
      "Epoch [221/3000], Loss: 5949.5074\n",
      "Validation Loss: 6690.0573\n",
      "Epoch [241/3000], Loss: 5860.2615\n",
      "Validation Loss: 6592.4092\n",
      "Epoch [261/3000], Loss: 5776.7538\n",
      "Validation Loss: 6496.6060\n",
      "Epoch [281/3000], Loss: 5700.4475\n",
      "Validation Loss: 6402.4082\n",
      "Epoch [301/3000], Loss: 5619.0495\n",
      "Validation Loss: 6309.8255\n",
      "Epoch [321/3000], Loss: 5518.2124\n",
      "Validation Loss: 6218.8065\n",
      "Epoch [341/3000], Loss: 5414.2306\n",
      "Validation Loss: 6129.3994\n",
      "Epoch [361/3000], Loss: 5338.2098\n",
      "Validation Loss: 6041.4689\n",
      "Epoch [381/3000], Loss: 5271.9294\n",
      "Validation Loss: 5955.1619\n",
      "Epoch [401/3000], Loss: 5192.7389\n",
      "Validation Loss: 5870.2280\n",
      "Epoch [421/3000], Loss: 5112.8637\n",
      "Validation Loss: 5786.7934\n",
      "Epoch [441/3000], Loss: 5040.2115\n",
      "Validation Loss: 5704.8371\n",
      "Epoch [461/3000], Loss: 4955.5771\n",
      "Validation Loss: 5624.3312\n",
      "Epoch [481/3000], Loss: 4889.7922\n",
      "Validation Loss: 5545.1679\n",
      "Epoch [501/3000], Loss: 4839.3794\n",
      "Validation Loss: 5467.5393\n",
      "Epoch [521/3000], Loss: 4749.5881\n",
      "Validation Loss: 5391.3342\n",
      "Epoch [541/3000], Loss: 4681.2729\n",
      "Validation Loss: 5316.5978\n",
      "Epoch [561/3000], Loss: 4613.7934\n",
      "Validation Loss: 5243.2913\n",
      "Epoch [581/3000], Loss: 4570.6035\n",
      "Validation Loss: 5171.4253\n",
      "Epoch [601/3000], Loss: 4482.4924\n",
      "Validation Loss: 5100.9621\n",
      "Epoch [621/3000], Loss: 4428.1417\n",
      "Validation Loss: 5031.9602\n",
      "Epoch [641/3000], Loss: 4355.7161\n",
      "Validation Loss: 4964.3721\n",
      "Epoch [661/3000], Loss: 4302.8446\n",
      "Validation Loss: 4898.2006\n",
      "Epoch [681/3000], Loss: 4251.2553\n",
      "Validation Loss: 4833.4105\n",
      "Epoch [701/3000], Loss: 4200.0818\n",
      "Validation Loss: 4770.0476\n",
      "Epoch [721/3000], Loss: 4144.3856\n",
      "Validation Loss: 4708.1784\n",
      "Epoch [741/3000], Loss: 4072.0279\n",
      "Validation Loss: 4647.7454\n",
      "Epoch [761/3000], Loss: 4038.9977\n",
      "Validation Loss: 4588.7016\n",
      "Epoch [781/3000], Loss: 3962.7848\n",
      "Validation Loss: 4531.0974\n",
      "Epoch [801/3000], Loss: 3916.9176\n",
      "Validation Loss: 4474.8088\n",
      "Epoch [821/3000], Loss: 3870.3162\n",
      "Validation Loss: 4419.9064\n",
      "Epoch [841/3000], Loss: 3815.8764\n",
      "Validation Loss: 4366.4929\n",
      "Epoch [861/3000], Loss: 3778.7984\n",
      "Validation Loss: 4314.3957\n",
      "Epoch [881/3000], Loss: 3729.2037\n",
      "Validation Loss: 4263.6948\n",
      "Epoch [901/3000], Loss: 3681.1361\n",
      "Validation Loss: 4214.3964\n",
      "Epoch [921/3000], Loss: 3643.3250\n",
      "Validation Loss: 4166.5852\n",
      "Epoch [941/3000], Loss: 3606.7559\n",
      "Validation Loss: 4119.9578\n",
      "Epoch [961/3000], Loss: 3567.2043\n",
      "Validation Loss: 4074.8642\n",
      "Epoch [981/3000], Loss: 3532.4962\n",
      "Validation Loss: 4031.1584\n",
      "Epoch [1001/3000], Loss: 3499.0795\n",
      "Validation Loss: 3988.8276\n",
      "Epoch [1021/3000], Loss: 3459.0184\n",
      "Validation Loss: 3947.8191\n",
      "Epoch [1041/3000], Loss: 3422.3936\n",
      "Validation Loss: 3908.2074\n",
      "Epoch [1061/3000], Loss: 3383.8938\n",
      "Validation Loss: 3870.0115\n",
      "Epoch [1081/3000], Loss: 3358.8239\n",
      "Validation Loss: 3833.1060\n",
      "Epoch [1101/3000], Loss: 3316.2097\n",
      "Validation Loss: 3797.4759\n",
      "Epoch [1121/3000], Loss: 3287.3080\n",
      "Validation Loss: 3763.2757\n",
      "Epoch [1141/3000], Loss: 3264.3671\n",
      "Validation Loss: 3730.4490\n",
      "Epoch [1161/3000], Loss: 3236.1046\n",
      "Validation Loss: 3698.8893\n",
      "Epoch [1181/3000], Loss: 3212.6169\n",
      "Validation Loss: 3668.6894\n",
      "Epoch [1201/3000], Loss: 3187.6720\n",
      "Validation Loss: 3639.7462\n",
      "Epoch [1221/3000], Loss: 3156.4499\n",
      "Validation Loss: 3612.1053\n",
      "Epoch [1241/3000], Loss: 3148.5982\n",
      "Validation Loss: 3585.8407\n",
      "Epoch [1261/3000], Loss: 3130.6400\n",
      "Validation Loss: 3560.8403\n",
      "Epoch [1281/3000], Loss: 3114.6327\n",
      "Validation Loss: 3537.1829\n",
      "Epoch [1301/3000], Loss: 3088.2715\n",
      "Validation Loss: 3514.7949\n",
      "Epoch [1321/3000], Loss: 3067.4005\n",
      "Validation Loss: 3493.7764\n",
      "Epoch [1341/3000], Loss: 3072.8915\n",
      "Validation Loss: 3473.7936\n",
      "Epoch [1361/3000], Loss: 3048.3144\n",
      "Validation Loss: 3455.1673\n",
      "Epoch [1381/3000], Loss: 1922.6536\n",
      "Validation Loss: 2401.8158\n",
      "Epoch [1401/3000], Loss: 1832.2924\n",
      "Validation Loss: 2367.9138\n",
      "Epoch [1421/3000], Loss: 1756.0993\n",
      "Validation Loss: 2310.3402\n",
      "Epoch [1441/3000], Loss: 1689.7594\n",
      "Validation Loss: 2258.4989\n",
      "Epoch [1461/3000], Loss: 1649.4671\n",
      "Validation Loss: 2205.3621\n",
      "Epoch [1481/3000], Loss: 1587.6917\n",
      "Validation Loss: 2152.1437\n",
      "Epoch [1501/3000], Loss: 1558.7835\n",
      "Validation Loss: 2104.0264\n",
      "Epoch [1521/3000], Loss: 1510.5850\n",
      "Validation Loss: 2057.5051\n",
      "Epoch [1541/3000], Loss: 1469.4311\n",
      "Validation Loss: 2010.6739\n",
      "Epoch [1561/3000], Loss: 1424.4237\n",
      "Validation Loss: 1967.0265\n",
      "Epoch [1581/3000], Loss: 1395.9636\n",
      "Validation Loss: 1922.6020\n",
      "Epoch [1601/3000], Loss: 1346.0190\n",
      "Validation Loss: 1880.5381\n",
      "Epoch [1621/3000], Loss: 1307.5711\n",
      "Validation Loss: 1841.1332\n",
      "Epoch [1641/3000], Loss: 1269.8946\n",
      "Validation Loss: 1798.0744\n",
      "Epoch [1661/3000], Loss: 1237.0271\n",
      "Validation Loss: 1759.0887\n",
      "Epoch [1681/3000], Loss: 1202.4743\n",
      "Validation Loss: 1720.3671\n",
      "Epoch [1701/3000], Loss: 1172.1893\n",
      "Validation Loss: 1681.0104\n",
      "Epoch [1721/3000], Loss: 1137.5930\n",
      "Validation Loss: 1644.0290\n",
      "Epoch [1741/3000], Loss: 1105.6525\n",
      "Validation Loss: 1602.3241\n",
      "Epoch [1761/3000], Loss: 1068.1604\n",
      "Validation Loss: 1568.6739\n",
      "Epoch [1781/3000], Loss: 1044.4518\n",
      "Validation Loss: 1557.3062\n",
      "Epoch [1801/3000], Loss: 1005.5478\n",
      "Validation Loss: 1506.3091\n",
      "Epoch [1821/3000], Loss: 983.3736\n",
      "Validation Loss: 1472.1201\n",
      "Epoch [1841/3000], Loss: 950.0076\n",
      "Validation Loss: 1439.6722\n",
      "Epoch [1861/3000], Loss: 919.7792\n",
      "Validation Loss: 1408.1658\n",
      "Epoch [1881/3000], Loss: 887.5626\n",
      "Validation Loss: 1376.6688\n",
      "Epoch [1901/3000], Loss: 864.7767\n",
      "Validation Loss: 1346.9583\n",
      "Epoch [1921/3000], Loss: 832.4418\n",
      "Validation Loss: 1318.1396\n",
      "Epoch [1941/3000], Loss: 805.6091\n",
      "Validation Loss: 1290.8699\n",
      "Epoch [1961/3000], Loss: 780.4943\n",
      "Validation Loss: 1264.8412\n",
      "Epoch [1981/3000], Loss: 762.0937\n",
      "Validation Loss: 1237.4563\n",
      "Epoch [2001/3000], Loss: 731.2720\n",
      "Validation Loss: 1211.3737\n",
      "Epoch [2021/3000], Loss: 713.3867\n",
      "Validation Loss: 1185.8214\n",
      "Epoch [2041/3000], Loss: 684.9049\n",
      "Validation Loss: 1158.8442\n",
      "Epoch [2061/3000], Loss: 663.1410\n",
      "Validation Loss: 1132.7555\n",
      "Epoch [2081/3000], Loss: 638.5526\n",
      "Validation Loss: 1107.8588\n",
      "Epoch [2101/3000], Loss: 622.8852\n",
      "Validation Loss: 1083.3065\n",
      "Epoch [2121/3000], Loss: 593.9668\n",
      "Validation Loss: 1061.4107\n",
      "Epoch [2141/3000], Loss: 576.0716\n",
      "Validation Loss: 1042.1691\n",
      "Epoch [2161/3000], Loss: 555.8554\n",
      "Validation Loss: 1022.9749\n",
      "Epoch [2181/3000], Loss: 538.0808\n",
      "Validation Loss: 1001.6500\n",
      "Epoch [2201/3000], Loss: 518.6896\n",
      "Validation Loss: 980.6888\n",
      "Epoch [2221/3000], Loss: 499.3366\n",
      "Validation Loss: 964.8940\n",
      "Epoch [2241/3000], Loss: 480.2271\n",
      "Validation Loss: 944.5940\n",
      "Epoch [2261/3000], Loss: 465.9298\n",
      "Validation Loss: 925.1084\n",
      "Epoch [2281/3000], Loss: 449.3564\n",
      "Validation Loss: 910.2359\n",
      "Epoch [2301/3000], Loss: 431.5328\n",
      "Validation Loss: 889.8567\n",
      "Epoch [2321/3000], Loss: 415.2245\n",
      "Validation Loss: 871.4870\n",
      "Epoch [2341/3000], Loss: 400.7434\n",
      "Validation Loss: 858.6384\n",
      "Epoch [2361/3000], Loss: 387.2498\n",
      "Validation Loss: 846.2224\n",
      "Epoch [2381/3000], Loss: 370.6831\n",
      "Validation Loss: 841.4689\n",
      "Epoch [2401/3000], Loss: 357.0785\n",
      "Validation Loss: 823.6297\n",
      "Epoch [2421/3000], Loss: 344.4569\n",
      "Validation Loss: 806.7267\n",
      "Epoch [2441/3000], Loss: 330.4229\n",
      "Validation Loss: 789.9673\n",
      "Epoch [2461/3000], Loss: 317.8413\n",
      "Validation Loss: 776.0114\n",
      "Epoch [2481/3000], Loss: 302.1310\n",
      "Validation Loss: 764.0560\n",
      "Epoch [2501/3000], Loss: 293.0480\n",
      "Validation Loss: 753.3811\n",
      "Epoch [2521/3000], Loss: 279.2342\n",
      "Validation Loss: 741.1779\n",
      "Epoch [2541/3000], Loss: 270.4774\n",
      "Validation Loss: 729.3007\n",
      "Epoch [2561/3000], Loss: 259.1880\n",
      "Validation Loss: 717.7796\n",
      "Epoch [2581/3000], Loss: 250.7120\n",
      "Validation Loss: 706.8650\n",
      "Epoch [2601/3000], Loss: 239.7827\n",
      "Validation Loss: 697.4123\n",
      "Epoch [2621/3000], Loss: 226.7275\n",
      "Validation Loss: 688.6175\n",
      "Epoch [2641/3000], Loss: 219.6238\n",
      "Validation Loss: 679.6984\n",
      "Epoch [2661/3000], Loss: 208.3256\n",
      "Validation Loss: 671.4356\n",
      "Epoch [2681/3000], Loss: 201.3934\n",
      "Validation Loss: 666.0068\n",
      "Epoch [2701/3000], Loss: 191.0557\n",
      "Validation Loss: 660.8497\n",
      "Epoch [2721/3000], Loss: 184.6202\n",
      "Validation Loss: 658.9559\n",
      "Epoch [2741/3000], Loss: 176.1393\n",
      "Validation Loss: 652.2060\n",
      "Epoch [2761/3000], Loss: 169.6363\n",
      "Validation Loss: 642.8548\n",
      "Epoch [2781/3000], Loss: 164.3024\n",
      "Validation Loss: 643.3019\n",
      "Epoch [2801/3000], Loss: 154.3259\n",
      "Validation Loss: 634.6405\n",
      "Epoch [2821/3000], Loss: 149.9654\n",
      "Validation Loss: 631.0256\n",
      "Epoch [2841/3000], Loss: 144.0025\n",
      "Validation Loss: 624.0594\n",
      "Epoch [2861/3000], Loss: 137.3795\n",
      "Validation Loss: 622.5161\n",
      "Epoch [2881/3000], Loss: 131.1162\n",
      "Validation Loss: 621.0689\n",
      "Epoch [2901/3000], Loss: 124.4473\n",
      "Validation Loss: 615.9379\n",
      "Epoch [2921/3000], Loss: 118.5885\n",
      "Validation Loss: 616.8544\n",
      "Epoch [2941/3000], Loss: 114.8911\n",
      "Validation Loss: 613.9438\n",
      "Epoch [2961/3000], Loss: 109.6845\n",
      "Validation Loss: 615.6213\n",
      "Epoch [2981/3000], Loss: 103.2233\n",
      "Validation Loss: 609.7849\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day066_plane0_Fall.mat\n",
      "(15013, 773)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8806.2069\n",
      "Validation Loss: 5875.4571\n",
      "Epoch [21/3000], Loss: 7248.3091\n",
      "Validation Loss: 4742.5085\n",
      "Epoch [41/3000], Loss: 6895.8205\n",
      "Validation Loss: 4475.9592\n",
      "Epoch [61/3000], Loss: 6551.3958\n",
      "Validation Loss: 4241.1384\n",
      "Epoch [81/3000], Loss: 6252.6823\n",
      "Validation Loss: 4029.7373\n",
      "Epoch [101/3000], Loss: 5947.4314\n",
      "Validation Loss: 3836.7787\n",
      "Epoch [121/3000], Loss: 5667.8504\n",
      "Validation Loss: 3660.8412\n",
      "Epoch [141/3000], Loss: 5429.0568\n",
      "Validation Loss: 3500.2449\n",
      "Epoch [161/3000], Loss: 5185.7451\n",
      "Validation Loss: 3356.7123\n",
      "Epoch [181/3000], Loss: 4958.8836\n",
      "Validation Loss: 3229.8249\n",
      "Epoch [201/3000], Loss: 4745.9402\n",
      "Validation Loss: 3119.0769\n",
      "Epoch [221/3000], Loss: 4555.2262\n",
      "Validation Loss: 3024.2754\n",
      "Epoch [241/3000], Loss: 4378.7436\n",
      "Validation Loss: 2945.2823\n",
      "Epoch [261/3000], Loss: 4228.4247\n",
      "Validation Loss: 2881.8309\n",
      "Epoch [281/3000], Loss: 4090.3411\n",
      "Validation Loss: 2833.6625\n",
      "Epoch [301/3000], Loss: 3957.9328\n",
      "Validation Loss: 2800.4024\n",
      "Epoch [321/3000], Loss: 3854.7094\n",
      "Validation Loss: 2781.6030\n",
      "Epoch [341/3000], Loss: 3758.0763\n",
      "Validation Loss: 2776.7170\n",
      "Epoch [361/3000], Loss: 3682.8838\n",
      "Validation Loss: 2784.9455\n",
      "Epoch [381/3000], Loss: 3616.4106\n",
      "Validation Loss: 2805.1807\n",
      "Epoch [401/3000], Loss: 3569.3280\n",
      "Validation Loss: 2836.0287\n",
      "Epoch [421/3000], Loss: 2247.7574\n",
      "Validation Loss: 3163.1267\n",
      "Epoch [441/3000], Loss: 1998.9850\n",
      "Validation Loss: 3135.7338\n",
      "Epoch [461/3000], Loss: 1829.2976\n",
      "Validation Loss: 2932.3575\n",
      "Epoch [481/3000], Loss: 1702.0160\n",
      "Validation Loss: 2982.6216\n",
      "Epoch [501/3000], Loss: 1547.6673\n",
      "Validation Loss: 3017.9651\n",
      "Epoch [521/3000], Loss: 1415.4492\n",
      "Validation Loss: 3067.4787\n",
      "Epoch [541/3000], Loss: 1304.0525\n",
      "Validation Loss: 3194.7354\n",
      "Epoch [561/3000], Loss: 1187.7209\n",
      "Validation Loss: 3091.1589\n",
      "Epoch [581/3000], Loss: 1080.5954\n",
      "Validation Loss: 3151.9903\n",
      "Epoch [601/3000], Loss: 986.9719\n",
      "Validation Loss: 3305.7509\n",
      "Epoch [621/3000], Loss: 895.1505\n",
      "Validation Loss: 3293.0152\n",
      "Epoch [641/3000], Loss: 814.5050\n",
      "Validation Loss: 3394.1194\n",
      "Epoch [661/3000], Loss: 737.7596\n",
      "Validation Loss: 3498.9373\n",
      "Epoch [681/3000], Loss: 664.4275\n",
      "Validation Loss: 3587.9661\n",
      "Epoch [701/3000], Loss: 599.1231\n",
      "Validation Loss: 3668.3407\n",
      "Epoch [721/3000], Loss: 535.3005\n",
      "Validation Loss: 3783.1112\n",
      "Epoch [741/3000], Loss: 481.2500\n",
      "Validation Loss: 3862.4644\n",
      "Epoch [761/3000], Loss: 430.3433\n",
      "Validation Loss: 3983.1611\n",
      "Epoch [781/3000], Loss: 382.2357\n",
      "Validation Loss: 4087.7566\n",
      "Epoch [801/3000], Loss: 338.8194\n",
      "Validation Loss: 4213.7455\n",
      "Epoch [821/3000], Loss: 299.6275\n",
      "Validation Loss: 4229.1703\n",
      "Epoch [841/3000], Loss: 263.7751\n",
      "Validation Loss: 4341.7796\n",
      "Epoch [861/3000], Loss: 230.6285\n",
      "Validation Loss: 4432.9586\n",
      "Epoch [881/3000], Loss: 200.0693\n",
      "Validation Loss: 4577.8594\n",
      "Epoch [901/3000], Loss: 171.2138\n",
      "Validation Loss: 4710.4535\n",
      "Epoch [921/3000], Loss: 145.5983\n",
      "Validation Loss: 4792.0942\n",
      "Epoch [941/3000], Loss: 152.2704\n",
      "Validation Loss: 4648.6551\n",
      "Epoch [961/3000], Loss: 100.7252\n",
      "Validation Loss: 4945.3390\n",
      "Epoch [981/3000], Loss: 81.9741\n",
      "Validation Loss: 5056.6848\n",
      "Epoch [1001/3000], Loss: 65.4331\n",
      "Validation Loss: 5173.4967\n",
      "Epoch [1021/3000], Loss: 51.0489\n",
      "Validation Loss: 5357.7226\n",
      "Epoch [1041/3000], Loss: 39.2905\n",
      "Validation Loss: 5440.1402\n",
      "Epoch [1061/3000], Loss: 29.7427\n",
      "Validation Loss: 5439.8156\n",
      "Epoch [1081/3000], Loss: 22.0312\n",
      "Validation Loss: 5466.1841\n",
      "Epoch [1101/3000], Loss: 16.4057\n",
      "Validation Loss: 5662.4734\n",
      "Epoch [1121/3000], Loss: 12.4651\n",
      "Validation Loss: 5505.1623\n",
      "Epoch [1141/3000], Loss: 9.5048\n",
      "Validation Loss: 5679.1088\n",
      "Epoch [1161/3000], Loss: 7.5452\n",
      "Validation Loss: 5710.0842\n",
      "Epoch [1181/3000], Loss: 5.7827\n",
      "Validation Loss: 5823.1294\n",
      "Epoch [1201/3000], Loss: 4.0741\n",
      "Validation Loss: 5894.5807\n",
      "Epoch [1221/3000], Loss: 2.6893\n",
      "Validation Loss: 5973.4729\n",
      "Epoch [1241/3000], Loss: 1.8559\n",
      "Validation Loss: 5811.6013\n",
      "Epoch [1261/3000], Loss: 1.1479\n",
      "Validation Loss: 5783.4814\n",
      "Epoch [1281/3000], Loss: 0.7160\n",
      "Validation Loss: 5916.9220\n",
      "Epoch [1301/3000], Loss: 0.5737\n",
      "Validation Loss: 5747.9796\n",
      "Epoch [1321/3000], Loss: 0.4523\n",
      "Validation Loss: 5796.7616\n",
      "Epoch [1341/3000], Loss: 0.3905\n",
      "Validation Loss: 5798.4680\n",
      "Epoch [1361/3000], Loss: 0.3395\n",
      "Validation Loss: 5826.9220\n",
      "Epoch [1381/3000], Loss: 0.3001\n",
      "Validation Loss: 5871.4953\n",
      "Epoch [1401/3000], Loss: 0.2620\n",
      "Validation Loss: 5849.7728\n",
      "Epoch [1421/3000], Loss: 0.2266\n",
      "Validation Loss: 5826.3844\n",
      "Epoch [1441/3000], Loss: 0.1828\n",
      "Validation Loss: 5834.0246\n",
      "Epoch [1461/3000], Loss: 0.1673\n",
      "Validation Loss: 5844.3484\n",
      "Epoch [1481/3000], Loss: 0.1408\n",
      "Validation Loss: 5872.0812\n",
      "Epoch [1501/3000], Loss: 0.1332\n",
      "Validation Loss: 5856.9958\n",
      "Epoch [1521/3000], Loss: 0.1217\n",
      "Validation Loss: 5875.6111\n",
      "Epoch [1541/3000], Loss: 0.1038\n",
      "Validation Loss: 5857.9681\n",
      "Epoch [1561/3000], Loss: 0.1025\n",
      "Validation Loss: 5863.4560\n",
      "Epoch [1581/3000], Loss: 0.0888\n",
      "Validation Loss: 5876.2485\n",
      "Epoch [1601/3000], Loss: 0.0874\n",
      "Validation Loss: 5928.2230\n",
      "Epoch [1621/3000], Loss: 0.0794\n",
      "Validation Loss: 5874.5327\n",
      "Epoch [1641/3000], Loss: 0.0783\n",
      "Validation Loss: 5900.1075\n",
      "Epoch [1661/3000], Loss: 0.0695\n",
      "Validation Loss: 5892.0299\n",
      "Epoch [1681/3000], Loss: 0.0632\n",
      "Validation Loss: 5892.2191\n",
      "Epoch [1701/3000], Loss: 0.0651\n",
      "Validation Loss: 5879.8252\n",
      "Epoch [1721/3000], Loss: 0.0558\n",
      "Validation Loss: 5915.9592\n",
      "Epoch [1741/3000], Loss: 0.0548\n",
      "Validation Loss: 5907.0536\n",
      "Epoch [1761/3000], Loss: 0.0545\n",
      "Validation Loss: 5903.1021\n",
      "Epoch [1781/3000], Loss: 0.0538\n",
      "Validation Loss: 5937.4852\n",
      "Epoch [1801/3000], Loss: 0.0507\n",
      "Validation Loss: 5865.6719\n",
      "Epoch [1821/3000], Loss: 0.0492\n",
      "Validation Loss: 5909.5464\n",
      "Epoch [1841/3000], Loss: 0.0452\n",
      "Validation Loss: 5884.1440\n",
      "Epoch [1861/3000], Loss: 0.0393\n",
      "Validation Loss: 5895.0824\n",
      "Epoch [1881/3000], Loss: 0.0436\n",
      "Validation Loss: 5916.1976\n",
      "Epoch [1901/3000], Loss: 0.0386\n",
      "Validation Loss: 5886.9039\n",
      "Epoch [1921/3000], Loss: 0.0370\n",
      "Validation Loss: 5916.8225\n",
      "Epoch [1941/3000], Loss: 0.0459\n",
      "Validation Loss: 5886.6440\n",
      "Epoch [1961/3000], Loss: 0.0412\n",
      "Validation Loss: 5950.2531\n",
      "Epoch [1981/3000], Loss: 0.0341\n",
      "Validation Loss: 5907.4016\n",
      "Epoch [2001/3000], Loss: 0.0347\n",
      "Validation Loss: 5906.2944\n",
      "Epoch [2021/3000], Loss: 0.1232\n",
      "Validation Loss: 5621.6319\n",
      "Epoch [2041/3000], Loss: 0.0509\n",
      "Validation Loss: 5695.6595\n",
      "Epoch [2061/3000], Loss: 0.0345\n",
      "Validation Loss: 5733.1108\n",
      "Epoch [2081/3000], Loss: 0.0286\n",
      "Validation Loss: 5765.8568\n",
      "Epoch [2101/3000], Loss: 0.0268\n",
      "Validation Loss: 5795.9682\n",
      "Epoch [2121/3000], Loss: 0.0259\n",
      "Validation Loss: 5808.2307\n",
      "Epoch [2141/3000], Loss: 0.0273\n",
      "Validation Loss: 5825.2311\n",
      "Epoch [2161/3000], Loss: 0.0281\n",
      "Validation Loss: 5848.9749\n",
      "Epoch [2181/3000], Loss: 0.0275\n",
      "Validation Loss: 5847.5176\n",
      "Epoch [2201/3000], Loss: 0.0290\n",
      "Validation Loss: 5864.5961\n",
      "Epoch [2221/3000], Loss: 0.0314\n",
      "Validation Loss: 5879.7551\n",
      "Epoch [2241/3000], Loss: 0.0273\n",
      "Validation Loss: 5903.6675\n",
      "Epoch [2261/3000], Loss: 0.0315\n",
      "Validation Loss: 5831.8667\n",
      "Epoch [2281/3000], Loss: 0.0275\n",
      "Validation Loss: 5862.1939\n",
      "Epoch [2301/3000], Loss: 0.0258\n",
      "Validation Loss: 5859.1281\n",
      "Epoch [2321/3000], Loss: 0.0242\n",
      "Validation Loss: 5883.4265\n",
      "Epoch [2341/3000], Loss: 0.0244\n",
      "Validation Loss: 5865.7919\n",
      "Epoch [2361/3000], Loss: 0.0266\n",
      "Validation Loss: 5890.9523\n",
      "Epoch [2381/3000], Loss: 0.0275\n",
      "Validation Loss: 5870.2732\n",
      "Epoch [2401/3000], Loss: 0.0214\n",
      "Validation Loss: 5871.7392\n",
      "Epoch [2421/3000], Loss: 0.0218\n",
      "Validation Loss: 5860.2694\n",
      "Epoch [2441/3000], Loss: 0.0251\n",
      "Validation Loss: 5921.7857\n",
      "Epoch [2461/3000], Loss: 0.0217\n",
      "Validation Loss: 5902.2739\n",
      "Epoch [2481/3000], Loss: 0.0267\n",
      "Validation Loss: 5852.7066\n",
      "Epoch [2501/3000], Loss: 0.0166\n",
      "Validation Loss: 5878.5566\n",
      "Epoch [2521/3000], Loss: 0.0195\n",
      "Validation Loss: 5869.3998\n",
      "Epoch [2541/3000], Loss: 0.0167\n",
      "Validation Loss: 5878.7555\n",
      "Epoch [2561/3000], Loss: 0.0173\n",
      "Validation Loss: 5891.9882\n",
      "Epoch [2581/3000], Loss: 0.0186\n",
      "Validation Loss: 5831.3081\n",
      "Epoch [2601/3000], Loss: 0.0211\n",
      "Validation Loss: 5887.7326\n",
      "Epoch [2621/3000], Loss: 0.0175\n",
      "Validation Loss: 5902.1896\n",
      "Epoch [2641/3000], Loss: 0.0142\n",
      "Validation Loss: 5875.9382\n",
      "Epoch [2661/3000], Loss: 0.0254\n",
      "Validation Loss: 5886.4520\n",
      "Epoch [2681/3000], Loss: 0.0156\n",
      "Validation Loss: 5901.2532\n",
      "Epoch [2701/3000], Loss: 0.0910\n",
      "Validation Loss: 5725.6364\n",
      "Epoch [2721/3000], Loss: 0.0354\n",
      "Validation Loss: 5768.0531\n",
      "Epoch [2741/3000], Loss: 0.0208\n",
      "Validation Loss: 5795.7796\n",
      "Epoch [2761/3000], Loss: 0.0149\n",
      "Validation Loss: 5807.8477\n",
      "Epoch [2781/3000], Loss: 0.0124\n",
      "Validation Loss: 5812.9941\n",
      "Epoch [2801/3000], Loss: 0.0121\n",
      "Validation Loss: 5830.1875\n",
      "Epoch [2821/3000], Loss: 0.0116\n",
      "Validation Loss: 5836.1703\n",
      "Epoch [2841/3000], Loss: 0.0129\n",
      "Validation Loss: 5851.0515\n",
      "Epoch [2861/3000], Loss: 0.0116\n",
      "Validation Loss: 5827.8844\n",
      "Epoch [2881/3000], Loss: 0.0141\n",
      "Validation Loss: 5844.0114\n",
      "Epoch [2901/3000], Loss: 0.0150\n",
      "Validation Loss: 5819.2391\n",
      "Epoch [2921/3000], Loss: 0.0136\n",
      "Validation Loss: 5848.7491\n",
      "Epoch [2941/3000], Loss: 0.0122\n",
      "Validation Loss: 5854.1177\n",
      "Epoch [2961/3000], Loss: 0.0127\n",
      "Validation Loss: 5872.5046\n",
      "Epoch [2981/3000], Loss: 0.6539\n",
      "Validation Loss: 5505.8285\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day067_plane0_Fall.mat\n",
      "(10834, 753)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9662.4034\n",
      "Validation Loss: 7712.0882\n",
      "Epoch [21/3000], Loss: 8111.7219\n",
      "Validation Loss: 6344.9430\n",
      "Epoch [41/3000], Loss: 7796.7091\n",
      "Validation Loss: 6057.4071\n",
      "Epoch [61/3000], Loss: 7512.3659\n",
      "Validation Loss: 5815.5143\n",
      "Epoch [81/3000], Loss: 7239.1353\n",
      "Validation Loss: 5572.4370\n",
      "Epoch [101/3000], Loss: 6974.9309\n",
      "Validation Loss: 5355.9202\n",
      "Epoch [121/3000], Loss: 6743.8547\n",
      "Validation Loss: 5152.0039\n",
      "Epoch [141/3000], Loss: 6518.8517\n",
      "Validation Loss: 4958.0834\n",
      "Epoch [161/3000], Loss: 6306.1413\n",
      "Validation Loss: 4773.4065\n",
      "Epoch [181/3000], Loss: 6096.0572\n",
      "Validation Loss: 4597.8155\n",
      "Epoch [201/3000], Loss: 5891.8046\n",
      "Validation Loss: 4431.0807\n",
      "Epoch [221/3000], Loss: 5702.9758\n",
      "Validation Loss: 4273.1451\n",
      "Epoch [241/3000], Loss: 5518.8725\n",
      "Validation Loss: 4123.9586\n",
      "Epoch [261/3000], Loss: 5351.7879\n",
      "Validation Loss: 3983.5343\n",
      "Epoch [281/3000], Loss: 5183.0656\n",
      "Validation Loss: 3851.7866\n",
      "Epoch [301/3000], Loss: 5028.5913\n",
      "Validation Loss: 3728.6589\n",
      "Epoch [321/3000], Loss: 4881.3831\n",
      "Validation Loss: 3614.0651\n",
      "Epoch [341/3000], Loss: 4744.5525\n",
      "Validation Loss: 3508.0041\n",
      "Epoch [361/3000], Loss: 4612.1690\n",
      "Validation Loss: 3410.4282\n",
      "Epoch [381/3000], Loss: 4485.8100\n",
      "Validation Loss: 3321.2141\n",
      "Epoch [401/3000], Loss: 4376.1696\n",
      "Validation Loss: 3240.3452\n",
      "Epoch [421/3000], Loss: 4272.4252\n",
      "Validation Loss: 3167.7566\n",
      "Epoch [441/3000], Loss: 4169.6689\n",
      "Validation Loss: 3103.2885\n",
      "Epoch [461/3000], Loss: 4093.8920\n",
      "Validation Loss: 3046.9016\n",
      "Epoch [481/3000], Loss: 4011.6055\n",
      "Validation Loss: 2998.4146\n",
      "Epoch [501/3000], Loss: 3939.9933\n",
      "Validation Loss: 2957.6797\n",
      "Epoch [521/3000], Loss: 3876.1616\n",
      "Validation Loss: 2924.5135\n",
      "Epoch [541/3000], Loss: 3818.7074\n",
      "Validation Loss: 2898.6417\n",
      "Epoch [561/3000], Loss: 3769.6947\n",
      "Validation Loss: 2879.8529\n",
      "Epoch [581/3000], Loss: 3729.2524\n",
      "Validation Loss: 2867.7190\n",
      "Epoch [601/3000], Loss: 3699.0572\n",
      "Validation Loss: 2861.7507\n",
      "Epoch [621/3000], Loss: 3669.6762\n",
      "Validation Loss: 2849.4236\n",
      "Epoch [641/3000], Loss: 2097.1670\n",
      "Validation Loss: 1545.8244\n",
      "Epoch [661/3000], Loss: 1928.5477\n",
      "Validation Loss: 1450.5871\n",
      "Epoch [681/3000], Loss: 1806.7585\n",
      "Validation Loss: 1371.3717\n",
      "Epoch [701/3000], Loss: 1689.8020\n",
      "Validation Loss: 1296.8509\n",
      "Epoch [721/3000], Loss: 1584.1049\n",
      "Validation Loss: 1229.4040\n",
      "Epoch [741/3000], Loss: 1485.5407\n",
      "Validation Loss: 1172.5218\n",
      "Epoch [761/3000], Loss: 1389.3510\n",
      "Validation Loss: 1121.0039\n",
      "Epoch [781/3000], Loss: 1297.2377\n",
      "Validation Loss: 1068.2710\n",
      "Epoch [801/3000], Loss: 1215.8073\n",
      "Validation Loss: 1017.9605\n",
      "Epoch [821/3000], Loss: 1133.2695\n",
      "Validation Loss: 973.4730\n",
      "Epoch [841/3000], Loss: 1053.6353\n",
      "Validation Loss: 932.2189\n",
      "Epoch [861/3000], Loss: 981.5981\n",
      "Validation Loss: 892.7379\n",
      "Epoch [881/3000], Loss: 910.0161\n",
      "Validation Loss: 853.8028\n",
      "Epoch [901/3000], Loss: 843.6720\n",
      "Validation Loss: 816.7879\n",
      "Epoch [921/3000], Loss: 779.7779\n",
      "Validation Loss: 785.6760\n",
      "Epoch [941/3000], Loss: 717.8713\n",
      "Validation Loss: 758.2578\n",
      "Epoch [961/3000], Loss: 662.5023\n",
      "Validation Loss: 736.5880\n",
      "Epoch [981/3000], Loss: 609.6719\n",
      "Validation Loss: 713.8672\n",
      "Epoch [1001/3000], Loss: 558.4052\n",
      "Validation Loss: 694.2987\n",
      "Epoch [1021/3000], Loss: 509.3329\n",
      "Validation Loss: 680.9147\n",
      "Epoch [1041/3000], Loss: 463.9031\n",
      "Validation Loss: 669.2159\n",
      "Epoch [1061/3000], Loss: 422.5209\n",
      "Validation Loss: 660.7847\n",
      "Epoch [1081/3000], Loss: 381.0371\n",
      "Validation Loss: 651.6374\n",
      "Epoch [1101/3000], Loss: 344.2579\n",
      "Validation Loss: 642.0834\n",
      "Epoch [1121/3000], Loss: 310.0643\n",
      "Validation Loss: 633.0447\n",
      "Epoch [1141/3000], Loss: 278.2253\n",
      "Validation Loss: 617.4806\n",
      "Epoch [1161/3000], Loss: 247.1385\n",
      "Validation Loss: 611.5706\n",
      "Epoch [1181/3000], Loss: 218.2934\n",
      "Validation Loss: 607.7775\n",
      "Epoch [1201/3000], Loss: 193.6585\n",
      "Validation Loss: 608.8691\n",
      "Epoch [1221/3000], Loss: 169.9550\n",
      "Validation Loss: 609.6471\n",
      "Epoch [1241/3000], Loss: 147.7627\n",
      "Validation Loss: 611.2405\n",
      "Epoch [1261/3000], Loss: 128.0758\n",
      "Validation Loss: 619.2988\n",
      "Epoch [1281/3000], Loss: 109.9926\n",
      "Validation Loss: 620.5788\n",
      "Epoch [1301/3000], Loss: 94.4385\n",
      "Validation Loss: 621.8569\n",
      "Epoch [1321/3000], Loss: 80.2573\n",
      "Validation Loss: 620.7813\n",
      "Epoch [1341/3000], Loss: 69.2489\n",
      "Validation Loss: 626.7765\n",
      "Epoch [1361/3000], Loss: 59.1312\n",
      "Validation Loss: 622.8111\n",
      "Epoch [1381/3000], Loss: 51.0040\n",
      "Validation Loss: 632.2757\n",
      "Epoch [1401/3000], Loss: 44.0256\n",
      "Validation Loss: 631.2167\n",
      "Epoch [1421/3000], Loss: 38.2776\n",
      "Validation Loss: 628.7412\n",
      "Epoch [1441/3000], Loss: 32.1867\n",
      "Validation Loss: 628.0572\n",
      "Epoch [1461/3000], Loss: 26.9849\n",
      "Validation Loss: 634.8747\n",
      "Epoch [1481/3000], Loss: 21.8446\n",
      "Validation Loss: 647.5607\n",
      "Epoch [1501/3000], Loss: 17.3984\n",
      "Validation Loss: 647.4288\n",
      "Epoch [1521/3000], Loss: 13.8802\n",
      "Validation Loss: 649.0360\n",
      "Epoch [1541/3000], Loss: 10.7970\n",
      "Validation Loss: 645.5907\n",
      "Epoch [1561/3000], Loss: 8.2803\n",
      "Validation Loss: 651.9610\n",
      "Epoch [1581/3000], Loss: 6.3186\n",
      "Validation Loss: 636.9973\n",
      "Epoch [1601/3000], Loss: 4.6559\n",
      "Validation Loss: 624.6999\n",
      "Epoch [1621/3000], Loss: 3.3623\n",
      "Validation Loss: 630.1087\n",
      "Epoch [1641/3000], Loss: 2.3776\n",
      "Validation Loss: 636.3032\n",
      "Epoch [1661/3000], Loss: 1.6875\n",
      "Validation Loss: 629.7950\n",
      "Epoch [1681/3000], Loss: 1.1146\n",
      "Validation Loss: 628.0588\n",
      "Epoch [1701/3000], Loss: 0.7386\n",
      "Validation Loss: 627.4719\n",
      "Epoch [1721/3000], Loss: 0.4891\n",
      "Validation Loss: 626.6094\n",
      "Epoch [1741/3000], Loss: 0.3224\n",
      "Validation Loss: 631.2878\n",
      "Epoch [1761/3000], Loss: 0.2101\n",
      "Validation Loss: 638.8916\n",
      "Epoch [1781/3000], Loss: 0.1423\n",
      "Validation Loss: 632.0206\n",
      "Epoch [1801/3000], Loss: 0.0984\n",
      "Validation Loss: 633.1186\n",
      "Epoch [1821/3000], Loss: 0.0776\n",
      "Validation Loss: 636.5113\n",
      "Epoch [1841/3000], Loss: 0.0690\n",
      "Validation Loss: 637.5088\n",
      "Epoch [1861/3000], Loss: 0.0681\n",
      "Validation Loss: 640.9868\n",
      "Epoch [1881/3000], Loss: 0.0483\n",
      "Validation Loss: 635.4055\n",
      "Epoch [1901/3000], Loss: 0.0436\n",
      "Validation Loss: 632.8477\n",
      "Epoch [1921/3000], Loss: 0.0535\n",
      "Validation Loss: 641.0191\n",
      "Epoch [1941/3000], Loss: 0.0429\n",
      "Validation Loss: 641.4449\n",
      "Epoch [1961/3000], Loss: 0.0341\n",
      "Validation Loss: 637.6326\n",
      "Epoch [1981/3000], Loss: 0.0371\n",
      "Validation Loss: 641.2231\n",
      "Epoch [2001/3000], Loss: 0.0343\n",
      "Validation Loss: 637.2613\n",
      "Epoch [2021/3000], Loss: 0.0317\n",
      "Validation Loss: 643.3040\n",
      "Epoch [2041/3000], Loss: 0.0283\n",
      "Validation Loss: 638.3609\n",
      "Epoch [2061/3000], Loss: 0.0276\n",
      "Validation Loss: 642.6546\n",
      "Epoch [2081/3000], Loss: 0.0275\n",
      "Validation Loss: 638.1323\n",
      "Epoch [2101/3000], Loss: 0.0302\n",
      "Validation Loss: 639.3242\n",
      "Epoch [2121/3000], Loss: 0.0255\n",
      "Validation Loss: 641.5702\n",
      "Epoch [2141/3000], Loss: 0.0239\n",
      "Validation Loss: 639.8435\n",
      "Epoch [2161/3000], Loss: 0.0219\n",
      "Validation Loss: 641.7160\n",
      "Epoch [2181/3000], Loss: 0.0221\n",
      "Validation Loss: 642.6432\n",
      "Epoch [2201/3000], Loss: 0.0233\n",
      "Validation Loss: 644.3468\n",
      "Epoch [2221/3000], Loss: 0.0231\n",
      "Validation Loss: 641.2444\n",
      "Epoch [2241/3000], Loss: 0.0189\n",
      "Validation Loss: 637.9436\n",
      "Epoch [2261/3000], Loss: 0.0178\n",
      "Validation Loss: 641.9374\n",
      "Epoch [2281/3000], Loss: 0.0184\n",
      "Validation Loss: 642.1843\n",
      "Epoch [2301/3000], Loss: 0.0167\n",
      "Validation Loss: 641.1757\n",
      "Epoch [2321/3000], Loss: 0.0156\n",
      "Validation Loss: 645.3210\n",
      "Epoch [2341/3000], Loss: 0.0194\n",
      "Validation Loss: 642.8148\n",
      "Epoch [2361/3000], Loss: 0.0168\n",
      "Validation Loss: 642.5975\n",
      "Epoch [2381/3000], Loss: 0.0165\n",
      "Validation Loss: 643.3574\n",
      "Epoch [2401/3000], Loss: 0.0144\n",
      "Validation Loss: 644.2883\n",
      "Epoch [2421/3000], Loss: 0.0140\n",
      "Validation Loss: 642.2436\n",
      "Epoch [2441/3000], Loss: 0.0172\n",
      "Validation Loss: 643.8542\n",
      "Epoch [2461/3000], Loss: 0.0146\n",
      "Validation Loss: 641.8756\n",
      "Epoch [2481/3000], Loss: 0.0138\n",
      "Validation Loss: 643.9930\n",
      "Epoch [2501/3000], Loss: 0.0120\n",
      "Validation Loss: 641.2497\n",
      "Epoch [2521/3000], Loss: 0.0108\n",
      "Validation Loss: 646.7841\n",
      "Epoch [2541/3000], Loss: 0.0130\n",
      "Validation Loss: 639.1564\n",
      "Epoch [2561/3000], Loss: 0.0170\n",
      "Validation Loss: 642.8320\n",
      "Epoch [2581/3000], Loss: 0.0114\n",
      "Validation Loss: 642.4462\n",
      "Epoch [2601/3000], Loss: 0.0159\n",
      "Validation Loss: 645.3575\n",
      "Epoch [2621/3000], Loss: 0.0116\n",
      "Validation Loss: 646.2104\n",
      "Epoch [2641/3000], Loss: 0.0089\n",
      "Validation Loss: 647.5046\n",
      "Epoch [2661/3000], Loss: 0.0179\n",
      "Validation Loss: 645.0980\n",
      "Epoch [2681/3000], Loss: 0.0098\n",
      "Validation Loss: 643.8137\n",
      "Epoch [2701/3000], Loss: 0.0100\n",
      "Validation Loss: 644.2467\n",
      "Epoch [2721/3000], Loss: 0.0082\n",
      "Validation Loss: 646.0948\n",
      "Epoch [2741/3000], Loss: 0.0085\n",
      "Validation Loss: 647.1250\n",
      "Epoch [2761/3000], Loss: 0.0088\n",
      "Validation Loss: 647.5069\n",
      "Epoch [2781/3000], Loss: 0.0096\n",
      "Validation Loss: 646.9167\n",
      "Epoch [2801/3000], Loss: 0.0073\n",
      "Validation Loss: 645.4929\n",
      "Epoch [2821/3000], Loss: 0.0078\n",
      "Validation Loss: 648.5819\n",
      "Epoch [2841/3000], Loss: 0.0106\n",
      "Validation Loss: 647.7174\n",
      "Epoch [2861/3000], Loss: 0.0091\n",
      "Validation Loss: 646.7256\n",
      "Epoch [2881/3000], Loss: 0.0074\n",
      "Validation Loss: 647.6092\n",
      "Epoch [2901/3000], Loss: 0.0108\n",
      "Validation Loss: 646.8249\n",
      "Epoch [2921/3000], Loss: 0.0074\n",
      "Validation Loss: 648.7317\n",
      "Epoch [2941/3000], Loss: 0.0067\n",
      "Validation Loss: 648.2559\n",
      "Epoch [2961/3000], Loss: 0.0070\n",
      "Validation Loss: 646.2525\n",
      "Epoch [2981/3000], Loss: 0.0097\n",
      "Validation Loss: 649.5146\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day068_plane0_Fall.mat\n",
      "(8880, 701)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7515.9167\n",
      "Validation Loss: 7301.3134\n",
      "Epoch [21/3000], Loss: 6270.4904\n",
      "Validation Loss: 6136.7166\n",
      "Epoch [41/3000], Loss: 6037.0871\n",
      "Validation Loss: 5917.4594\n",
      "Epoch [61/3000], Loss: 5845.6527\n",
      "Validation Loss: 5736.6368\n",
      "Epoch [81/3000], Loss: 5663.2437\n",
      "Validation Loss: 5573.4723\n",
      "Epoch [101/3000], Loss: 5507.5756\n",
      "Validation Loss: 5420.1320\n",
      "Epoch [121/3000], Loss: 5361.2439\n",
      "Validation Loss: 5274.5787\n",
      "Epoch [141/3000], Loss: 5196.8683\n",
      "Validation Loss: 5135.8050\n",
      "Epoch [161/3000], Loss: 5051.1420\n",
      "Validation Loss: 5003.4110\n",
      "Epoch [181/3000], Loss: 4945.4869\n",
      "Validation Loss: 4876.9657\n",
      "Epoch [201/3000], Loss: 4803.3252\n",
      "Validation Loss: 4756.3855\n",
      "Epoch [221/3000], Loss: 4677.6776\n",
      "Validation Loss: 4641.6347\n",
      "Epoch [241/3000], Loss: 4553.6158\n",
      "Validation Loss: 4532.6863\n",
      "Epoch [261/3000], Loss: 4439.2857\n",
      "Validation Loss: 4429.4355\n",
      "Epoch [281/3000], Loss: 4346.9551\n",
      "Validation Loss: 4331.7517\n",
      "Epoch [301/3000], Loss: 4240.7474\n",
      "Validation Loss: 4239.7005\n",
      "Epoch [321/3000], Loss: 4137.7707\n",
      "Validation Loss: 4153.1803\n",
      "Epoch [341/3000], Loss: 4050.5103\n",
      "Validation Loss: 4072.2716\n",
      "Epoch [361/3000], Loss: 3976.7343\n",
      "Validation Loss: 3996.8265\n",
      "Epoch [381/3000], Loss: 3902.4020\n",
      "Validation Loss: 3926.8587\n",
      "Epoch [401/3000], Loss: 3815.9451\n",
      "Validation Loss: 3862.1898\n",
      "Epoch [421/3000], Loss: 3746.2287\n",
      "Validation Loss: 3802.8895\n",
      "Epoch [441/3000], Loss: 3687.5822\n",
      "Validation Loss: 3748.9599\n",
      "Epoch [461/3000], Loss: 3625.8316\n",
      "Validation Loss: 3700.3612\n",
      "Epoch [481/3000], Loss: 3578.3263\n",
      "Validation Loss: 3656.8188\n",
      "Epoch [501/3000], Loss: 3529.7190\n",
      "Validation Loss: 3618.2224\n",
      "Epoch [521/3000], Loss: 3494.8668\n",
      "Validation Loss: 3584.5998\n",
      "Epoch [541/3000], Loss: 3460.2996\n",
      "Validation Loss: 3555.8967\n",
      "Epoch [561/3000], Loss: 3418.1914\n",
      "Validation Loss: 3531.8105\n",
      "Epoch [581/3000], Loss: 3386.5046\n",
      "Validation Loss: 3512.3130\n",
      "Epoch [601/3000], Loss: 3368.1442\n",
      "Validation Loss: 3496.8901\n",
      "Epoch [621/3000], Loss: 2257.3147\n",
      "Validation Loss: 2397.7240\n",
      "Epoch [641/3000], Loss: 2069.5588\n",
      "Validation Loss: 2264.5909\n",
      "Epoch [661/3000], Loss: 1955.4521\n",
      "Validation Loss: 2183.3838\n",
      "Epoch [681/3000], Loss: 1851.2464\n",
      "Validation Loss: 2092.4315\n",
      "Epoch [701/3000], Loss: 1761.6528\n",
      "Validation Loss: 2021.5809\n",
      "Epoch [721/3000], Loss: 1668.0563\n",
      "Validation Loss: 1941.0328\n",
      "Epoch [741/3000], Loss: 1592.0885\n",
      "Validation Loss: 1873.2467\n",
      "Epoch [761/3000], Loss: 1519.5866\n",
      "Validation Loss: 1800.9025\n",
      "Epoch [781/3000], Loss: 1444.5705\n",
      "Validation Loss: 1733.2251\n",
      "Epoch [801/3000], Loss: 1367.3580\n",
      "Validation Loss: 1672.5980\n",
      "Epoch [821/3000], Loss: 1298.5813\n",
      "Validation Loss: 1608.5996\n",
      "Epoch [841/3000], Loss: 1229.0777\n",
      "Validation Loss: 1551.1074\n",
      "Epoch [861/3000], Loss: 1162.9226\n",
      "Validation Loss: 1490.7113\n",
      "Epoch [881/3000], Loss: 1100.5204\n",
      "Validation Loss: 1433.4968\n",
      "Epoch [901/3000], Loss: 1043.6590\n",
      "Validation Loss: 1386.2724\n",
      "Epoch [921/3000], Loss: 985.0985\n",
      "Validation Loss: 1333.7453\n",
      "Epoch [941/3000], Loss: 927.9641\n",
      "Validation Loss: 1292.4135\n",
      "Epoch [961/3000], Loss: 880.1733\n",
      "Validation Loss: 1244.4026\n",
      "Epoch [981/3000], Loss: 831.5563\n",
      "Validation Loss: 1203.2486\n",
      "Epoch [1001/3000], Loss: 782.5207\n",
      "Validation Loss: 1156.4983\n",
      "Epoch [1021/3000], Loss: 738.3559\n",
      "Validation Loss: 1116.3836\n",
      "Epoch [1041/3000], Loss: 697.4470\n",
      "Validation Loss: 1086.9529\n",
      "Epoch [1061/3000], Loss: 651.5840\n",
      "Validation Loss: 1060.9546\n",
      "Epoch [1081/3000], Loss: 617.2406\n",
      "Validation Loss: 1034.8787\n",
      "Epoch [1101/3000], Loss: 575.4123\n",
      "Validation Loss: 1001.8576\n",
      "Epoch [1121/3000], Loss: 537.6051\n",
      "Validation Loss: 979.0664\n",
      "Epoch [1141/3000], Loss: 509.0313\n",
      "Validation Loss: 954.9927\n",
      "Epoch [1161/3000], Loss: 473.1853\n",
      "Validation Loss: 930.2063\n",
      "Epoch [1181/3000], Loss: 445.7934\n",
      "Validation Loss: 904.4091\n",
      "Epoch [1201/3000], Loss: 415.7231\n",
      "Validation Loss: 887.2352\n",
      "Epoch [1221/3000], Loss: 387.7836\n",
      "Validation Loss: 853.8692\n",
      "Epoch [1241/3000], Loss: 360.7308\n",
      "Validation Loss: 820.4695\n",
      "Epoch [1261/3000], Loss: 336.5612\n",
      "Validation Loss: 791.1340\n",
      "Epoch [1281/3000], Loss: 313.5035\n",
      "Validation Loss: 768.2764\n",
      "Epoch [1301/3000], Loss: 291.3098\n",
      "Validation Loss: 742.2860\n",
      "Epoch [1321/3000], Loss: 268.8077\n",
      "Validation Loss: 727.4665\n",
      "Epoch [1341/3000], Loss: 248.7186\n",
      "Validation Loss: 701.9846\n",
      "Epoch [1361/3000], Loss: 231.9124\n",
      "Validation Loss: 674.5021\n",
      "Epoch [1381/3000], Loss: 213.3761\n",
      "Validation Loss: 675.6292\n",
      "Epoch [1401/3000], Loss: 196.4449\n",
      "Validation Loss: 667.1159\n",
      "Epoch [1421/3000], Loss: 180.9953\n",
      "Validation Loss: 656.6544\n",
      "Epoch [1441/3000], Loss: 165.8520\n",
      "Validation Loss: 650.1935\n",
      "Epoch [1461/3000], Loss: 152.4799\n",
      "Validation Loss: 636.9811\n",
      "Epoch [1481/3000], Loss: 139.8731\n",
      "Validation Loss: 636.8193\n",
      "Epoch [1501/3000], Loss: 128.5751\n",
      "Validation Loss: 637.3288\n",
      "Epoch [1521/3000], Loss: 117.4486\n",
      "Validation Loss: 632.4032\n",
      "Epoch [1541/3000], Loss: 106.3196\n",
      "Validation Loss: 636.4902\n",
      "Epoch [1561/3000], Loss: 96.9445\n",
      "Validation Loss: 644.0804\n",
      "Epoch [1581/3000], Loss: 87.2051\n",
      "Validation Loss: 642.1004\n",
      "Epoch [1601/3000], Loss: 79.2547\n",
      "Validation Loss: 640.8485\n",
      "Epoch [1621/3000], Loss: 70.9134\n",
      "Validation Loss: 636.5203\n",
      "Epoch [1641/3000], Loss: 64.0852\n",
      "Validation Loss: 654.7973\n",
      "Epoch [1661/3000], Loss: 56.8795\n",
      "Validation Loss: 645.0775\n",
      "Epoch [1681/3000], Loss: 50.9220\n",
      "Validation Loss: 644.2932\n",
      "Epoch [1701/3000], Loss: 45.2452\n",
      "Validation Loss: 634.1755\n",
      "Epoch [1721/3000], Loss: 39.4833\n",
      "Validation Loss: 631.3418\n",
      "Epoch [1741/3000], Loss: 35.0253\n",
      "Validation Loss: 627.1983\n",
      "Epoch [1761/3000], Loss: 30.7712\n",
      "Validation Loss: 623.6751\n",
      "Epoch [1781/3000], Loss: 26.5055\n",
      "Validation Loss: 628.9501\n",
      "Epoch [1801/3000], Loss: 23.2966\n",
      "Validation Loss: 627.9138\n",
      "Epoch [1821/3000], Loss: 19.8689\n",
      "Validation Loss: 631.8022\n",
      "Epoch [1841/3000], Loss: 16.8422\n",
      "Validation Loss: 635.2837\n",
      "Epoch [1861/3000], Loss: 14.0144\n",
      "Validation Loss: 642.5741\n",
      "Epoch [1881/3000], Loss: 17.5197\n",
      "Validation Loss: 668.3990\n",
      "Epoch [1901/3000], Loss: 9.9436\n",
      "Validation Loss: 640.6423\n",
      "Epoch [1921/3000], Loss: 8.2160\n",
      "Validation Loss: 640.6839\n",
      "Epoch [1941/3000], Loss: 6.7735\n",
      "Validation Loss: 643.4218\n",
      "Epoch [1961/3000], Loss: 5.3910\n",
      "Validation Loss: 641.7001\n",
      "Epoch [1981/3000], Loss: 4.4188\n",
      "Validation Loss: 640.7303\n",
      "Epoch [2001/3000], Loss: 3.4149\n",
      "Validation Loss: 650.7518\n",
      "Epoch [2021/3000], Loss: 2.6012\n",
      "Validation Loss: 648.6819\n",
      "Epoch [2041/3000], Loss: 1.9821\n",
      "Validation Loss: 642.6794\n",
      "Epoch [2061/3000], Loss: 1.4786\n",
      "Validation Loss: 655.6300\n",
      "Epoch [2081/3000], Loss: 1.1134\n",
      "Validation Loss: 648.8826\n",
      "Epoch [2101/3000], Loss: 0.7811\n",
      "Validation Loss: 642.6359\n",
      "Epoch [2121/3000], Loss: 0.5318\n",
      "Validation Loss: 648.8580\n",
      "Epoch [2141/3000], Loss: 0.3685\n",
      "Validation Loss: 636.8588\n",
      "Epoch [2161/3000], Loss: 0.2625\n",
      "Validation Loss: 639.6752\n",
      "Epoch [2181/3000], Loss: 0.1938\n",
      "Validation Loss: 627.3356\n",
      "Epoch [2201/3000], Loss: 0.1472\n",
      "Validation Loss: 631.7135\n",
      "Epoch [2221/3000], Loss: 0.1051\n",
      "Validation Loss: 633.7174\n",
      "Epoch [2241/3000], Loss: 0.0936\n",
      "Validation Loss: 630.9853\n",
      "Epoch [2261/3000], Loss: 0.0703\n",
      "Validation Loss: 630.5887\n",
      "Epoch [2281/3000], Loss: 0.0610\n",
      "Validation Loss: 628.2231\n",
      "Epoch [2301/3000], Loss: 0.0528\n",
      "Validation Loss: 625.2878\n",
      "Epoch [2321/3000], Loss: 0.0508\n",
      "Validation Loss: 624.0267\n",
      "Epoch [2341/3000], Loss: 0.0474\n",
      "Validation Loss: 620.4356\n",
      "Epoch [2361/3000], Loss: 0.0523\n",
      "Validation Loss: 619.2011\n",
      "Epoch [2381/3000], Loss: 0.0595\n",
      "Validation Loss: 621.6869\n",
      "Epoch [2401/3000], Loss: 0.0482\n",
      "Validation Loss: 621.6734\n",
      "Epoch [2421/3000], Loss: 0.0403\n",
      "Validation Loss: 622.3989\n",
      "Epoch [2441/3000], Loss: 0.0349\n",
      "Validation Loss: 617.4682\n",
      "Epoch [2461/3000], Loss: 0.0411\n",
      "Validation Loss: 624.1872\n",
      "Epoch [2481/3000], Loss: 0.0350\n",
      "Validation Loss: 616.5670\n",
      "Epoch [2501/3000], Loss: 0.0444\n",
      "Validation Loss: 618.1370\n",
      "Epoch [2521/3000], Loss: 0.0306\n",
      "Validation Loss: 620.6227\n",
      "Epoch [2541/3000], Loss: 0.0480\n",
      "Validation Loss: 618.4628\n",
      "Epoch [2561/3000], Loss: 0.0299\n",
      "Validation Loss: 619.2942\n",
      "Epoch [2581/3000], Loss: 0.0270\n",
      "Validation Loss: 621.5758\n",
      "Epoch [2601/3000], Loss: 0.0252\n",
      "Validation Loss: 618.7212\n",
      "Epoch [2621/3000], Loss: 0.0296\n",
      "Validation Loss: 622.7767\n",
      "Epoch [2641/3000], Loss: 0.0236\n",
      "Validation Loss: 620.6266\n",
      "Epoch [2661/3000], Loss: 0.0286\n",
      "Validation Loss: 619.8388\n",
      "Epoch [2681/3000], Loss: 0.0246\n",
      "Validation Loss: 618.2049\n",
      "Epoch [2701/3000], Loss: 0.0257\n",
      "Validation Loss: 617.6968\n",
      "Epoch [2721/3000], Loss: 0.0253\n",
      "Validation Loss: 618.5555\n",
      "Epoch [2741/3000], Loss: 0.0204\n",
      "Validation Loss: 617.7597\n",
      "Epoch [2761/3000], Loss: 0.0243\n",
      "Validation Loss: 616.1064\n",
      "Epoch [2781/3000], Loss: 0.0247\n",
      "Validation Loss: 615.3192\n",
      "Epoch [2801/3000], Loss: 0.0204\n",
      "Validation Loss: 620.6609\n",
      "Epoch [2821/3000], Loss: 0.0181\n",
      "Validation Loss: 617.5880\n",
      "Epoch [2841/3000], Loss: 0.1976\n",
      "Validation Loss: 589.6843\n",
      "Epoch [2861/3000], Loss: 0.0452\n",
      "Validation Loss: 603.6449\n",
      "Epoch [2881/3000], Loss: 0.0290\n",
      "Validation Loss: 607.2265\n",
      "Epoch [2901/3000], Loss: 0.0230\n",
      "Validation Loss: 609.3061\n",
      "Epoch [2921/3000], Loss: 0.0194\n",
      "Validation Loss: 609.5233\n",
      "Epoch [2941/3000], Loss: 0.0174\n",
      "Validation Loss: 610.3018\n",
      "Epoch [2961/3000], Loss: 0.0163\n",
      "Validation Loss: 611.1936\n",
      "Epoch [2981/3000], Loss: 0.0154\n",
      "Validation Loss: 611.4525\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day069_plane0_Fall.mat\n",
      "(5142, 903)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6581.2565\n",
      "Validation Loss: 7282.6395\n",
      "Epoch [21/3000], Loss: 5717.5404\n",
      "Validation Loss: 6286.5322\n",
      "Epoch [41/3000], Loss: 5517.4144\n",
      "Validation Loss: 6065.0873\n",
      "Epoch [61/3000], Loss: 5399.3020\n",
      "Validation Loss: 5930.7248\n",
      "Epoch [81/3000], Loss: 5305.6491\n",
      "Validation Loss: 5814.3665\n",
      "Epoch [101/3000], Loss: 5219.8033\n",
      "Validation Loss: 5706.3568\n",
      "Epoch [121/3000], Loss: 5130.0396\n",
      "Validation Loss: 5603.6782\n",
      "Epoch [141/3000], Loss: 5041.7666\n",
      "Validation Loss: 5504.8982\n",
      "Epoch [161/3000], Loss: 4962.1514\n",
      "Validation Loss: 5409.4312\n",
      "Epoch [181/3000], Loss: 4884.4812\n",
      "Validation Loss: 5316.7760\n",
      "Epoch [201/3000], Loss: 4806.0120\n",
      "Validation Loss: 5226.6399\n",
      "Epoch [221/3000], Loss: 4731.5999\n",
      "Validation Loss: 5138.8571\n",
      "Epoch [241/3000], Loss: 4671.4844\n",
      "Validation Loss: 5053.3140\n",
      "Epoch [261/3000], Loss: 4597.2134\n",
      "Validation Loss: 4969.8941\n",
      "Epoch [281/3000], Loss: 4531.2759\n",
      "Validation Loss: 4888.5084\n",
      "Epoch [301/3000], Loss: 4461.6651\n",
      "Validation Loss: 4809.1942\n",
      "Epoch [321/3000], Loss: 4396.4629\n",
      "Validation Loss: 4727.9458\n",
      "Epoch [341/3000], Loss: 4339.8647\n",
      "Validation Loss: 4652.0416\n",
      "Epoch [361/3000], Loss: 4269.6027\n",
      "Validation Loss: 4578.4724\n",
      "Epoch [381/3000], Loss: 4220.6490\n",
      "Validation Loss: 4506.8444\n",
      "Epoch [401/3000], Loss: 4169.5104\n",
      "Validation Loss: 4437.2643\n",
      "Epoch [421/3000], Loss: 4114.7820\n",
      "Validation Loss: 4369.6185\n",
      "Epoch [441/3000], Loss: 4059.3358\n",
      "Validation Loss: 4303.9244\n",
      "Epoch [461/3000], Loss: 4003.2109\n",
      "Validation Loss: 4240.1202\n",
      "Epoch [481/3000], Loss: 3959.7409\n",
      "Validation Loss: 4178.2234\n",
      "Epoch [501/3000], Loss: 3916.7272\n",
      "Validation Loss: 4118.2876\n",
      "Epoch [521/3000], Loss: 3875.8454\n",
      "Validation Loss: 4060.2608\n",
      "Epoch [541/3000], Loss: 3833.3601\n",
      "Validation Loss: 4004.1078\n",
      "Epoch [561/3000], Loss: 3792.9720\n",
      "Validation Loss: 3949.8952\n",
      "Epoch [581/3000], Loss: 3754.1000\n",
      "Validation Loss: 3897.5553\n",
      "Epoch [601/3000], Loss: 3713.4857\n",
      "Validation Loss: 3847.0875\n",
      "Epoch [621/3000], Loss: 3684.8542\n",
      "Validation Loss: 3798.4716\n",
      "Epoch [641/3000], Loss: 3648.2115\n",
      "Validation Loss: 3751.7951\n",
      "Epoch [661/3000], Loss: 3615.6821\n",
      "Validation Loss: 3707.0808\n",
      "Epoch [681/3000], Loss: 3593.0529\n",
      "Validation Loss: 3664.1330\n",
      "Epoch [701/3000], Loss: 3557.3598\n",
      "Validation Loss: 3623.0507\n",
      "Epoch [721/3000], Loss: 3536.5648\n",
      "Validation Loss: 3583.8186\n",
      "Epoch [741/3000], Loss: 3513.0777\n",
      "Validation Loss: 3546.4640\n",
      "Epoch [761/3000], Loss: 3488.3269\n",
      "Validation Loss: 3510.9193\n",
      "Epoch [781/3000], Loss: 3468.0334\n",
      "Validation Loss: 3477.1701\n",
      "Epoch [801/3000], Loss: 3447.7272\n",
      "Validation Loss: 3445.2452\n",
      "Epoch [821/3000], Loss: 3432.0217\n",
      "Validation Loss: 3415.0794\n",
      "Epoch [841/3000], Loss: 3416.9591\n",
      "Validation Loss: 3386.7804\n",
      "Epoch [861/3000], Loss: 3402.7358\n",
      "Validation Loss: 3360.2782\n",
      "Epoch [881/3000], Loss: 3383.9506\n",
      "Validation Loss: 3335.4720\n",
      "Epoch [901/3000], Loss: 3376.0521\n",
      "Validation Loss: 3312.3860\n",
      "Epoch [921/3000], Loss: 3367.3045\n",
      "Validation Loss: 3291.0503\n",
      "Epoch [941/3000], Loss: 2376.8288\n",
      "Validation Loss: 2796.2870\n",
      "Epoch [961/3000], Loss: 2266.1057\n",
      "Validation Loss: 2820.6498\n",
      "Epoch [981/3000], Loss: 2192.8133\n",
      "Validation Loss: 2745.7406\n",
      "Epoch [1001/3000], Loss: 2131.8792\n",
      "Validation Loss: 2727.9274\n",
      "Epoch [1021/3000], Loss: 2075.1405\n",
      "Validation Loss: 2664.8735\n",
      "Epoch [1041/3000], Loss: 2016.7728\n",
      "Validation Loss: 2551.0040\n",
      "Epoch [1061/3000], Loss: 1969.4629\n",
      "Validation Loss: 2513.9678\n",
      "Epoch [1081/3000], Loss: 1923.3214\n",
      "Validation Loss: 2466.5273\n",
      "Epoch [1101/3000], Loss: 1870.2992\n",
      "Validation Loss: 2431.6201\n",
      "Epoch [1121/3000], Loss: 1831.0279\n",
      "Validation Loss: 2387.3815\n",
      "Epoch [1141/3000], Loss: 1786.0739\n",
      "Validation Loss: 2347.1206\n",
      "Epoch [1161/3000], Loss: 1743.7464\n",
      "Validation Loss: 2304.4668\n",
      "Epoch [1181/3000], Loss: 1699.3008\n",
      "Validation Loss: 2258.4229\n",
      "Epoch [1201/3000], Loss: 1658.7728\n",
      "Validation Loss: 2223.3259\n",
      "Epoch [1221/3000], Loss: 1616.8620\n",
      "Validation Loss: 2187.1384\n",
      "Epoch [1241/3000], Loss: 1579.3180\n",
      "Validation Loss: 2153.7951\n",
      "Epoch [1261/3000], Loss: 1538.7727\n",
      "Validation Loss: 2117.9956\n",
      "Epoch [1281/3000], Loss: 1498.5550\n",
      "Validation Loss: 2069.4435\n",
      "Epoch [1301/3000], Loss: 1458.8814\n",
      "Validation Loss: 2023.9272\n",
      "Epoch [1321/3000], Loss: 1429.6739\n",
      "Validation Loss: 1963.0759\n",
      "Epoch [1341/3000], Loss: 1387.8426\n",
      "Validation Loss: 1971.2085\n",
      "Epoch [1361/3000], Loss: 1349.2430\n",
      "Validation Loss: 1929.2214\n",
      "Epoch [1381/3000], Loss: 1312.1097\n",
      "Validation Loss: 1896.9004\n",
      "Epoch [1401/3000], Loss: 1277.7399\n",
      "Validation Loss: 1868.4847\n",
      "Epoch [1421/3000], Loss: 1244.4921\n",
      "Validation Loss: 1841.0664\n",
      "Epoch [1441/3000], Loss: 1209.7164\n",
      "Validation Loss: 1812.0526\n",
      "Epoch [1461/3000], Loss: 1176.1562\n",
      "Validation Loss: 1781.2471\n",
      "Epoch [1481/3000], Loss: 1142.1002\n",
      "Validation Loss: 1755.5846\n",
      "Epoch [1501/3000], Loss: 1113.0414\n",
      "Validation Loss: 1731.8808\n",
      "Epoch [1521/3000], Loss: 1079.3931\n",
      "Validation Loss: 1700.8876\n",
      "Epoch [1541/3000], Loss: 1049.3928\n",
      "Validation Loss: 1676.7957\n",
      "Epoch [1561/3000], Loss: 1018.6389\n",
      "Validation Loss: 1655.4633\n",
      "Epoch [1581/3000], Loss: 990.7320\n",
      "Validation Loss: 1627.1801\n",
      "Epoch [1601/3000], Loss: 958.4351\n",
      "Validation Loss: 1605.3172\n",
      "Epoch [1621/3000], Loss: 932.4926\n",
      "Validation Loss: 1577.8046\n",
      "Epoch [1641/3000], Loss: 904.7732\n",
      "Validation Loss: 1555.7569\n",
      "Epoch [1661/3000], Loss: 879.4076\n",
      "Validation Loss: 1533.0481\n",
      "Epoch [1681/3000], Loss: 848.2630\n",
      "Validation Loss: 1514.1861\n",
      "Epoch [1701/3000], Loss: 826.2534\n",
      "Validation Loss: 1496.7146\n",
      "Epoch [1721/3000], Loss: 800.1113\n",
      "Validation Loss: 1488.1926\n",
      "Epoch [1741/3000], Loss: 776.5047\n",
      "Validation Loss: 1479.1358\n",
      "Epoch [1761/3000], Loss: 752.4632\n",
      "Validation Loss: 1453.2176\n",
      "Epoch [1781/3000], Loss: 727.9428\n",
      "Validation Loss: 1433.9519\n",
      "Epoch [1801/3000], Loss: 706.8196\n",
      "Validation Loss: 1420.1436\n",
      "Epoch [1821/3000], Loss: 683.9376\n",
      "Validation Loss: 1418.3514\n",
      "Epoch [1841/3000], Loss: 663.3986\n",
      "Validation Loss: 1411.7917\n",
      "Epoch [1861/3000], Loss: 637.9593\n",
      "Validation Loss: 1394.8944\n",
      "Epoch [1881/3000], Loss: 620.4168\n",
      "Validation Loss: 1383.5291\n",
      "Epoch [1901/3000], Loss: 598.8280\n",
      "Validation Loss: 1374.7207\n",
      "Epoch [1921/3000], Loss: 577.8620\n",
      "Validation Loss: 1368.3516\n",
      "Epoch [1941/3000], Loss: 557.7038\n",
      "Validation Loss: 1358.7693\n",
      "Epoch [1961/3000], Loss: 541.4861\n",
      "Validation Loss: 1355.1590\n",
      "Epoch [1981/3000], Loss: 522.4644\n",
      "Validation Loss: 1343.5046\n",
      "Epoch [2001/3000], Loss: 503.6739\n",
      "Validation Loss: 1338.7465\n",
      "Epoch [2021/3000], Loss: 484.6052\n",
      "Validation Loss: 1345.0306\n",
      "Epoch [2041/3000], Loss: 468.2249\n",
      "Validation Loss: 1324.5656\n",
      "Epoch [2061/3000], Loss: 451.0617\n",
      "Validation Loss: 1316.2086\n",
      "Epoch [2081/3000], Loss: 435.3438\n",
      "Validation Loss: 1310.6634\n",
      "Epoch [2101/3000], Loss: 418.9414\n",
      "Validation Loss: 1302.5681\n",
      "Epoch [2121/3000], Loss: 402.8579\n",
      "Validation Loss: 1288.9972\n",
      "Epoch [2141/3000], Loss: 387.8663\n",
      "Validation Loss: 1271.8801\n",
      "Epoch [2161/3000], Loss: 373.0614\n",
      "Validation Loss: 1265.4565\n",
      "Epoch [2181/3000], Loss: 359.4122\n",
      "Validation Loss: 1252.6388\n",
      "Epoch [2201/3000], Loss: 344.6110\n",
      "Validation Loss: 1246.0726\n",
      "Epoch [2221/3000], Loss: 330.6768\n",
      "Validation Loss: 1240.4249\n",
      "Epoch [2241/3000], Loss: 318.6615\n",
      "Validation Loss: 1224.2604\n",
      "Epoch [2261/3000], Loss: 305.7660\n",
      "Validation Loss: 1226.9725\n",
      "Epoch [2281/3000], Loss: 292.9820\n",
      "Validation Loss: 1214.4683\n",
      "Epoch [2301/3000], Loss: 280.8768\n",
      "Validation Loss: 1212.3032\n",
      "Epoch [2321/3000], Loss: 269.1898\n",
      "Validation Loss: 1203.7864\n",
      "Epoch [2341/3000], Loss: 257.9010\n",
      "Validation Loss: 1195.9862\n",
      "Epoch [2361/3000], Loss: 246.7949\n",
      "Validation Loss: 1186.8193\n",
      "Epoch [2381/3000], Loss: 236.3420\n",
      "Validation Loss: 1182.5820\n",
      "Epoch [2401/3000], Loss: 225.9631\n",
      "Validation Loss: 1174.3458\n",
      "Epoch [2421/3000], Loss: 215.9112\n",
      "Validation Loss: 1168.1165\n",
      "Epoch [2441/3000], Loss: 205.1738\n",
      "Validation Loss: 1165.4075\n",
      "Epoch [2461/3000], Loss: 195.7152\n",
      "Validation Loss: 1160.3816\n",
      "Epoch [2481/3000], Loss: 187.6687\n",
      "Validation Loss: 1156.2246\n",
      "Epoch [2501/3000], Loss: 178.7917\n",
      "Validation Loss: 1155.4296\n",
      "Epoch [2521/3000], Loss: 170.2382\n",
      "Validation Loss: 1146.8080\n",
      "Epoch [2541/3000], Loss: 161.6295\n",
      "Validation Loss: 1145.8083\n",
      "Epoch [2561/3000], Loss: 153.3599\n",
      "Validation Loss: 1140.2822\n",
      "Epoch [2581/3000], Loss: 146.3237\n",
      "Validation Loss: 1133.9812\n",
      "Epoch [2601/3000], Loss: 138.8778\n",
      "Validation Loss: 1131.5436\n",
      "Epoch [2621/3000], Loss: 131.4518\n",
      "Validation Loss: 1128.9622\n",
      "Epoch [2641/3000], Loss: 124.4277\n",
      "Validation Loss: 1131.3650\n",
      "Epoch [2661/3000], Loss: 118.1383\n",
      "Validation Loss: 1132.3453\n",
      "Epoch [2681/3000], Loss: 111.6204\n",
      "Validation Loss: 1135.5812\n",
      "Epoch [2701/3000], Loss: 105.2731\n",
      "Validation Loss: 1133.6256\n",
      "Epoch [2721/3000], Loss: 99.6437\n",
      "Validation Loss: 1135.1705\n",
      "Epoch [2741/3000], Loss: 93.7926\n",
      "Validation Loss: 1136.9573\n",
      "Epoch [2761/3000], Loss: 88.3265\n",
      "Validation Loss: 1134.0411\n",
      "Epoch [2781/3000], Loss: 83.0857\n",
      "Validation Loss: 1136.2932\n",
      "Epoch [2801/3000], Loss: 77.9854\n",
      "Validation Loss: 1126.2420\n",
      "Epoch [2821/3000], Loss: 73.3960\n",
      "Validation Loss: 1125.9030\n",
      "Epoch [2841/3000], Loss: 68.4856\n",
      "Validation Loss: 1115.8928\n",
      "Epoch [2861/3000], Loss: 64.0682\n",
      "Validation Loss: 1115.3539\n",
      "Epoch [2881/3000], Loss: 60.1319\n",
      "Validation Loss: 1113.4184\n",
      "Epoch [2901/3000], Loss: 56.3209\n",
      "Validation Loss: 1108.7296\n",
      "Epoch [2921/3000], Loss: 52.3743\n",
      "Validation Loss: 1108.4735\n",
      "Epoch [2941/3000], Loss: 48.7281\n",
      "Validation Loss: 1107.6044\n",
      "Epoch [2961/3000], Loss: 45.3355\n",
      "Validation Loss: 1109.2928\n",
      "Epoch [2981/3000], Loss: 41.8778\n",
      "Validation Loss: 1108.1574\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day070_plane0_Fall.mat\n",
      "(5890, 990)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7774.2470\n",
      "Validation Loss: 8221.3854\n",
      "Epoch [21/3000], Loss: 6704.4088\n",
      "Validation Loss: 7142.3834\n",
      "Epoch [41/3000], Loss: 6477.3101\n",
      "Validation Loss: 6913.7652\n",
      "Epoch [61/3000], Loss: 6313.9397\n",
      "Validation Loss: 6753.5679\n",
      "Epoch [81/3000], Loss: 6180.3171\n",
      "Validation Loss: 6612.0948\n",
      "Epoch [101/3000], Loss: 6061.3392\n",
      "Validation Loss: 6481.7037\n",
      "Epoch [121/3000], Loss: 5895.5885\n",
      "Validation Loss: 6357.4474\n",
      "Epoch [141/3000], Loss: 5806.7973\n",
      "Validation Loss: 6237.5381\n",
      "Epoch [161/3000], Loss: 5695.3676\n",
      "Validation Loss: 6121.3674\n",
      "Epoch [181/3000], Loss: 5562.6018\n",
      "Validation Loss: 6008.4416\n",
      "Epoch [201/3000], Loss: 5435.2540\n",
      "Validation Loss: 5898.3793\n",
      "Epoch [221/3000], Loss: 5370.5948\n",
      "Validation Loss: 5787.3293\n",
      "Epoch [241/3000], Loss: 5250.1139\n",
      "Validation Loss: 5681.5873\n",
      "Epoch [261/3000], Loss: 5108.4380\n",
      "Validation Loss: 5578.9199\n",
      "Epoch [281/3000], Loss: 5030.0871\n",
      "Validation Loss: 5479.0036\n",
      "Epoch [301/3000], Loss: 4981.6196\n",
      "Validation Loss: 5381.4232\n",
      "Epoch [321/3000], Loss: 4860.8133\n",
      "Validation Loss: 5286.3645\n",
      "Epoch [341/3000], Loss: 4753.1840\n",
      "Validation Loss: 5193.7438\n",
      "Epoch [361/3000], Loss: 4703.4100\n",
      "Validation Loss: 5103.4857\n",
      "Epoch [381/3000], Loss: 4637.3105\n",
      "Validation Loss: 5015.7357\n",
      "Epoch [401/3000], Loss: 4502.0489\n",
      "Validation Loss: 4930.2111\n",
      "Epoch [421/3000], Loss: 4436.3396\n",
      "Validation Loss: 4847.1148\n",
      "Epoch [441/3000], Loss: 4362.6404\n",
      "Validation Loss: 4766.3378\n",
      "Epoch [461/3000], Loss: 4272.5813\n",
      "Validation Loss: 4688.0411\n",
      "Epoch [481/3000], Loss: 4214.2386\n",
      "Validation Loss: 4612.1400\n",
      "Epoch [501/3000], Loss: 4140.5460\n",
      "Validation Loss: 4538.3741\n",
      "Epoch [521/3000], Loss: 4059.5436\n",
      "Validation Loss: 4467.1319\n",
      "Epoch [541/3000], Loss: 4004.6995\n",
      "Validation Loss: 4398.1484\n",
      "Epoch [561/3000], Loss: 3927.4709\n",
      "Validation Loss: 4331.4245\n",
      "Epoch [581/3000], Loss: 3861.7237\n",
      "Validation Loss: 4267.1173\n",
      "Epoch [601/3000], Loss: 3810.4341\n",
      "Validation Loss: 4205.0976\n",
      "Epoch [621/3000], Loss: 3763.0263\n",
      "Validation Loss: 4145.2891\n",
      "Epoch [641/3000], Loss: 3692.9575\n",
      "Validation Loss: 4087.8371\n",
      "Epoch [661/3000], Loss: 3631.2541\n",
      "Validation Loss: 4032.2779\n",
      "Epoch [681/3000], Loss: 3587.4266\n",
      "Validation Loss: 3978.5704\n",
      "Epoch [701/3000], Loss: 3540.8632\n",
      "Validation Loss: 3927.3001\n",
      "Epoch [721/3000], Loss: 3475.3153\n",
      "Validation Loss: 3877.0316\n",
      "Epoch [741/3000], Loss: 2793.4237\n",
      "Validation Loss: 3391.2034\n",
      "Epoch [761/3000], Loss: 2711.7468\n",
      "Validation Loss: 3361.8660\n",
      "Epoch [781/3000], Loss: 2626.4844\n",
      "Validation Loss: 3262.4462\n",
      "Epoch [801/3000], Loss: 2518.9463\n",
      "Validation Loss: 3264.0377\n",
      "Epoch [821/3000], Loss: 2448.0163\n",
      "Validation Loss: 3181.9738\n",
      "Epoch [841/3000], Loss: 2383.1758\n",
      "Validation Loss: 3116.1247\n",
      "Epoch [861/3000], Loss: 2308.7086\n",
      "Validation Loss: 3038.4346\n",
      "Epoch [881/3000], Loss: 2237.0180\n",
      "Validation Loss: 2978.8897\n",
      "Epoch [901/3000], Loss: 2172.7552\n",
      "Validation Loss: 2921.5347\n",
      "Epoch [921/3000], Loss: 2109.0687\n",
      "Validation Loss: 2852.6633\n",
      "Epoch [941/3000], Loss: 2050.5462\n",
      "Validation Loss: 2791.4806\n",
      "Epoch [961/3000], Loss: 1984.8935\n",
      "Validation Loss: 2724.2470\n",
      "Epoch [981/3000], Loss: 1892.9394\n",
      "Validation Loss: 2656.2201\n",
      "Epoch [1001/3000], Loss: 1866.2058\n",
      "Validation Loss: 2578.6434\n",
      "Epoch [1021/3000], Loss: 1818.2316\n",
      "Validation Loss: 2519.5560\n",
      "Epoch [1041/3000], Loss: 1747.8035\n",
      "Validation Loss: 2476.8578\n",
      "Epoch [1061/3000], Loss: 1691.1962\n",
      "Validation Loss: 2414.2325\n",
      "Epoch [1081/3000], Loss: 1648.7807\n",
      "Validation Loss: 2356.2755\n",
      "Epoch [1101/3000], Loss: 1574.4868\n",
      "Validation Loss: 2304.3499\n",
      "Epoch [1121/3000], Loss: 1520.4078\n",
      "Validation Loss: 2248.9747\n",
      "Epoch [1141/3000], Loss: 1468.0060\n",
      "Validation Loss: 2183.7679\n",
      "Epoch [1161/3000], Loss: 1430.0893\n",
      "Validation Loss: 2148.0775\n",
      "Epoch [1181/3000], Loss: 1367.3799\n",
      "Validation Loss: 2105.6878\n",
      "Epoch [1201/3000], Loss: 1319.6017\n",
      "Validation Loss: 2046.1437\n",
      "Epoch [1221/3000], Loss: 1266.0168\n",
      "Validation Loss: 2110.3565\n",
      "Epoch [1241/3000], Loss: 1238.3302\n",
      "Validation Loss: 2068.1671\n",
      "Epoch [1261/3000], Loss: 1190.0684\n",
      "Validation Loss: 2030.1663\n",
      "Epoch [1281/3000], Loss: 1149.3520\n",
      "Validation Loss: 1990.6883\n",
      "Epoch [1301/3000], Loss: 1117.0521\n",
      "Validation Loss: 1952.6609\n",
      "Epoch [1321/3000], Loss: 1058.5743\n",
      "Validation Loss: 1907.9805\n",
      "Epoch [1341/3000], Loss: 1030.6440\n",
      "Validation Loss: 1863.7145\n",
      "Epoch [1361/3000], Loss: 991.9599\n",
      "Validation Loss: 1825.2960\n",
      "Epoch [1381/3000], Loss: 955.0835\n",
      "Validation Loss: 1783.7380\n",
      "Epoch [1401/3000], Loss: 914.5837\n",
      "Validation Loss: 1732.9673\n",
      "Epoch [1421/3000], Loss: 878.6545\n",
      "Validation Loss: 1695.7704\n",
      "Epoch [1441/3000], Loss: 849.7718\n",
      "Validation Loss: 1656.5911\n",
      "Epoch [1461/3000], Loss: 814.2478\n",
      "Validation Loss: 1621.3967\n",
      "Epoch [1481/3000], Loss: 785.6773\n",
      "Validation Loss: 1578.9585\n",
      "Epoch [1501/3000], Loss: 740.3087\n",
      "Validation Loss: 1547.4199\n",
      "Epoch [1521/3000], Loss: 714.4318\n",
      "Validation Loss: 1506.8234\n",
      "Epoch [1541/3000], Loss: 690.2494\n",
      "Validation Loss: 1474.5923\n",
      "Epoch [1561/3000], Loss: 665.2460\n",
      "Validation Loss: 1438.2824\n",
      "Epoch [1581/3000], Loss: 635.7589\n",
      "Validation Loss: 1409.8097\n",
      "Epoch [1601/3000], Loss: 608.3568\n",
      "Validation Loss: 1383.7181\n",
      "Epoch [1621/3000], Loss: 582.8738\n",
      "Validation Loss: 1364.8743\n",
      "Epoch [1641/3000], Loss: 555.1598\n",
      "Validation Loss: 1356.7041\n",
      "Epoch [1661/3000], Loss: 533.7519\n",
      "Validation Loss: 1322.9370\n",
      "Epoch [1681/3000], Loss: 516.2080\n",
      "Validation Loss: 1310.3196\n",
      "Epoch [1701/3000], Loss: 477.2307\n",
      "Validation Loss: 1294.6748\n",
      "Epoch [1721/3000], Loss: 473.5500\n",
      "Validation Loss: 1478.8331\n",
      "Epoch [1741/3000], Loss: 446.3453\n",
      "Validation Loss: 1445.5940\n",
      "Epoch [1761/3000], Loss: 430.2428\n",
      "Validation Loss: 1419.0302\n",
      "Epoch [1781/3000], Loss: 407.2799\n",
      "Validation Loss: 1387.8520\n",
      "Epoch [1801/3000], Loss: 393.4589\n",
      "Validation Loss: 1361.9538\n",
      "Epoch [1821/3000], Loss: 373.8422\n",
      "Validation Loss: 1321.0566\n",
      "Epoch [1841/3000], Loss: 359.8988\n",
      "Validation Loss: 1274.9109\n",
      "Epoch [1861/3000], Loss: 340.6229\n",
      "Validation Loss: 1232.7413\n",
      "Epoch [1881/3000], Loss: 330.0227\n",
      "Validation Loss: 1193.1776\n",
      "Epoch [1901/3000], Loss: 311.0951\n",
      "Validation Loss: 1161.7193\n",
      "Epoch [1921/3000], Loss: 293.3413\n",
      "Validation Loss: 1125.1286\n",
      "Epoch [1941/3000], Loss: 287.6188\n",
      "Validation Loss: 1097.8129\n",
      "Epoch [1961/3000], Loss: 274.8245\n",
      "Validation Loss: 1077.0411\n",
      "Epoch [1981/3000], Loss: 260.3268\n",
      "Validation Loss: 1056.2891\n",
      "Epoch [2001/3000], Loss: 244.9845\n",
      "Validation Loss: 1036.6331\n",
      "Epoch [2021/3000], Loss: 234.5146\n",
      "Validation Loss: 1027.1518\n",
      "Epoch [2041/3000], Loss: 227.2959\n",
      "Validation Loss: 1005.2424\n",
      "Epoch [2061/3000], Loss: 215.6390\n",
      "Validation Loss: 995.1963\n",
      "Epoch [2081/3000], Loss: 204.3328\n",
      "Validation Loss: 977.4036\n",
      "Epoch [2101/3000], Loss: 193.8152\n",
      "Validation Loss: 984.7014\n",
      "Epoch [2121/3000], Loss: 185.4303\n",
      "Validation Loss: 957.9634\n",
      "Epoch [2141/3000], Loss: 178.6924\n",
      "Validation Loss: 940.8982\n",
      "Epoch [2161/3000], Loss: 170.1930\n",
      "Validation Loss: 941.7115\n",
      "Epoch [2181/3000], Loss: 162.0919\n",
      "Validation Loss: 923.8863\n",
      "Epoch [2201/3000], Loss: 153.7034\n",
      "Validation Loss: 911.8677\n",
      "Epoch [2221/3000], Loss: 148.5597\n",
      "Validation Loss: 890.0382\n",
      "Epoch [2241/3000], Loss: 141.1977\n",
      "Validation Loss: 880.2043\n",
      "Epoch [2261/3000], Loss: 133.6185\n",
      "Validation Loss: 870.0086\n",
      "Epoch [2281/3000], Loss: 127.4234\n",
      "Validation Loss: 854.8070\n",
      "Epoch [2301/3000], Loss: 120.1104\n",
      "Validation Loss: 849.9470\n",
      "Epoch [2321/3000], Loss: 115.6415\n",
      "Validation Loss: 905.4638\n",
      "Epoch [2341/3000], Loss: 108.8098\n",
      "Validation Loss: 856.0245\n",
      "Epoch [2361/3000], Loss: 103.9776\n",
      "Validation Loss: 856.7457\n",
      "Epoch [2381/3000], Loss: 99.3590\n",
      "Validation Loss: 861.9656\n",
      "Epoch [2401/3000], Loss: 94.3948\n",
      "Validation Loss: 885.7443\n",
      "Epoch [2421/3000], Loss: 87.7048\n",
      "Validation Loss: 863.7787\n",
      "Epoch [2441/3000], Loss: 83.3637\n",
      "Validation Loss: 872.1818\n",
      "Epoch [2461/3000], Loss: 79.1971\n",
      "Validation Loss: 870.2156\n",
      "Epoch [2481/3000], Loss: 72.6369\n",
      "Validation Loss: 884.0775\n",
      "Epoch [2501/3000], Loss: 67.0993\n",
      "Validation Loss: 877.5641\n",
      "Epoch [2521/3000], Loss: 64.5518\n",
      "Validation Loss: 889.0127\n",
      "Epoch [2541/3000], Loss: 60.9097\n",
      "Validation Loss: 888.8995\n",
      "Epoch [2561/3000], Loss: 54.2948\n",
      "Validation Loss: 894.1817\n",
      "Epoch [2581/3000], Loss: 53.4031\n",
      "Validation Loss: 904.6744\n",
      "Epoch [2601/3000], Loss: 48.1275\n",
      "Validation Loss: 896.9984\n",
      "Epoch [2621/3000], Loss: 44.8904\n",
      "Validation Loss: 882.7096\n",
      "Epoch [2641/3000], Loss: 42.2632\n",
      "Validation Loss: 883.6189\n",
      "Epoch [2661/3000], Loss: 37.9441\n",
      "Validation Loss: 887.3405\n",
      "Epoch [2681/3000], Loss: 34.4551\n",
      "Validation Loss: 881.8508\n",
      "Epoch [2701/3000], Loss: 33.0093\n",
      "Validation Loss: 881.4582\n",
      "Epoch [2721/3000], Loss: 29.4955\n",
      "Validation Loss: 877.5312\n",
      "Epoch [2741/3000], Loss: 27.1813\n",
      "Validation Loss: 884.3266\n",
      "Epoch [2761/3000], Loss: 24.9750\n",
      "Validation Loss: 874.1398\n",
      "Epoch [2781/3000], Loss: 22.8186\n",
      "Validation Loss: 870.3293\n",
      "Epoch [2801/3000], Loss: 20.4789\n",
      "Validation Loss: 872.6728\n",
      "Epoch [2821/3000], Loss: 18.7980\n",
      "Validation Loss: 865.8107\n",
      "Epoch [2841/3000], Loss: 16.6899\n",
      "Validation Loss: 854.2308\n",
      "Epoch [2861/3000], Loss: 14.9236\n",
      "Validation Loss: 859.6199\n",
      "Epoch [2881/3000], Loss: 13.5251\n",
      "Validation Loss: 851.3590\n",
      "Epoch [2901/3000], Loss: 11.8888\n",
      "Validation Loss: 869.0970\n",
      "Epoch [2921/3000], Loss: 10.8372\n",
      "Validation Loss: 874.7951\n",
      "Epoch [2941/3000], Loss: 9.6337\n",
      "Validation Loss: 874.9548\n",
      "Epoch [2961/3000], Loss: 8.4037\n",
      "Validation Loss: 861.5320\n",
      "Epoch [2981/3000], Loss: 7.5009\n",
      "Validation Loss: 851.2629\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day071_plane0_Fall.mat\n",
      "(6565, 1045)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7807.6268\n",
      "Validation Loss: 10264.0059\n",
      "Epoch [21/3000], Loss: 6758.0577\n",
      "Validation Loss: 8947.9229\n",
      "Epoch [41/3000], Loss: 6486.1830\n",
      "Validation Loss: 8677.5893\n",
      "Epoch [61/3000], Loss: 6317.6654\n",
      "Validation Loss: 8475.4854\n",
      "Epoch [81/3000], Loss: 6189.8254\n",
      "Validation Loss: 8301.4143\n",
      "Epoch [101/3000], Loss: 6078.0033\n",
      "Validation Loss: 8137.3438\n",
      "Epoch [121/3000], Loss: 5957.8106\n",
      "Validation Loss: 7980.1083\n",
      "Epoch [141/3000], Loss: 5805.0061\n",
      "Validation Loss: 7827.9107\n",
      "Epoch [161/3000], Loss: 5689.1201\n",
      "Validation Loss: 7680.0065\n",
      "Epoch [181/3000], Loss: 5592.3048\n",
      "Validation Loss: 7535.9912\n",
      "Epoch [201/3000], Loss: 5483.2738\n",
      "Validation Loss: 7395.6518\n",
      "Epoch [221/3000], Loss: 5369.1591\n",
      "Validation Loss: 7258.4479\n",
      "Epoch [241/3000], Loss: 5280.9821\n",
      "Validation Loss: 7124.4835\n",
      "Epoch [261/3000], Loss: 5182.0008\n",
      "Validation Loss: 6994.0967\n",
      "Epoch [281/3000], Loss: 5068.8979\n",
      "Validation Loss: 6866.6749\n",
      "Epoch [301/3000], Loss: 4973.4436\n",
      "Validation Loss: 6739.2463\n",
      "Epoch [321/3000], Loss: 4868.2254\n",
      "Validation Loss: 6617.4232\n",
      "Epoch [341/3000], Loss: 4788.2962\n",
      "Validation Loss: 6498.5185\n",
      "Epoch [361/3000], Loss: 4690.7639\n",
      "Validation Loss: 6381.5798\n",
      "Epoch [381/3000], Loss: 4327.0918\n",
      "Validation Loss: 6074.0996\n",
      "Epoch [401/3000], Loss: 4208.2173\n",
      "Validation Loss: 5953.6861\n",
      "Epoch [421/3000], Loss: 4090.5681\n",
      "Validation Loss: 5840.7488\n",
      "Epoch [441/3000], Loss: 3966.0648\n",
      "Validation Loss: 5705.4152\n",
      "Epoch [461/3000], Loss: 3886.4226\n",
      "Validation Loss: 5590.8089\n",
      "Epoch [481/3000], Loss: 3778.8478\n",
      "Validation Loss: 5477.0624\n",
      "Epoch [501/3000], Loss: 3661.6330\n",
      "Validation Loss: 5356.7867\n",
      "Epoch [521/3000], Loss: 3567.0612\n",
      "Validation Loss: 5247.5237\n",
      "Epoch [541/3000], Loss: 3484.2865\n",
      "Validation Loss: 5136.9258\n",
      "Epoch [561/3000], Loss: 3383.0396\n",
      "Validation Loss: 5025.5904\n",
      "Epoch [581/3000], Loss: 3278.2189\n",
      "Validation Loss: 4914.6729\n",
      "Epoch [601/3000], Loss: 3192.2482\n",
      "Validation Loss: 4809.8551\n",
      "Epoch [621/3000], Loss: 3107.3079\n",
      "Validation Loss: 4706.0701\n",
      "Epoch [641/3000], Loss: 3020.1039\n",
      "Validation Loss: 4605.2201\n",
      "Epoch [661/3000], Loss: 2936.7224\n",
      "Validation Loss: 4504.6443\n",
      "Epoch [681/3000], Loss: 2858.6529\n",
      "Validation Loss: 4404.4414\n",
      "Epoch [701/3000], Loss: 2791.2535\n",
      "Validation Loss: 4304.5994\n",
      "Epoch [721/3000], Loss: 2688.1538\n",
      "Validation Loss: 4209.1663\n",
      "Epoch [741/3000], Loss: 2637.4308\n",
      "Validation Loss: 4113.9357\n",
      "Epoch [761/3000], Loss: 2569.4722\n",
      "Validation Loss: 4022.7076\n",
      "Epoch [781/3000], Loss: 2495.2191\n",
      "Validation Loss: 3931.5442\n",
      "Epoch [801/3000], Loss: 2398.3787\n",
      "Validation Loss: 3842.1846\n",
      "Epoch [821/3000], Loss: 2328.7902\n",
      "Validation Loss: 3742.8450\n",
      "Epoch [841/3000], Loss: 2264.9845\n",
      "Validation Loss: 3654.6374\n",
      "Epoch [861/3000], Loss: 2192.6016\n",
      "Validation Loss: 3569.0773\n",
      "Epoch [881/3000], Loss: 2132.1684\n",
      "Validation Loss: 3475.7130\n",
      "Epoch [901/3000], Loss: 2058.3773\n",
      "Validation Loss: 3392.4592\n",
      "Epoch [921/3000], Loss: 2022.1247\n",
      "Validation Loss: 3312.0158\n",
      "Epoch [941/3000], Loss: 1939.4006\n",
      "Validation Loss: 3242.2277\n",
      "Epoch [961/3000], Loss: 1874.2544\n",
      "Validation Loss: 3176.0190\n",
      "Epoch [981/3000], Loss: 1814.7996\n",
      "Validation Loss: 3085.4538\n",
      "Epoch [1001/3000], Loss: 1762.6579\n",
      "Validation Loss: 3003.5928\n",
      "Epoch [1021/3000], Loss: 1710.9791\n",
      "Validation Loss: 2923.5835\n",
      "Epoch [1041/3000], Loss: 1651.9591\n",
      "Validation Loss: 2846.7777\n",
      "Epoch [1061/3000], Loss: 1610.9435\n",
      "Validation Loss: 2780.0016\n",
      "Epoch [1081/3000], Loss: 1550.9678\n",
      "Validation Loss: 2714.8536\n",
      "Epoch [1101/3000], Loss: 1493.3182\n",
      "Validation Loss: 2638.0714\n",
      "Epoch [1121/3000], Loss: 1444.8213\n",
      "Validation Loss: 2594.9409\n",
      "Epoch [1141/3000], Loss: 1393.7799\n",
      "Validation Loss: 2510.4758\n",
      "Epoch [1161/3000], Loss: 1341.4266\n",
      "Validation Loss: 2449.2171\n",
      "Epoch [1181/3000], Loss: 1299.8534\n",
      "Validation Loss: 2387.4741\n",
      "Epoch [1201/3000], Loss: 1255.7735\n",
      "Validation Loss: 2329.1440\n",
      "Epoch [1221/3000], Loss: 1205.1421\n",
      "Validation Loss: 2275.6085\n",
      "Epoch [1241/3000], Loss: 1172.6059\n",
      "Validation Loss: 2221.1011\n",
      "Epoch [1261/3000], Loss: 1125.8525\n",
      "Validation Loss: 2171.0180\n",
      "Epoch [1281/3000], Loss: 1095.3073\n",
      "Validation Loss: 2110.4783\n",
      "Epoch [1301/3000], Loss: 1052.0722\n",
      "Validation Loss: 2077.1405\n",
      "Epoch [1321/3000], Loss: 1009.0207\n",
      "Validation Loss: 2067.5480\n",
      "Epoch [1341/3000], Loss: 969.9424\n",
      "Validation Loss: 1997.9299\n",
      "Epoch [1361/3000], Loss: 946.0040\n",
      "Validation Loss: 1944.3602\n",
      "Epoch [1381/3000], Loss: 904.6402\n",
      "Validation Loss: 1899.6717\n",
      "Epoch [1401/3000], Loss: 878.6417\n",
      "Validation Loss: 1862.7976\n",
      "Epoch [1421/3000], Loss: 837.4075\n",
      "Validation Loss: 1822.1919\n",
      "Epoch [1441/3000], Loss: 802.6688\n",
      "Validation Loss: 1795.0105\n",
      "Epoch [1461/3000], Loss: 771.7021\n",
      "Validation Loss: 1740.9471\n",
      "Epoch [1481/3000], Loss: 738.5210\n",
      "Validation Loss: 1697.2465\n",
      "Epoch [1501/3000], Loss: 713.1052\n",
      "Validation Loss: 1648.2746\n",
      "Epoch [1521/3000], Loss: 681.2398\n",
      "Validation Loss: 1617.1230\n",
      "Epoch [1541/3000], Loss: 652.4088\n",
      "Validation Loss: 1581.7031\n",
      "Epoch [1561/3000], Loss: 624.0800\n",
      "Validation Loss: 1546.9232\n",
      "Epoch [1581/3000], Loss: 596.5060\n",
      "Validation Loss: 1516.3395\n",
      "Epoch [1601/3000], Loss: 568.4629\n",
      "Validation Loss: 1461.8091\n",
      "Epoch [1621/3000], Loss: 544.3618\n",
      "Validation Loss: 1435.0152\n",
      "Epoch [1641/3000], Loss: 517.8976\n",
      "Validation Loss: 1391.7773\n",
      "Epoch [1661/3000], Loss: 493.8104\n",
      "Validation Loss: 1380.2036\n",
      "Epoch [1681/3000], Loss: 470.4363\n",
      "Validation Loss: 1344.2521\n",
      "Epoch [1701/3000], Loss: 447.8089\n",
      "Validation Loss: 1309.3922\n",
      "Epoch [1721/3000], Loss: 427.2019\n",
      "Validation Loss: 1291.8622\n",
      "Epoch [1741/3000], Loss: 401.2886\n",
      "Validation Loss: 1265.7502\n",
      "Epoch [1761/3000], Loss: 382.4663\n",
      "Validation Loss: 1240.7489\n",
      "Epoch [1781/3000], Loss: 359.8834\n",
      "Validation Loss: 1215.9928\n",
      "Epoch [1801/3000], Loss: 342.7336\n",
      "Validation Loss: 1189.8885\n",
      "Epoch [1821/3000], Loss: 323.0157\n",
      "Validation Loss: 1162.5274\n",
      "Epoch [1841/3000], Loss: 308.6749\n",
      "Validation Loss: 1139.9051\n",
      "Epoch [1861/3000], Loss: 287.6441\n",
      "Validation Loss: 1120.6067\n",
      "Epoch [1881/3000], Loss: 273.0852\n",
      "Validation Loss: 1097.8994\n",
      "Epoch [1901/3000], Loss: 257.1266\n",
      "Validation Loss: 1089.8873\n",
      "Epoch [1921/3000], Loss: 241.4439\n",
      "Validation Loss: 1076.7672\n",
      "Epoch [1941/3000], Loss: 225.2010\n",
      "Validation Loss: 1068.0687\n",
      "Epoch [1961/3000], Loss: 211.3847\n",
      "Validation Loss: 1066.0624\n",
      "Epoch [1981/3000], Loss: 199.9608\n",
      "Validation Loss: 1065.9034\n",
      "Epoch [2001/3000], Loss: 187.8476\n",
      "Validation Loss: 1049.1089\n",
      "Epoch [2021/3000], Loss: 174.9806\n",
      "Validation Loss: 1023.5018\n",
      "Epoch [2041/3000], Loss: 163.9646\n",
      "Validation Loss: 1025.8318\n",
      "Epoch [2061/3000], Loss: 152.5823\n",
      "Validation Loss: 1031.0277\n",
      "Epoch [2081/3000], Loss: 142.4858\n",
      "Validation Loss: 1024.8360\n",
      "Epoch [2101/3000], Loss: 130.6695\n",
      "Validation Loss: 1017.7417\n",
      "Epoch [2121/3000], Loss: 123.5758\n",
      "Validation Loss: 1008.5751\n",
      "Epoch [2141/3000], Loss: 114.0788\n",
      "Validation Loss: 1014.4082\n",
      "Epoch [2161/3000], Loss: 105.0877\n",
      "Validation Loss: 1011.9418\n",
      "Epoch [2181/3000], Loss: 98.2073\n",
      "Validation Loss: 1022.6619\n",
      "Epoch [2201/3000], Loss: 90.3627\n",
      "Validation Loss: 1014.4256\n",
      "Epoch [2221/3000], Loss: 82.8575\n",
      "Validation Loss: 1019.2614\n",
      "Epoch [2241/3000], Loss: 75.0149\n",
      "Validation Loss: 1019.0610\n",
      "Epoch [2261/3000], Loss: 68.7154\n",
      "Validation Loss: 1015.6655\n",
      "Epoch [2281/3000], Loss: 63.7854\n",
      "Validation Loss: 1004.4863\n",
      "Epoch [2301/3000], Loss: 58.1369\n",
      "Validation Loss: 996.8467\n",
      "Epoch [2321/3000], Loss: 52.8605\n",
      "Validation Loss: 999.6275\n",
      "Epoch [2341/3000], Loss: 47.4839\n",
      "Validation Loss: 1000.0102\n",
      "Epoch [2361/3000], Loss: 43.2072\n",
      "Validation Loss: 999.5889\n",
      "Epoch [2381/3000], Loss: 39.2130\n",
      "Validation Loss: 1005.2578\n",
      "Epoch [2401/3000], Loss: 35.0638\n",
      "Validation Loss: 1014.4689\n",
      "Epoch [2421/3000], Loss: 31.6986\n",
      "Validation Loss: 1017.5325\n",
      "Epoch [2441/3000], Loss: 28.1765\n",
      "Validation Loss: 1022.3573\n",
      "Epoch [2461/3000], Loss: 24.4052\n",
      "Validation Loss: 1017.2609\n",
      "Epoch [2481/3000], Loss: 22.1099\n",
      "Validation Loss: 1033.6099\n",
      "Epoch [2501/3000], Loss: 19.5192\n",
      "Validation Loss: 1024.4115\n",
      "Epoch [2521/3000], Loss: 17.2052\n",
      "Validation Loss: 1029.5467\n",
      "Epoch [2541/3000], Loss: 14.8508\n",
      "Validation Loss: 1017.0190\n",
      "Epoch [2561/3000], Loss: 12.9849\n",
      "Validation Loss: 1019.0553\n",
      "Epoch [2581/3000], Loss: 11.1963\n",
      "Validation Loss: 1011.7244\n",
      "Epoch [2601/3000], Loss: 9.6342\n",
      "Validation Loss: 1008.3984\n",
      "Epoch [2621/3000], Loss: 8.0261\n",
      "Validation Loss: 1016.4491\n",
      "Epoch [2641/3000], Loss: 6.9150\n",
      "Validation Loss: 1013.9372\n",
      "Epoch [2661/3000], Loss: 5.8100\n",
      "Validation Loss: 1013.1326\n",
      "Epoch [2681/3000], Loss: 4.8045\n",
      "Validation Loss: 1018.8502\n",
      "Epoch [2701/3000], Loss: 3.9821\n",
      "Validation Loss: 1021.2256\n",
      "Epoch [2721/3000], Loss: 3.2303\n",
      "Validation Loss: 1017.7260\n",
      "Epoch [2741/3000], Loss: 2.5797\n",
      "Validation Loss: 1021.8034\n",
      "Epoch [2761/3000], Loss: 2.0323\n",
      "Validation Loss: 1027.6154\n",
      "Epoch [2781/3000], Loss: 1.6161\n",
      "Validation Loss: 1026.9101\n",
      "Epoch [2801/3000], Loss: 1.2038\n",
      "Validation Loss: 1015.8230\n",
      "Epoch [2821/3000], Loss: 0.9224\n",
      "Validation Loss: 1017.4848\n",
      "Epoch [2841/3000], Loss: 0.6616\n",
      "Validation Loss: 1019.0163\n",
      "Epoch [2861/3000], Loss: 0.4758\n",
      "Validation Loss: 1009.1853\n",
      "Epoch [2881/3000], Loss: 0.3273\n",
      "Validation Loss: 1018.4026\n",
      "Epoch [2901/3000], Loss: 0.2196\n",
      "Validation Loss: 1020.3124\n",
      "Epoch [2921/3000], Loss: 0.1426\n",
      "Validation Loss: 1022.2947\n",
      "Epoch [2941/3000], Loss: 0.0918\n",
      "Validation Loss: 1023.0694\n",
      "Epoch [2961/3000], Loss: 0.0633\n",
      "Validation Loss: 1026.1821\n",
      "Epoch [2981/3000], Loss: 0.0376\n",
      "Validation Loss: 1028.9599\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day072_plane0_Fall.mat\n",
      "(8386, 1131)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8647.3107\n",
      "Validation Loss: 11916.2780\n",
      "Epoch [21/3000], Loss: 7416.1325\n",
      "Validation Loss: 10313.0687\n",
      "Epoch [41/3000], Loss: 7148.7672\n",
      "Validation Loss: 9996.1088\n",
      "Epoch [61/3000], Loss: 6983.4745\n",
      "Validation Loss: 9734.8857\n",
      "Epoch [81/3000], Loss: 6772.2707\n",
      "Validation Loss: 9492.3471\n",
      "Epoch [101/3000], Loss: 6607.3583\n",
      "Validation Loss: 9261.7880\n",
      "Epoch [121/3000], Loss: 6465.2286\n",
      "Validation Loss: 9039.5490\n",
      "Epoch [141/3000], Loss: 6307.0358\n",
      "Validation Loss: 8824.1974\n",
      "Epoch [161/3000], Loss: 6159.2125\n",
      "Validation Loss: 8614.7052\n",
      "Epoch [181/3000], Loss: 6012.7546\n",
      "Validation Loss: 8411.2153\n",
      "Epoch [201/3000], Loss: 5841.5927\n",
      "Validation Loss: 8213.2431\n",
      "Epoch [221/3000], Loss: 5730.8749\n",
      "Validation Loss: 8020.4286\n",
      "Epoch [241/3000], Loss: 5584.3152\n",
      "Validation Loss: 7833.1116\n",
      "Epoch [261/3000], Loss: 5487.2681\n",
      "Validation Loss: 7650.6247\n",
      "Epoch [281/3000], Loss: 5346.5034\n",
      "Validation Loss: 7473.5134\n",
      "Epoch [301/3000], Loss: 5210.4799\n",
      "Validation Loss: 7301.6866\n",
      "Epoch [321/3000], Loss: 5119.0457\n",
      "Validation Loss: 7135.0798\n",
      "Epoch [341/3000], Loss: 5022.5755\n",
      "Validation Loss: 6973.3193\n",
      "Epoch [361/3000], Loss: 4919.8772\n",
      "Validation Loss: 6816.6708\n",
      "Epoch [381/3000], Loss: 4803.2752\n",
      "Validation Loss: 6665.3577\n",
      "Epoch [401/3000], Loss: 4719.8684\n",
      "Validation Loss: 6519.2664\n",
      "Epoch [421/3000], Loss: 4639.1021\n",
      "Validation Loss: 6378.1263\n",
      "Epoch [441/3000], Loss: 4555.7885\n",
      "Validation Loss: 6241.9361\n",
      "Epoch [461/3000], Loss: 4466.0470\n",
      "Validation Loss: 6110.9801\n",
      "Epoch [481/3000], Loss: 4408.1144\n",
      "Validation Loss: 5984.0627\n",
      "Epoch [501/3000], Loss: 4336.4126\n",
      "Validation Loss: 5862.5883\n",
      "Epoch [521/3000], Loss: 4293.9951\n",
      "Validation Loss: 5746.7113\n",
      "Epoch [541/3000], Loss: 4217.8674\n",
      "Validation Loss: 5635.7924\n",
      "Epoch [561/3000], Loss: 4171.5816\n",
      "Validation Loss: 5530.2716\n",
      "Epoch [581/3000], Loss: 4104.8032\n",
      "Validation Loss: 5429.9382\n",
      "Epoch [601/3000], Loss: 3572.4909\n",
      "Validation Loss: 4828.2951\n",
      "Epoch [621/3000], Loss: 2967.5166\n",
      "Validation Loss: 4517.9995\n",
      "Epoch [641/3000], Loss: 2829.5896\n",
      "Validation Loss: 4346.9258\n",
      "Epoch [661/3000], Loss: 2728.3608\n",
      "Validation Loss: 4239.1057\n",
      "Epoch [681/3000], Loss: 2617.6760\n",
      "Validation Loss: 4070.1319\n",
      "Epoch [701/3000], Loss: 2518.0822\n",
      "Validation Loss: 3946.5321\n",
      "Epoch [721/3000], Loss: 2423.7381\n",
      "Validation Loss: 3819.5718\n",
      "Epoch [741/3000], Loss: 2332.1890\n",
      "Validation Loss: 3686.8292\n",
      "Epoch [761/3000], Loss: 2238.5634\n",
      "Validation Loss: 3560.6499\n",
      "Epoch [781/3000], Loss: 2148.1010\n",
      "Validation Loss: 3441.6131\n",
      "Epoch [801/3000], Loss: 2046.5191\n",
      "Validation Loss: 3329.4794\n",
      "Epoch [821/3000], Loss: 1970.8383\n",
      "Validation Loss: 3213.0669\n",
      "Epoch [841/3000], Loss: 1886.4570\n",
      "Validation Loss: 3107.0297\n",
      "Epoch [861/3000], Loss: 1809.9238\n",
      "Validation Loss: 2983.8219\n",
      "Epoch [881/3000], Loss: 1735.6568\n",
      "Validation Loss: 2881.1034\n",
      "Epoch [901/3000], Loss: 1660.4413\n",
      "Validation Loss: 2774.6873\n",
      "Epoch [921/3000], Loss: 1573.3905\n",
      "Validation Loss: 2677.7633\n",
      "Epoch [941/3000], Loss: 1513.8209\n",
      "Validation Loss: 2600.9073\n",
      "Epoch [961/3000], Loss: 1440.4788\n",
      "Validation Loss: 2497.1994\n",
      "Epoch [981/3000], Loss: 1373.4127\n",
      "Validation Loss: 2400.7608\n",
      "Epoch [1001/3000], Loss: 1318.4166\n",
      "Validation Loss: 2307.8243\n",
      "Epoch [1021/3000], Loss: 1249.0910\n",
      "Validation Loss: 2225.4463\n",
      "Epoch [1041/3000], Loss: 1188.5969\n",
      "Validation Loss: 2138.0479\n",
      "Epoch [1061/3000], Loss: 1131.5864\n",
      "Validation Loss: 2061.7706\n",
      "Epoch [1081/3000], Loss: 1065.3130\n",
      "Validation Loss: 1980.5672\n",
      "Epoch [1101/3000], Loss: 1015.1021\n",
      "Validation Loss: 1907.7572\n",
      "Epoch [1121/3000], Loss: 963.7545\n",
      "Validation Loss: 1836.6759\n",
      "Epoch [1141/3000], Loss: 912.1101\n",
      "Validation Loss: 1769.7845\n",
      "Epoch [1161/3000], Loss: 859.3093\n",
      "Validation Loss: 1706.2629\n",
      "Epoch [1181/3000], Loss: 817.6234\n",
      "Validation Loss: 1644.9723\n",
      "Epoch [1201/3000], Loss: 774.2648\n",
      "Validation Loss: 1589.8345\n",
      "Epoch [1221/3000], Loss: 782.2886\n",
      "Validation Loss: 1527.6779\n",
      "Epoch [1241/3000], Loss: 683.7604\n",
      "Validation Loss: 1493.6175\n",
      "Epoch [1261/3000], Loss: 642.7659\n",
      "Validation Loss: 1440.4425\n",
      "Epoch [1281/3000], Loss: 606.2560\n",
      "Validation Loss: 1389.0714\n",
      "Epoch [1301/3000], Loss: 569.4775\n",
      "Validation Loss: 1345.4503\n",
      "Epoch [1321/3000], Loss: 535.1323\n",
      "Validation Loss: 1303.9503\n",
      "Epoch [1341/3000], Loss: 503.7361\n",
      "Validation Loss: 1269.9898\n",
      "Epoch [1361/3000], Loss: 468.0463\n",
      "Validation Loss: 1236.6445\n",
      "Epoch [1381/3000], Loss: 436.3204\n",
      "Validation Loss: 1209.7994\n",
      "Epoch [1401/3000], Loss: 406.2546\n",
      "Validation Loss: 1173.4070\n",
      "Epoch [1421/3000], Loss: 381.1854\n",
      "Validation Loss: 1145.9246\n",
      "Epoch [1441/3000], Loss: 352.9448\n",
      "Validation Loss: 1126.4895\n",
      "Epoch [1461/3000], Loss: 327.9529\n",
      "Validation Loss: 1104.0017\n",
      "Epoch [1481/3000], Loss: 304.1485\n",
      "Validation Loss: 1079.8223\n",
      "Epoch [1501/3000], Loss: 280.9059\n",
      "Validation Loss: 1057.9926\n",
      "Epoch [1521/3000], Loss: 259.9383\n",
      "Validation Loss: 1037.1443\n",
      "Epoch [1541/3000], Loss: 240.0592\n",
      "Validation Loss: 1016.0060\n",
      "Epoch [1561/3000], Loss: 221.9607\n",
      "Validation Loss: 994.3556\n",
      "Epoch [1581/3000], Loss: 202.6198\n",
      "Validation Loss: 971.6967\n",
      "Epoch [1601/3000], Loss: 185.9359\n",
      "Validation Loss: 949.7107\n",
      "Epoch [1621/3000], Loss: 169.8067\n",
      "Validation Loss: 929.6409\n",
      "Epoch [1641/3000], Loss: 154.4745\n",
      "Validation Loss: 919.9445\n",
      "Epoch [1661/3000], Loss: 140.3680\n",
      "Validation Loss: 911.9175\n",
      "Epoch [1681/3000], Loss: 127.4482\n",
      "Validation Loss: 901.0934\n",
      "Epoch [1701/3000], Loss: 117.8654\n",
      "Validation Loss: 905.4389\n",
      "Epoch [1721/3000], Loss: 103.2612\n",
      "Validation Loss: 894.8294\n",
      "Epoch [1741/3000], Loss: 93.2800\n",
      "Validation Loss: 890.1124\n",
      "Epoch [1761/3000], Loss: 83.4341\n",
      "Validation Loss: 891.1914\n",
      "Epoch [1781/3000], Loss: 75.1467\n",
      "Validation Loss: 894.6581\n",
      "Epoch [1801/3000], Loss: 66.4015\n",
      "Validation Loss: 899.4661\n",
      "Epoch [1821/3000], Loss: 58.7013\n",
      "Validation Loss: 904.8790\n",
      "Epoch [1841/3000], Loss: 51.1691\n",
      "Validation Loss: 911.0946\n",
      "Epoch [1861/3000], Loss: 44.9454\n",
      "Validation Loss: 917.5941\n",
      "Epoch [1881/3000], Loss: 39.2849\n",
      "Validation Loss: 923.0715\n",
      "Epoch [1901/3000], Loss: 33.9300\n",
      "Validation Loss: 928.2759\n",
      "Epoch [1921/3000], Loss: 28.8596\n",
      "Validation Loss: 930.2676\n",
      "Epoch [1941/3000], Loss: 24.8877\n",
      "Validation Loss: 939.3487\n",
      "Epoch [1961/3000], Loss: 21.1773\n",
      "Validation Loss: 944.9006\n",
      "Epoch [1981/3000], Loss: 17.6002\n",
      "Validation Loss: 950.9672\n",
      "Epoch [2001/3000], Loss: 14.8189\n",
      "Validation Loss: 965.8901\n",
      "Epoch [2021/3000], Loss: 12.0649\n",
      "Validation Loss: 975.6312\n",
      "Epoch [2041/3000], Loss: 9.8700\n",
      "Validation Loss: 982.9511\n",
      "Epoch [2061/3000], Loss: 7.9630\n",
      "Validation Loss: 989.5299\n",
      "Epoch [2081/3000], Loss: 6.4294\n",
      "Validation Loss: 991.3858\n",
      "Epoch [2101/3000], Loss: 5.0890\n",
      "Validation Loss: 991.2566\n",
      "Epoch [2121/3000], Loss: 3.9613\n",
      "Validation Loss: 992.3331\n",
      "Epoch [2141/3000], Loss: 3.0769\n",
      "Validation Loss: 994.1651\n",
      "Epoch [2161/3000], Loss: 2.2681\n",
      "Validation Loss: 997.9391\n",
      "Epoch [2181/3000], Loss: 1.6858\n",
      "Validation Loss: 1001.9910\n",
      "Epoch [2201/3000], Loss: 1.2141\n",
      "Validation Loss: 1006.7144\n",
      "Epoch [2221/3000], Loss: 0.8268\n",
      "Validation Loss: 1004.1061\n",
      "Epoch [2241/3000], Loss: 0.5493\n",
      "Validation Loss: 1000.9144\n",
      "Epoch [2261/3000], Loss: 0.3745\n",
      "Validation Loss: 998.4368\n",
      "Epoch [2281/3000], Loss: 0.2428\n",
      "Validation Loss: 995.0650\n",
      "Epoch [2301/3000], Loss: 0.1589\n",
      "Validation Loss: 990.3966\n",
      "Epoch [2321/3000], Loss: 0.1125\n",
      "Validation Loss: 980.5871\n",
      "Epoch [2341/3000], Loss: 0.0861\n",
      "Validation Loss: 976.0150\n",
      "Epoch [2361/3000], Loss: 0.0727\n",
      "Validation Loss: 974.6920\n",
      "Epoch [2381/3000], Loss: 0.0625\n",
      "Validation Loss: 970.3868\n",
      "Epoch [2401/3000], Loss: 0.0584\n",
      "Validation Loss: 970.3237\n",
      "Epoch [2421/3000], Loss: 0.0449\n",
      "Validation Loss: 968.9658\n",
      "Epoch [2441/3000], Loss: 0.0416\n",
      "Validation Loss: 967.1319\n",
      "Epoch [2461/3000], Loss: 0.0445\n",
      "Validation Loss: 966.2513\n",
      "Epoch [2481/3000], Loss: 0.0439\n",
      "Validation Loss: 967.2892\n",
      "Epoch [2501/3000], Loss: 0.0352\n",
      "Validation Loss: 964.1590\n",
      "Epoch [2521/3000], Loss: 0.0338\n",
      "Validation Loss: 963.8858\n",
      "Epoch [2541/3000], Loss: 0.0344\n",
      "Validation Loss: 960.8980\n",
      "Epoch [2561/3000], Loss: 0.0356\n",
      "Validation Loss: 963.1281\n",
      "Epoch [2581/3000], Loss: 0.0268\n",
      "Validation Loss: 961.5856\n",
      "Epoch [2601/3000], Loss: 0.0237\n",
      "Validation Loss: 961.1614\n",
      "Epoch [2621/3000], Loss: 0.1277\n",
      "Validation Loss: 991.8340\n",
      "Epoch [2641/3000], Loss: 0.0410\n",
      "Validation Loss: 990.9522\n",
      "Epoch [2661/3000], Loss: 0.0299\n",
      "Validation Loss: 989.8637\n",
      "Epoch [2681/3000], Loss: 0.0250\n",
      "Validation Loss: 988.6333\n",
      "Epoch [2701/3000], Loss: 0.0226\n",
      "Validation Loss: 987.1404\n",
      "Epoch [2721/3000], Loss: 0.0218\n",
      "Validation Loss: 985.6168\n",
      "Epoch [2741/3000], Loss: 0.0203\n",
      "Validation Loss: 985.4404\n",
      "Epoch [2761/3000], Loss: 0.0197\n",
      "Validation Loss: 983.2908\n",
      "Epoch [2781/3000], Loss: 0.0204\n",
      "Validation Loss: 982.2086\n",
      "Epoch [2801/3000], Loss: 0.0194\n",
      "Validation Loss: 981.1178\n",
      "Epoch [2821/3000], Loss: 0.0210\n",
      "Validation Loss: 981.1830\n",
      "Epoch [2841/3000], Loss: 0.0202\n",
      "Validation Loss: 980.6566\n",
      "Epoch [2861/3000], Loss: 0.0190\n",
      "Validation Loss: 977.8828\n",
      "Epoch [2881/3000], Loss: 0.0205\n",
      "Validation Loss: 976.4920\n",
      "Epoch [2901/3000], Loss: 0.0190\n",
      "Validation Loss: 976.8207\n",
      "Epoch [2921/3000], Loss: 0.0195\n",
      "Validation Loss: 976.0580\n",
      "Epoch [2941/3000], Loss: 0.0208\n",
      "Validation Loss: 974.7808\n",
      "Epoch [2961/3000], Loss: 0.0175\n",
      "Validation Loss: 974.4554\n",
      "Epoch [2981/3000], Loss: 0.0256\n",
      "Validation Loss: 971.6211\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day073_plane0_Fall.mat\n",
      "(5068, 919)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 6563.5086\n",
      "Validation Loss: 5708.7444\n",
      "Epoch [21/3000], Loss: 5700.5175\n",
      "Validation Loss: 4921.9240\n",
      "Epoch [41/3000], Loss: 5526.4866\n",
      "Validation Loss: 4738.2117\n",
      "Epoch [61/3000], Loss: 5378.1164\n",
      "Validation Loss: 4627.9504\n",
      "Epoch [81/3000], Loss: 5273.0247\n",
      "Validation Loss: 4536.5114\n",
      "Epoch [101/3000], Loss: 5151.4618\n",
      "Validation Loss: 4452.7717\n",
      "Epoch [121/3000], Loss: 5095.2870\n",
      "Validation Loss: 4373.7197\n",
      "Epoch [141/3000], Loss: 5030.9931\n",
      "Validation Loss: 4296.9421\n",
      "Epoch [161/3000], Loss: 4903.9715\n",
      "Validation Loss: 4223.9469\n",
      "Epoch [181/3000], Loss: 4797.5416\n",
      "Validation Loss: 4153.6947\n",
      "Epoch [201/3000], Loss: 4753.9975\n",
      "Validation Loss: 4085.7713\n",
      "Epoch [221/3000], Loss: 4695.7974\n",
      "Validation Loss: 4019.9335\n",
      "Epoch [241/3000], Loss: 4585.4928\n",
      "Validation Loss: 3956.1997\n",
      "Epoch [261/3000], Loss: 4534.3219\n",
      "Validation Loss: 3894.4572\n",
      "Epoch [281/3000], Loss: 4486.0764\n",
      "Validation Loss: 3834.4199\n",
      "Epoch [301/3000], Loss: 4404.9395\n",
      "Validation Loss: 3776.2289\n",
      "Epoch [321/3000], Loss: 4349.0284\n",
      "Validation Loss: 3719.9678\n",
      "Epoch [341/3000], Loss: 4279.0407\n",
      "Validation Loss: 3665.4411\n",
      "Epoch [361/3000], Loss: 4207.1429\n",
      "Validation Loss: 3612.7786\n",
      "Epoch [381/3000], Loss: 4154.4648\n",
      "Validation Loss: 3561.7852\n",
      "Epoch [401/3000], Loss: 4100.8658\n",
      "Validation Loss: 3512.6358\n",
      "Epoch [421/3000], Loss: 4016.9030\n",
      "Validation Loss: 3465.2684\n",
      "Epoch [441/3000], Loss: 3993.4826\n",
      "Validation Loss: 3419.5263\n",
      "Epoch [461/3000], Loss: 3920.5216\n",
      "Validation Loss: 3375.5417\n",
      "Epoch [481/3000], Loss: 3869.7554\n",
      "Validation Loss: 3333.1759\n",
      "Epoch [501/3000], Loss: 3835.3962\n",
      "Validation Loss: 3292.6153\n",
      "Epoch [521/3000], Loss: 3753.7475\n",
      "Validation Loss: 3253.7062\n",
      "Epoch [541/3000], Loss: 3708.5788\n",
      "Validation Loss: 3216.5409\n",
      "Epoch [561/3000], Loss: 3677.2830\n",
      "Validation Loss: 3181.0153\n",
      "Epoch [581/3000], Loss: 3618.8522\n",
      "Validation Loss: 3147.1348\n",
      "Epoch [601/3000], Loss: 3575.3387\n",
      "Validation Loss: 3115.0572\n",
      "Epoch [621/3000], Loss: 3547.9651\n",
      "Validation Loss: 3084.5051\n",
      "Epoch [641/3000], Loss: 3522.4568\n",
      "Validation Loss: 3055.5526\n",
      "Epoch [661/3000], Loss: 3477.3107\n",
      "Validation Loss: 3028.2854\n",
      "Epoch [681/3000], Loss: 3476.5467\n",
      "Validation Loss: 3002.5484\n",
      "Epoch [701/3000], Loss: 3410.1420\n",
      "Validation Loss: 2978.5855\n",
      "Epoch [721/3000], Loss: 3398.6398\n",
      "Validation Loss: 2956.0744\n",
      "Epoch [741/3000], Loss: 3362.3078\n",
      "Validation Loss: 2935.2285\n",
      "Epoch [761/3000], Loss: 3315.0582\n",
      "Validation Loss: 2916.0003\n",
      "Epoch [781/3000], Loss: 3305.1447\n",
      "Validation Loss: 2898.2057\n",
      "Epoch [801/3000], Loss: 3238.6784\n",
      "Validation Loss: 2881.9447\n",
      "Epoch [821/3000], Loss: 3273.9183\n",
      "Validation Loss: 2867.1633\n",
      "Epoch [841/3000], Loss: 3237.5324\n",
      "Validation Loss: 2853.8480\n",
      "Epoch [861/3000], Loss: 3216.0092\n",
      "Validation Loss: 2842.0295\n",
      "Epoch [881/3000], Loss: 3175.7949\n",
      "Validation Loss: 2831.5657\n",
      "Epoch [901/3000], Loss: 3176.1993\n",
      "Validation Loss: 2822.5191\n",
      "Epoch [921/3000], Loss: 3143.3469\n",
      "Validation Loss: 2814.7946\n",
      "Epoch [941/3000], Loss: 3127.2087\n",
      "Validation Loss: 2808.3391\n",
      "Epoch [961/3000], Loss: 3131.3462\n",
      "Validation Loss: 2803.1421\n",
      "Epoch [981/3000], Loss: 3115.6444\n",
      "Validation Loss: 2799.1235\n",
      "Epoch [1001/3000], Loss: 3115.6855\n",
      "Validation Loss: 2796.2242\n",
      "Epoch [1021/3000], Loss: 3070.8082\n",
      "Validation Loss: 2780.1889\n",
      "Epoch [1041/3000], Loss: 2133.9663\n",
      "Validation Loss: 1890.5321\n",
      "Epoch [1061/3000], Loss: 2039.3578\n",
      "Validation Loss: 1902.7606\n",
      "Epoch [1081/3000], Loss: 1960.7849\n",
      "Validation Loss: 1972.0677\n",
      "Epoch [1101/3000], Loss: 1929.2053\n",
      "Validation Loss: 1950.0962\n",
      "Epoch [1121/3000], Loss: 1832.2293\n",
      "Validation Loss: 1876.5767\n",
      "Epoch [1141/3000], Loss: 1810.0054\n",
      "Validation Loss: 1858.9342\n",
      "Epoch [1161/3000], Loss: 1759.2490\n",
      "Validation Loss: 1825.4158\n",
      "Epoch [1181/3000], Loss: 1728.2792\n",
      "Validation Loss: 1796.0972\n",
      "Epoch [1201/3000], Loss: 1683.6906\n",
      "Validation Loss: 1755.8300\n",
      "Epoch [1221/3000], Loss: 1632.5634\n",
      "Validation Loss: 1723.2811\n",
      "Epoch [1241/3000], Loss: 1613.5129\n",
      "Validation Loss: 1687.4851\n",
      "Epoch [1261/3000], Loss: 1577.4658\n",
      "Validation Loss: 1661.1957\n",
      "Epoch [1281/3000], Loss: 1532.5079\n",
      "Validation Loss: 1627.9137\n",
      "Epoch [1301/3000], Loss: 1490.8901\n",
      "Validation Loss: 1605.2640\n",
      "Epoch [1321/3000], Loss: 1458.3854\n",
      "Validation Loss: 1584.3772\n",
      "Epoch [1341/3000], Loss: 1416.6080\n",
      "Validation Loss: 1573.5538\n",
      "Epoch [1361/3000], Loss: 1390.3035\n",
      "Validation Loss: 1537.8763\n",
      "Epoch [1381/3000], Loss: 1347.8769\n",
      "Validation Loss: 1503.1543\n",
      "Epoch [1401/3000], Loss: 1309.7336\n",
      "Validation Loss: 1465.3966\n",
      "Epoch [1421/3000], Loss: 1283.9919\n",
      "Validation Loss: 1437.3033\n",
      "Epoch [1441/3000], Loss: 1265.5827\n",
      "Validation Loss: 1411.1753\n",
      "Epoch [1461/3000], Loss: 1215.2245\n",
      "Validation Loss: 1388.3425\n",
      "Epoch [1481/3000], Loss: 1188.4105\n",
      "Validation Loss: 1362.2691\n",
      "Epoch [1501/3000], Loss: 1151.0941\n",
      "Validation Loss: 1335.2165\n",
      "Epoch [1521/3000], Loss: 1137.4188\n",
      "Validation Loss: 1308.3012\n",
      "Epoch [1541/3000], Loss: 1111.3837\n",
      "Validation Loss: 1290.8201\n",
      "Epoch [1561/3000], Loss: 1073.4432\n",
      "Validation Loss: 1266.0067\n",
      "Epoch [1581/3000], Loss: 1051.6996\n",
      "Validation Loss: 1248.6223\n",
      "Epoch [1601/3000], Loss: 1015.1015\n",
      "Validation Loss: 1226.8747\n",
      "Epoch [1621/3000], Loss: 995.6442\n",
      "Validation Loss: 1202.8988\n",
      "Epoch [1641/3000], Loss: 976.0631\n",
      "Validation Loss: 1259.2665\n",
      "Epoch [1661/3000], Loss: 939.7087\n",
      "Validation Loss: 1225.5637\n",
      "Epoch [1681/3000], Loss: 905.4377\n",
      "Validation Loss: 1199.4585\n",
      "Epoch [1701/3000], Loss: 883.9190\n",
      "Validation Loss: 1174.5446\n",
      "Epoch [1721/3000], Loss: 855.4816\n",
      "Validation Loss: 1153.5245\n",
      "Epoch [1741/3000], Loss: 843.8534\n",
      "Validation Loss: 1133.4621\n",
      "Epoch [1761/3000], Loss: 813.6748\n",
      "Validation Loss: 1112.8134\n",
      "Epoch [1781/3000], Loss: 781.9951\n",
      "Validation Loss: 1093.3517\n",
      "Epoch [1801/3000], Loss: 768.2002\n",
      "Validation Loss: 1077.0501\n",
      "Epoch [1821/3000], Loss: 742.2788\n",
      "Validation Loss: 1049.8828\n",
      "Epoch [1841/3000], Loss: 726.4503\n",
      "Validation Loss: 1034.7094\n",
      "Epoch [1861/3000], Loss: 695.0460\n",
      "Validation Loss: 1015.6970\n",
      "Epoch [1881/3000], Loss: 677.4827\n",
      "Validation Loss: 1002.1128\n",
      "Epoch [1901/3000], Loss: 667.8099\n",
      "Validation Loss: 986.0607\n",
      "Epoch [1921/3000], Loss: 633.9049\n",
      "Validation Loss: 968.3025\n",
      "Epoch [1941/3000], Loss: 615.2366\n",
      "Validation Loss: 956.0454\n",
      "Epoch [1961/3000], Loss: 601.4243\n",
      "Validation Loss: 946.0390\n",
      "Epoch [1981/3000], Loss: 585.8814\n",
      "Validation Loss: 930.6187\n",
      "Epoch [2001/3000], Loss: 568.9608\n",
      "Validation Loss: 923.3406\n",
      "Epoch [2021/3000], Loss: 547.1656\n",
      "Validation Loss: 893.3298\n",
      "Epoch [2041/3000], Loss: 528.4378\n",
      "Validation Loss: 913.4649\n",
      "Epoch [2061/3000], Loss: 511.7517\n",
      "Validation Loss: 961.3568\n",
      "Epoch [2081/3000], Loss: 493.5771\n",
      "Validation Loss: 937.9612\n",
      "Epoch [2101/3000], Loss: 477.7818\n",
      "Validation Loss: 918.6607\n",
      "Epoch [2121/3000], Loss: 465.6869\n",
      "Validation Loss: 902.5503\n",
      "Epoch [2141/3000], Loss: 451.4552\n",
      "Validation Loss: 887.4086\n",
      "Epoch [2161/3000], Loss: 433.6208\n",
      "Validation Loss: 873.6649\n",
      "Epoch [2181/3000], Loss: 419.7563\n",
      "Validation Loss: 862.7904\n",
      "Epoch [2201/3000], Loss: 404.9010\n",
      "Validation Loss: 848.0609\n",
      "Epoch [2221/3000], Loss: 389.2461\n",
      "Validation Loss: 830.6141\n",
      "Epoch [2241/3000], Loss: 378.9894\n",
      "Validation Loss: 818.5596\n",
      "Epoch [2261/3000], Loss: 361.5233\n",
      "Validation Loss: 802.7208\n",
      "Epoch [2281/3000], Loss: 348.1369\n",
      "Validation Loss: 788.0644\n",
      "Epoch [2301/3000], Loss: 338.5193\n",
      "Validation Loss: 771.3485\n",
      "Epoch [2321/3000], Loss: 325.1640\n",
      "Validation Loss: 768.7014\n",
      "Epoch [2341/3000], Loss: 316.0519\n",
      "Validation Loss: 766.7641\n",
      "Epoch [2361/3000], Loss: 299.8594\n",
      "Validation Loss: 745.9659\n",
      "Epoch [2381/3000], Loss: 292.5323\n",
      "Validation Loss: 730.1532\n",
      "Epoch [2401/3000], Loss: 277.7577\n",
      "Validation Loss: 735.8026\n",
      "Epoch [2421/3000], Loss: 263.0332\n",
      "Validation Loss: 712.7371\n",
      "Epoch [2441/3000], Loss: 254.4988\n",
      "Validation Loss: 707.1590\n",
      "Epoch [2461/3000], Loss: 247.2587\n",
      "Validation Loss: 685.2186\n",
      "Epoch [2481/3000], Loss: 237.0027\n",
      "Validation Loss: 687.5653\n",
      "Epoch [2501/3000], Loss: 227.7420\n",
      "Validation Loss: 669.7614\n",
      "Epoch [2521/3000], Loss: 215.6906\n",
      "Validation Loss: 677.8008\n",
      "Epoch [2541/3000], Loss: 206.6272\n",
      "Validation Loss: 660.9097\n",
      "Epoch [2561/3000], Loss: 201.6776\n",
      "Validation Loss: 679.6095\n",
      "Epoch [2581/3000], Loss: 188.6472\n",
      "Validation Loss: 642.1442\n",
      "Epoch [2601/3000], Loss: 179.6926\n",
      "Validation Loss: 635.2260\n",
      "Epoch [2621/3000], Loss: 172.4042\n",
      "Validation Loss: 624.5346\n",
      "Epoch [2641/3000], Loss: 166.3893\n",
      "Validation Loss: 613.7533\n",
      "Epoch [2661/3000], Loss: 158.9552\n",
      "Validation Loss: 630.1811\n",
      "Epoch [2681/3000], Loss: 151.9449\n",
      "Validation Loss: 609.9218\n",
      "Epoch [2701/3000], Loss: 144.7297\n",
      "Validation Loss: 577.0290\n",
      "Epoch [2721/3000], Loss: 136.9628\n",
      "Validation Loss: 576.2245\n",
      "Epoch [2741/3000], Loss: 131.9716\n",
      "Validation Loss: 599.6160\n",
      "Epoch [2761/3000], Loss: 124.3126\n",
      "Validation Loss: 572.4790\n",
      "Epoch [2781/3000], Loss: 117.4515\n",
      "Validation Loss: 559.5171\n",
      "Epoch [2801/3000], Loss: 111.4601\n",
      "Validation Loss: 564.2276\n",
      "Epoch [2821/3000], Loss: 106.4344\n",
      "Validation Loss: 553.4217\n",
      "Epoch [2841/3000], Loss: 99.0599\n",
      "Validation Loss: 553.6290\n",
      "Epoch [2861/3000], Loss: 94.1699\n",
      "Validation Loss: 567.4195\n",
      "Epoch [2881/3000], Loss: 88.7841\n",
      "Validation Loss: 546.4286\n",
      "Epoch [2901/3000], Loss: 84.3258\n",
      "Validation Loss: 535.0229\n",
      "Epoch [2921/3000], Loss: 79.3033\n",
      "Validation Loss: 548.0700\n",
      "Epoch [2941/3000], Loss: 74.7408\n",
      "Validation Loss: 539.6530\n",
      "Epoch [2961/3000], Loss: 69.6592\n",
      "Validation Loss: 536.9108\n",
      "Epoch [2981/3000], Loss: 65.9662\n",
      "Validation Loss: 523.7120\n",
      "Y:\\analysis\\fmats\\e201\\days\\e201_day075_plane0_Fall.mat\n",
      "(6015, 1177)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7239.2393\n",
      "Validation Loss: 5224.5939\n",
      "Epoch [21/3000], Loss: 6269.0605\n",
      "Validation Loss: 4659.0234\n",
      "Epoch [41/3000], Loss: 6044.6931\n",
      "Validation Loss: 4510.6974\n",
      "Epoch [61/3000], Loss: 5902.9392\n",
      "Validation Loss: 4420.3727\n",
      "Epoch [81/3000], Loss: 5743.3923\n",
      "Validation Loss: 4343.5654\n",
      "Epoch [101/3000], Loss: 5617.3893\n",
      "Validation Loss: 4273.3346\n",
      "Epoch [121/3000], Loss: 5537.5225\n",
      "Validation Loss: 4207.1283\n",
      "Epoch [141/3000], Loss: 5385.5868\n",
      "Validation Loss: 4147.7336\n",
      "Epoch [161/3000], Loss: 5297.6415\n",
      "Validation Loss: 4091.9451\n",
      "Epoch [181/3000], Loss: 5191.9037\n",
      "Validation Loss: 4039.0571\n",
      "Epoch [201/3000], Loss: 5102.9572\n",
      "Validation Loss: 3988.4204\n",
      "Epoch [221/3000], Loss: 4976.6801\n",
      "Validation Loss: 3940.6469\n",
      "Epoch [241/3000], Loss: 4897.3477\n",
      "Validation Loss: 3899.0564\n",
      "Epoch [261/3000], Loss: 4766.5313\n",
      "Validation Loss: 3911.2691\n",
      "Epoch [281/3000], Loss: 4590.0702\n",
      "Validation Loss: 4022.9501\n",
      "Epoch [301/3000], Loss: 4480.2877\n",
      "Validation Loss: 3994.5937\n",
      "Epoch [321/3000], Loss: 4349.4445\n",
      "Validation Loss: 3941.5923\n",
      "Epoch [341/3000], Loss: 4234.4822\n",
      "Validation Loss: 3869.0745\n",
      "Epoch [361/3000], Loss: 4150.0351\n",
      "Validation Loss: 3822.8100\n",
      "Epoch [381/3000], Loss: 4059.3310\n",
      "Validation Loss: 3760.9166\n",
      "Epoch [401/3000], Loss: 3934.3883\n",
      "Validation Loss: 3714.1481\n",
      "Epoch [421/3000], Loss: 3852.1494\n",
      "Validation Loss: 3666.0531\n",
      "Epoch [441/3000], Loss: 3763.1500\n",
      "Validation Loss: 3615.5239\n",
      "Epoch [461/3000], Loss: 3678.6068\n",
      "Validation Loss: 3575.0743\n",
      "Epoch [481/3000], Loss: 3587.1389\n",
      "Validation Loss: 3525.5799\n",
      "Epoch [501/3000], Loss: 3458.4319\n",
      "Validation Loss: 3511.9370\n",
      "Epoch [521/3000], Loss: 3404.6447\n",
      "Validation Loss: 3443.5730\n",
      "Epoch [541/3000], Loss: 3327.6233\n",
      "Validation Loss: 3406.5197\n",
      "Epoch [561/3000], Loss: 3224.8621\n",
      "Validation Loss: 3356.5125\n",
      "Epoch [581/3000], Loss: 3149.3228\n",
      "Validation Loss: 3314.6260\n",
      "Epoch [601/3000], Loss: 3091.8826\n",
      "Validation Loss: 3270.3853\n",
      "Epoch [621/3000], Loss: 2979.8754\n",
      "Validation Loss: 3227.4893\n",
      "Epoch [641/3000], Loss: 2916.7272\n",
      "Validation Loss: 3174.0261\n",
      "Epoch [661/3000], Loss: 2845.1056\n",
      "Validation Loss: 3127.3802\n",
      "Epoch [681/3000], Loss: 2768.4126\n",
      "Validation Loss: 3086.0931\n",
      "Epoch [701/3000], Loss: 2696.1418\n",
      "Validation Loss: 3132.8626\n",
      "Epoch [721/3000], Loss: 2621.6589\n",
      "Validation Loss: 3104.4439\n",
      "Epoch [741/3000], Loss: 2552.4189\n",
      "Validation Loss: 3069.7465\n",
      "Epoch [761/3000], Loss: 2472.6067\n",
      "Validation Loss: 3044.6467\n",
      "Epoch [781/3000], Loss: 2413.4659\n",
      "Validation Loss: 3017.5373\n",
      "Epoch [801/3000], Loss: 2355.3095\n",
      "Validation Loss: 2984.1048\n",
      "Epoch [821/3000], Loss: 2282.5332\n",
      "Validation Loss: 2959.7177\n",
      "Epoch [841/3000], Loss: 2207.9808\n",
      "Validation Loss: 3003.0039\n",
      "Epoch [861/3000], Loss: 2154.0089\n",
      "Validation Loss: 2964.8074\n",
      "Epoch [881/3000], Loss: 2100.3238\n",
      "Validation Loss: 2935.0706\n",
      "Epoch [901/3000], Loss: 2035.0182\n",
      "Validation Loss: 2907.6466\n",
      "Epoch [921/3000], Loss: 1983.5259\n",
      "Validation Loss: 2880.2091\n",
      "Epoch [941/3000], Loss: 1923.0733\n",
      "Validation Loss: 2857.2021\n",
      "Epoch [961/3000], Loss: 1863.0232\n",
      "Validation Loss: 2834.7602\n",
      "Epoch [981/3000], Loss: 1804.8024\n",
      "Validation Loss: 2776.6393\n",
      "Epoch [1001/3000], Loss: 1749.7305\n",
      "Validation Loss: 2767.5993\n",
      "Epoch [1021/3000], Loss: 1696.7240\n",
      "Validation Loss: 2757.6362\n",
      "Epoch [1041/3000], Loss: 1643.4570\n",
      "Validation Loss: 2747.3475\n",
      "Epoch [1061/3000], Loss: 1593.8037\n",
      "Validation Loss: 2723.3950\n",
      "Epoch [1081/3000], Loss: 1549.1104\n",
      "Validation Loss: 2709.3840\n",
      "Epoch [1101/3000], Loss: 1511.7509\n",
      "Validation Loss: 2703.1997\n",
      "Epoch [1121/3000], Loss: 1455.4149\n",
      "Validation Loss: 2663.0309\n",
      "Epoch [1141/3000], Loss: 1408.2564\n",
      "Validation Loss: 2653.0679\n",
      "Epoch [1161/3000], Loss: 1363.7667\n",
      "Validation Loss: 2641.6086\n",
      "Epoch [1181/3000], Loss: 1319.0411\n",
      "Validation Loss: 2628.8759\n",
      "Epoch [1201/3000], Loss: 1279.9838\n",
      "Validation Loss: 2615.7394\n",
      "Epoch [1221/3000], Loss: 1242.8086\n",
      "Validation Loss: 2603.2542\n",
      "Epoch [1241/3000], Loss: 1197.1235\n",
      "Validation Loss: 2607.5338\n",
      "Epoch [1261/3000], Loss: 1157.8246\n",
      "Validation Loss: 2592.2134\n",
      "Epoch [1281/3000], Loss: 1119.8814\n",
      "Validation Loss: 2584.0894\n",
      "Epoch [1301/3000], Loss: 1090.3231\n",
      "Validation Loss: 2568.7848\n",
      "Epoch [1321/3000], Loss: 1050.9273\n",
      "Validation Loss: 2556.0660\n",
      "Epoch [1341/3000], Loss: 1012.0259\n",
      "Validation Loss: 2594.7627\n",
      "Epoch [1361/3000], Loss: 980.8014\n",
      "Validation Loss: 2576.5798\n",
      "Epoch [1381/3000], Loss: 949.2961\n",
      "Validation Loss: 2571.9872\n",
      "Epoch [1401/3000], Loss: 916.5183\n",
      "Validation Loss: 2536.4300\n",
      "Epoch [1421/3000], Loss: 889.1323\n",
      "Validation Loss: 2499.1799\n",
      "Epoch [1441/3000], Loss: 855.0843\n",
      "Validation Loss: 2492.5677\n",
      "Epoch [1461/3000], Loss: 824.0496\n",
      "Validation Loss: 2492.9347\n",
      "Epoch [1481/3000], Loss: 790.7590\n",
      "Validation Loss: 2496.8664\n",
      "Epoch [1501/3000], Loss: 767.5758\n",
      "Validation Loss: 2467.1737\n",
      "Epoch [1521/3000], Loss: 738.3830\n",
      "Validation Loss: 2458.8460\n",
      "Epoch [1541/3000], Loss: 711.3385\n",
      "Validation Loss: 2446.4635\n",
      "Epoch [1561/3000], Loss: 685.8507\n",
      "Validation Loss: 2443.5198\n",
      "Epoch [1581/3000], Loss: 661.9545\n",
      "Validation Loss: 2436.4795\n",
      "Epoch [1601/3000], Loss: 652.1893\n",
      "Validation Loss: 2419.3772\n",
      "Epoch [1621/3000], Loss: 611.0876\n",
      "Validation Loss: 2455.8238\n",
      "Epoch [1641/3000], Loss: 583.5978\n",
      "Validation Loss: 2446.0753\n",
      "Epoch [1661/3000], Loss: 564.5782\n",
      "Validation Loss: 2434.5595\n",
      "Epoch [1681/3000], Loss: 543.0855\n",
      "Validation Loss: 2416.1146\n",
      "Epoch [1701/3000], Loss: 518.8414\n",
      "Validation Loss: 2399.1137\n",
      "Epoch [1721/3000], Loss: 497.9812\n",
      "Validation Loss: 2381.2248\n",
      "Epoch [1741/3000], Loss: 478.0320\n",
      "Validation Loss: 2371.6389\n",
      "Epoch [1761/3000], Loss: 456.6108\n",
      "Validation Loss: 2356.5701\n",
      "Epoch [1781/3000], Loss: 437.7502\n",
      "Validation Loss: 2343.7849\n",
      "Epoch [1801/3000], Loss: 422.0001\n",
      "Validation Loss: 2334.5267\n",
      "Epoch [1821/3000], Loss: 401.9585\n",
      "Validation Loss: 2324.8392\n",
      "Epoch [1841/3000], Loss: 382.7854\n",
      "Validation Loss: 2315.3124\n",
      "Epoch [1861/3000], Loss: 371.0104\n",
      "Validation Loss: 2325.7777\n",
      "Epoch [1881/3000], Loss: 349.7653\n",
      "Validation Loss: 2314.7846\n",
      "Epoch [1901/3000], Loss: 334.3737\n",
      "Validation Loss: 2301.5213\n",
      "Epoch [1921/3000], Loss: 318.7374\n",
      "Validation Loss: 2285.8361\n",
      "Epoch [1941/3000], Loss: 303.5379\n",
      "Validation Loss: 2275.7663\n",
      "Epoch [1961/3000], Loss: 288.2687\n",
      "Validation Loss: 2269.6750\n",
      "Epoch [1981/3000], Loss: 275.0779\n",
      "Validation Loss: 2259.0366\n",
      "Epoch [2001/3000], Loss: 261.7599\n",
      "Validation Loss: 2227.8162\n",
      "Epoch [2021/3000], Loss: 249.3975\n",
      "Validation Loss: 2217.1718\n",
      "Epoch [2041/3000], Loss: 236.2790\n",
      "Validation Loss: 2211.5040\n",
      "Epoch [2061/3000], Loss: 226.3314\n",
      "Validation Loss: 2204.8169\n",
      "Epoch [2081/3000], Loss: 210.6855\n",
      "Validation Loss: 2197.4193\n",
      "Epoch [2101/3000], Loss: 199.4400\n",
      "Validation Loss: 2191.4096\n",
      "Epoch [2121/3000], Loss: 188.6561\n",
      "Validation Loss: 2185.8730\n",
      "Epoch [2141/3000], Loss: 178.4470\n",
      "Validation Loss: 2178.3981\n",
      "Epoch [2161/3000], Loss: 168.9036\n",
      "Validation Loss: 2174.0104\n",
      "Epoch [2181/3000], Loss: 158.8397\n",
      "Validation Loss: 2175.4367\n",
      "Epoch [2201/3000], Loss: 150.0109\n",
      "Validation Loss: 2169.6717\n",
      "Epoch [2221/3000], Loss: 140.7618\n",
      "Validation Loss: 2170.0849\n",
      "Epoch [2241/3000], Loss: 132.8488\n",
      "Validation Loss: 2173.3611\n",
      "Epoch [2261/3000], Loss: 123.9761\n",
      "Validation Loss: 2172.3973\n",
      "Epoch [2281/3000], Loss: 116.3386\n",
      "Validation Loss: 2176.7974\n",
      "Epoch [2301/3000], Loss: 110.2659\n",
      "Validation Loss: 2174.0894\n",
      "Epoch [2321/3000], Loss: 101.9153\n",
      "Validation Loss: 2175.6335\n",
      "Epoch [2341/3000], Loss: 94.6906\n",
      "Validation Loss: 2182.6835\n",
      "Epoch [2361/3000], Loss: 88.5955\n",
      "Validation Loss: 2201.8701\n",
      "Epoch [2381/3000], Loss: 83.0202\n",
      "Validation Loss: 2181.0618\n",
      "Epoch [2401/3000], Loss: 77.2347\n",
      "Validation Loss: 2185.8469\n",
      "Epoch [2421/3000], Loss: 89.1390\n",
      "Validation Loss: 2275.2185\n",
      "Epoch [2441/3000], Loss: 65.9666\n",
      "Validation Loss: 2254.7893\n",
      "Epoch [2461/3000], Loss: 61.1317\n",
      "Validation Loss: 2250.8703\n",
      "Epoch [2481/3000], Loss: 56.6049\n",
      "Validation Loss: 2246.6538\n",
      "Epoch [2501/3000], Loss: 51.5383\n",
      "Validation Loss: 2243.0019\n",
      "Epoch [2521/3000], Loss: 47.1059\n",
      "Validation Loss: 2237.2322\n",
      "Epoch [2541/3000], Loss: 43.3958\n",
      "Validation Loss: 2234.1177\n",
      "Epoch [2561/3000], Loss: 39.6378\n",
      "Validation Loss: 2230.7932\n",
      "Epoch [2581/3000], Loss: 36.2731\n",
      "Validation Loss: 2228.8438\n",
      "Epoch [2601/3000], Loss: 33.0642\n",
      "Validation Loss: 2229.5642\n",
      "Epoch [2621/3000], Loss: 29.7471\n",
      "Validation Loss: 2226.4742\n",
      "Epoch [2641/3000], Loss: 26.6124\n",
      "Validation Loss: 2223.4737\n",
      "Epoch [2661/3000], Loss: 24.4553\n",
      "Validation Loss: 2220.1339\n",
      "Epoch [2681/3000], Loss: 22.0059\n",
      "Validation Loss: 2214.5140\n",
      "Epoch [2701/3000], Loss: 19.4912\n",
      "Validation Loss: 2209.0542\n",
      "Epoch [2721/3000], Loss: 17.4759\n",
      "Validation Loss: 2205.4666\n",
      "Epoch [2741/3000], Loss: 15.6221\n",
      "Validation Loss: 2200.2055\n",
      "Epoch [2761/3000], Loss: 13.6251\n",
      "Validation Loss: 2197.9481\n",
      "Epoch [2781/3000], Loss: 12.0682\n",
      "Validation Loss: 2196.0379\n",
      "Epoch [2801/3000], Loss: 10.5409\n",
      "Validation Loss: 2192.3898\n",
      "Epoch [2821/3000], Loss: 9.0102\n",
      "Validation Loss: 2189.9828\n",
      "Epoch [2841/3000], Loss: 8.0064\n",
      "Validation Loss: 2181.1776\n",
      "Epoch [2861/3000], Loss: 6.7495\n",
      "Validation Loss: 2180.5532\n",
      "Epoch [2881/3000], Loss: 5.8772\n",
      "Validation Loss: 2173.8782\n",
      "Epoch [2901/3000], Loss: 5.0545\n",
      "Validation Loss: 2167.1939\n",
      "Epoch [2921/3000], Loss: 4.2096\n",
      "Validation Loss: 2166.1511\n",
      "Epoch [2941/3000], Loss: 3.6008\n",
      "Validation Loss: 2167.0427\n",
      "Epoch [2961/3000], Loss: 3.0601\n",
      "Validation Loss: 2176.5208\n",
      "Epoch [2981/3000], Loss: 2.5345\n",
      "Validation Loss: 2166.6318\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day002_plane0_Fall.mat\n",
      "(9181, 369)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9139.7113\n",
      "Validation Loss: 7910.7623\n",
      "Epoch [21/3000], Loss: 7757.9774\n",
      "Validation Loss: 6636.0120\n",
      "Epoch [41/3000], Loss: 7458.6680\n",
      "Validation Loss: 6372.6416\n",
      "Epoch [61/3000], Loss: 7201.8243\n",
      "Validation Loss: 6158.5948\n",
      "Epoch [81/3000], Loss: 7001.7582\n",
      "Validation Loss: 5962.2716\n",
      "Epoch [101/3000], Loss: 6778.7291\n",
      "Validation Loss: 5776.5943\n",
      "Epoch [121/3000], Loss: 6594.7658\n",
      "Validation Loss: 5599.1087\n",
      "Epoch [141/3000], Loss: 6393.2968\n",
      "Validation Loss: 5428.7154\n",
      "Epoch [161/3000], Loss: 6220.9555\n",
      "Validation Loss: 5264.8638\n",
      "Epoch [181/3000], Loss: 6037.9695\n",
      "Validation Loss: 5107.5037\n",
      "Epoch [201/3000], Loss: 5872.9400\n",
      "Validation Loss: 4956.2486\n",
      "Epoch [221/3000], Loss: 5688.8896\n",
      "Validation Loss: 4811.0907\n",
      "Epoch [241/3000], Loss: 5556.3870\n",
      "Validation Loss: 4671.9075\n",
      "Epoch [261/3000], Loss: 5412.9270\n",
      "Validation Loss: 4538.7331\n",
      "Epoch [281/3000], Loss: 5239.6737\n",
      "Validation Loss: 4411.4782\n",
      "Epoch [301/3000], Loss: 5103.1623\n",
      "Validation Loss: 4290.1884\n",
      "Epoch [321/3000], Loss: 4955.8945\n",
      "Validation Loss: 4174.8400\n",
      "Epoch [341/3000], Loss: 4850.7289\n",
      "Validation Loss: 4065.2729\n",
      "Epoch [361/3000], Loss: 4718.5768\n",
      "Validation Loss: 3961.6456\n",
      "Epoch [381/3000], Loss: 4603.9477\n",
      "Validation Loss: 3863.8073\n",
      "Epoch [401/3000], Loss: 4492.1309\n",
      "Validation Loss: 3771.2045\n",
      "Epoch [421/3000], Loss: 4366.3994\n",
      "Validation Loss: 3683.9666\n",
      "Epoch [441/3000], Loss: 4265.1692\n",
      "Validation Loss: 3603.1329\n",
      "Epoch [461/3000], Loss: 4168.8098\n",
      "Validation Loss: 3528.1821\n",
      "Epoch [481/3000], Loss: 4078.7580\n",
      "Validation Loss: 3458.8750\n",
      "Epoch [501/3000], Loss: 4016.2002\n",
      "Validation Loss: 3395.3404\n",
      "Epoch [521/3000], Loss: 3934.1628\n",
      "Validation Loss: 3337.3380\n",
      "Epoch [541/3000], Loss: 3866.1444\n",
      "Validation Loss: 3283.6776\n",
      "Epoch [561/3000], Loss: 3317.5136\n",
      "Validation Loss: 2546.1824\n",
      "Epoch [581/3000], Loss: 2865.9228\n",
      "Validation Loss: 2330.7192\n",
      "Epoch [601/3000], Loss: 2713.1212\n",
      "Validation Loss: 2226.6554\n",
      "Epoch [621/3000], Loss: 2573.3813\n",
      "Validation Loss: 2141.2871\n",
      "Epoch [641/3000], Loss: 2453.4650\n",
      "Validation Loss: 2061.1167\n",
      "Epoch [661/3000], Loss: 2312.3624\n",
      "Validation Loss: 2016.1171\n",
      "Epoch [681/3000], Loss: 2203.0496\n",
      "Validation Loss: 1890.3315\n",
      "Epoch [701/3000], Loss: 2092.6922\n",
      "Validation Loss: 1802.1819\n",
      "Epoch [721/3000], Loss: 1993.9624\n",
      "Validation Loss: 1708.2174\n",
      "Epoch [741/3000], Loss: 1895.0370\n",
      "Validation Loss: 1651.4245\n",
      "Epoch [761/3000], Loss: 1802.6312\n",
      "Validation Loss: 1545.5263\n",
      "Epoch [781/3000], Loss: 1716.5564\n",
      "Validation Loss: 1472.1439\n",
      "Epoch [801/3000], Loss: 1634.7598\n",
      "Validation Loss: 1408.6286\n",
      "Epoch [821/3000], Loss: 1545.7375\n",
      "Validation Loss: 1336.6979\n",
      "Epoch [841/3000], Loss: 1466.4107\n",
      "Validation Loss: 1265.1265\n",
      "Epoch [861/3000], Loss: 1394.4636\n",
      "Validation Loss: 1198.3039\n",
      "Epoch [881/3000], Loss: 1324.4705\n",
      "Validation Loss: 1149.5980\n",
      "Epoch [901/3000], Loss: 1248.2896\n",
      "Validation Loss: 1104.8531\n",
      "Epoch [921/3000], Loss: 1179.6250\n",
      "Validation Loss: 1057.1993\n",
      "Epoch [941/3000], Loss: 1121.3916\n",
      "Validation Loss: 1046.7702\n",
      "Epoch [961/3000], Loss: 1042.3979\n",
      "Validation Loss: 965.9246\n",
      "Epoch [981/3000], Loss: 988.6424\n",
      "Validation Loss: 930.7823\n",
      "Epoch [1001/3000], Loss: 925.0276\n",
      "Validation Loss: 897.7960\n",
      "Epoch [1021/3000], Loss: 875.3125\n",
      "Validation Loss: 896.3835\n",
      "Epoch [1041/3000], Loss: 814.4267\n",
      "Validation Loss: 856.3365\n",
      "Epoch [1061/3000], Loss: 765.1799\n",
      "Validation Loss: 815.2522\n",
      "Epoch [1081/3000], Loss: 717.5265\n",
      "Validation Loss: 792.5385\n",
      "Epoch [1101/3000], Loss: 663.3710\n",
      "Validation Loss: 764.7610\n",
      "Epoch [1121/3000], Loss: 617.6112\n",
      "Validation Loss: 737.5543\n",
      "Epoch [1141/3000], Loss: 574.0507\n",
      "Validation Loss: 723.6510\n",
      "Epoch [1161/3000], Loss: 537.5732\n",
      "Validation Loss: 707.1598\n",
      "Epoch [1181/3000], Loss: 498.4891\n",
      "Validation Loss: 698.0413\n",
      "Epoch [1201/3000], Loss: 464.3210\n",
      "Validation Loss: 673.3150\n",
      "Epoch [1221/3000], Loss: 428.8699\n",
      "Validation Loss: 655.6404\n",
      "Epoch [1241/3000], Loss: 396.7494\n",
      "Validation Loss: 642.9404\n",
      "Epoch [1261/3000], Loss: 363.8314\n",
      "Validation Loss: 629.1163\n",
      "Epoch [1281/3000], Loss: 336.4468\n",
      "Validation Loss: 628.1500\n",
      "Epoch [1301/3000], Loss: 307.8087\n",
      "Validation Loss: 609.7146\n",
      "Epoch [1321/3000], Loss: 282.5136\n",
      "Validation Loss: 598.9155\n",
      "Epoch [1341/3000], Loss: 257.0244\n",
      "Validation Loss: 586.6097\n",
      "Epoch [1361/3000], Loss: 234.0738\n",
      "Validation Loss: 570.6892\n",
      "Epoch [1381/3000], Loss: 214.0508\n",
      "Validation Loss: 549.7339\n",
      "Epoch [1401/3000], Loss: 193.7069\n",
      "Validation Loss: 539.2241\n",
      "Epoch [1421/3000], Loss: 174.0197\n",
      "Validation Loss: 529.4554\n",
      "Epoch [1441/3000], Loss: 158.4077\n",
      "Validation Loss: 535.3662\n",
      "Epoch [1461/3000], Loss: 143.9559\n",
      "Validation Loss: 530.8775\n",
      "Epoch [1481/3000], Loss: 129.2136\n",
      "Validation Loss: 518.4905\n",
      "Epoch [1501/3000], Loss: 115.9005\n",
      "Validation Loss: 519.8336\n",
      "Epoch [1521/3000], Loss: 104.2862\n",
      "Validation Loss: 502.3680\n",
      "Epoch [1541/3000], Loss: 94.1121\n",
      "Validation Loss: 492.9814\n",
      "Epoch [1561/3000], Loss: 84.1184\n",
      "Validation Loss: 486.4394\n",
      "Epoch [1581/3000], Loss: 74.6507\n",
      "Validation Loss: 482.1879\n",
      "Epoch [1601/3000], Loss: 66.5307\n",
      "Validation Loss: 474.5384\n",
      "Epoch [1621/3000], Loss: 59.5835\n",
      "Validation Loss: 466.5400\n",
      "Epoch [1641/3000], Loss: 53.4477\n",
      "Validation Loss: 461.6146\n",
      "Epoch [1661/3000], Loss: 47.0437\n",
      "Validation Loss: 455.6334\n",
      "Epoch [1681/3000], Loss: 40.8311\n",
      "Validation Loss: 463.6369\n",
      "Epoch [1701/3000], Loss: 36.4540\n",
      "Validation Loss: 454.6103\n",
      "Epoch [1721/3000], Loss: 31.6462\n",
      "Validation Loss: 454.1994\n",
      "Epoch [1741/3000], Loss: 27.1959\n",
      "Validation Loss: 458.9465\n",
      "Epoch [1761/3000], Loss: 23.3643\n",
      "Validation Loss: 468.6843\n",
      "Epoch [1781/3000], Loss: 19.5588\n",
      "Validation Loss: 479.9820\n",
      "Epoch [1801/3000], Loss: 16.6467\n",
      "Validation Loss: 488.3099\n",
      "Epoch [1821/3000], Loss: 13.7179\n",
      "Validation Loss: 482.8004\n",
      "Epoch [1841/3000], Loss: 11.4819\n",
      "Validation Loss: 500.2579\n",
      "Epoch [1861/3000], Loss: 9.4021\n",
      "Validation Loss: 490.0643\n",
      "Epoch [1881/3000], Loss: 7.6674\n",
      "Validation Loss: 499.5127\n",
      "Epoch [1901/3000], Loss: 6.1108\n",
      "Validation Loss: 486.6062\n",
      "Epoch [1921/3000], Loss: 4.7952\n",
      "Validation Loss: 507.6727\n",
      "Epoch [1941/3000], Loss: 3.7232\n",
      "Validation Loss: 500.1416\n",
      "Epoch [1961/3000], Loss: 2.8533\n",
      "Validation Loss: 506.2988\n",
      "Epoch [1981/3000], Loss: 2.1864\n",
      "Validation Loss: 506.2069\n",
      "Epoch [2001/3000], Loss: 1.5650\n",
      "Validation Loss: 514.2347\n",
      "Epoch [2021/3000], Loss: 1.1506\n",
      "Validation Loss: 518.2713\n",
      "Epoch [2041/3000], Loss: 0.8212\n",
      "Validation Loss: 509.0451\n",
      "Epoch [2061/3000], Loss: 0.6199\n",
      "Validation Loss: 514.0354\n",
      "Epoch [2081/3000], Loss: 0.4782\n",
      "Validation Loss: 518.3730\n",
      "Epoch [2101/3000], Loss: 0.3649\n",
      "Validation Loss: 509.0345\n",
      "Epoch [2121/3000], Loss: 0.2850\n",
      "Validation Loss: 509.6105\n",
      "Epoch [2141/3000], Loss: 0.2192\n",
      "Validation Loss: 484.4535\n",
      "Epoch [2161/3000], Loss: 0.1709\n",
      "Validation Loss: 502.2543\n",
      "Epoch [2181/3000], Loss: 0.1545\n",
      "Validation Loss: 493.8030\n",
      "Epoch [2201/3000], Loss: 0.1105\n",
      "Validation Loss: 493.3355\n",
      "Epoch [2221/3000], Loss: 0.1086\n",
      "Validation Loss: 482.0507\n",
      "Epoch [2241/3000], Loss: 0.0946\n",
      "Validation Loss: 492.8816\n",
      "Epoch [2261/3000], Loss: 0.0837\n",
      "Validation Loss: 490.2425\n",
      "Epoch [2281/3000], Loss: 0.0744\n",
      "Validation Loss: 491.0435\n",
      "Epoch [2301/3000], Loss: 0.0681\n",
      "Validation Loss: 493.8388\n",
      "Epoch [2321/3000], Loss: 0.0831\n",
      "Validation Loss: 497.4467\n",
      "Epoch [2341/3000], Loss: 0.0672\n",
      "Validation Loss: 496.4105\n",
      "Epoch [2361/3000], Loss: 0.0764\n",
      "Validation Loss: 492.6870\n",
      "Epoch [2381/3000], Loss: 0.0581\n",
      "Validation Loss: 492.9968\n",
      "Epoch [2401/3000], Loss: 0.0659\n",
      "Validation Loss: 493.8962\n",
      "Epoch [2421/3000], Loss: 0.0565\n",
      "Validation Loss: 496.7576\n",
      "Epoch [2441/3000], Loss: 0.0593\n",
      "Validation Loss: 494.6175\n",
      "Epoch [2461/3000], Loss: 0.0598\n",
      "Validation Loss: 491.7494\n",
      "Epoch [2481/3000], Loss: 0.0439\n",
      "Validation Loss: 494.2529\n",
      "Epoch [2501/3000], Loss: 0.0472\n",
      "Validation Loss: 496.4000\n",
      "Epoch [2521/3000], Loss: 0.0517\n",
      "Validation Loss: 492.7907\n",
      "Epoch [2541/3000], Loss: 0.0408\n",
      "Validation Loss: 493.8401\n",
      "Epoch [2561/3000], Loss: 0.0402\n",
      "Validation Loss: 489.0715\n",
      "Epoch [2581/3000], Loss: 0.0965\n",
      "Validation Loss: 488.4484\n",
      "Epoch [2601/3000], Loss: 0.0387\n",
      "Validation Loss: 491.7310\n",
      "Epoch [2621/3000], Loss: 0.0344\n",
      "Validation Loss: 488.9865\n",
      "Epoch [2641/3000], Loss: 0.0343\n",
      "Validation Loss: 488.7155\n",
      "Epoch [2661/3000], Loss: 0.0332\n",
      "Validation Loss: 487.8311\n",
      "Epoch [2681/3000], Loss: 0.0343\n",
      "Validation Loss: 490.3775\n",
      "Epoch [2701/3000], Loss: 0.0337\n",
      "Validation Loss: 487.8113\n",
      "Epoch [2721/3000], Loss: 0.0400\n",
      "Validation Loss: 490.6745\n",
      "Epoch [2741/3000], Loss: 0.0294\n",
      "Validation Loss: 489.6275\n",
      "Epoch [2761/3000], Loss: 0.0318\n",
      "Validation Loss: 492.4714\n",
      "Epoch [2781/3000], Loss: 0.0255\n",
      "Validation Loss: 493.3382\n",
      "Epoch [2801/3000], Loss: 0.0342\n",
      "Validation Loss: 492.8699\n",
      "Epoch [2821/3000], Loss: 0.0288\n",
      "Validation Loss: 488.1282\n",
      "Epoch [2841/3000], Loss: 0.0257\n",
      "Validation Loss: 488.7907\n",
      "Epoch [2861/3000], Loss: 0.0240\n",
      "Validation Loss: 488.7795\n",
      "Epoch [2881/3000], Loss: 0.0270\n",
      "Validation Loss: 491.7136\n",
      "Epoch [2901/3000], Loss: 0.0238\n",
      "Validation Loss: 494.3344\n",
      "Epoch [2921/3000], Loss: 0.0301\n",
      "Validation Loss: 487.3002\n",
      "Epoch [2941/3000], Loss: 0.0237\n",
      "Validation Loss: 491.7867\n",
      "Epoch [2961/3000], Loss: 0.0502\n",
      "Validation Loss: 490.3091\n",
      "Epoch [2981/3000], Loss: 0.0240\n",
      "Validation Loss: 488.4501\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day003_plane0_Fall.mat\n",
      "(13514, 428)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8501.5319\n",
      "Validation Loss: 9190.5985\n",
      "Epoch [21/3000], Loss: 7070.5371\n",
      "Validation Loss: 7729.1454\n",
      "Epoch [41/3000], Loss: 6736.5812\n",
      "Validation Loss: 7394.0913\n",
      "Epoch [61/3000], Loss: 6441.8755\n",
      "Validation Loss: 7098.9241\n",
      "Epoch [81/3000], Loss: 6176.6153\n",
      "Validation Loss: 6824.2232\n",
      "Epoch [101/3000], Loss: 5935.6890\n",
      "Validation Loss: 6565.1788\n",
      "Epoch [121/3000], Loss: 5693.7075\n",
      "Validation Loss: 6318.1892\n",
      "Epoch [141/3000], Loss: 5465.8498\n",
      "Validation Loss: 6086.0322\n",
      "Epoch [161/3000], Loss: 5251.9029\n",
      "Validation Loss: 5865.3939\n",
      "Epoch [181/3000], Loss: 5048.1761\n",
      "Validation Loss: 5659.5013\n",
      "Epoch [201/3000], Loss: 4862.6528\n",
      "Validation Loss: 5466.8189\n",
      "Epoch [221/3000], Loss: 4699.2517\n",
      "Validation Loss: 5287.2760\n",
      "Epoch [241/3000], Loss: 4542.1297\n",
      "Validation Loss: 5120.9625\n",
      "Epoch [261/3000], Loss: 4389.4128\n",
      "Validation Loss: 4967.6580\n",
      "Epoch [281/3000], Loss: 4261.1870\n",
      "Validation Loss: 4827.1624\n",
      "Epoch [301/3000], Loss: 4129.7596\n",
      "Validation Loss: 4697.7470\n",
      "Epoch [321/3000], Loss: 3487.7741\n",
      "Validation Loss: 4614.7782\n",
      "Epoch [341/3000], Loss: 3179.4208\n",
      "Validation Loss: 4547.0212\n",
      "Epoch [361/3000], Loss: 2958.6067\n",
      "Validation Loss: 4657.8884\n",
      "Epoch [381/3000], Loss: 2760.6545\n",
      "Validation Loss: 4479.3359\n",
      "Epoch [401/3000], Loss: 2591.9870\n",
      "Validation Loss: 4421.4107\n",
      "Epoch [421/3000], Loss: 2420.3899\n",
      "Validation Loss: 4740.3750\n",
      "Epoch [441/3000], Loss: 2271.7896\n",
      "Validation Loss: 4675.7504\n",
      "Epoch [461/3000], Loss: 2126.6259\n",
      "Validation Loss: 4435.1763\n",
      "Epoch [481/3000], Loss: 1987.9325\n",
      "Validation Loss: 4408.4346\n",
      "Epoch [501/3000], Loss: 1841.3658\n",
      "Validation Loss: 4232.0386\n",
      "Epoch [521/3000], Loss: 1713.6377\n",
      "Validation Loss: 4352.1109\n",
      "Epoch [541/3000], Loss: 1602.9097\n",
      "Validation Loss: 4338.1519\n",
      "Epoch [561/3000], Loss: 1484.6327\n",
      "Validation Loss: 4182.5584\n",
      "Epoch [581/3000], Loss: 1373.2224\n",
      "Validation Loss: 4211.2392\n",
      "Epoch [601/3000], Loss: 1272.7756\n",
      "Validation Loss: 4185.9131\n",
      "Epoch [621/3000], Loss: 1181.4950\n",
      "Validation Loss: 4195.1879\n",
      "Epoch [641/3000], Loss: 1089.2188\n",
      "Validation Loss: 4236.3054\n",
      "Epoch [661/3000], Loss: 1001.8999\n",
      "Validation Loss: 4250.4152\n",
      "Epoch [681/3000], Loss: 916.7370\n",
      "Validation Loss: 4230.2793\n",
      "Epoch [701/3000], Loss: 837.3703\n",
      "Validation Loss: 4300.0519\n",
      "Epoch [721/3000], Loss: 767.6229\n",
      "Validation Loss: 4080.9245\n",
      "Epoch [741/3000], Loss: 700.8340\n",
      "Validation Loss: 4280.5142\n",
      "Epoch [761/3000], Loss: 636.4687\n",
      "Validation Loss: 4265.7542\n",
      "Epoch [781/3000], Loss: 577.8991\n",
      "Validation Loss: 4354.5218\n",
      "Epoch [801/3000], Loss: 519.7634\n",
      "Validation Loss: 4246.6333\n",
      "Epoch [821/3000], Loss: 467.6507\n",
      "Validation Loss: 4264.8801\n",
      "Epoch [841/3000], Loss: 422.8246\n",
      "Validation Loss: 4352.8651\n",
      "Epoch [861/3000], Loss: 372.5775\n",
      "Validation Loss: 4411.5125\n",
      "Epoch [881/3000], Loss: 335.3546\n",
      "Validation Loss: 4468.3576\n",
      "Epoch [901/3000], Loss: 297.0533\n",
      "Validation Loss: 4599.6885\n",
      "Epoch [921/3000], Loss: 261.1275\n",
      "Validation Loss: 4580.6717\n",
      "Epoch [941/3000], Loss: 231.3185\n",
      "Validation Loss: 4572.0144\n",
      "Epoch [961/3000], Loss: 204.0244\n",
      "Validation Loss: 4629.5228\n",
      "Epoch [981/3000], Loss: 178.9200\n",
      "Validation Loss: 4618.7240\n",
      "Epoch [1001/3000], Loss: 156.2450\n",
      "Validation Loss: 4653.5167\n",
      "Epoch [1021/3000], Loss: 135.1558\n",
      "Validation Loss: 4761.6756\n",
      "Epoch [1041/3000], Loss: 113.0049\n",
      "Validation Loss: 4789.7163\n",
      "Epoch [1061/3000], Loss: 96.0892\n",
      "Validation Loss: 4830.9066\n",
      "Epoch [1081/3000], Loss: 81.2034\n",
      "Validation Loss: 4900.9625\n",
      "Epoch [1101/3000], Loss: 67.7003\n",
      "Validation Loss: 4919.5622\n",
      "Epoch [1121/3000], Loss: 56.2705\n",
      "Validation Loss: 4965.4045\n",
      "Epoch [1141/3000], Loss: 46.4450\n",
      "Validation Loss: 5105.7159\n",
      "Epoch [1161/3000], Loss: 37.7164\n",
      "Validation Loss: 5206.4143\n",
      "Epoch [1181/3000], Loss: 30.6297\n",
      "Validation Loss: 5103.6618\n",
      "Epoch [1201/3000], Loss: 24.4122\n",
      "Validation Loss: 5113.2270\n",
      "Epoch [1221/3000], Loss: 19.8144\n",
      "Validation Loss: 4929.9658\n",
      "Epoch [1241/3000], Loss: 15.9542\n",
      "Validation Loss: 4974.3156\n",
      "Epoch [1261/3000], Loss: 12.6047\n",
      "Validation Loss: 4977.7334\n",
      "Epoch [1281/3000], Loss: 9.5390\n",
      "Validation Loss: 5014.0383\n",
      "Epoch [1301/3000], Loss: 7.0631\n",
      "Validation Loss: 4994.7988\n",
      "Epoch [1321/3000], Loss: 5.0410\n",
      "Validation Loss: 5096.6386\n",
      "Epoch [1341/3000], Loss: 3.5405\n",
      "Validation Loss: 5060.5994\n",
      "Epoch [1361/3000], Loss: 2.5912\n",
      "Validation Loss: 5039.6041\n",
      "Epoch [1381/3000], Loss: 1.8495\n",
      "Validation Loss: 4963.6046\n",
      "Epoch [1401/3000], Loss: 1.5536\n",
      "Validation Loss: 5028.0952\n",
      "Epoch [1421/3000], Loss: 1.3359\n",
      "Validation Loss: 5015.2087\n",
      "Epoch [1441/3000], Loss: 1.1686\n",
      "Validation Loss: 5009.7083\n",
      "Epoch [1461/3000], Loss: 0.9988\n",
      "Validation Loss: 4994.4484\n",
      "Epoch [1481/3000], Loss: 0.8728\n",
      "Validation Loss: 5004.0398\n",
      "Epoch [1501/3000], Loss: 0.7330\n",
      "Validation Loss: 4943.5108\n",
      "Epoch [1521/3000], Loss: 0.6199\n",
      "Validation Loss: 4953.2675\n",
      "Epoch [1541/3000], Loss: 0.6035\n",
      "Validation Loss: 4934.5230\n",
      "Epoch [1561/3000], Loss: 0.4715\n",
      "Validation Loss: 4886.8320\n",
      "Epoch [1581/3000], Loss: 0.4393\n",
      "Validation Loss: 4902.6856\n",
      "Epoch [1601/3000], Loss: 0.3501\n",
      "Validation Loss: 4871.2276\n",
      "Epoch [1621/3000], Loss: 0.3432\n",
      "Validation Loss: 4867.7277\n",
      "Epoch [1641/3000], Loss: 0.2966\n",
      "Validation Loss: 4890.1391\n",
      "Epoch [1661/3000], Loss: 0.2746\n",
      "Validation Loss: 4848.1423\n",
      "Epoch [1681/3000], Loss: 0.2436\n",
      "Validation Loss: 4858.1802\n",
      "Epoch [1701/3000], Loss: 0.2259\n",
      "Validation Loss: 4862.3909\n",
      "Epoch [1721/3000], Loss: 0.2109\n",
      "Validation Loss: 4845.7666\n",
      "Epoch [1741/3000], Loss: 0.1981\n",
      "Validation Loss: 4878.2332\n",
      "Epoch [1761/3000], Loss: 0.1980\n",
      "Validation Loss: 4892.9904\n",
      "Epoch [1781/3000], Loss: 0.1770\n",
      "Validation Loss: 4884.7799\n",
      "Epoch [1801/3000], Loss: 0.1622\n",
      "Validation Loss: 4858.3550\n",
      "Epoch [1821/3000], Loss: 0.1484\n",
      "Validation Loss: 4892.1453\n",
      "Epoch [1841/3000], Loss: 0.2599\n",
      "Validation Loss: 4841.5238\n",
      "Epoch [1861/3000], Loss: 0.1524\n",
      "Validation Loss: 4836.5107\n",
      "Epoch [1881/3000], Loss: 0.1298\n",
      "Validation Loss: 4840.6997\n",
      "Epoch [1901/3000], Loss: 0.1217\n",
      "Validation Loss: 4842.4544\n",
      "Epoch [1921/3000], Loss: 0.1179\n",
      "Validation Loss: 4856.9875\n",
      "Epoch [1941/3000], Loss: 0.1178\n",
      "Validation Loss: 4854.0654\n",
      "Epoch [1961/3000], Loss: 0.1180\n",
      "Validation Loss: 4864.4220\n",
      "Epoch [1981/3000], Loss: 0.1271\n",
      "Validation Loss: 4864.5918\n",
      "Epoch [2001/3000], Loss: 0.1202\n",
      "Validation Loss: 4878.6541\n",
      "Epoch [2021/3000], Loss: 0.1154\n",
      "Validation Loss: 4896.9737\n",
      "Epoch [2041/3000], Loss: 0.1241\n",
      "Validation Loss: 4883.9411\n",
      "Epoch [2061/3000], Loss: 0.1188\n",
      "Validation Loss: 4860.6225\n",
      "Epoch [2081/3000], Loss: 0.1042\n",
      "Validation Loss: 4887.9877\n",
      "Epoch [2101/3000], Loss: 0.4157\n",
      "Validation Loss: 4936.3230\n",
      "Epoch [2121/3000], Loss: 0.1099\n",
      "Validation Loss: 4914.0522\n",
      "Epoch [2141/3000], Loss: 0.0882\n",
      "Validation Loss: 4917.0359\n",
      "Epoch [2161/3000], Loss: 0.0812\n",
      "Validation Loss: 4916.0740\n",
      "Epoch [2181/3000], Loss: 0.0805\n",
      "Validation Loss: 4907.7645\n",
      "Epoch [2201/3000], Loss: 0.0783\n",
      "Validation Loss: 4919.2103\n",
      "Epoch [2221/3000], Loss: 0.0802\n",
      "Validation Loss: 4904.2159\n",
      "Epoch [2241/3000], Loss: 0.0893\n",
      "Validation Loss: 4917.3749\n",
      "Epoch [2261/3000], Loss: 0.0850\n",
      "Validation Loss: 4908.1650\n",
      "Epoch [2281/3000], Loss: 0.0921\n",
      "Validation Loss: 4930.1758\n",
      "Epoch [2301/3000], Loss: 0.1019\n",
      "Validation Loss: 4913.9188\n",
      "Epoch [2321/3000], Loss: 0.0806\n",
      "Validation Loss: 4913.4865\n",
      "Epoch [2341/3000], Loss: 0.0799\n",
      "Validation Loss: 4910.7223\n",
      "Epoch [2361/3000], Loss: 0.0750\n",
      "Validation Loss: 4909.2461\n",
      "Epoch [2381/3000], Loss: 0.0726\n",
      "Validation Loss: 4901.0982\n",
      "Epoch [2401/3000], Loss: 0.0665\n",
      "Validation Loss: 4887.4326\n",
      "Epoch [2421/3000], Loss: 0.0841\n",
      "Validation Loss: 4894.9177\n",
      "Epoch [2441/3000], Loss: 0.0732\n",
      "Validation Loss: 4906.1181\n",
      "Epoch [2461/3000], Loss: 0.0637\n",
      "Validation Loss: 4897.0398\n",
      "Epoch [2481/3000], Loss: 0.0820\n",
      "Validation Loss: 4910.0376\n",
      "Epoch [2501/3000], Loss: 0.0692\n",
      "Validation Loss: 4897.1257\n",
      "Epoch [2521/3000], Loss: 0.0652\n",
      "Validation Loss: 4907.7417\n",
      "Epoch [2541/3000], Loss: 0.1073\n",
      "Validation Loss: 4916.7011\n",
      "Epoch [2561/3000], Loss: 0.0594\n",
      "Validation Loss: 4925.9628\n",
      "Epoch [2581/3000], Loss: 0.0644\n",
      "Validation Loss: 4932.9896\n",
      "Epoch [2601/3000], Loss: 0.0489\n",
      "Validation Loss: 4913.5035\n",
      "Epoch [2621/3000], Loss: 0.0477\n",
      "Validation Loss: 4917.8155\n",
      "Epoch [2641/3000], Loss: 0.0608\n",
      "Validation Loss: 4902.0811\n",
      "Epoch [2661/3000], Loss: 0.0512\n",
      "Validation Loss: 4873.1514\n",
      "Epoch [2681/3000], Loss: 0.0479\n",
      "Validation Loss: 4898.9408\n",
      "Epoch [2701/3000], Loss: 0.0401\n",
      "Validation Loss: 4914.8167\n",
      "Epoch [2721/3000], Loss: 0.0375\n",
      "Validation Loss: 4906.8215\n",
      "Epoch [2741/3000], Loss: 0.0453\n",
      "Validation Loss: 4891.1530\n",
      "Epoch [2761/3000], Loss: 0.0471\n",
      "Validation Loss: 4906.5220\n",
      "Epoch [2781/3000], Loss: 0.0391\n",
      "Validation Loss: 4907.3918\n",
      "Epoch [2801/3000], Loss: 0.0357\n",
      "Validation Loss: 4907.4608\n",
      "Epoch [2821/3000], Loss: 0.0381\n",
      "Validation Loss: 4891.5600\n",
      "Epoch [2841/3000], Loss: 0.0464\n",
      "Validation Loss: 4906.4386\n",
      "Epoch [2861/3000], Loss: 0.0334\n",
      "Validation Loss: 4915.1437\n",
      "Epoch [2881/3000], Loss: 0.0286\n",
      "Validation Loss: 4888.8180\n",
      "Epoch [2901/3000], Loss: 0.0714\n",
      "Validation Loss: 4880.8449\n",
      "Epoch [2921/3000], Loss: 0.0286\n",
      "Validation Loss: 4898.1750\n",
      "Epoch [2941/3000], Loss: 0.0388\n",
      "Validation Loss: 4890.7900\n",
      "Epoch [2961/3000], Loss: 0.0411\n",
      "Validation Loss: 4909.1141\n",
      "Epoch [2981/3000], Loss: 0.0422\n",
      "Validation Loss: 4903.4447\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day004_plane0_Fall.mat\n",
      "(5447, 295)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8087.0536\n",
      "Validation Loss: 7274.6979\n",
      "Epoch [21/3000], Loss: 6990.1144\n",
      "Validation Loss: 6245.0139\n",
      "Epoch [41/3000], Loss: 6734.3400\n",
      "Validation Loss: 6028.7421\n",
      "Epoch [61/3000], Loss: 6599.0205\n",
      "Validation Loss: 5893.4192\n",
      "Epoch [81/3000], Loss: 6471.7066\n",
      "Validation Loss: 5773.3945\n",
      "Epoch [101/3000], Loss: 6337.9635\n",
      "Validation Loss: 5661.4122\n",
      "Epoch [121/3000], Loss: 6215.7514\n",
      "Validation Loss: 5554.7772\n",
      "Epoch [141/3000], Loss: 6103.3306\n",
      "Validation Loss: 5451.7003\n",
      "Epoch [161/3000], Loss: 5996.3833\n",
      "Validation Loss: 5352.4249\n",
      "Epoch [181/3000], Loss: 5884.1386\n",
      "Validation Loss: 5256.2799\n",
      "Epoch [201/3000], Loss: 5783.4698\n",
      "Validation Loss: 5162.8286\n",
      "Epoch [221/3000], Loss: 5677.1198\n",
      "Validation Loss: 5071.8936\n",
      "Epoch [241/3000], Loss: 5580.7642\n",
      "Validation Loss: 4983.4428\n",
      "Epoch [261/3000], Loss: 5484.3336\n",
      "Validation Loss: 4897.2972\n",
      "Epoch [281/3000], Loss: 5389.8956\n",
      "Validation Loss: 4813.3214\n",
      "Epoch [301/3000], Loss: 5301.9024\n",
      "Validation Loss: 4731.6428\n",
      "Epoch [321/3000], Loss: 5206.9429\n",
      "Validation Loss: 4652.1810\n",
      "Epoch [341/3000], Loss: 5129.8971\n",
      "Validation Loss: 4574.8028\n",
      "Epoch [361/3000], Loss: 5029.3390\n",
      "Validation Loss: 4499.6457\n",
      "Epoch [381/3000], Loss: 4947.5006\n",
      "Validation Loss: 4426.5819\n",
      "Epoch [401/3000], Loss: 4870.0024\n",
      "Validation Loss: 4355.6031\n",
      "Epoch [421/3000], Loss: 4792.1768\n",
      "Validation Loss: 4286.8238\n",
      "Epoch [441/3000], Loss: 4709.4271\n",
      "Validation Loss: 4220.0426\n",
      "Epoch [461/3000], Loss: 4624.9757\n",
      "Validation Loss: 4155.4942\n",
      "Epoch [481/3000], Loss: 4563.3885\n",
      "Validation Loss: 4092.9174\n",
      "Epoch [501/3000], Loss: 4494.3317\n",
      "Validation Loss: 4032.4974\n",
      "Epoch [521/3000], Loss: 4421.9327\n",
      "Validation Loss: 3974.1454\n",
      "Epoch [541/3000], Loss: 4355.2535\n",
      "Validation Loss: 3917.8213\n",
      "Epoch [561/3000], Loss: 4294.2670\n",
      "Validation Loss: 3863.6076\n",
      "Epoch [581/3000], Loss: 4224.3203\n",
      "Validation Loss: 3811.4483\n",
      "Epoch [601/3000], Loss: 4175.0087\n",
      "Validation Loss: 3761.3286\n",
      "Epoch [621/3000], Loss: 4108.1981\n",
      "Validation Loss: 3713.2341\n",
      "Epoch [641/3000], Loss: 4053.6218\n",
      "Validation Loss: 3667.2316\n",
      "Epoch [661/3000], Loss: 4002.0480\n",
      "Validation Loss: 3623.2872\n",
      "Epoch [681/3000], Loss: 3945.5133\n",
      "Validation Loss: 3581.3339\n",
      "Epoch [701/3000], Loss: 3894.8869\n",
      "Validation Loss: 3541.3861\n",
      "Epoch [721/3000], Loss: 3853.1389\n",
      "Validation Loss: 3503.3896\n",
      "Epoch [741/3000], Loss: 3801.3753\n",
      "Validation Loss: 3467.4129\n",
      "Epoch [761/3000], Loss: 3750.9945\n",
      "Validation Loss: 3433.4123\n",
      "Epoch [781/3000], Loss: 3713.8102\n",
      "Validation Loss: 3401.4462\n",
      "Epoch [801/3000], Loss: 3679.6702\n",
      "Validation Loss: 3371.3239\n",
      "Epoch [821/3000], Loss: 3640.2072\n",
      "Validation Loss: 3343.1783\n",
      "Epoch [841/3000], Loss: 3601.2571\n",
      "Validation Loss: 3316.9059\n",
      "Epoch [861/3000], Loss: 3561.0337\n",
      "Validation Loss: 3292.5512\n",
      "Epoch [881/3000], Loss: 3533.6455\n",
      "Validation Loss: 3270.0458\n",
      "Epoch [901/3000], Loss: 3507.8007\n",
      "Validation Loss: 3249.3084\n",
      "Epoch [921/3000], Loss: 2623.5895\n",
      "Validation Loss: 2241.6508\n",
      "Epoch [941/3000], Loss: 2518.3466\n",
      "Validation Loss: 2180.4535\n",
      "Epoch [961/3000], Loss: 2436.9208\n",
      "Validation Loss: 2110.7520\n",
      "Epoch [981/3000], Loss: 2368.2726\n",
      "Validation Loss: 2069.9411\n",
      "Epoch [1001/3000], Loss: 2280.8919\n",
      "Validation Loss: 2016.3360\n",
      "Epoch [1021/3000], Loss: 2213.0609\n",
      "Validation Loss: 1954.6398\n",
      "Epoch [1041/3000], Loss: 2154.2768\n",
      "Validation Loss: 1902.5630\n",
      "Epoch [1061/3000], Loss: 2099.7148\n",
      "Validation Loss: 1871.5698\n",
      "Epoch [1081/3000], Loss: 2030.9776\n",
      "Validation Loss: 1830.5892\n",
      "Epoch [1101/3000], Loss: 1978.2847\n",
      "Validation Loss: 1774.6130\n",
      "Epoch [1121/3000], Loss: 1925.5613\n",
      "Validation Loss: 1719.0590\n",
      "Epoch [1141/3000], Loss: 1857.2436\n",
      "Validation Loss: 1667.7031\n",
      "Epoch [1161/3000], Loss: 1816.8221\n",
      "Validation Loss: 1620.0872\n",
      "Epoch [1181/3000], Loss: 1761.5530\n",
      "Validation Loss: 1590.0093\n",
      "Epoch [1201/3000], Loss: 1717.9814\n",
      "Validation Loss: 1547.8989\n",
      "Epoch [1221/3000], Loss: 1655.5420\n",
      "Validation Loss: 1497.7247\n",
      "Epoch [1241/3000], Loss: 1608.2412\n",
      "Validation Loss: 1459.9019\n",
      "Epoch [1261/3000], Loss: 1567.7660\n",
      "Validation Loss: 1454.2974\n",
      "Epoch [1281/3000], Loss: 1514.2604\n",
      "Validation Loss: 1381.7459\n",
      "Epoch [1301/3000], Loss: 1473.7977\n",
      "Validation Loss: 1335.4785\n",
      "Epoch [1321/3000], Loss: 1424.8464\n",
      "Validation Loss: 1305.1029\n",
      "Epoch [1341/3000], Loss: 1389.1917\n",
      "Validation Loss: 1371.0607\n",
      "Epoch [1361/3000], Loss: 1338.5245\n",
      "Validation Loss: 1269.4908\n",
      "Epoch [1381/3000], Loss: 1302.8825\n",
      "Validation Loss: 1221.6347\n",
      "Epoch [1401/3000], Loss: 1267.3231\n",
      "Validation Loss: 1188.6101\n",
      "Epoch [1421/3000], Loss: 1217.4958\n",
      "Validation Loss: 1152.7974\n",
      "Epoch [1441/3000], Loss: 1179.3055\n",
      "Validation Loss: 1113.2109\n",
      "Epoch [1461/3000], Loss: 1140.3038\n",
      "Validation Loss: 1078.0180\n",
      "Epoch [1481/3000], Loss: 1109.9656\n",
      "Validation Loss: 1047.7343\n",
      "Epoch [1501/3000], Loss: 1071.3887\n",
      "Validation Loss: 1022.4027\n",
      "Epoch [1521/3000], Loss: 1031.0553\n",
      "Validation Loss: 991.5298\n",
      "Epoch [1541/3000], Loss: 1010.1982\n",
      "Validation Loss: 964.5317\n",
      "Epoch [1561/3000], Loss: 974.4431\n",
      "Validation Loss: 955.8879\n",
      "Epoch [1581/3000], Loss: 941.1997\n",
      "Validation Loss: 926.8462\n",
      "Epoch [1601/3000], Loss: 907.2601\n",
      "Validation Loss: 892.2620\n",
      "Epoch [1621/3000], Loss: 877.2388\n",
      "Validation Loss: 873.3252\n",
      "Epoch [1641/3000], Loss: 849.7097\n",
      "Validation Loss: 913.3135\n",
      "Epoch [1661/3000], Loss: 826.6479\n",
      "Validation Loss: 860.1500\n",
      "Epoch [1681/3000], Loss: 796.9083\n",
      "Validation Loss: 838.1974\n",
      "Epoch [1701/3000], Loss: 766.4273\n",
      "Validation Loss: 813.6792\n",
      "Epoch [1721/3000], Loss: 743.1516\n",
      "Validation Loss: 791.8561\n",
      "Epoch [1741/3000], Loss: 716.4511\n",
      "Validation Loss: 766.8883\n",
      "Epoch [1761/3000], Loss: 693.0708\n",
      "Validation Loss: 747.0396\n",
      "Epoch [1781/3000], Loss: 664.9162\n",
      "Validation Loss: 726.4057\n",
      "Epoch [1801/3000], Loss: 645.0801\n",
      "Validation Loss: 705.8854\n",
      "Epoch [1821/3000], Loss: 625.7711\n",
      "Validation Loss: 686.7100\n",
      "Epoch [1841/3000], Loss: 598.1619\n",
      "Validation Loss: 667.7574\n",
      "Epoch [1861/3000], Loss: 578.5939\n",
      "Validation Loss: 649.9066\n",
      "Epoch [1881/3000], Loss: 556.9664\n",
      "Validation Loss: 650.4254\n",
      "Epoch [1901/3000], Loss: 536.8466\n",
      "Validation Loss: 633.5601\n",
      "Epoch [1921/3000], Loss: 520.9527\n",
      "Validation Loss: 613.9909\n",
      "Epoch [1941/3000], Loss: 496.4595\n",
      "Validation Loss: 615.2007\n",
      "Epoch [1961/3000], Loss: 481.4022\n",
      "Validation Loss: 610.2120\n",
      "Epoch [1981/3000], Loss: 461.8287\n",
      "Validation Loss: 601.7208\n",
      "Epoch [2001/3000], Loss: 485.5399\n",
      "Validation Loss: 464.9226\n",
      "Epoch [2021/3000], Loss: 422.6453\n",
      "Validation Loss: 612.7878\n",
      "Epoch [2041/3000], Loss: 408.1015\n",
      "Validation Loss: 595.8800\n",
      "Epoch [2061/3000], Loss: 392.0732\n",
      "Validation Loss: 581.1833\n",
      "Epoch [2081/3000], Loss: 380.3675\n",
      "Validation Loss: 566.9779\n",
      "Epoch [2101/3000], Loss: 360.5510\n",
      "Validation Loss: 551.8637\n",
      "Epoch [2121/3000], Loss: 345.7144\n",
      "Validation Loss: 537.5327\n",
      "Epoch [2141/3000], Loss: 330.7796\n",
      "Validation Loss: 524.0200\n",
      "Epoch [2161/3000], Loss: 317.5070\n",
      "Validation Loss: 511.7877\n",
      "Epoch [2181/3000], Loss: 300.6935\n",
      "Validation Loss: 499.2898\n",
      "Epoch [2201/3000], Loss: 288.8962\n",
      "Validation Loss: 482.1930\n",
      "Epoch [2221/3000], Loss: 273.6976\n",
      "Validation Loss: 470.7193\n",
      "Epoch [2241/3000], Loss: 263.3020\n",
      "Validation Loss: 459.4049\n",
      "Epoch [2261/3000], Loss: 249.8188\n",
      "Validation Loss: 449.9368\n",
      "Epoch [2281/3000], Loss: 237.7662\n",
      "Validation Loss: 454.5389\n",
      "Epoch [2301/3000], Loss: 224.7974\n",
      "Validation Loss: 434.8871\n",
      "Epoch [2321/3000], Loss: 214.2741\n",
      "Validation Loss: 433.2178\n",
      "Epoch [2341/3000], Loss: 205.3120\n",
      "Validation Loss: 444.4869\n",
      "Epoch [2361/3000], Loss: 193.1534\n",
      "Validation Loss: 415.6922\n",
      "Epoch [2381/3000], Loss: 183.8516\n",
      "Validation Loss: 428.8081\n",
      "Epoch [2401/3000], Loss: 175.5730\n",
      "Validation Loss: 411.4900\n",
      "Epoch [2421/3000], Loss: 166.5964\n",
      "Validation Loss: 410.2092\n",
      "Epoch [2441/3000], Loss: 156.5863\n",
      "Validation Loss: 403.6570\n",
      "Epoch [2461/3000], Loss: 148.5464\n",
      "Validation Loss: 412.1413\n",
      "Epoch [2481/3000], Loss: 140.1797\n",
      "Validation Loss: 402.9734\n",
      "Epoch [2501/3000], Loss: 131.7279\n",
      "Validation Loss: 398.4219\n",
      "Epoch [2521/3000], Loss: 124.3438\n",
      "Validation Loss: 381.1086\n",
      "Epoch [2541/3000], Loss: 117.3764\n",
      "Validation Loss: 385.0267\n",
      "Epoch [2561/3000], Loss: 109.3952\n",
      "Validation Loss: 383.3068\n",
      "Epoch [2581/3000], Loss: 103.5095\n",
      "Validation Loss: 428.4964\n",
      "Epoch [2601/3000], Loss: 97.4075\n",
      "Validation Loss: 397.9510\n",
      "Epoch [2621/3000], Loss: 91.5983\n",
      "Validation Loss: 393.5538\n",
      "Epoch [2641/3000], Loss: 91.1029\n",
      "Validation Loss: 435.3179\n",
      "Epoch [2661/3000], Loss: 80.5671\n",
      "Validation Loss: 378.2400\n",
      "Epoch [2681/3000], Loss: 75.1719\n",
      "Validation Loss: 374.2219\n",
      "Epoch [2701/3000], Loss: 69.7934\n",
      "Validation Loss: 371.1347\n",
      "Epoch [2721/3000], Loss: 64.9189\n",
      "Validation Loss: 369.1245\n",
      "Epoch [2741/3000], Loss: 60.6233\n",
      "Validation Loss: 366.6796\n",
      "Epoch [2761/3000], Loss: 55.8526\n",
      "Validation Loss: 366.3126\n",
      "Epoch [2781/3000], Loss: 52.3418\n",
      "Validation Loss: 362.5485\n",
      "Epoch [2801/3000], Loss: 48.1229\n",
      "Validation Loss: 365.6746\n",
      "Epoch [2821/3000], Loss: 44.1224\n",
      "Validation Loss: 361.6634\n",
      "Epoch [2841/3000], Loss: 41.0934\n",
      "Validation Loss: 360.0175\n",
      "Epoch [2861/3000], Loss: 37.4628\n",
      "Validation Loss: 359.1182\n",
      "Epoch [2881/3000], Loss: 34.6508\n",
      "Validation Loss: 355.3405\n",
      "Epoch [2901/3000], Loss: 31.6195\n",
      "Validation Loss: 356.3393\n",
      "Epoch [2921/3000], Loss: 29.0421\n",
      "Validation Loss: 352.5388\n",
      "Epoch [2941/3000], Loss: 26.5412\n",
      "Validation Loss: 351.7247\n",
      "Epoch [2961/3000], Loss: 24.1101\n",
      "Validation Loss: 357.5249\n",
      "Epoch [2981/3000], Loss: 21.7860\n",
      "Validation Loss: 353.8404\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day005_plane0_Fall.mat\n",
      "(14918, 473)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9648.9205\n",
      "Validation Loss: 7053.7494\n",
      "Epoch [21/3000], Loss: 7982.5234\n",
      "Validation Loss: 5709.9057\n",
      "Epoch [41/3000], Loss: 7569.6059\n",
      "Validation Loss: 5393.5032\n",
      "Epoch [61/3000], Loss: 7209.0539\n",
      "Validation Loss: 5116.5486\n",
      "Epoch [81/3000], Loss: 6877.6053\n",
      "Validation Loss: 4861.8347\n",
      "Epoch [101/3000], Loss: 6557.7000\n",
      "Validation Loss: 4625.7833\n",
      "Epoch [121/3000], Loss: 6255.7142\n",
      "Validation Loss: 4406.7565\n",
      "Epoch [141/3000], Loss: 5983.3727\n",
      "Validation Loss: 4204.5453\n",
      "Epoch [161/3000], Loss: 5710.6958\n",
      "Validation Loss: 4018.7755\n",
      "Epoch [181/3000], Loss: 5463.4127\n",
      "Validation Loss: 3849.2562\n",
      "Epoch [201/3000], Loss: 5237.4593\n",
      "Validation Loss: 3696.0386\n",
      "Epoch [221/3000], Loss: 5023.9491\n",
      "Validation Loss: 3558.8507\n",
      "Epoch [241/3000], Loss: 4824.4261\n",
      "Validation Loss: 3437.5152\n",
      "Epoch [261/3000], Loss: 4637.3129\n",
      "Validation Loss: 3332.0376\n",
      "Epoch [281/3000], Loss: 4469.8508\n",
      "Validation Loss: 3242.1323\n",
      "Epoch [301/3000], Loss: 4321.7539\n",
      "Validation Loss: 3167.5602\n",
      "Epoch [321/3000], Loss: 4190.5958\n",
      "Validation Loss: 3107.9948\n",
      "Epoch [341/3000], Loss: 3281.7038\n",
      "Validation Loss: 2785.4801\n",
      "Epoch [361/3000], Loss: 2971.2601\n",
      "Validation Loss: 2611.7710\n",
      "Epoch [381/3000], Loss: 2736.4608\n",
      "Validation Loss: 2505.3873\n",
      "Epoch [401/3000], Loss: 2532.1736\n",
      "Validation Loss: 2438.5465\n",
      "Epoch [421/3000], Loss: 2342.9584\n",
      "Validation Loss: 2399.6905\n",
      "Epoch [441/3000], Loss: 2161.3616\n",
      "Validation Loss: 2314.7673\n",
      "Epoch [461/3000], Loss: 1993.8793\n",
      "Validation Loss: 2307.2866\n",
      "Epoch [481/3000], Loss: 1831.3132\n",
      "Validation Loss: 2285.3235\n",
      "Epoch [501/3000], Loss: 1686.8085\n",
      "Validation Loss: 2261.2204\n",
      "Epoch [521/3000], Loss: 1543.6507\n",
      "Validation Loss: 2268.4360\n",
      "Epoch [541/3000], Loss: 1413.7054\n",
      "Validation Loss: 2244.9198\n",
      "Epoch [561/3000], Loss: 1290.0170\n",
      "Validation Loss: 2210.3902\n",
      "Epoch [581/3000], Loss: 1177.1748\n",
      "Validation Loss: 2194.9556\n",
      "Epoch [601/3000], Loss: 1065.1240\n",
      "Validation Loss: 2189.4616\n",
      "Epoch [621/3000], Loss: 964.9255\n",
      "Validation Loss: 2206.4103\n",
      "Epoch [641/3000], Loss: 880.1760\n",
      "Validation Loss: 2164.6654\n",
      "Epoch [661/3000], Loss: 776.3648\n",
      "Validation Loss: 2171.2927\n",
      "Epoch [681/3000], Loss: 707.2662\n",
      "Validation Loss: 2157.1624\n",
      "Epoch [701/3000], Loss: 622.5709\n",
      "Validation Loss: 2170.5470\n",
      "Epoch [721/3000], Loss: 554.5003\n",
      "Validation Loss: 2165.3888\n",
      "Epoch [741/3000], Loss: 502.2856\n",
      "Validation Loss: 2025.2888\n",
      "Epoch [761/3000], Loss: 432.8544\n",
      "Validation Loss: 2129.2702\n",
      "Epoch [781/3000], Loss: 374.4005\n",
      "Validation Loss: 2066.7200\n",
      "Epoch [801/3000], Loss: 324.7453\n",
      "Validation Loss: 2194.5350\n",
      "Epoch [821/3000], Loss: 280.8562\n",
      "Validation Loss: 2080.5089\n",
      "Epoch [841/3000], Loss: 241.1867\n",
      "Validation Loss: 2139.9942\n",
      "Epoch [861/3000], Loss: 206.6856\n",
      "Validation Loss: 2147.7986\n",
      "Epoch [881/3000], Loss: 176.0481\n",
      "Validation Loss: 2258.2285\n",
      "Epoch [901/3000], Loss: 148.8482\n",
      "Validation Loss: 2221.4553\n",
      "Epoch [921/3000], Loss: 125.3550\n",
      "Validation Loss: 2298.9852\n",
      "Epoch [941/3000], Loss: 104.5921\n",
      "Validation Loss: 2299.3679\n",
      "Epoch [961/3000], Loss: 99.4287\n",
      "Validation Loss: 2050.3395\n",
      "Epoch [981/3000], Loss: 71.5185\n",
      "Validation Loss: 2342.2662\n",
      "Epoch [1001/3000], Loss: 58.3735\n",
      "Validation Loss: 2354.9973\n",
      "Epoch [1021/3000], Loss: 46.3304\n",
      "Validation Loss: 2335.2709\n",
      "Epoch [1041/3000], Loss: 34.4879\n",
      "Validation Loss: 2478.1266\n",
      "Epoch [1061/3000], Loss: 27.4149\n",
      "Validation Loss: 2396.4011\n",
      "Epoch [1081/3000], Loss: 20.5159\n",
      "Validation Loss: 2455.0406\n",
      "Epoch [1101/3000], Loss: 15.5219\n",
      "Validation Loss: 2456.9295\n",
      "Epoch [1121/3000], Loss: 11.5878\n",
      "Validation Loss: 2465.6954\n",
      "Epoch [1141/3000], Loss: 8.7741\n",
      "Validation Loss: 2408.5401\n",
      "Epoch [1161/3000], Loss: 6.4223\n",
      "Validation Loss: 2398.4344\n",
      "Epoch [1181/3000], Loss: 4.9485\n",
      "Validation Loss: 2433.9028\n",
      "Epoch [1201/3000], Loss: 3.9239\n",
      "Validation Loss: 2402.9244\n",
      "Epoch [1221/3000], Loss: 2.9916\n",
      "Validation Loss: 2376.5537\n",
      "Epoch [1241/3000], Loss: 2.2056\n",
      "Validation Loss: 2385.1876\n",
      "Epoch [1261/3000], Loss: 1.6268\n",
      "Validation Loss: 2344.8832\n",
      "Epoch [1281/3000], Loss: 1.2196\n",
      "Validation Loss: 2283.5599\n",
      "Epoch [1301/3000], Loss: 0.8975\n",
      "Validation Loss: 2312.7452\n",
      "Epoch [1321/3000], Loss: 0.6721\n",
      "Validation Loss: 2231.0694\n",
      "Epoch [1341/3000], Loss: 0.5314\n",
      "Validation Loss: 2303.9167\n",
      "Epoch [1361/3000], Loss: 0.4177\n",
      "Validation Loss: 2315.3207\n",
      "Epoch [1381/3000], Loss: 0.4744\n",
      "Validation Loss: 2402.7044\n",
      "Epoch [1401/3000], Loss: 0.3663\n",
      "Validation Loss: 2387.6772\n",
      "Epoch [1421/3000], Loss: 0.3377\n",
      "Validation Loss: 2379.4713\n",
      "Epoch [1441/3000], Loss: 0.3231\n",
      "Validation Loss: 2369.3213\n",
      "Epoch [1461/3000], Loss: 0.3001\n",
      "Validation Loss: 2371.1377\n",
      "Epoch [1481/3000], Loss: 0.2838\n",
      "Validation Loss: 2353.6823\n",
      "Epoch [1501/3000], Loss: 0.2668\n",
      "Validation Loss: 2339.6450\n",
      "Epoch [1521/3000], Loss: 0.2403\n",
      "Validation Loss: 2350.1605\n",
      "Epoch [1541/3000], Loss: 0.2259\n",
      "Validation Loss: 2350.8465\n",
      "Epoch [1561/3000], Loss: 0.2156\n",
      "Validation Loss: 2329.4316\n",
      "Epoch [1581/3000], Loss: 0.1837\n",
      "Validation Loss: 2346.8618\n",
      "Epoch [1601/3000], Loss: 0.1843\n",
      "Validation Loss: 2382.2012\n",
      "Epoch [1621/3000], Loss: 0.1646\n",
      "Validation Loss: 2361.2046\n",
      "Epoch [1641/3000], Loss: 0.1631\n",
      "Validation Loss: 2297.5699\n",
      "Epoch [1661/3000], Loss: 0.1336\n",
      "Validation Loss: 2391.7827\n",
      "Epoch [1681/3000], Loss: 0.1275\n",
      "Validation Loss: 2402.1637\n",
      "Epoch [1701/3000], Loss: 0.1421\n",
      "Validation Loss: 2398.3029\n",
      "Epoch [1721/3000], Loss: 0.1055\n",
      "Validation Loss: 2426.2795\n",
      "Epoch [1741/3000], Loss: 0.1766\n",
      "Validation Loss: 2333.9835\n",
      "Epoch [1761/3000], Loss: 0.1109\n",
      "Validation Loss: 2353.6712\n",
      "Epoch [1781/3000], Loss: 0.0931\n",
      "Validation Loss: 2365.1536\n",
      "Epoch [1801/3000], Loss: 0.0877\n",
      "Validation Loss: 2373.7021\n",
      "Epoch [1821/3000], Loss: 0.0872\n",
      "Validation Loss: 2366.7058\n",
      "Epoch [1841/3000], Loss: 0.0881\n",
      "Validation Loss: 2384.4906\n",
      "Epoch [1861/3000], Loss: 0.0990\n",
      "Validation Loss: 2387.2039\n",
      "Epoch [1881/3000], Loss: 0.0999\n",
      "Validation Loss: 2404.9492\n",
      "Epoch [1901/3000], Loss: 0.0911\n",
      "Validation Loss: 2428.7471\n",
      "Epoch [1921/3000], Loss: 0.0987\n",
      "Validation Loss: 2408.8473\n",
      "Epoch [1941/3000], Loss: 0.0986\n",
      "Validation Loss: 2446.9590\n",
      "Epoch [1961/3000], Loss: 0.0726\n",
      "Validation Loss: 2442.1707\n",
      "Epoch [1981/3000], Loss: 0.0754\n",
      "Validation Loss: 2477.4465\n",
      "Epoch [2001/3000], Loss: 0.0821\n",
      "Validation Loss: 2450.3743\n",
      "Epoch [2021/3000], Loss: 0.0667\n",
      "Validation Loss: 2454.9459\n",
      "Epoch [2041/3000], Loss: 0.0744\n",
      "Validation Loss: 2481.0683\n",
      "Epoch [2061/3000], Loss: 0.0654\n",
      "Validation Loss: 2459.2903\n",
      "Epoch [2081/3000], Loss: 0.0594\n",
      "Validation Loss: 2492.5564\n",
      "Epoch [2101/3000], Loss: 0.0602\n",
      "Validation Loss: 2487.0415\n",
      "Epoch [2121/3000], Loss: 0.0564\n",
      "Validation Loss: 2487.3450\n",
      "Epoch [2141/3000], Loss: 0.0640\n",
      "Validation Loss: 2477.9735\n",
      "Epoch [2161/3000], Loss: 0.0526\n",
      "Validation Loss: 2517.9729\n",
      "Epoch [2181/3000], Loss: 0.0565\n",
      "Validation Loss: 2522.1209\n",
      "Epoch [2201/3000], Loss: 0.0483\n",
      "Validation Loss: 2485.9103\n",
      "Epoch [2221/3000], Loss: 0.0439\n",
      "Validation Loss: 2522.3727\n",
      "Epoch [2241/3000], Loss: 99.2898\n",
      "Validation Loss: 2850.5085\n",
      "Epoch [2261/3000], Loss: 0.0969\n",
      "Validation Loss: 2516.0707\n",
      "Epoch [2281/3000], Loss: 0.0528\n",
      "Validation Loss: 2523.3093\n",
      "Epoch [2301/3000], Loss: 0.0402\n",
      "Validation Loss: 2520.5347\n",
      "Epoch [2321/3000], Loss: 0.0353\n",
      "Validation Loss: 2522.7824\n",
      "Epoch [2341/3000], Loss: 0.0324\n",
      "Validation Loss: 2526.7011\n",
      "Epoch [2361/3000], Loss: 0.0329\n",
      "Validation Loss: 2522.5672\n",
      "Epoch [2381/3000], Loss: 0.0336\n",
      "Validation Loss: 2519.2105\n",
      "Epoch [2401/3000], Loss: 0.0358\n",
      "Validation Loss: 2534.5692\n",
      "Epoch [2421/3000], Loss: 0.0369\n",
      "Validation Loss: 2518.1058\n",
      "Epoch [2441/3000], Loss: 0.0441\n",
      "Validation Loss: 2506.8218\n",
      "Epoch [2461/3000], Loss: 0.0729\n",
      "Validation Loss: 2477.7312\n",
      "Epoch [2481/3000], Loss: 0.0497\n",
      "Validation Loss: 2533.4488\n",
      "Epoch [2501/3000], Loss: 0.0431\n",
      "Validation Loss: 2536.2042\n",
      "Epoch [2521/3000], Loss: 0.0379\n",
      "Validation Loss: 2534.7634\n",
      "Epoch [2541/3000], Loss: 0.0342\n",
      "Validation Loss: 2542.0826\n",
      "Epoch [2561/3000], Loss: 0.0346\n",
      "Validation Loss: 2529.0671\n",
      "Epoch [2581/3000], Loss: 0.0318\n",
      "Validation Loss: 2553.6700\n",
      "Epoch [2601/3000], Loss: 0.0747\n",
      "Validation Loss: 2539.0468\n",
      "Epoch [2621/3000], Loss: 0.0354\n",
      "Validation Loss: 2533.6152\n",
      "Epoch [2641/3000], Loss: 0.0255\n",
      "Validation Loss: 2554.1478\n",
      "Epoch [2661/3000], Loss: 0.0290\n",
      "Validation Loss: 2580.3583\n",
      "Epoch [2681/3000], Loss: 0.0354\n",
      "Validation Loss: 2583.5546\n",
      "Epoch [2701/3000], Loss: 0.0302\n",
      "Validation Loss: 2540.3686\n",
      "Epoch [2721/3000], Loss: 0.0420\n",
      "Validation Loss: 2565.2802\n",
      "Epoch [2741/3000], Loss: 0.0290\n",
      "Validation Loss: 2538.6753\n",
      "Epoch [2761/3000], Loss: 0.0221\n",
      "Validation Loss: 2536.7041\n",
      "Epoch [2781/3000], Loss: 0.0223\n",
      "Validation Loss: 2557.9395\n",
      "Epoch [2801/3000], Loss: 0.0225\n",
      "Validation Loss: 2554.5982\n",
      "Epoch [2821/3000], Loss: 0.0244\n",
      "Validation Loss: 2536.8597\n",
      "Epoch [2841/3000], Loss: 0.0220\n",
      "Validation Loss: 2574.2897\n",
      "Epoch [2861/3000], Loss: 0.0192\n",
      "Validation Loss: 2565.1654\n",
      "Epoch [2881/3000], Loss: 0.0195\n",
      "Validation Loss: 2556.0456\n",
      "Epoch [2901/3000], Loss: 0.0177\n",
      "Validation Loss: 2580.9073\n",
      "Epoch [2921/3000], Loss: 0.0258\n",
      "Validation Loss: 2546.7689\n",
      "Epoch [2941/3000], Loss: 0.0205\n",
      "Validation Loss: 2548.4403\n",
      "Epoch [2961/3000], Loss: 0.0183\n",
      "Validation Loss: 2546.4680\n",
      "Epoch [2981/3000], Loss: 0.0220\n",
      "Validation Loss: 2554.0142\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day031_plane0_Fall.mat\n",
      "(9075, 127)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8167.2402\n",
      "Validation Loss: 6316.0236\n",
      "Epoch [21/3000], Loss: 6934.6529\n",
      "Validation Loss: 5237.4650\n",
      "Epoch [41/3000], Loss: 6672.5729\n",
      "Validation Loss: 5011.0242\n",
      "Epoch [61/3000], Loss: 6470.0327\n",
      "Validation Loss: 4830.9056\n",
      "Epoch [81/3000], Loss: 6264.3966\n",
      "Validation Loss: 4663.1996\n",
      "Epoch [101/3000], Loss: 6082.9998\n",
      "Validation Loss: 4506.7601\n",
      "Epoch [121/3000], Loss: 5886.8302\n",
      "Validation Loss: 4356.5661\n",
      "Epoch [141/3000], Loss: 5734.6782\n",
      "Validation Loss: 4214.4918\n",
      "Epoch [161/3000], Loss: 5545.0895\n",
      "Validation Loss: 4079.2729\n",
      "Epoch [181/3000], Loss: 5394.6202\n",
      "Validation Loss: 3950.3412\n",
      "Epoch [201/3000], Loss: 5253.3955\n",
      "Validation Loss: 3827.7067\n",
      "Epoch [221/3000], Loss: 5103.7242\n",
      "Validation Loss: 3711.0934\n",
      "Epoch [241/3000], Loss: 4974.6872\n",
      "Validation Loss: 3600.6118\n",
      "Epoch [261/3000], Loss: 4835.2998\n",
      "Validation Loss: 3496.2313\n",
      "Epoch [281/3000], Loss: 4716.0669\n",
      "Validation Loss: 3397.8156\n",
      "Epoch [301/3000], Loss: 4586.9967\n",
      "Validation Loss: 3305.2867\n",
      "Epoch [321/3000], Loss: 4488.7988\n",
      "Validation Loss: 3218.6199\n",
      "Epoch [341/3000], Loss: 4360.9509\n",
      "Validation Loss: 3137.9781\n",
      "Epoch [361/3000], Loss: 4263.5190\n",
      "Validation Loss: 3063.1158\n",
      "Epoch [381/3000], Loss: 4175.4058\n",
      "Validation Loss: 2994.0322\n",
      "Epoch [401/3000], Loss: 4079.0965\n",
      "Validation Loss: 2930.7274\n",
      "Epoch [421/3000], Loss: 3985.6427\n",
      "Validation Loss: 2873.0913\n",
      "Epoch [441/3000], Loss: 3912.7214\n",
      "Validation Loss: 2821.1255\n",
      "Epoch [461/3000], Loss: 3841.6333\n",
      "Validation Loss: 2774.7204\n",
      "Epoch [481/3000], Loss: 3775.5530\n",
      "Validation Loss: 2733.8530\n",
      "Epoch [501/3000], Loss: 3722.8649\n",
      "Validation Loss: 2698.3776\n",
      "Epoch [521/3000], Loss: 3659.3284\n",
      "Validation Loss: 2668.1991\n",
      "Epoch [541/3000], Loss: 3614.2642\n",
      "Validation Loss: 2643.1785\n",
      "Epoch [561/3000], Loss: 3562.2622\n",
      "Validation Loss: 2623.2423\n",
      "Epoch [581/3000], Loss: 3531.6080\n",
      "Validation Loss: 2608.1628\n",
      "Epoch [601/3000], Loss: 3492.8889\n",
      "Validation Loss: 2597.7420\n",
      "Epoch [621/3000], Loss: 3460.2327\n",
      "Validation Loss: 2591.6697\n",
      "Epoch [641/3000], Loss: 3444.2450\n",
      "Validation Loss: 2589.6409\n",
      "Epoch [661/3000], Loss: 3419.1893\n",
      "Validation Loss: 2591.2099\n",
      "Epoch [681/3000], Loss: 3399.3316\n",
      "Validation Loss: 2595.8297\n",
      "Epoch [701/3000], Loss: 3387.2566\n",
      "Validation Loss: 2602.8538\n",
      "Epoch [721/3000], Loss: 3381.6035\n",
      "Validation Loss: 2611.4641\n",
      "Epoch [741/3000], Loss: 3376.7684\n",
      "Validation Loss: 2620.8355\n",
      "Epoch [761/3000], Loss: 2098.0728\n",
      "Validation Loss: 1867.3475\n",
      "Epoch [781/3000], Loss: 1907.1395\n",
      "Validation Loss: 1773.6004\n",
      "Epoch [801/3000], Loss: 1785.0759\n",
      "Validation Loss: 1711.9118\n",
      "Epoch [821/3000], Loss: 1682.9114\n",
      "Validation Loss: 1673.5182\n",
      "Epoch [841/3000], Loss: 1592.7989\n",
      "Validation Loss: 1624.1957\n",
      "Epoch [861/3000], Loss: 1509.6822\n",
      "Validation Loss: 1581.2921\n",
      "Epoch [881/3000], Loss: 1435.6858\n",
      "Validation Loss: 1549.1284\n",
      "Epoch [901/3000], Loss: 1357.4061\n",
      "Validation Loss: 1531.7133\n",
      "Epoch [921/3000], Loss: 1287.3901\n",
      "Validation Loss: 1515.9703\n",
      "Epoch [941/3000], Loss: 1206.7886\n",
      "Validation Loss: 1569.7368\n",
      "Epoch [961/3000], Loss: 1129.8646\n",
      "Validation Loss: 1525.8058\n",
      "Epoch [981/3000], Loss: 1068.3616\n",
      "Validation Loss: 1519.8656\n",
      "Epoch [1001/3000], Loss: 1005.6262\n",
      "Validation Loss: 1452.8132\n",
      "Epoch [1021/3000], Loss: 944.9996\n",
      "Validation Loss: 1446.2099\n",
      "Epoch [1041/3000], Loss: 896.1688\n",
      "Validation Loss: 1460.3943\n",
      "Epoch [1061/3000], Loss: 840.5347\n",
      "Validation Loss: 1423.3557\n",
      "Epoch [1081/3000], Loss: 792.9007\n",
      "Validation Loss: 1393.8165\n",
      "Epoch [1101/3000], Loss: 750.1702\n",
      "Validation Loss: 1415.1495\n",
      "Epoch [1121/3000], Loss: 701.8413\n",
      "Validation Loss: 1355.1649\n",
      "Epoch [1141/3000], Loss: 657.4830\n",
      "Validation Loss: 1349.1107\n",
      "Epoch [1161/3000], Loss: 619.1284\n",
      "Validation Loss: 1338.1909\n",
      "Epoch [1181/3000], Loss: 579.4651\n",
      "Validation Loss: 1324.6891\n",
      "Epoch [1201/3000], Loss: 543.7024\n",
      "Validation Loss: 1317.6290\n",
      "Epoch [1221/3000], Loss: 509.0394\n",
      "Validation Loss: 1321.7604\n",
      "Epoch [1241/3000], Loss: 475.5731\n",
      "Validation Loss: 1324.7273\n",
      "Epoch [1261/3000], Loss: 444.6280\n",
      "Validation Loss: 1325.1372\n",
      "Epoch [1281/3000], Loss: 453.2935\n",
      "Validation Loss: 1327.7116\n",
      "Epoch [1301/3000], Loss: 387.4733\n",
      "Validation Loss: 1332.6591\n",
      "Epoch [1321/3000], Loss: 362.2359\n",
      "Validation Loss: 1342.0571\n",
      "Epoch [1341/3000], Loss: 337.4572\n",
      "Validation Loss: 1349.6197\n",
      "Epoch [1361/3000], Loss: 310.6708\n",
      "Validation Loss: 1333.6442\n",
      "Epoch [1381/3000], Loss: 283.1697\n",
      "Validation Loss: 1326.0063\n",
      "Epoch [1401/3000], Loss: 259.0423\n",
      "Validation Loss: 1348.8717\n",
      "Epoch [1421/3000], Loss: 239.7231\n",
      "Validation Loss: 1369.1829\n",
      "Epoch [1441/3000], Loss: 218.5921\n",
      "Validation Loss: 1388.5637\n",
      "Epoch [1461/3000], Loss: 199.8531\n",
      "Validation Loss: 1404.9783\n",
      "Epoch [1481/3000], Loss: 182.5052\n",
      "Validation Loss: 1383.5575\n",
      "Epoch [1501/3000], Loss: 167.1937\n",
      "Validation Loss: 1384.2564\n",
      "Epoch [1521/3000], Loss: 152.6040\n",
      "Validation Loss: 1394.6204\n",
      "Epoch [1541/3000], Loss: 138.5639\n",
      "Validation Loss: 1401.5107\n",
      "Epoch [1561/3000], Loss: 124.7601\n",
      "Validation Loss: 1415.0835\n",
      "Epoch [1581/3000], Loss: 112.0618\n",
      "Validation Loss: 1420.6729\n",
      "Epoch [1601/3000], Loss: 171.5284\n",
      "Validation Loss: 1454.5580\n",
      "Epoch [1621/3000], Loss: 90.8210\n",
      "Validation Loss: 1438.8175\n",
      "Epoch [1641/3000], Loss: 85.1000\n",
      "Validation Loss: 1427.0632\n",
      "Epoch [1661/3000], Loss: 81.2103\n",
      "Validation Loss: 1496.3436\n",
      "Epoch [1681/3000], Loss: 64.9280\n",
      "Validation Loss: 1466.4000\n",
      "Epoch [1701/3000], Loss: 57.8065\n",
      "Validation Loss: 1477.0315\n",
      "Epoch [1721/3000], Loss: 51.3931\n",
      "Validation Loss: 1487.8611\n",
      "Epoch [1741/3000], Loss: 45.4688\n",
      "Validation Loss: 1477.2117\n",
      "Epoch [1761/3000], Loss: 39.7835\n",
      "Validation Loss: 1468.3039\n",
      "Epoch [1781/3000], Loss: 34.5888\n",
      "Validation Loss: 1482.8277\n",
      "Epoch [1801/3000], Loss: 30.9189\n",
      "Validation Loss: 1474.6171\n",
      "Epoch [1821/3000], Loss: 27.2715\n",
      "Validation Loss: 1478.3745\n",
      "Epoch [1841/3000], Loss: 23.5554\n",
      "Validation Loss: 1478.9238\n",
      "Epoch [1861/3000], Loss: 20.4195\n",
      "Validation Loss: 1481.5725\n",
      "Epoch [1881/3000], Loss: 17.3352\n",
      "Validation Loss: 1495.4879\n",
      "Epoch [1901/3000], Loss: 46.7628\n",
      "Validation Loss: 1494.4058\n",
      "Epoch [1921/3000], Loss: 13.5012\n",
      "Validation Loss: 1499.0710\n",
      "Epoch [1941/3000], Loss: 11.9715\n",
      "Validation Loss: 1508.3631\n",
      "Epoch [1961/3000], Loss: 10.4715\n",
      "Validation Loss: 1514.9957\n",
      "Epoch [1981/3000], Loss: 8.7502\n",
      "Validation Loss: 1529.7509\n",
      "Epoch [2001/3000], Loss: 7.2433\n",
      "Validation Loss: 1539.3905\n",
      "Epoch [2021/3000], Loss: 5.8965\n",
      "Validation Loss: 1530.7553\n",
      "Epoch [2041/3000], Loss: 4.7375\n",
      "Validation Loss: 1517.8424\n",
      "Epoch [2061/3000], Loss: 26.3285\n",
      "Validation Loss: 1592.4089\n",
      "Epoch [2081/3000], Loss: 3.7340\n",
      "Validation Loss: 1518.0527\n",
      "Epoch [2101/3000], Loss: 3.3414\n",
      "Validation Loss: 1523.3744\n",
      "Epoch [2121/3000], Loss: 3.0040\n",
      "Validation Loss: 1526.8368\n",
      "Epoch [2141/3000], Loss: 2.6340\n",
      "Validation Loss: 1532.1488\n",
      "Epoch [2161/3000], Loss: 2.2900\n",
      "Validation Loss: 1535.5271\n",
      "Epoch [2181/3000], Loss: 2.0042\n",
      "Validation Loss: 1533.6281\n",
      "Epoch [2201/3000], Loss: 1.7325\n",
      "Validation Loss: 1523.7799\n",
      "Epoch [2221/3000], Loss: 1.5323\n",
      "Validation Loss: 1514.1108\n",
      "Epoch [2241/3000], Loss: 1.3221\n",
      "Validation Loss: 1525.9989\n",
      "Epoch [2261/3000], Loss: 1.1892\n",
      "Validation Loss: 1517.0205\n",
      "Epoch [2281/3000], Loss: 0.9762\n",
      "Validation Loss: 1506.1031\n",
      "Epoch [2301/3000], Loss: 0.8987\n",
      "Validation Loss: 1504.8226\n",
      "Epoch [2321/3000], Loss: 0.7796\n",
      "Validation Loss: 1517.4994\n",
      "Epoch [2341/3000], Loss: 0.6430\n",
      "Validation Loss: 1496.3178\n",
      "Epoch [2361/3000], Loss: 0.7642\n",
      "Validation Loss: 1479.1273\n",
      "Epoch [2381/3000], Loss: 0.6068\n",
      "Validation Loss: 1483.3912\n",
      "Epoch [2401/3000], Loss: 0.5685\n",
      "Validation Loss: 1491.1989\n",
      "Epoch [2421/3000], Loss: 0.5486\n",
      "Validation Loss: 1493.3113\n",
      "Epoch [2441/3000], Loss: 0.5282\n",
      "Validation Loss: 1491.7198\n",
      "Epoch [2461/3000], Loss: 0.5145\n",
      "Validation Loss: 1492.9151\n",
      "Epoch [2481/3000], Loss: 0.4913\n",
      "Validation Loss: 1489.0470\n",
      "Epoch [2501/3000], Loss: 0.4670\n",
      "Validation Loss: 1486.9484\n",
      "Epoch [2521/3000], Loss: 0.4503\n",
      "Validation Loss: 1503.1066\n",
      "Epoch [2541/3000], Loss: 0.4200\n",
      "Validation Loss: 1486.4129\n",
      "Epoch [2561/3000], Loss: 0.3964\n",
      "Validation Loss: 1503.0201\n",
      "Epoch [2581/3000], Loss: 0.3681\n",
      "Validation Loss: 1494.7211\n",
      "Epoch [2601/3000], Loss: 0.3363\n",
      "Validation Loss: 1499.5154\n",
      "Epoch [2621/3000], Loss: 0.3304\n",
      "Validation Loss: 1486.5555\n",
      "Epoch [2641/3000], Loss: 0.3135\n",
      "Validation Loss: 1509.8173\n",
      "Epoch [2661/3000], Loss: 0.2851\n",
      "Validation Loss: 1506.6709\n",
      "Epoch [2681/3000], Loss: 0.4087\n",
      "Validation Loss: 1458.5039\n",
      "Epoch [2701/3000], Loss: 0.2817\n",
      "Validation Loss: 1466.4429\n",
      "Epoch [2721/3000], Loss: 0.2539\n",
      "Validation Loss: 1472.0404\n",
      "Epoch [2741/3000], Loss: 0.2405\n",
      "Validation Loss: 1475.8582\n",
      "Epoch [2761/3000], Loss: 0.2394\n",
      "Validation Loss: 1476.9533\n",
      "Epoch [2781/3000], Loss: 0.2391\n",
      "Validation Loss: 1483.7037\n",
      "Epoch [2801/3000], Loss: 0.2268\n",
      "Validation Loss: 1481.3894\n",
      "Epoch [2821/3000], Loss: 0.2395\n",
      "Validation Loss: 1486.8443\n",
      "Epoch [2841/3000], Loss: 0.2371\n",
      "Validation Loss: 1488.3120\n",
      "Epoch [2861/3000], Loss: 0.2470\n",
      "Validation Loss: 1486.1544\n",
      "Epoch [2881/3000], Loss: 0.2246\n",
      "Validation Loss: 1498.6491\n",
      "Epoch [2901/3000], Loss: 0.2368\n",
      "Validation Loss: 1488.4049\n",
      "Epoch [2921/3000], Loss: 0.2091\n",
      "Validation Loss: 1498.4907\n",
      "Epoch [2941/3000], Loss: 0.2103\n",
      "Validation Loss: 1500.9346\n",
      "Epoch [2961/3000], Loss: 0.2110\n",
      "Validation Loss: 1500.8764\n",
      "Epoch [2981/3000], Loss: 0.1988\n",
      "Validation Loss: 1489.0463\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day032_plane0_Fall.mat\n",
      "(6858, 90)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8577.8840\n",
      "Validation Loss: 7965.1265\n",
      "Epoch [21/3000], Loss: 7365.5382\n",
      "Validation Loss: 6824.4001\n",
      "Epoch [41/3000], Loss: 7124.5365\n",
      "Validation Loss: 6583.4658\n",
      "Epoch [61/3000], Loss: 6969.6579\n",
      "Validation Loss: 6415.4828\n",
      "Epoch [81/3000], Loss: 6799.2603\n",
      "Validation Loss: 6262.7898\n",
      "Epoch [101/3000], Loss: 6629.3953\n",
      "Validation Loss: 6114.1199\n",
      "Epoch [121/3000], Loss: 6471.1210\n",
      "Validation Loss: 5976.0362\n",
      "Epoch [141/3000], Loss: 6330.1120\n",
      "Validation Loss: 5843.1856\n",
      "Epoch [161/3000], Loss: 6199.1428\n",
      "Validation Loss: 5714.5622\n",
      "Epoch [181/3000], Loss: 6056.3466\n",
      "Validation Loss: 5586.4263\n",
      "Epoch [201/3000], Loss: 5948.0623\n",
      "Validation Loss: 5463.8969\n",
      "Epoch [221/3000], Loss: 5802.2422\n",
      "Validation Loss: 5344.4487\n",
      "Epoch [241/3000], Loss: 5694.0312\n",
      "Validation Loss: 5229.0936\n",
      "Epoch [261/3000], Loss: 5553.2671\n",
      "Validation Loss: 5115.4045\n",
      "Epoch [281/3000], Loss: 5437.0088\n",
      "Validation Loss: 5005.9947\n",
      "Epoch [301/3000], Loss: 5334.4083\n",
      "Validation Loss: 4900.2182\n",
      "Epoch [321/3000], Loss: 5235.3569\n",
      "Validation Loss: 4797.8816\n",
      "Epoch [341/3000], Loss: 5106.5158\n",
      "Validation Loss: 4697.6991\n",
      "Epoch [361/3000], Loss: 5023.0315\n",
      "Validation Loss: 4601.0621\n",
      "Epoch [381/3000], Loss: 4935.6273\n",
      "Validation Loss: 4508.0880\n",
      "Epoch [401/3000], Loss: 4811.2529\n",
      "Validation Loss: 4418.4062\n",
      "Epoch [421/3000], Loss: 4726.2179\n",
      "Validation Loss: 4332.0164\n",
      "Epoch [441/3000], Loss: 4644.6601\n",
      "Validation Loss: 4247.5221\n",
      "Epoch [461/3000], Loss: 4542.0692\n",
      "Validation Loss: 4167.0435\n",
      "Epoch [481/3000], Loss: 4467.1494\n",
      "Validation Loss: 4089.9460\n",
      "Epoch [501/3000], Loss: 4392.9737\n",
      "Validation Loss: 4016.2125\n",
      "Epoch [521/3000], Loss: 4302.2628\n",
      "Validation Loss: 3945.5859\n",
      "Epoch [541/3000], Loss: 4226.3498\n",
      "Validation Loss: 3878.2577\n",
      "Epoch [561/3000], Loss: 4154.9946\n",
      "Validation Loss: 3813.5177\n",
      "Epoch [581/3000], Loss: 4104.5883\n",
      "Validation Loss: 3751.7537\n",
      "Epoch [601/3000], Loss: 4017.2141\n",
      "Validation Loss: 3693.6827\n",
      "Epoch [621/3000], Loss: 3960.6089\n",
      "Validation Loss: 3637.6521\n",
      "Epoch [641/3000], Loss: 3895.9500\n",
      "Validation Loss: 3585.7254\n",
      "Epoch [661/3000], Loss: 3867.9264\n",
      "Validation Loss: 3536.9717\n",
      "Epoch [681/3000], Loss: 3805.3150\n",
      "Validation Loss: 3491.3563\n",
      "Epoch [701/3000], Loss: 3747.5539\n",
      "Validation Loss: 3448.7836\n",
      "Epoch [721/3000], Loss: 3708.5845\n",
      "Validation Loss: 3409.4129\n",
      "Epoch [741/3000], Loss: 3649.2828\n",
      "Validation Loss: 3373.0546\n",
      "Epoch [761/3000], Loss: 3617.5605\n",
      "Validation Loss: 3339.5695\n",
      "Epoch [781/3000], Loss: 3578.9311\n",
      "Validation Loss: 3309.2153\n",
      "Epoch [801/3000], Loss: 3540.6256\n",
      "Validation Loss: 3281.6867\n",
      "Epoch [821/3000], Loss: 3521.8406\n",
      "Validation Loss: 3256.9519\n",
      "Epoch [841/3000], Loss: 3500.9441\n",
      "Validation Loss: 3235.0051\n",
      "Epoch [861/3000], Loss: 3465.7681\n",
      "Validation Loss: 3215.7993\n",
      "Epoch [881/3000], Loss: 3447.8625\n",
      "Validation Loss: 3199.2512\n",
      "Epoch [901/3000], Loss: 3413.0555\n",
      "Validation Loss: 3185.2150\n",
      "Epoch [921/3000], Loss: 3411.4801\n",
      "Validation Loss: 3173.6346\n",
      "Epoch [941/3000], Loss: 3381.9582\n",
      "Validation Loss: 3164.2796\n",
      "Epoch [961/3000], Loss: 2723.4699\n",
      "Validation Loss: 2465.1812\n",
      "Epoch [981/3000], Loss: 2266.3997\n",
      "Validation Loss: 2039.0378\n",
      "Epoch [1001/3000], Loss: 2163.7653\n",
      "Validation Loss: 1960.6076\n",
      "Epoch [1021/3000], Loss: 2076.3274\n",
      "Validation Loss: 1890.4385\n",
      "Epoch [1041/3000], Loss: 1988.4587\n",
      "Validation Loss: 1835.4598\n",
      "Epoch [1061/3000], Loss: 1910.6199\n",
      "Validation Loss: 1790.5175\n",
      "Epoch [1081/3000], Loss: 1834.8290\n",
      "Validation Loss: 1749.0538\n",
      "Epoch [1101/3000], Loss: 1751.8688\n",
      "Validation Loss: 1713.9520\n",
      "Epoch [1121/3000], Loss: 1686.1190\n",
      "Validation Loss: 1681.5488\n",
      "Epoch [1141/3000], Loss: 1624.5478\n",
      "Validation Loss: 1653.6981\n",
      "Epoch [1161/3000], Loss: 1554.0197\n",
      "Validation Loss: 1614.2133\n",
      "Epoch [1181/3000], Loss: 1507.9182\n",
      "Validation Loss: 1587.7369\n",
      "Epoch [1201/3000], Loss: 1467.2268\n",
      "Validation Loss: 1560.1948\n",
      "Epoch [1221/3000], Loss: 1396.4437\n",
      "Validation Loss: 1547.1917\n",
      "Epoch [1241/3000], Loss: 1352.5130\n",
      "Validation Loss: 1527.1949\n",
      "Epoch [1261/3000], Loss: 1303.0818\n",
      "Validation Loss: 1504.7851\n",
      "Epoch [1281/3000], Loss: 1267.0101\n",
      "Validation Loss: 1492.8849\n",
      "Epoch [1301/3000], Loss: 1234.2154\n",
      "Validation Loss: 1476.7516\n",
      "Epoch [1321/3000], Loss: 1177.5835\n",
      "Validation Loss: 1459.3482\n",
      "Epoch [1341/3000], Loss: 1145.8010\n",
      "Validation Loss: 1453.3804\n",
      "Epoch [1361/3000], Loss: 1108.8354\n",
      "Validation Loss: 1430.8072\n",
      "Epoch [1381/3000], Loss: 1068.1988\n",
      "Validation Loss: 1404.6118\n",
      "Epoch [1401/3000], Loss: 1030.2513\n",
      "Validation Loss: 1402.4495\n",
      "Epoch [1421/3000], Loss: 1003.9262\n",
      "Validation Loss: 1400.7906\n",
      "Epoch [1441/3000], Loss: 970.4326\n",
      "Validation Loss: 1384.2384\n",
      "Epoch [1461/3000], Loss: 938.1729\n",
      "Validation Loss: 1373.0251\n",
      "Epoch [1481/3000], Loss: 903.7399\n",
      "Validation Loss: 1398.6541\n",
      "Epoch [1501/3000], Loss: 883.5401\n",
      "Validation Loss: 1381.4368\n",
      "Epoch [1521/3000], Loss: 872.2618\n",
      "Validation Loss: 1376.0932\n",
      "Epoch [1541/3000], Loss: 833.9585\n",
      "Validation Loss: 1364.5192\n",
      "Epoch [1561/3000], Loss: 822.0634\n",
      "Validation Loss: 1376.6754\n",
      "Epoch [1581/3000], Loss: 804.9975\n",
      "Validation Loss: 1386.6171\n",
      "Epoch [1601/3000], Loss: 770.3268\n",
      "Validation Loss: 1361.4185\n",
      "Epoch [1621/3000], Loss: 752.9038\n",
      "Validation Loss: 1380.1478\n",
      "Epoch [1641/3000], Loss: 721.4578\n",
      "Validation Loss: 1367.5342\n",
      "Epoch [1661/3000], Loss: 703.9351\n",
      "Validation Loss: 1391.4482\n",
      "Epoch [1681/3000], Loss: 679.7312\n",
      "Validation Loss: 1401.8106\n",
      "Epoch [1701/3000], Loss: 658.3438\n",
      "Validation Loss: 1381.9758\n",
      "Epoch [1721/3000], Loss: 634.4960\n",
      "Validation Loss: 1401.6415\n",
      "Epoch [1741/3000], Loss: 618.7928\n",
      "Validation Loss: 1400.3876\n",
      "Epoch [1761/3000], Loss: 598.5523\n",
      "Validation Loss: 1403.3832\n",
      "Epoch [1781/3000], Loss: 587.3807\n",
      "Validation Loss: 1423.6551\n",
      "Epoch [1801/3000], Loss: 563.0801\n",
      "Validation Loss: 1363.5268\n",
      "Epoch [1821/3000], Loss: 549.5016\n",
      "Validation Loss: 1410.9433\n",
      "Epoch [1841/3000], Loss: 535.1261\n",
      "Validation Loss: 1403.6764\n",
      "Epoch [1861/3000], Loss: 514.7543\n",
      "Validation Loss: 1390.4622\n",
      "Epoch [1881/3000], Loss: 503.9786\n",
      "Validation Loss: 1424.1748\n",
      "Epoch [1901/3000], Loss: 489.1330\n",
      "Validation Loss: 1431.1827\n",
      "Epoch [1921/3000], Loss: 474.9977\n",
      "Validation Loss: 1449.5143\n",
      "Epoch [1941/3000], Loss: 461.4277\n",
      "Validation Loss: 1458.8538\n",
      "Epoch [1961/3000], Loss: 460.0785\n",
      "Validation Loss: 1464.4437\n",
      "Epoch [1981/3000], Loss: 432.4390\n",
      "Validation Loss: 1457.0776\n",
      "Epoch [2001/3000], Loss: 427.5503\n",
      "Validation Loss: 1453.6746\n",
      "Epoch [2021/3000], Loss: 428.8072\n",
      "Validation Loss: 1492.1467\n",
      "Epoch [2041/3000], Loss: 422.2363\n",
      "Validation Loss: 1483.8984\n",
      "Epoch [2061/3000], Loss: 384.7313\n",
      "Validation Loss: 1441.8898\n",
      "Epoch [2081/3000], Loss: 387.2057\n",
      "Validation Loss: 1491.6306\n",
      "Epoch [2101/3000], Loss: 368.2213\n",
      "Validation Loss: 1475.1755\n",
      "Epoch [2121/3000], Loss: 362.3110\n",
      "Validation Loss: 1503.9778\n",
      "Epoch [2141/3000], Loss: 335.5739\n",
      "Validation Loss: 1515.7133\n",
      "Epoch [2161/3000], Loss: 323.7440\n",
      "Validation Loss: 1483.9059\n",
      "Epoch [2181/3000], Loss: 314.5669\n",
      "Validation Loss: 1510.9565\n",
      "Epoch [2201/3000], Loss: 309.5773\n",
      "Validation Loss: 1524.2006\n",
      "Epoch [2221/3000], Loss: 301.1433\n",
      "Validation Loss: 1578.7666\n",
      "Epoch [2241/3000], Loss: 286.2483\n",
      "Validation Loss: 1530.5519\n",
      "Epoch [2261/3000], Loss: 269.0722\n",
      "Validation Loss: 1521.6193\n",
      "Epoch [2281/3000], Loss: 260.3873\n",
      "Validation Loss: 1537.3223\n",
      "Epoch [2301/3000], Loss: 257.5911\n",
      "Validation Loss: 1541.0550\n",
      "Epoch [2321/3000], Loss: 236.1073\n",
      "Validation Loss: 1553.5875\n",
      "Epoch [2341/3000], Loss: 230.5413\n",
      "Validation Loss: 1557.7312\n",
      "Epoch [2361/3000], Loss: 228.1661\n",
      "Validation Loss: 1559.4364\n",
      "Epoch [2381/3000], Loss: 215.8874\n",
      "Validation Loss: 1581.6454\n",
      "Epoch [2401/3000], Loss: 210.1792\n",
      "Validation Loss: 1583.2392\n",
      "Epoch [2421/3000], Loss: 210.2912\n",
      "Validation Loss: 1609.0269\n",
      "Epoch [2441/3000], Loss: 196.8300\n",
      "Validation Loss: 1574.2500\n",
      "Epoch [2461/3000], Loss: 188.2136\n",
      "Validation Loss: 1596.5471\n",
      "Epoch [2481/3000], Loss: 181.6157\n",
      "Validation Loss: 1596.1139\n",
      "Epoch [2501/3000], Loss: 179.2413\n",
      "Validation Loss: 1666.6425\n",
      "Epoch [2521/3000], Loss: 167.5668\n",
      "Validation Loss: 1656.8113\n",
      "Epoch [2541/3000], Loss: 158.3849\n",
      "Validation Loss: 1653.9334\n",
      "Epoch [2561/3000], Loss: 167.2194\n",
      "Validation Loss: 1665.4167\n",
      "Epoch [2581/3000], Loss: 149.1411\n",
      "Validation Loss: 1719.2295\n",
      "Epoch [2601/3000], Loss: 133.1349\n",
      "Validation Loss: 1685.4718\n",
      "Epoch [2621/3000], Loss: 127.3074\n",
      "Validation Loss: 1717.9168\n",
      "Epoch [2641/3000], Loss: 122.0629\n",
      "Validation Loss: 1682.8824\n",
      "Epoch [2661/3000], Loss: 117.1931\n",
      "Validation Loss: 1657.4488\n",
      "Epoch [2681/3000], Loss: 113.0453\n",
      "Validation Loss: 1696.1115\n",
      "Epoch [2701/3000], Loss: 110.6054\n",
      "Validation Loss: 1687.9462\n",
      "Epoch [2721/3000], Loss: 103.3076\n",
      "Validation Loss: 1704.4805\n",
      "Epoch [2741/3000], Loss: 100.0702\n",
      "Validation Loss: 1707.8125\n",
      "Epoch [2761/3000], Loss: 93.8972\n",
      "Validation Loss: 1700.8969\n",
      "Epoch [2781/3000], Loss: 90.3823\n",
      "Validation Loss: 1704.8439\n",
      "Epoch [2801/3000], Loss: 87.2085\n",
      "Validation Loss: 1699.4162\n",
      "Epoch [2821/3000], Loss: 82.4795\n",
      "Validation Loss: 1726.2986\n",
      "Epoch [2841/3000], Loss: 82.4779\n",
      "Validation Loss: 1694.2385\n",
      "Epoch [2861/3000], Loss: 78.1269\n",
      "Validation Loss: 1715.0910\n",
      "Epoch [2881/3000], Loss: 76.8314\n",
      "Validation Loss: 1683.5194\n",
      "Epoch [2901/3000], Loss: 75.6327\n",
      "Validation Loss: 1726.3569\n",
      "Epoch [2921/3000], Loss: 106.8867\n",
      "Validation Loss: 1789.9077\n",
      "Epoch [2941/3000], Loss: 69.8862\n",
      "Validation Loss: 1688.0507\n",
      "Epoch [2961/3000], Loss: 68.6182\n",
      "Validation Loss: 1665.5100\n",
      "Epoch [2981/3000], Loss: 65.2280\n",
      "Validation Loss: 1686.4220\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day033_plane0_Fall.mat\n",
      "(5033, 167)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9575.3291\n",
      "Validation Loss: 8443.1834\n",
      "Epoch [21/3000], Loss: 8346.5679\n",
      "Validation Loss: 7316.8514\n",
      "Epoch [41/3000], Loss: 8043.9429\n",
      "Validation Loss: 7051.1682\n",
      "Epoch [61/3000], Loss: 7876.4342\n",
      "Validation Loss: 6898.3149\n",
      "Epoch [81/3000], Loss: 7721.0638\n",
      "Validation Loss: 6766.1060\n",
      "Epoch [101/3000], Loss: 7560.1333\n",
      "Validation Loss: 6641.3856\n",
      "Epoch [121/3000], Loss: 7434.3952\n",
      "Validation Loss: 6524.1955\n",
      "Epoch [141/3000], Loss: 7327.2358\n",
      "Validation Loss: 6408.7124\n",
      "Epoch [161/3000], Loss: 7206.4097\n",
      "Validation Loss: 6298.3647\n",
      "Epoch [181/3000], Loss: 7058.6828\n",
      "Validation Loss: 6191.1353\n",
      "Epoch [201/3000], Loss: 6952.1949\n",
      "Validation Loss: 6086.5643\n",
      "Epoch [221/3000], Loss: 6866.9025\n",
      "Validation Loss: 5984.1611\n",
      "Epoch [241/3000], Loss: 6737.8819\n",
      "Validation Loss: 5883.9200\n",
      "Epoch [261/3000], Loss: 6589.3466\n",
      "Validation Loss: 5785.9081\n",
      "Epoch [281/3000], Loss: 6512.0444\n",
      "Validation Loss: 5689.7896\n",
      "Epoch [301/3000], Loss: 6407.6779\n",
      "Validation Loss: 5595.4810\n",
      "Epoch [321/3000], Loss: 6309.9001\n",
      "Validation Loss: 5503.0583\n",
      "Epoch [341/3000], Loss: 6212.5837\n",
      "Validation Loss: 5412.4660\n",
      "Epoch [361/3000], Loss: 6137.2041\n",
      "Validation Loss: 5323.6541\n",
      "Epoch [381/3000], Loss: 5996.9666\n",
      "Validation Loss: 5236.6916\n",
      "Epoch [401/3000], Loss: 5921.1502\n",
      "Validation Loss: 5151.5712\n",
      "Epoch [421/3000], Loss: 5814.2740\n",
      "Validation Loss: 5068.2633\n",
      "Epoch [441/3000], Loss: 5727.0054\n",
      "Validation Loss: 4986.6098\n",
      "Epoch [461/3000], Loss: 5630.9365\n",
      "Validation Loss: 4906.8543\n",
      "Epoch [481/3000], Loss: 5545.4727\n",
      "Validation Loss: 4828.8742\n",
      "Epoch [501/3000], Loss: 5470.7728\n",
      "Validation Loss: 4752.5726\n",
      "Epoch [521/3000], Loss: 5360.0674\n",
      "Validation Loss: 4678.0314\n",
      "Epoch [541/3000], Loss: 5301.4607\n",
      "Validation Loss: 4605.2961\n",
      "Epoch [561/3000], Loss: 5190.2316\n",
      "Validation Loss: 4534.2695\n",
      "Epoch [581/3000], Loss: 5133.3379\n",
      "Validation Loss: 4464.9734\n",
      "Epoch [601/3000], Loss: 5016.8963\n",
      "Validation Loss: 4397.4584\n",
      "Epoch [621/3000], Loss: 4958.9856\n",
      "Validation Loss: 4331.7297\n",
      "Epoch [641/3000], Loss: 4880.8263\n",
      "Validation Loss: 4267.7151\n",
      "Epoch [661/3000], Loss: 4812.3589\n",
      "Validation Loss: 4205.4621\n",
      "Epoch [681/3000], Loss: 4730.7873\n",
      "Validation Loss: 4144.1250\n",
      "Epoch [701/3000], Loss: 4689.4170\n",
      "Validation Loss: 4084.2288\n",
      "Epoch [721/3000], Loss: 4604.9671\n",
      "Validation Loss: 4026.7821\n",
      "Epoch [741/3000], Loss: 4518.7878\n",
      "Validation Loss: 3971.2220\n",
      "Epoch [761/3000], Loss: 4477.8477\n",
      "Validation Loss: 3917.3666\n",
      "Epoch [781/3000], Loss: 4402.2343\n",
      "Validation Loss: 3865.2384\n",
      "Epoch [801/3000], Loss: 4336.8722\n",
      "Validation Loss: 3814.8715\n",
      "Epoch [821/3000], Loss: 4280.6439\n",
      "Validation Loss: 3766.2451\n",
      "Epoch [841/3000], Loss: 4241.2322\n",
      "Validation Loss: 3719.3413\n",
      "Epoch [861/3000], Loss: 4148.5052\n",
      "Validation Loss: 3674.0866\n",
      "Epoch [881/3000], Loss: 4121.2869\n",
      "Validation Loss: 3630.6006\n",
      "Epoch [901/3000], Loss: 4047.2774\n",
      "Validation Loss: 3588.8214\n",
      "Epoch [921/3000], Loss: 3999.2579\n",
      "Validation Loss: 3548.7517\n",
      "Epoch [941/3000], Loss: 3959.0411\n",
      "Validation Loss: 3510.2455\n",
      "Epoch [961/3000], Loss: 3918.8074\n",
      "Validation Loss: 3473.5610\n",
      "Epoch [981/3000], Loss: 3856.2817\n",
      "Validation Loss: 3438.3855\n",
      "Epoch [1001/3000], Loss: 3815.9283\n",
      "Validation Loss: 3404.9356\n",
      "Epoch [1021/3000], Loss: 3764.2244\n",
      "Validation Loss: 3373.0927\n",
      "Epoch [1041/3000], Loss: 3737.6747\n",
      "Validation Loss: 3342.9570\n",
      "Epoch [1061/3000], Loss: 3710.7751\n",
      "Validation Loss: 3314.4533\n",
      "Epoch [1081/3000], Loss: 3634.6087\n",
      "Validation Loss: 3287.5342\n",
      "Epoch [1101/3000], Loss: 3072.3089\n",
      "Validation Loss: 2771.3871\n",
      "Epoch [1121/3000], Loss: 2713.6089\n",
      "Validation Loss: 2450.4945\n",
      "Epoch [1141/3000], Loss: 2616.8351\n",
      "Validation Loss: 2375.3177\n",
      "Epoch [1161/3000], Loss: 2528.3620\n",
      "Validation Loss: 2338.7456\n",
      "Epoch [1181/3000], Loss: 2445.0010\n",
      "Validation Loss: 2288.2871\n",
      "Epoch [1201/3000], Loss: 2388.2978\n",
      "Validation Loss: 2251.1699\n",
      "Epoch [1221/3000], Loss: 2310.2336\n",
      "Validation Loss: 2276.3576\n",
      "Epoch [1241/3000], Loss: 2263.5403\n",
      "Validation Loss: 2223.1573\n",
      "Epoch [1261/3000], Loss: 2195.9464\n",
      "Validation Loss: 2200.9636\n",
      "Epoch [1281/3000], Loss: 2140.0525\n",
      "Validation Loss: 2132.3454\n",
      "Epoch [1301/3000], Loss: 2080.2467\n",
      "Validation Loss: 2164.3611\n",
      "Epoch [1321/3000], Loss: 2005.8045\n",
      "Validation Loss: 2040.4069\n",
      "Epoch [1341/3000], Loss: 1982.0129\n",
      "Validation Loss: 1964.0423\n",
      "Epoch [1361/3000], Loss: 1907.7354\n",
      "Validation Loss: 1952.0263\n",
      "Epoch [1381/3000], Loss: 1853.7024\n",
      "Validation Loss: 1900.8519\n",
      "Epoch [1401/3000], Loss: 1819.9197\n",
      "Validation Loss: 1928.0551\n",
      "Epoch [1421/3000], Loss: 1770.0567\n",
      "Validation Loss: 1864.7549\n",
      "Epoch [1441/3000], Loss: 1709.0111\n",
      "Validation Loss: 1821.7638\n",
      "Epoch [1461/3000], Loss: 1663.0991\n",
      "Validation Loss: 1783.0590\n",
      "Epoch [1481/3000], Loss: 1610.4463\n",
      "Validation Loss: 1726.1599\n",
      "Epoch [1501/3000], Loss: 1550.5417\n",
      "Validation Loss: 1697.4376\n",
      "Epoch [1521/3000], Loss: 1497.3524\n",
      "Validation Loss: 1655.2949\n",
      "Epoch [1541/3000], Loss: 1458.9075\n",
      "Validation Loss: 1650.6848\n",
      "Epoch [1561/3000], Loss: 1411.4215\n",
      "Validation Loss: 1603.8378\n",
      "Epoch [1581/3000], Loss: 1377.8240\n",
      "Validation Loss: 1574.3476\n",
      "Epoch [1601/3000], Loss: 1337.4175\n",
      "Validation Loss: 1524.2391\n",
      "Epoch [1621/3000], Loss: 1286.0872\n",
      "Validation Loss: 1493.8554\n",
      "Epoch [1641/3000], Loss: 1256.8566\n",
      "Validation Loss: 1526.4076\n",
      "Epoch [1661/3000], Loss: 1209.8693\n",
      "Validation Loss: 1495.4357\n",
      "Epoch [1681/3000], Loss: 1175.3239\n",
      "Validation Loss: 1455.0883\n",
      "Epoch [1701/3000], Loss: 1138.1397\n",
      "Validation Loss: 1425.1520\n",
      "Epoch [1721/3000], Loss: 1100.6302\n",
      "Validation Loss: 1402.5241\n",
      "Epoch [1741/3000], Loss: 1060.8160\n",
      "Validation Loss: 1352.9835\n",
      "Epoch [1761/3000], Loss: 1024.4640\n",
      "Validation Loss: 1331.6542\n",
      "Epoch [1781/3000], Loss: 991.6950\n",
      "Validation Loss: 1297.2028\n",
      "Epoch [1801/3000], Loss: 962.2659\n",
      "Validation Loss: 1269.8987\n",
      "Epoch [1821/3000], Loss: 928.1234\n",
      "Validation Loss: 1250.2661\n",
      "Epoch [1841/3000], Loss: 894.1810\n",
      "Validation Loss: 1262.2649\n",
      "Epoch [1861/3000], Loss: 863.7417\n",
      "Validation Loss: 1234.3498\n",
      "Epoch [1881/3000], Loss: 837.5781\n",
      "Validation Loss: 1211.5339\n",
      "Epoch [1901/3000], Loss: 803.8745\n",
      "Validation Loss: 1187.4978\n",
      "Epoch [1921/3000], Loss: 776.2010\n",
      "Validation Loss: 1170.8513\n",
      "Epoch [1941/3000], Loss: 748.2905\n",
      "Validation Loss: 1153.5480\n",
      "Epoch [1961/3000], Loss: 718.9123\n",
      "Validation Loss: 1134.7247\n",
      "Epoch [1981/3000], Loss: 693.0994\n",
      "Validation Loss: 1110.0557\n",
      "Epoch [2001/3000], Loss: 666.2907\n",
      "Validation Loss: 1099.7619\n",
      "Epoch [2021/3000], Loss: 642.7701\n",
      "Validation Loss: 1058.9811\n",
      "Epoch [2041/3000], Loss: 620.6595\n",
      "Validation Loss: 1058.4344\n",
      "Epoch [2061/3000], Loss: 591.4333\n",
      "Validation Loss: 1041.3318\n",
      "Epoch [2081/3000], Loss: 568.8721\n",
      "Validation Loss: 1065.4387\n",
      "Epoch [2101/3000], Loss: 546.4838\n",
      "Validation Loss: 1066.9169\n",
      "Epoch [2121/3000], Loss: 521.8597\n",
      "Validation Loss: 1034.3394\n",
      "Epoch [2141/3000], Loss: 507.3623\n",
      "Validation Loss: 1042.8217\n",
      "Epoch [2161/3000], Loss: 499.0006\n",
      "Validation Loss: 1063.8454\n",
      "Epoch [2181/3000], Loss: 462.6261\n",
      "Validation Loss: 1059.9800\n",
      "Epoch [2201/3000], Loss: 449.5067\n",
      "Validation Loss: 1050.6378\n",
      "Epoch [2221/3000], Loss: 427.0894\n",
      "Validation Loss: 1042.8311\n",
      "Epoch [2241/3000], Loss: 408.9798\n",
      "Validation Loss: 1035.8693\n",
      "Epoch [2261/3000], Loss: 390.8061\n",
      "Validation Loss: 1024.7043\n",
      "Epoch [2281/3000], Loss: 374.5288\n",
      "Validation Loss: 1019.3919\n",
      "Epoch [2301/3000], Loss: 361.0118\n",
      "Validation Loss: 1017.1569\n",
      "Epoch [2321/3000], Loss: 337.4284\n",
      "Validation Loss: 1009.1311\n",
      "Epoch [2341/3000], Loss: 329.5515\n",
      "Validation Loss: 1006.6032\n",
      "Epoch [2361/3000], Loss: 313.8215\n",
      "Validation Loss: 997.3725\n",
      "Epoch [2381/3000], Loss: 297.5793\n",
      "Validation Loss: 983.2900\n",
      "Epoch [2401/3000], Loss: 284.0948\n",
      "Validation Loss: 982.6275\n",
      "Epoch [2421/3000], Loss: 271.1420\n",
      "Validation Loss: 981.8613\n",
      "Epoch [2441/3000], Loss: 256.3312\n",
      "Validation Loss: 978.0960\n",
      "Epoch [2461/3000], Loss: 242.8474\n",
      "Validation Loss: 966.1630\n",
      "Epoch [2481/3000], Loss: 232.6770\n",
      "Validation Loss: 975.2940\n",
      "Epoch [2501/3000], Loss: 220.6161\n",
      "Validation Loss: 970.7425\n",
      "Epoch [2521/3000], Loss: 212.1165\n",
      "Validation Loss: 969.6716\n",
      "Epoch [2541/3000], Loss: 199.7973\n",
      "Validation Loss: 970.8628\n",
      "Epoch [2561/3000], Loss: 190.8524\n",
      "Validation Loss: 978.6434\n",
      "Epoch [2581/3000], Loss: 182.0710\n",
      "Validation Loss: 985.1328\n",
      "Epoch [2601/3000], Loss: 171.0670\n",
      "Validation Loss: 997.4133\n",
      "Epoch [2621/3000], Loss: 160.0724\n",
      "Validation Loss: 1006.1861\n",
      "Epoch [2641/3000], Loss: 154.7098\n",
      "Validation Loss: 1025.4803\n",
      "Epoch [2661/3000], Loss: 144.5948\n",
      "Validation Loss: 1022.0093\n",
      "Epoch [2681/3000], Loss: 135.8931\n",
      "Validation Loss: 1030.7319\n",
      "Epoch [2701/3000], Loss: 130.1988\n",
      "Validation Loss: 1053.3350\n",
      "Epoch [2721/3000], Loss: 122.2169\n",
      "Validation Loss: 1064.0123\n",
      "Epoch [2741/3000], Loss: 115.7961\n",
      "Validation Loss: 1076.8725\n",
      "Epoch [2761/3000], Loss: 108.2169\n",
      "Validation Loss: 1099.0926\n",
      "Epoch [2781/3000], Loss: 102.1171\n",
      "Validation Loss: 1113.8110\n",
      "Epoch [2801/3000], Loss: 97.5623\n",
      "Validation Loss: 1124.2778\n",
      "Epoch [2821/3000], Loss: 92.0904\n",
      "Validation Loss: 1121.8660\n",
      "Epoch [2841/3000], Loss: 85.7329\n",
      "Validation Loss: 1137.0956\n",
      "Epoch [2861/3000], Loss: 80.0180\n",
      "Validation Loss: 1147.8331\n",
      "Epoch [2881/3000], Loss: 74.1569\n",
      "Validation Loss: 1157.6691\n",
      "Epoch [2901/3000], Loss: 69.6153\n",
      "Validation Loss: 1169.1120\n",
      "Epoch [2921/3000], Loss: 66.0131\n",
      "Validation Loss: 1182.7023\n",
      "Epoch [2941/3000], Loss: 64.8356\n",
      "Validation Loss: 1142.0814\n",
      "Epoch [2961/3000], Loss: 58.0648\n",
      "Validation Loss: 1169.6794\n",
      "Epoch [2981/3000], Loss: 55.2516\n",
      "Validation Loss: 1176.6505\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day034_plane0_Fall.mat\n",
      "(5655, 143)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9922.4633\n",
      "Validation Loss: 6927.7111\n",
      "Epoch [21/3000], Loss: 8637.8531\n",
      "Validation Loss: 5978.7345\n",
      "Epoch [41/3000], Loss: 8352.6607\n",
      "Validation Loss: 5778.1290\n",
      "Epoch [61/3000], Loss: 8170.4941\n",
      "Validation Loss: 5648.7486\n",
      "Epoch [81/3000], Loss: 8004.3190\n",
      "Validation Loss: 5533.6320\n",
      "Epoch [101/3000], Loss: 7843.5740\n",
      "Validation Loss: 5429.9751\n",
      "Epoch [121/3000], Loss: 7712.9244\n",
      "Validation Loss: 5331.7193\n",
      "Epoch [141/3000], Loss: 7576.1163\n",
      "Validation Loss: 5237.0980\n",
      "Epoch [161/3000], Loss: 7430.6905\n",
      "Validation Loss: 5146.1554\n",
      "Epoch [181/3000], Loss: 7303.6991\n",
      "Validation Loss: 5058.3519\n",
      "Epoch [201/3000], Loss: 7177.9662\n",
      "Validation Loss: 4973.3542\n",
      "Epoch [221/3000], Loss: 7061.6864\n",
      "Validation Loss: 4891.0365\n",
      "Epoch [241/3000], Loss: 6938.5402\n",
      "Validation Loss: 4811.3160\n",
      "Epoch [261/3000], Loss: 6815.3720\n",
      "Validation Loss: 4733.5250\n",
      "Epoch [281/3000], Loss: 6697.1856\n",
      "Validation Loss: 4657.2106\n",
      "Epoch [301/3000], Loss: 6584.2844\n",
      "Validation Loss: 4584.4184\n",
      "Epoch [321/3000], Loss: 6462.1968\n",
      "Validation Loss: 4514.1488\n",
      "Epoch [341/3000], Loss: 6359.4713\n",
      "Validation Loss: 4446.3160\n",
      "Epoch [361/3000], Loss: 6249.6966\n",
      "Validation Loss: 4380.8341\n",
      "Epoch [381/3000], Loss: 6148.5059\n",
      "Validation Loss: 4317.7909\n",
      "Epoch [401/3000], Loss: 6039.1380\n",
      "Validation Loss: 4257.0794\n",
      "Epoch [421/3000], Loss: 5936.9159\n",
      "Validation Loss: 4198.7296\n",
      "Epoch [441/3000], Loss: 5849.7460\n",
      "Validation Loss: 4142.6881\n",
      "Epoch [461/3000], Loss: 5753.9258\n",
      "Validation Loss: 4088.9738\n",
      "Epoch [481/3000], Loss: 5659.2373\n",
      "Validation Loss: 4037.6199\n",
      "Epoch [501/3000], Loss: 5571.6640\n",
      "Validation Loss: 3988.5630\n",
      "Epoch [521/3000], Loss: 5482.2436\n",
      "Validation Loss: 3941.7939\n",
      "Epoch [541/3000], Loss: 5394.2041\n",
      "Validation Loss: 3897.3509\n",
      "Epoch [561/3000], Loss: 5304.4526\n",
      "Validation Loss: 3855.1935\n",
      "Epoch [581/3000], Loss: 5231.5393\n",
      "Validation Loss: 3815.3161\n",
      "Epoch [601/3000], Loss: 5149.7019\n",
      "Validation Loss: 3777.7239\n",
      "Epoch [621/3000], Loss: 5063.6313\n",
      "Validation Loss: 3742.3828\n",
      "Epoch [641/3000], Loss: 5004.2300\n",
      "Validation Loss: 3709.2965\n",
      "Epoch [661/3000], Loss: 4927.7836\n",
      "Validation Loss: 3678.4920\n",
      "Epoch [681/3000], Loss: 4857.5502\n",
      "Validation Loss: 3649.9132\n",
      "Epoch [701/3000], Loss: 4790.1855\n",
      "Validation Loss: 3622.9853\n",
      "Epoch [721/3000], Loss: 4723.6579\n",
      "Validation Loss: 3598.6850\n",
      "Epoch [741/3000], Loss: 4663.9848\n",
      "Validation Loss: 3576.6921\n",
      "Epoch [761/3000], Loss: 4602.8875\n",
      "Validation Loss: 3556.9057\n",
      "Epoch [781/3000], Loss: 4462.2491\n",
      "Validation Loss: 3401.0189\n",
      "Epoch [801/3000], Loss: 3779.2605\n",
      "Validation Loss: 2526.6305\n",
      "Epoch [821/3000], Loss: 3653.1358\n",
      "Validation Loss: 2432.6408\n",
      "Epoch [841/3000], Loss: 3543.5439\n",
      "Validation Loss: 2360.1439\n",
      "Epoch [861/3000], Loss: 3437.8011\n",
      "Validation Loss: 2290.3778\n",
      "Epoch [881/3000], Loss: 3343.7299\n",
      "Validation Loss: 2226.8147\n",
      "Epoch [901/3000], Loss: 3250.2819\n",
      "Validation Loss: 2175.0365\n",
      "Epoch [921/3000], Loss: 3156.3316\n",
      "Validation Loss: 2126.2889\n",
      "Epoch [941/3000], Loss: 3067.5757\n",
      "Validation Loss: 2083.4868\n",
      "Epoch [961/3000], Loss: 2992.0574\n",
      "Validation Loss: 2031.4700\n",
      "Epoch [981/3000], Loss: 2910.0795\n",
      "Validation Loss: 2002.6384\n",
      "Epoch [1001/3000], Loss: 2828.1368\n",
      "Validation Loss: 1955.5374\n",
      "Epoch [1021/3000], Loss: 2752.9570\n",
      "Validation Loss: 1909.0846\n",
      "Epoch [1041/3000], Loss: 2674.3918\n",
      "Validation Loss: 1870.8914\n",
      "Epoch [1061/3000], Loss: 2620.8579\n",
      "Validation Loss: 1809.2987\n",
      "Epoch [1081/3000], Loss: 2526.2831\n",
      "Validation Loss: 1782.2130\n",
      "Epoch [1101/3000], Loss: 2459.4160\n",
      "Validation Loss: 1748.9135\n",
      "Epoch [1121/3000], Loss: 2388.9628\n",
      "Validation Loss: 1700.7362\n",
      "Epoch [1141/3000], Loss: 2322.7693\n",
      "Validation Loss: 1653.3937\n",
      "Epoch [1161/3000], Loss: 2255.2114\n",
      "Validation Loss: 1620.9563\n",
      "Epoch [1181/3000], Loss: 2186.1106\n",
      "Validation Loss: 1572.1964\n",
      "Epoch [1201/3000], Loss: 2121.5229\n",
      "Validation Loss: 1532.9906\n",
      "Epoch [1221/3000], Loss: 2063.5397\n",
      "Validation Loss: 1521.0203\n",
      "Epoch [1241/3000], Loss: 1997.4041\n",
      "Validation Loss: 1471.1810\n",
      "Epoch [1261/3000], Loss: 1938.9975\n",
      "Validation Loss: 1429.2212\n",
      "Epoch [1281/3000], Loss: 1879.0738\n",
      "Validation Loss: 1393.0233\n",
      "Epoch [1301/3000], Loss: 1821.4845\n",
      "Validation Loss: 1357.9041\n",
      "Epoch [1321/3000], Loss: 1766.8537\n",
      "Validation Loss: 1318.1238\n",
      "Epoch [1341/3000], Loss: 1710.0985\n",
      "Validation Loss: 1286.9204\n",
      "Epoch [1361/3000], Loss: 1657.0960\n",
      "Validation Loss: 1250.4004\n",
      "Epoch [1381/3000], Loss: 1604.0564\n",
      "Validation Loss: 1217.4703\n",
      "Epoch [1401/3000], Loss: 1552.6768\n",
      "Validation Loss: 1196.7919\n",
      "Epoch [1421/3000], Loss: 1499.8029\n",
      "Validation Loss: 1194.1977\n",
      "Epoch [1441/3000], Loss: 1454.8235\n",
      "Validation Loss: 1154.3030\n",
      "Epoch [1461/3000], Loss: 1403.5796\n",
      "Validation Loss: 1128.0979\n",
      "Epoch [1481/3000], Loss: 1358.3400\n",
      "Validation Loss: 1097.4736\n",
      "Epoch [1501/3000], Loss: 1313.0035\n",
      "Validation Loss: 1069.6305\n",
      "Epoch [1521/3000], Loss: 1268.3249\n",
      "Validation Loss: 1043.5477\n",
      "Epoch [1541/3000], Loss: 1226.0543\n",
      "Validation Loss: 1014.2657\n",
      "Epoch [1561/3000], Loss: 1179.9761\n",
      "Validation Loss: 983.9010\n",
      "Epoch [1581/3000], Loss: 1138.1124\n",
      "Validation Loss: 957.0813\n",
      "Epoch [1601/3000], Loss: 1097.0663\n",
      "Validation Loss: 929.9995\n",
      "Epoch [1621/3000], Loss: 1059.2504\n",
      "Validation Loss: 911.1551\n",
      "Epoch [1641/3000], Loss: 1059.6045\n",
      "Validation Loss: 947.3939\n",
      "Epoch [1661/3000], Loss: 982.7729\n",
      "Validation Loss: 898.2683\n",
      "Epoch [1681/3000], Loss: 944.8181\n",
      "Validation Loss: 874.7181\n",
      "Epoch [1701/3000], Loss: 908.7104\n",
      "Validation Loss: 849.4285\n",
      "Epoch [1721/3000], Loss: 876.3372\n",
      "Validation Loss: 826.7900\n",
      "Epoch [1741/3000], Loss: 841.2300\n",
      "Validation Loss: 806.3882\n",
      "Epoch [1761/3000], Loss: 808.7127\n",
      "Validation Loss: 788.5543\n",
      "Epoch [1781/3000], Loss: 777.6033\n",
      "Validation Loss: 761.7825\n",
      "Epoch [1801/3000], Loss: 745.5358\n",
      "Validation Loss: 744.9529\n",
      "Epoch [1821/3000], Loss: 714.7691\n",
      "Validation Loss: 728.0081\n",
      "Epoch [1841/3000], Loss: 683.6965\n",
      "Validation Loss: 692.8921\n",
      "Epoch [1861/3000], Loss: 655.3839\n",
      "Validation Loss: 676.8207\n",
      "Epoch [1881/3000], Loss: 627.3812\n",
      "Validation Loss: 665.0132\n",
      "Epoch [1901/3000], Loss: 600.0643\n",
      "Validation Loss: 642.6243\n",
      "Epoch [1921/3000], Loss: 572.5846\n",
      "Validation Loss: 629.7573\n",
      "Epoch [1941/3000], Loss: 547.8157\n",
      "Validation Loss: 618.9905\n",
      "Epoch [1961/3000], Loss: 525.2448\n",
      "Validation Loss: 630.1366\n",
      "Epoch [1981/3000], Loss: 501.2385\n",
      "Validation Loss: 619.1358\n",
      "Epoch [2001/3000], Loss: 477.8704\n",
      "Validation Loss: 608.1601\n",
      "Epoch [2021/3000], Loss: 458.3691\n",
      "Validation Loss: 595.8192\n",
      "Epoch [2041/3000], Loss: 436.9046\n",
      "Validation Loss: 584.1345\n",
      "Epoch [2061/3000], Loss: 417.0608\n",
      "Validation Loss: 575.4556\n",
      "Epoch [2081/3000], Loss: 397.7963\n",
      "Validation Loss: 559.0956\n",
      "Epoch [2101/3000], Loss: 377.1146\n",
      "Validation Loss: 534.9384\n",
      "Epoch [2121/3000], Loss: 356.8580\n",
      "Validation Loss: 520.1513\n",
      "Epoch [2141/3000], Loss: 338.2503\n",
      "Validation Loss: 519.0568\n",
      "Epoch [2161/3000], Loss: 319.4050\n",
      "Validation Loss: 511.8525\n",
      "Epoch [2181/3000], Loss: 302.7760\n",
      "Validation Loss: 512.8971\n",
      "Epoch [2201/3000], Loss: 301.0430\n",
      "Validation Loss: 501.7717\n",
      "Epoch [2221/3000], Loss: 271.0467\n",
      "Validation Loss: 512.0386\n",
      "Epoch [2241/3000], Loss: 255.3661\n",
      "Validation Loss: 505.3867\n",
      "Epoch [2261/3000], Loss: 241.7612\n",
      "Validation Loss: 498.1909\n",
      "Epoch [2281/3000], Loss: 227.6956\n",
      "Validation Loss: 494.6510\n",
      "Epoch [2301/3000], Loss: 214.3763\n",
      "Validation Loss: 492.4293\n",
      "Epoch [2321/3000], Loss: 201.6336\n",
      "Validation Loss: 492.8040\n",
      "Epoch [2341/3000], Loss: 188.4905\n",
      "Validation Loss: 505.6081\n",
      "Epoch [2361/3000], Loss: 176.7769\n",
      "Validation Loss: 513.6072\n",
      "Epoch [2381/3000], Loss: 165.2451\n",
      "Validation Loss: 518.9568\n",
      "Epoch [2401/3000], Loss: 153.8650\n",
      "Validation Loss: 523.1088\n",
      "Epoch [2421/3000], Loss: 143.3326\n",
      "Validation Loss: 527.4116\n",
      "Epoch [2441/3000], Loss: 133.7460\n",
      "Validation Loss: 527.8865\n",
      "Epoch [2461/3000], Loss: 124.6723\n",
      "Validation Loss: 529.7498\n",
      "Epoch [2481/3000], Loss: 115.6356\n",
      "Validation Loss: 528.8536\n",
      "Epoch [2501/3000], Loss: 107.2031\n",
      "Validation Loss: 526.5825\n",
      "Epoch [2521/3000], Loss: 99.5475\n",
      "Validation Loss: 525.2104\n",
      "Epoch [2541/3000], Loss: 92.3822\n",
      "Validation Loss: 533.3548\n",
      "Epoch [2561/3000], Loss: 85.6284\n",
      "Validation Loss: 534.4349\n",
      "Epoch [2581/3000], Loss: 79.0807\n",
      "Validation Loss: 535.0883\n",
      "Epoch [2601/3000], Loss: 72.6515\n",
      "Validation Loss: 532.9610\n",
      "Epoch [2621/3000], Loss: 66.7014\n",
      "Validation Loss: 528.0066\n",
      "Epoch [2641/3000], Loss: 61.3190\n",
      "Validation Loss: 525.6808\n",
      "Epoch [2661/3000], Loss: 56.0510\n",
      "Validation Loss: 524.6249\n",
      "Epoch [2681/3000], Loss: 51.1162\n",
      "Validation Loss: 522.4150\n",
      "Epoch [2701/3000], Loss: 46.4838\n",
      "Validation Loss: 519.6843\n",
      "Epoch [2721/3000], Loss: 42.2942\n",
      "Validation Loss: 512.9645\n",
      "Epoch [2741/3000], Loss: 38.4857\n",
      "Validation Loss: 514.9467\n",
      "Epoch [2761/3000], Loss: 34.9834\n",
      "Validation Loss: 510.7970\n",
      "Epoch [2781/3000], Loss: 31.6053\n",
      "Validation Loss: 512.7464\n",
      "Epoch [2801/3000], Loss: 28.4569\n",
      "Validation Loss: 514.5439\n",
      "Epoch [2821/3000], Loss: 25.5978\n",
      "Validation Loss: 515.8283\n",
      "Epoch [2841/3000], Loss: 22.8426\n",
      "Validation Loss: 509.8413\n",
      "Epoch [2861/3000], Loss: 20.4593\n",
      "Validation Loss: 512.5946\n",
      "Epoch [2881/3000], Loss: 18.0820\n",
      "Validation Loss: 500.9848\n",
      "Epoch [2901/3000], Loss: 16.0820\n",
      "Validation Loss: 499.8850\n",
      "Epoch [2921/3000], Loss: 14.0991\n",
      "Validation Loss: 501.2153\n",
      "Epoch [2941/3000], Loss: 12.3573\n",
      "Validation Loss: 501.4347\n",
      "Epoch [2961/3000], Loss: 10.7860\n",
      "Validation Loss: 501.9554\n",
      "Epoch [2981/3000], Loss: 9.3719\n",
      "Validation Loss: 507.4141\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day036_plane0_Fall.mat\n",
      "(5485, 153)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9241.9180\n",
      "Validation Loss: 8569.4563\n",
      "Epoch [21/3000], Loss: 8069.0575\n",
      "Validation Loss: 7463.1753\n",
      "Epoch [41/3000], Loss: 7758.7197\n",
      "Validation Loss: 7206.9970\n",
      "Epoch [61/3000], Loss: 7615.6949\n",
      "Validation Loss: 7045.4885\n",
      "Epoch [81/3000], Loss: 7464.7403\n",
      "Validation Loss: 6905.4586\n",
      "Epoch [101/3000], Loss: 7331.6502\n",
      "Validation Loss: 6776.4464\n",
      "Epoch [121/3000], Loss: 7198.6487\n",
      "Validation Loss: 6653.6133\n",
      "Epoch [141/3000], Loss: 7077.0910\n",
      "Validation Loss: 6534.5737\n",
      "Epoch [161/3000], Loss: 6923.6087\n",
      "Validation Loss: 6418.7763\n",
      "Epoch [181/3000], Loss: 6813.0127\n",
      "Validation Loss: 6306.4608\n",
      "Epoch [201/3000], Loss: 6683.5007\n",
      "Validation Loss: 6197.0125\n",
      "Epoch [221/3000], Loss: 6586.4201\n",
      "Validation Loss: 6090.4468\n",
      "Epoch [241/3000], Loss: 6465.5862\n",
      "Validation Loss: 5986.1890\n",
      "Epoch [261/3000], Loss: 6355.5612\n",
      "Validation Loss: 5884.4544\n",
      "Epoch [281/3000], Loss: 6233.3077\n",
      "Validation Loss: 5785.0323\n",
      "Epoch [301/3000], Loss: 6118.1810\n",
      "Validation Loss: 5687.9905\n",
      "Epoch [321/3000], Loss: 6042.1235\n",
      "Validation Loss: 5593.1673\n",
      "Epoch [341/3000], Loss: 5944.4487\n",
      "Validation Loss: 5500.5577\n",
      "Epoch [361/3000], Loss: 5834.3981\n",
      "Validation Loss: 5410.1847\n",
      "Epoch [381/3000], Loss: 5753.9189\n",
      "Validation Loss: 5322.1246\n",
      "Epoch [401/3000], Loss: 5649.3443\n",
      "Validation Loss: 5236.2654\n",
      "Epoch [421/3000], Loss: 5523.7231\n",
      "Validation Loss: 5152.5385\n",
      "Epoch [441/3000], Loss: 5458.9810\n",
      "Validation Loss: 5071.1034\n",
      "Epoch [461/3000], Loss: 5399.8049\n",
      "Validation Loss: 4991.7081\n",
      "Epoch [481/3000], Loss: 5296.4748\n",
      "Validation Loss: 4914.5487\n",
      "Epoch [501/3000], Loss: 5194.7909\n",
      "Validation Loss: 4839.7047\n",
      "Epoch [521/3000], Loss: 5123.4503\n",
      "Validation Loss: 4767.0511\n",
      "Epoch [541/3000], Loss: 5042.0650\n",
      "Validation Loss: 4696.4835\n",
      "Epoch [561/3000], Loss: 4954.3248\n",
      "Validation Loss: 4628.0390\n",
      "Epoch [581/3000], Loss: 4888.8722\n",
      "Validation Loss: 4561.7452\n",
      "Epoch [601/3000], Loss: 4824.1800\n",
      "Validation Loss: 4497.6426\n",
      "Epoch [621/3000], Loss: 4736.2932\n",
      "Validation Loss: 4435.6881\n",
      "Epoch [641/3000], Loss: 4661.8900\n",
      "Validation Loss: 4375.8636\n",
      "Epoch [661/3000], Loss: 4601.3567\n",
      "Validation Loss: 4318.1707\n",
      "Epoch [681/3000], Loss: 4548.4272\n",
      "Validation Loss: 4262.6434\n",
      "Epoch [701/3000], Loss: 4487.7981\n",
      "Validation Loss: 4209.2086\n",
      "Epoch [721/3000], Loss: 4422.0335\n",
      "Validation Loss: 4157.8409\n",
      "Epoch [741/3000], Loss: 4355.8776\n",
      "Validation Loss: 4108.6135\n",
      "Epoch [761/3000], Loss: 4298.8947\n",
      "Validation Loss: 4061.5445\n",
      "Epoch [781/3000], Loss: 4237.3164\n",
      "Validation Loss: 4016.5409\n",
      "Epoch [801/3000], Loss: 4192.5108\n",
      "Validation Loss: 3973.5637\n",
      "Epoch [821/3000], Loss: 4146.9390\n",
      "Validation Loss: 3932.7537\n",
      "Epoch [841/3000], Loss: 4090.3196\n",
      "Validation Loss: 3893.9478\n",
      "Epoch [861/3000], Loss: 4056.1526\n",
      "Validation Loss: 3857.2149\n",
      "Epoch [881/3000], Loss: 4016.7697\n",
      "Validation Loss: 3822.4551\n",
      "Epoch [901/3000], Loss: 3970.0571\n",
      "Validation Loss: 3789.7100\n",
      "Epoch [921/3000], Loss: 3929.2725\n",
      "Validation Loss: 3758.9444\n",
      "Epoch [941/3000], Loss: 3033.9966\n",
      "Validation Loss: 2791.9569\n",
      "Epoch [961/3000], Loss: 2867.4120\n",
      "Validation Loss: 2675.0518\n",
      "Epoch [981/3000], Loss: 2770.7439\n",
      "Validation Loss: 2601.3034\n",
      "Epoch [1001/3000], Loss: 2659.4172\n",
      "Validation Loss: 2525.2756\n",
      "Epoch [1021/3000], Loss: 2593.2984\n",
      "Validation Loss: 2445.2154\n",
      "Epoch [1041/3000], Loss: 2509.2659\n",
      "Validation Loss: 2377.2180\n",
      "Epoch [1061/3000], Loss: 2436.8195\n",
      "Validation Loss: 2320.9479\n",
      "Epoch [1081/3000], Loss: 2365.0288\n",
      "Validation Loss: 2246.7043\n",
      "Epoch [1101/3000], Loss: 2306.7541\n",
      "Validation Loss: 2202.1360\n",
      "Epoch [1121/3000], Loss: 2222.2161\n",
      "Validation Loss: 2137.4829\n",
      "Epoch [1141/3000], Loss: 2173.8197\n",
      "Validation Loss: 2079.1533\n",
      "Epoch [1161/3000], Loss: 2108.7955\n",
      "Validation Loss: 2023.5993\n",
      "Epoch [1181/3000], Loss: 2039.6529\n",
      "Validation Loss: 1973.6911\n",
      "Epoch [1201/3000], Loss: 1979.9955\n",
      "Validation Loss: 1914.3738\n",
      "Epoch [1221/3000], Loss: 1927.1494\n",
      "Validation Loss: 1861.7546\n",
      "Epoch [1241/3000], Loss: 1870.3261\n",
      "Validation Loss: 1810.8220\n",
      "Epoch [1261/3000], Loss: 1816.4263\n",
      "Validation Loss: 1757.3139\n",
      "Epoch [1281/3000], Loss: 1758.5113\n",
      "Validation Loss: 1707.8389\n",
      "Epoch [1301/3000], Loss: 1707.0368\n",
      "Validation Loss: 1657.7916\n",
      "Epoch [1321/3000], Loss: 1634.5411\n",
      "Validation Loss: 1610.5144\n",
      "Epoch [1341/3000], Loss: 1591.4692\n",
      "Validation Loss: 1563.0003\n",
      "Epoch [1361/3000], Loss: 1535.8715\n",
      "Validation Loss: 1517.5726\n",
      "Epoch [1381/3000], Loss: 1498.5754\n",
      "Validation Loss: 1470.6672\n",
      "Epoch [1401/3000], Loss: 1443.3544\n",
      "Validation Loss: 1428.9035\n",
      "Epoch [1421/3000], Loss: 1395.5556\n",
      "Validation Loss: 1385.7889\n",
      "Epoch [1441/3000], Loss: 1347.5527\n",
      "Validation Loss: 1344.3623\n",
      "Epoch [1461/3000], Loss: 1307.4056\n",
      "Validation Loss: 1304.0353\n",
      "Epoch [1481/3000], Loss: 1253.6327\n",
      "Validation Loss: 1264.8962\n",
      "Epoch [1501/3000], Loss: 1206.7468\n",
      "Validation Loss: 1227.6701\n",
      "Epoch [1521/3000], Loss: 1168.0071\n",
      "Validation Loss: 1191.6001\n",
      "Epoch [1541/3000], Loss: 1136.3694\n",
      "Validation Loss: 1155.6781\n",
      "Epoch [1561/3000], Loss: 1091.1460\n",
      "Validation Loss: 1122.0816\n",
      "Epoch [1581/3000], Loss: 1048.3360\n",
      "Validation Loss: 1088.6199\n",
      "Epoch [1601/3000], Loss: 1018.4827\n",
      "Validation Loss: 1049.8819\n",
      "Epoch [1621/3000], Loss: 971.7557\n",
      "Validation Loss: 1021.0183\n",
      "Epoch [1641/3000], Loss: 937.5682\n",
      "Validation Loss: 988.8092\n",
      "Epoch [1661/3000], Loss: 902.1057\n",
      "Validation Loss: 958.6987\n",
      "Epoch [1681/3000], Loss: 861.1588\n",
      "Validation Loss: 929.7921\n",
      "Epoch [1701/3000], Loss: 833.7942\n",
      "Validation Loss: 901.5423\n",
      "Epoch [1721/3000], Loss: 795.2962\n",
      "Validation Loss: 874.7758\n",
      "Epoch [1741/3000], Loss: 764.9449\n",
      "Validation Loss: 849.2286\n",
      "Epoch [1761/3000], Loss: 739.2195\n",
      "Validation Loss: 824.6867\n",
      "Epoch [1781/3000], Loss: 703.5090\n",
      "Validation Loss: 800.2032\n",
      "Epoch [1801/3000], Loss: 677.2810\n",
      "Validation Loss: 776.4977\n",
      "Epoch [1821/3000], Loss: 647.3239\n",
      "Validation Loss: 752.9715\n",
      "Epoch [1841/3000], Loss: 621.1050\n",
      "Validation Loss: 733.2146\n",
      "Epoch [1861/3000], Loss: 596.2345\n",
      "Validation Loss: 713.2874\n",
      "Epoch [1881/3000], Loss: 569.2662\n",
      "Validation Loss: 694.7509\n",
      "Epoch [1901/3000], Loss: 545.3340\n",
      "Validation Loss: 676.8241\n",
      "Epoch [1921/3000], Loss: 526.2634\n",
      "Validation Loss: 659.7726\n",
      "Epoch [1941/3000], Loss: 496.9913\n",
      "Validation Loss: 640.0191\n",
      "Epoch [1961/3000], Loss: 478.9652\n",
      "Validation Loss: 622.4459\n",
      "Epoch [1981/3000], Loss: 456.6538\n",
      "Validation Loss: 605.1590\n",
      "Epoch [2001/3000], Loss: 433.5500\n",
      "Validation Loss: 588.7835\n",
      "Epoch [2021/3000], Loss: 410.9767\n",
      "Validation Loss: 574.6350\n",
      "Epoch [2041/3000], Loss: 390.7208\n",
      "Validation Loss: 559.8418\n",
      "Epoch [2061/3000], Loss: 374.7407\n",
      "Validation Loss: 545.8323\n",
      "Epoch [2081/3000], Loss: 356.1453\n",
      "Validation Loss: 533.5002\n",
      "Epoch [2101/3000], Loss: 342.0290\n",
      "Validation Loss: 520.2241\n",
      "Epoch [2121/3000], Loss: 325.5992\n",
      "Validation Loss: 508.5482\n",
      "Epoch [2141/3000], Loss: 310.4153\n",
      "Validation Loss: 499.7722\n",
      "Epoch [2161/3000], Loss: 294.2644\n",
      "Validation Loss: 489.5041\n",
      "Epoch [2181/3000], Loss: 278.2414\n",
      "Validation Loss: 481.0991\n",
      "Epoch [2201/3000], Loss: 265.2528\n",
      "Validation Loss: 475.2412\n",
      "Epoch [2221/3000], Loss: 251.6612\n",
      "Validation Loss: 475.8270\n",
      "Epoch [2241/3000], Loss: 236.6262\n",
      "Validation Loss: 466.0717\n",
      "Epoch [2261/3000], Loss: 226.8033\n",
      "Validation Loss: 466.2782\n",
      "Epoch [2281/3000], Loss: 213.0133\n",
      "Validation Loss: 463.4617\n",
      "Epoch [2301/3000], Loss: 202.2816\n",
      "Validation Loss: 454.1088\n",
      "Epoch [2321/3000], Loss: 191.5300\n",
      "Validation Loss: 449.4551\n",
      "Epoch [2341/3000], Loss: 182.7975\n",
      "Validation Loss: 444.4603\n",
      "Epoch [2361/3000], Loss: 173.3621\n",
      "Validation Loss: 440.6958\n",
      "Epoch [2381/3000], Loss: 163.8669\n",
      "Validation Loss: 437.7078\n",
      "Epoch [2401/3000], Loss: 156.1352\n",
      "Validation Loss: 434.7019\n",
      "Epoch [2421/3000], Loss: 147.2832\n",
      "Validation Loss: 431.7975\n",
      "Epoch [2441/3000], Loss: 139.7425\n",
      "Validation Loss: 428.5506\n",
      "Epoch [2461/3000], Loss: 132.8514\n",
      "Validation Loss: 425.4823\n",
      "Epoch [2481/3000], Loss: 123.8909\n",
      "Validation Loss: 423.6269\n",
      "Epoch [2501/3000], Loss: 116.2240\n",
      "Validation Loss: 424.5794\n",
      "Epoch [2521/3000], Loss: 109.3977\n",
      "Validation Loss: 422.7436\n",
      "Epoch [2541/3000], Loss: 102.7574\n",
      "Validation Loss: 423.9494\n",
      "Epoch [2561/3000], Loss: 97.8416\n",
      "Validation Loss: 426.3049\n",
      "Epoch [2581/3000], Loss: 91.3588\n",
      "Validation Loss: 430.3021\n",
      "Epoch [2601/3000], Loss: 85.3640\n",
      "Validation Loss: 430.4212\n",
      "Epoch [2621/3000], Loss: 81.3873\n",
      "Validation Loss: 431.8895\n",
      "Epoch [2641/3000], Loss: 75.4798\n",
      "Validation Loss: 431.2461\n",
      "Epoch [2661/3000], Loss: 71.2204\n",
      "Validation Loss: 431.3167\n",
      "Epoch [2681/3000], Loss: 65.8179\n",
      "Validation Loss: 434.3946\n",
      "Epoch [2701/3000], Loss: 61.6139\n",
      "Validation Loss: 435.5077\n",
      "Epoch [2721/3000], Loss: 57.5925\n",
      "Validation Loss: 438.2129\n",
      "Epoch [2741/3000], Loss: 53.5138\n",
      "Validation Loss: 441.8134\n",
      "Epoch [2761/3000], Loss: 49.2653\n",
      "Validation Loss: 443.0318\n",
      "Epoch [2781/3000], Loss: 45.5274\n",
      "Validation Loss: 423.5573\n",
      "Epoch [2801/3000], Loss: 41.5977\n",
      "Validation Loss: 426.6141\n",
      "Epoch [2821/3000], Loss: 38.6250\n",
      "Validation Loss: 429.0612\n",
      "Epoch [2841/3000], Loss: 35.5226\n",
      "Validation Loss: 431.2004\n",
      "Epoch [2861/3000], Loss: 32.5687\n",
      "Validation Loss: 433.0585\n",
      "Epoch [2881/3000], Loss: 30.0285\n",
      "Validation Loss: 435.2090\n",
      "Epoch [2901/3000], Loss: 27.1893\n",
      "Validation Loss: 436.0727\n",
      "Epoch [2921/3000], Loss: 24.4138\n",
      "Validation Loss: 439.1640\n",
      "Epoch [2941/3000], Loss: 22.4170\n",
      "Validation Loss: 440.1721\n",
      "Epoch [2961/3000], Loss: 19.8417\n",
      "Validation Loss: 444.6099\n",
      "Epoch [2981/3000], Loss: 18.2485\n",
      "Validation Loss: 446.6617\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day037_plane0_Fall.mat\n",
      "(5397, 137)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7847.4630\n",
      "Validation Loss: 6751.1673\n",
      "Epoch [21/3000], Loss: 6737.4747\n",
      "Validation Loss: 5807.2174\n",
      "Epoch [41/3000], Loss: 6502.1554\n",
      "Validation Loss: 5613.3271\n",
      "Epoch [61/3000], Loss: 6351.1262\n",
      "Validation Loss: 5492.3375\n",
      "Epoch [81/3000], Loss: 6217.7456\n",
      "Validation Loss: 5385.4185\n",
      "Epoch [101/3000], Loss: 6100.0205\n",
      "Validation Loss: 5286.1892\n",
      "Epoch [121/3000], Loss: 5990.2436\n",
      "Validation Loss: 5192.2207\n",
      "Epoch [141/3000], Loss: 5877.2817\n",
      "Validation Loss: 5102.1886\n",
      "Epoch [161/3000], Loss: 5771.3091\n",
      "Validation Loss: 5015.4789\n",
      "Epoch [181/3000], Loss: 5664.6630\n",
      "Validation Loss: 4931.5780\n",
      "Epoch [201/3000], Loss: 5563.6121\n",
      "Validation Loss: 4850.3002\n",
      "Epoch [221/3000], Loss: 5462.3454\n",
      "Validation Loss: 4771.4945\n",
      "Epoch [241/3000], Loss: 5364.5400\n",
      "Validation Loss: 4695.0412\n",
      "Epoch [261/3000], Loss: 5275.7117\n",
      "Validation Loss: 4619.7827\n",
      "Epoch [281/3000], Loss: 5179.2236\n",
      "Validation Loss: 4544.3983\n",
      "Epoch [301/3000], Loss: 5091.6224\n",
      "Validation Loss: 4474.0248\n",
      "Epoch [321/3000], Loss: 5003.2463\n",
      "Validation Loss: 4405.9732\n",
      "Epoch [341/3000], Loss: 4912.8315\n",
      "Validation Loss: 4340.2450\n",
      "Epoch [361/3000], Loss: 4833.5593\n",
      "Validation Loss: 4276.6633\n",
      "Epoch [381/3000], Loss: 4745.1031\n",
      "Validation Loss: 4215.2522\n",
      "Epoch [401/3000], Loss: 4668.1260\n",
      "Validation Loss: 4156.0341\n",
      "Epoch [421/3000], Loss: 4595.4952\n",
      "Validation Loss: 4098.9097\n",
      "Epoch [441/3000], Loss: 4521.5546\n",
      "Validation Loss: 4043.9650\n",
      "Epoch [461/3000], Loss: 4447.4109\n",
      "Validation Loss: 3991.0794\n",
      "Epoch [481/3000], Loss: 4378.5652\n",
      "Validation Loss: 3940.3983\n",
      "Epoch [501/3000], Loss: 4309.7259\n",
      "Validation Loss: 3891.7570\n",
      "Epoch [521/3000], Loss: 4238.7179\n",
      "Validation Loss: 3845.2128\n",
      "Epoch [541/3000], Loss: 4178.6253\n",
      "Validation Loss: 3800.7898\n",
      "Epoch [561/3000], Loss: 4119.8979\n",
      "Validation Loss: 3758.4588\n",
      "Epoch [581/3000], Loss: 4058.3228\n",
      "Validation Loss: 3718.1601\n",
      "Epoch [601/3000], Loss: 3998.7859\n",
      "Validation Loss: 3679.9839\n",
      "Epoch [621/3000], Loss: 3945.5303\n",
      "Validation Loss: 3643.7903\n",
      "Epoch [641/3000], Loss: 3889.7349\n",
      "Validation Loss: 3609.6636\n",
      "Epoch [661/3000], Loss: 3838.6992\n",
      "Validation Loss: 3577.6013\n",
      "Epoch [681/3000], Loss: 3791.3064\n",
      "Validation Loss: 3547.4973\n",
      "Epoch [701/3000], Loss: 3742.6774\n",
      "Validation Loss: 3519.4198\n",
      "Epoch [721/3000], Loss: 3696.9450\n",
      "Validation Loss: 3493.3625\n",
      "Epoch [741/3000], Loss: 3656.6584\n",
      "Validation Loss: 3469.2573\n",
      "Epoch [761/3000], Loss: 3612.2866\n",
      "Validation Loss: 3447.0895\n",
      "Epoch [781/3000], Loss: 3572.4753\n",
      "Validation Loss: 3426.8731\n",
      "Epoch [801/3000], Loss: 3536.2254\n",
      "Validation Loss: 3408.5446\n",
      "Epoch [821/3000], Loss: 3505.4275\n",
      "Validation Loss: 3392.1410\n",
      "Epoch [841/3000], Loss: 3471.4785\n",
      "Validation Loss: 3377.5754\n",
      "Epoch [861/3000], Loss: 3440.6980\n",
      "Validation Loss: 3364.8640\n",
      "Epoch [881/3000], Loss: 3410.9574\n",
      "Validation Loss: 3353.9382\n",
      "Epoch [901/3000], Loss: 2507.7817\n",
      "Validation Loss: 2422.3562\n",
      "Epoch [921/3000], Loss: 2388.2791\n",
      "Validation Loss: 2291.3268\n",
      "Epoch [941/3000], Loss: 2298.4697\n",
      "Validation Loss: 2207.1412\n",
      "Epoch [961/3000], Loss: 2220.7530\n",
      "Validation Loss: 2154.1654\n",
      "Epoch [981/3000], Loss: 2151.6368\n",
      "Validation Loss: 2083.4698\n",
      "Epoch [1001/3000], Loss: 2084.8526\n",
      "Validation Loss: 2048.5144\n",
      "Epoch [1021/3000], Loss: 2023.3669\n",
      "Validation Loss: 1985.5350\n",
      "Epoch [1041/3000], Loss: 1958.5266\n",
      "Validation Loss: 1939.8092\n",
      "Epoch [1061/3000], Loss: 1903.3145\n",
      "Validation Loss: 1897.5821\n",
      "Epoch [1081/3000], Loss: 1844.9954\n",
      "Validation Loss: 1853.9050\n",
      "Epoch [1101/3000], Loss: 1784.6794\n",
      "Validation Loss: 1810.9156\n",
      "Epoch [1121/3000], Loss: 1734.2938\n",
      "Validation Loss: 1772.1298\n",
      "Epoch [1141/3000], Loss: 1678.7360\n",
      "Validation Loss: 1740.7122\n",
      "Epoch [1161/3000], Loss: 1629.8682\n",
      "Validation Loss: 1703.0324\n",
      "Epoch [1181/3000], Loss: 1576.8170\n",
      "Validation Loss: 1668.6493\n",
      "Epoch [1201/3000], Loss: 1528.5743\n",
      "Validation Loss: 1638.2989\n",
      "Epoch [1221/3000], Loss: 1479.1994\n",
      "Validation Loss: 1592.2957\n",
      "Epoch [1241/3000], Loss: 1429.9463\n",
      "Validation Loss: 1562.7177\n",
      "Epoch [1261/3000], Loss: 1387.2449\n",
      "Validation Loss: 1528.9692\n",
      "Epoch [1281/3000], Loss: 1344.5792\n",
      "Validation Loss: 1492.1314\n",
      "Epoch [1301/3000], Loss: 1301.8569\n",
      "Validation Loss: 1458.1498\n",
      "Epoch [1321/3000], Loss: 1258.5829\n",
      "Validation Loss: 1425.1165\n",
      "Epoch [1341/3000], Loss: 1216.7814\n",
      "Validation Loss: 1392.2265\n",
      "Epoch [1361/3000], Loss: 1177.5365\n",
      "Validation Loss: 1359.5060\n",
      "Epoch [1381/3000], Loss: 1139.4460\n",
      "Validation Loss: 1329.0386\n",
      "Epoch [1401/3000], Loss: 1099.1935\n",
      "Validation Loss: 1299.6418\n",
      "Epoch [1421/3000], Loss: 1066.3600\n",
      "Validation Loss: 1271.7876\n",
      "Epoch [1441/3000], Loss: 1028.9495\n",
      "Validation Loss: 1247.0188\n",
      "Epoch [1461/3000], Loss: 994.2070\n",
      "Validation Loss: 1221.3293\n",
      "Epoch [1481/3000], Loss: 960.1771\n",
      "Validation Loss: 1205.6403\n",
      "Epoch [1501/3000], Loss: 928.4557\n",
      "Validation Loss: 1174.9301\n",
      "Epoch [1521/3000], Loss: 897.1731\n",
      "Validation Loss: 1157.0580\n",
      "Epoch [1541/3000], Loss: 867.8863\n",
      "Validation Loss: 1132.6066\n",
      "Epoch [1561/3000], Loss: 835.3864\n",
      "Validation Loss: 1115.9073\n",
      "Epoch [1581/3000], Loss: 807.8672\n",
      "Validation Loss: 1091.6066\n",
      "Epoch [1601/3000], Loss: 778.2036\n",
      "Validation Loss: 1073.0481\n",
      "Epoch [1621/3000], Loss: 752.6988\n",
      "Validation Loss: 1054.6156\n",
      "Epoch [1641/3000], Loss: 725.2830\n",
      "Validation Loss: 1048.0872\n",
      "Epoch [1661/3000], Loss: 699.8480\n",
      "Validation Loss: 1029.2802\n",
      "Epoch [1681/3000], Loss: 675.4077\n",
      "Validation Loss: 1016.7475\n",
      "Epoch [1701/3000], Loss: 650.7452\n",
      "Validation Loss: 989.9839\n",
      "Epoch [1721/3000], Loss: 627.0621\n",
      "Validation Loss: 979.1642\n",
      "Epoch [1741/3000], Loss: 602.5929\n",
      "Validation Loss: 958.8041\n",
      "Epoch [1761/3000], Loss: 581.2150\n",
      "Validation Loss: 954.9408\n",
      "Epoch [1781/3000], Loss: 560.1354\n",
      "Validation Loss: 980.4363\n",
      "Epoch [1801/3000], Loss: 537.3182\n",
      "Validation Loss: 1018.8462\n",
      "Epoch [1821/3000], Loss: 516.2419\n",
      "Validation Loss: 970.3875\n",
      "Epoch [1841/3000], Loss: 499.9562\n",
      "Validation Loss: 989.8496\n",
      "Epoch [1861/3000], Loss: 475.2746\n",
      "Validation Loss: 1012.9964\n",
      "Epoch [1881/3000], Loss: 455.1096\n",
      "Validation Loss: 906.6078\n",
      "Epoch [1901/3000], Loss: 437.9203\n",
      "Validation Loss: 898.1696\n",
      "Epoch [1921/3000], Loss: 420.6181\n",
      "Validation Loss: 884.2150\n",
      "Epoch [1941/3000], Loss: 410.2622\n",
      "Validation Loss: 853.9824\n",
      "Epoch [1961/3000], Loss: 386.1319\n",
      "Validation Loss: 846.0216\n",
      "Epoch [1981/3000], Loss: 370.6332\n",
      "Validation Loss: 842.6455\n",
      "Epoch [2001/3000], Loss: 355.2896\n",
      "Validation Loss: 821.9813\n",
      "Epoch [2021/3000], Loss: 339.6971\n",
      "Validation Loss: 809.1611\n",
      "Epoch [2041/3000], Loss: 325.0409\n",
      "Validation Loss: 806.8504\n",
      "Epoch [2061/3000], Loss: 311.0485\n",
      "Validation Loss: 804.6046\n",
      "Epoch [2081/3000], Loss: 297.3975\n",
      "Validation Loss: 787.1733\n",
      "Epoch [2101/3000], Loss: 284.1804\n",
      "Validation Loss: 779.5158\n",
      "Epoch [2121/3000], Loss: 271.4799\n",
      "Validation Loss: 794.4329\n",
      "Epoch [2141/3000], Loss: 273.4548\n",
      "Validation Loss: 787.0580\n",
      "Epoch [2161/3000], Loss: 247.4963\n",
      "Validation Loss: 743.1223\n",
      "Epoch [2181/3000], Loss: 237.5979\n",
      "Validation Loss: 733.9881\n",
      "Epoch [2201/3000], Loss: 226.5809\n",
      "Validation Loss: 727.9614\n",
      "Epoch [2221/3000], Loss: 216.9872\n",
      "Validation Loss: 717.6821\n",
      "Epoch [2241/3000], Loss: 207.3656\n",
      "Validation Loss: 714.8366\n",
      "Epoch [2261/3000], Loss: 198.6307\n",
      "Validation Loss: 703.4772\n",
      "Epoch [2281/3000], Loss: 189.8636\n",
      "Validation Loss: 704.6314\n",
      "Epoch [2301/3000], Loss: 181.2498\n",
      "Validation Loss: 699.1926\n",
      "Epoch [2321/3000], Loss: 172.3398\n",
      "Validation Loss: 697.3599\n",
      "Epoch [2341/3000], Loss: 164.1739\n",
      "Validation Loss: 694.1467\n",
      "Epoch [2361/3000], Loss: 156.1882\n",
      "Validation Loss: 700.7850\n",
      "Epoch [2381/3000], Loss: 147.7382\n",
      "Validation Loss: 704.1925\n",
      "Epoch [2401/3000], Loss: 139.5944\n",
      "Validation Loss: 744.2574\n",
      "Epoch [2421/3000], Loss: 132.0312\n",
      "Validation Loss: 699.6484\n",
      "Epoch [2441/3000], Loss: 124.6024\n",
      "Validation Loss: 703.3588\n",
      "Epoch [2461/3000], Loss: 117.9327\n",
      "Validation Loss: 755.5238\n",
      "Epoch [2481/3000], Loss: 111.2766\n",
      "Validation Loss: 699.8585\n",
      "Epoch [2501/3000], Loss: 104.9919\n",
      "Validation Loss: 752.1681\n",
      "Epoch [2521/3000], Loss: 127.6681\n",
      "Validation Loss: 733.5679\n",
      "Epoch [2541/3000], Loss: 93.2949\n",
      "Validation Loss: 681.3216\n",
      "Epoch [2561/3000], Loss: 87.9508\n",
      "Validation Loss: 678.2241\n",
      "Epoch [2581/3000], Loss: 82.7901\n",
      "Validation Loss: 678.1841\n",
      "Epoch [2601/3000], Loss: 77.8255\n",
      "Validation Loss: 677.4750\n",
      "Epoch [2621/3000], Loss: 72.8359\n",
      "Validation Loss: 671.9123\n",
      "Epoch [2641/3000], Loss: 68.4060\n",
      "Validation Loss: 676.8997\n",
      "Epoch [2661/3000], Loss: 64.1836\n",
      "Validation Loss: 673.1860\n",
      "Epoch [2681/3000], Loss: 59.7574\n",
      "Validation Loss: 675.0599\n",
      "Epoch [2701/3000], Loss: 55.9430\n",
      "Validation Loss: 681.3573\n",
      "Epoch [2721/3000], Loss: 52.1264\n",
      "Validation Loss: 678.4645\n",
      "Epoch [2741/3000], Loss: 48.5034\n",
      "Validation Loss: 679.2064\n",
      "Epoch [2761/3000], Loss: 44.8128\n",
      "Validation Loss: 687.9581\n",
      "Epoch [2781/3000], Loss: 41.6183\n",
      "Validation Loss: 681.1833\n",
      "Epoch [2801/3000], Loss: 38.4252\n",
      "Validation Loss: 682.6770\n",
      "Epoch [2821/3000], Loss: 35.2913\n",
      "Validation Loss: 688.1306\n",
      "Epoch [2841/3000], Loss: 32.3848\n",
      "Validation Loss: 675.8063\n",
      "Epoch [2861/3000], Loss: 29.8128\n",
      "Validation Loss: 683.6505\n",
      "Epoch [2881/3000], Loss: 27.3211\n",
      "Validation Loss: 680.0292\n",
      "Epoch [2901/3000], Loss: 25.8717\n",
      "Validation Loss: 718.1406\n",
      "Epoch [2921/3000], Loss: 22.8174\n",
      "Validation Loss: 670.3029\n",
      "Epoch [2941/3000], Loss: 20.9251\n",
      "Validation Loss: 670.0024\n",
      "Epoch [2961/3000], Loss: 18.9948\n",
      "Validation Loss: 663.2229\n",
      "Epoch [2981/3000], Loss: 17.3096\n",
      "Validation Loss: 661.8328\n",
      "Y:\\analysis\\fmats\\e186\\days\\e186_day040_plane0_Fall.mat\n",
      "(8039, 124)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9027.5219\n",
      "Validation Loss: 8158.0431\n",
      "Epoch [21/3000], Loss: 7745.3938\n",
      "Validation Loss: 6983.9556\n",
      "Epoch [41/3000], Loss: 7472.7056\n",
      "Validation Loss: 6754.7472\n",
      "Epoch [61/3000], Loss: 7280.9899\n",
      "Validation Loss: 6568.9053\n",
      "Epoch [81/3000], Loss: 7089.0753\n",
      "Validation Loss: 6398.7061\n",
      "Epoch [101/3000], Loss: 6914.4535\n",
      "Validation Loss: 6238.5522\n",
      "Epoch [121/3000], Loss: 6753.2421\n",
      "Validation Loss: 6085.6296\n",
      "Epoch [141/3000], Loss: 6580.2517\n",
      "Validation Loss: 5938.6770\n",
      "Epoch [161/3000], Loss: 6420.4786\n",
      "Validation Loss: 5797.1337\n",
      "Epoch [181/3000], Loss: 6256.4079\n",
      "Validation Loss: 5659.7124\n",
      "Epoch [201/3000], Loss: 6109.5947\n",
      "Validation Loss: 5527.1749\n",
      "Epoch [221/3000], Loss: 5961.1054\n",
      "Validation Loss: 5399.9498\n",
      "Epoch [241/3000], Loss: 5812.6078\n",
      "Validation Loss: 5277.4159\n",
      "Epoch [261/3000], Loss: 5690.3893\n",
      "Validation Loss: 5159.7983\n",
      "Epoch [281/3000], Loss: 5562.8313\n",
      "Validation Loss: 5046.8445\n",
      "Epoch [301/3000], Loss: 5437.2708\n",
      "Validation Loss: 4938.5277\n",
      "Epoch [321/3000], Loss: 5315.7939\n",
      "Validation Loss: 4834.7461\n",
      "Epoch [341/3000], Loss: 5205.5393\n",
      "Validation Loss: 4735.6990\n",
      "Epoch [361/3000], Loss: 5086.9950\n",
      "Validation Loss: 4641.2033\n",
      "Epoch [381/3000], Loss: 4983.4395\n",
      "Validation Loss: 4551.3591\n",
      "Epoch [401/3000], Loss: 4886.3059\n",
      "Validation Loss: 4466.0622\n",
      "Epoch [421/3000], Loss: 4765.0691\n",
      "Validation Loss: 4385.2327\n",
      "Epoch [441/3000], Loss: 4694.9507\n",
      "Validation Loss: 4309.0137\n",
      "Epoch [461/3000], Loss: 4600.4911\n",
      "Validation Loss: 4237.2395\n",
      "Epoch [481/3000], Loss: 4518.5225\n",
      "Validation Loss: 4169.9722\n",
      "Epoch [501/3000], Loss: 4435.3510\n",
      "Validation Loss: 4107.1501\n",
      "Epoch [521/3000], Loss: 4357.5871\n",
      "Validation Loss: 4048.7431\n",
      "Epoch [541/3000], Loss: 4280.8101\n",
      "Validation Loss: 3994.7218\n",
      "Epoch [561/3000], Loss: 4233.3025\n",
      "Validation Loss: 3944.8978\n",
      "Epoch [581/3000], Loss: 4170.6464\n",
      "Validation Loss: 3898.5658\n",
      "Epoch [601/3000], Loss: 4116.4287\n",
      "Validation Loss: 3857.2372\n",
      "Epoch [621/3000], Loss: 3281.4286\n",
      "Validation Loss: 3357.6755\n",
      "Epoch [641/3000], Loss: 3070.2656\n",
      "Validation Loss: 3630.6315\n",
      "Epoch [661/3000], Loss: 2899.1644\n",
      "Validation Loss: 3731.8142\n",
      "Epoch [681/3000], Loss: 2779.2605\n",
      "Validation Loss: 3659.9160\n",
      "Epoch [701/3000], Loss: 2650.1856\n",
      "Validation Loss: 3583.5587\n",
      "Epoch [721/3000], Loss: 2561.8320\n",
      "Validation Loss: 3451.1044\n",
      "Epoch [741/3000], Loss: 2448.1118\n",
      "Validation Loss: 3349.0737\n",
      "Epoch [761/3000], Loss: 2357.5561\n",
      "Validation Loss: 3345.2923\n",
      "Epoch [781/3000], Loss: 2264.4104\n",
      "Validation Loss: 3105.7766\n",
      "Epoch [801/3000], Loss: 2179.9420\n",
      "Validation Loss: 3170.6066\n",
      "Epoch [821/3000], Loss: 2088.0044\n",
      "Validation Loss: 3136.4644\n",
      "Epoch [841/3000], Loss: 2004.5393\n",
      "Validation Loss: 2943.4680\n",
      "Epoch [861/3000], Loss: 1954.7133\n",
      "Validation Loss: 2858.6167\n",
      "Epoch [881/3000], Loss: 1838.0234\n",
      "Validation Loss: 2833.5644\n",
      "Epoch [901/3000], Loss: 1761.7686\n",
      "Validation Loss: 2782.2534\n",
      "Epoch [921/3000], Loss: 1675.5540\n",
      "Validation Loss: 2660.8428\n",
      "Epoch [941/3000], Loss: 1609.9813\n",
      "Validation Loss: 2533.5253\n",
      "Epoch [961/3000], Loss: 1541.1903\n",
      "Validation Loss: 2522.1577\n",
      "Epoch [981/3000], Loss: 1472.8610\n",
      "Validation Loss: 2499.5120\n",
      "Epoch [1001/3000], Loss: 1401.6931\n",
      "Validation Loss: 2472.0164\n",
      "Epoch [1021/3000], Loss: 1338.0785\n",
      "Validation Loss: 2404.5412\n",
      "Epoch [1041/3000], Loss: 1280.4331\n",
      "Validation Loss: 2341.6357\n",
      "Epoch [1061/3000], Loss: 1224.0739\n",
      "Validation Loss: 2309.9913\n",
      "Epoch [1081/3000], Loss: 1162.9279\n",
      "Validation Loss: 2256.9771\n",
      "Epoch [1101/3000], Loss: 1109.4405\n",
      "Validation Loss: 2280.6993\n",
      "Epoch [1121/3000], Loss: 1055.7540\n",
      "Validation Loss: 2226.0508\n",
      "Epoch [1141/3000], Loss: 1001.2495\n",
      "Validation Loss: 2158.0827\n",
      "Epoch [1161/3000], Loss: 941.9118\n",
      "Validation Loss: 2167.9639\n",
      "Epoch [1181/3000], Loss: 891.6392\n",
      "Validation Loss: 2079.4811\n",
      "Epoch [1201/3000], Loss: 848.4884\n",
      "Validation Loss: 2069.1729\n",
      "Epoch [1221/3000], Loss: 800.5008\n",
      "Validation Loss: 2066.6874\n",
      "Epoch [1241/3000], Loss: 766.2960\n",
      "Validation Loss: 1926.6297\n",
      "Epoch [1261/3000], Loss: 712.5578\n",
      "Validation Loss: 2011.2768\n",
      "Epoch [1281/3000], Loss: 670.9290\n",
      "Validation Loss: 2006.8287\n",
      "Epoch [1301/3000], Loss: 633.0741\n",
      "Validation Loss: 1944.5751\n",
      "Epoch [1321/3000], Loss: 596.4902\n",
      "Validation Loss: 1962.0492\n",
      "Epoch [1341/3000], Loss: 562.2863\n",
      "Validation Loss: 1923.2866\n",
      "Epoch [1361/3000], Loss: 530.5197\n",
      "Validation Loss: 1926.1558\n",
      "Epoch [1381/3000], Loss: 498.1500\n",
      "Validation Loss: 1897.4136\n",
      "Epoch [1401/3000], Loss: 469.1661\n",
      "Validation Loss: 1888.4705\n",
      "Epoch [1421/3000], Loss: 442.8245\n",
      "Validation Loss: 1871.7178\n",
      "Epoch [1441/3000], Loss: 413.9762\n",
      "Validation Loss: 1902.5994\n",
      "Epoch [1461/3000], Loss: 384.0668\n",
      "Validation Loss: 1878.5728\n",
      "Epoch [1481/3000], Loss: 366.9492\n",
      "Validation Loss: 2011.6840\n",
      "Epoch [1501/3000], Loss: 332.6593\n",
      "Validation Loss: 1879.0525\n",
      "Epoch [1521/3000], Loss: 310.3199\n",
      "Validation Loss: 1870.7486\n",
      "Epoch [1541/3000], Loss: 287.6253\n",
      "Validation Loss: 1855.2459\n",
      "Epoch [1561/3000], Loss: 267.4988\n",
      "Validation Loss: 1891.6626\n",
      "Epoch [1581/3000], Loss: 297.1595\n",
      "Validation Loss: 2107.8698\n",
      "Epoch [1601/3000], Loss: 230.5477\n",
      "Validation Loss: 1864.1893\n",
      "Epoch [1621/3000], Loss: 215.0651\n",
      "Validation Loss: 1853.6956\n",
      "Epoch [1641/3000], Loss: 199.1044\n",
      "Validation Loss: 1849.9749\n",
      "Epoch [1661/3000], Loss: 183.0283\n",
      "Validation Loss: 1829.9558\n",
      "Epoch [1681/3000], Loss: 169.3573\n",
      "Validation Loss: 1785.0502\n",
      "Epoch [1701/3000], Loss: 171.4940\n",
      "Validation Loss: 1737.6915\n",
      "Epoch [1721/3000], Loss: 141.6627\n",
      "Validation Loss: 1789.4341\n",
      "Epoch [1741/3000], Loss: 129.1502\n",
      "Validation Loss: 1779.5158\n",
      "Epoch [1761/3000], Loss: 118.1272\n",
      "Validation Loss: 1732.0295\n",
      "Epoch [1781/3000], Loss: 107.7127\n",
      "Validation Loss: 1711.4520\n",
      "Epoch [1801/3000], Loss: 99.9143\n",
      "Validation Loss: 1889.5205\n",
      "Epoch [1821/3000], Loss: 88.4238\n",
      "Validation Loss: 1723.3628\n",
      "Epoch [1841/3000], Loss: 80.2146\n",
      "Validation Loss: 1712.1113\n",
      "Epoch [1861/3000], Loss: 71.1753\n",
      "Validation Loss: 1709.9769\n",
      "Epoch [1881/3000], Loss: 62.9729\n",
      "Validation Loss: 1718.4665\n",
      "Epoch [1901/3000], Loss: 55.0879\n",
      "Validation Loss: 1707.7325\n",
      "Epoch [1921/3000], Loss: 48.4279\n",
      "Validation Loss: 1702.1254\n",
      "Epoch [1941/3000], Loss: 42.3664\n",
      "Validation Loss: 1707.6301\n",
      "Epoch [1961/3000], Loss: 69.5501\n",
      "Validation Loss: 1801.8084\n",
      "Epoch [1981/3000], Loss: 33.2904\n",
      "Validation Loss: 1753.3035\n",
      "Epoch [2001/3000], Loss: 29.0569\n",
      "Validation Loss: 1746.2872\n",
      "Epoch [2021/3000], Loss: 25.4512\n",
      "Validation Loss: 1734.6890\n",
      "Epoch [2041/3000], Loss: 22.1936\n",
      "Validation Loss: 1723.7167\n",
      "Epoch [2061/3000], Loss: 19.5520\n",
      "Validation Loss: 1728.1961\n",
      "Epoch [2081/3000], Loss: 16.7233\n",
      "Validation Loss: 1738.8858\n",
      "Epoch [2101/3000], Loss: 14.1955\n",
      "Validation Loss: 1761.3945\n",
      "Epoch [2121/3000], Loss: 12.1464\n",
      "Validation Loss: 1791.4811\n",
      "Epoch [2141/3000], Loss: 10.0037\n",
      "Validation Loss: 1760.1458\n",
      "Epoch [2161/3000], Loss: 8.2560\n",
      "Validation Loss: 1796.6788\n",
      "Epoch [2181/3000], Loss: 7.1519\n",
      "Validation Loss: 1748.8604\n",
      "Epoch [2201/3000], Loss: 5.9181\n",
      "Validation Loss: 1855.4967\n",
      "Epoch [2221/3000], Loss: 5.2082\n",
      "Validation Loss: 1833.8403\n",
      "Epoch [2241/3000], Loss: 4.4747\n",
      "Validation Loss: 1819.4116\n",
      "Epoch [2261/3000], Loss: 3.8185\n",
      "Validation Loss: 1822.2864\n",
      "Epoch [2281/3000], Loss: 3.2183\n",
      "Validation Loss: 1811.7377\n",
      "Epoch [2301/3000], Loss: 2.6786\n",
      "Validation Loss: 1809.6789\n",
      "Epoch [2321/3000], Loss: 2.2475\n",
      "Validation Loss: 1803.5151\n",
      "Epoch [2341/3000], Loss: 1.9152\n",
      "Validation Loss: 1802.1268\n",
      "Epoch [2361/3000], Loss: 1.5666\n",
      "Validation Loss: 1774.5808\n",
      "Epoch [2381/3000], Loss: 1.3302\n",
      "Validation Loss: 1780.1816\n",
      "Epoch [2401/3000], Loss: 1.1064\n",
      "Validation Loss: 1774.7296\n",
      "Epoch [2421/3000], Loss: 0.9395\n",
      "Validation Loss: 1772.0872\n",
      "Epoch [2441/3000], Loss: 1.1316\n",
      "Validation Loss: 1783.1050\n",
      "Epoch [2461/3000], Loss: 0.9345\n",
      "Validation Loss: 1788.8964\n",
      "Epoch [2481/3000], Loss: 0.8605\n",
      "Validation Loss: 1784.8002\n",
      "Epoch [2501/3000], Loss: 0.8035\n",
      "Validation Loss: 1784.3695\n",
      "Epoch [2521/3000], Loss: 0.7716\n",
      "Validation Loss: 1784.7738\n",
      "Epoch [2541/3000], Loss: 0.7347\n",
      "Validation Loss: 1779.6339\n",
      "Epoch [2561/3000], Loss: 0.6881\n",
      "Validation Loss: 1778.4834\n",
      "Epoch [2581/3000], Loss: 0.6549\n",
      "Validation Loss: 1776.2215\n",
      "Epoch [2601/3000], Loss: 0.6005\n",
      "Validation Loss: 1785.3691\n",
      "Epoch [2621/3000], Loss: 0.5652\n",
      "Validation Loss: 1780.3144\n",
      "Epoch [2641/3000], Loss: 0.5269\n",
      "Validation Loss: 1778.6298\n",
      "Epoch [2661/3000], Loss: 0.5086\n",
      "Validation Loss: 1792.1567\n",
      "Epoch [2681/3000], Loss: 33.4386\n",
      "Validation Loss: 1768.5581\n",
      "Epoch [2701/3000], Loss: 0.5142\n",
      "Validation Loss: 1806.8373\n",
      "Epoch [2721/3000], Loss: 0.4586\n",
      "Validation Loss: 1803.9981\n",
      "Epoch [2741/3000], Loss: 0.4310\n",
      "Validation Loss: 1797.9985\n",
      "Epoch [2761/3000], Loss: 0.4212\n",
      "Validation Loss: 1798.6943\n",
      "Epoch [2781/3000], Loss: 0.4133\n",
      "Validation Loss: 1797.4850\n",
      "Epoch [2801/3000], Loss: 0.3963\n",
      "Validation Loss: 1800.7534\n",
      "Epoch [2821/3000], Loss: 0.3901\n",
      "Validation Loss: 1798.0742\n",
      "Epoch [2841/3000], Loss: 0.3873\n",
      "Validation Loss: 1797.9004\n",
      "Epoch [2861/3000], Loss: 0.3625\n",
      "Validation Loss: 1794.8792\n",
      "Epoch [2881/3000], Loss: 0.3509\n",
      "Validation Loss: 1793.0367\n",
      "Epoch [2901/3000], Loss: 0.3365\n",
      "Validation Loss: 1789.3837\n",
      "Epoch [2921/3000], Loss: 0.3156\n",
      "Validation Loss: 1801.5573\n",
      "Epoch [2941/3000], Loss: 0.3415\n",
      "Validation Loss: 1798.2041\n",
      "Epoch [2961/3000], Loss: 0.3696\n",
      "Validation Loss: 1808.5776\n",
      "Epoch [2981/3000], Loss: 0.3149\n",
      "Validation Loss: 1809.1175\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day033_plane0_Fall.mat\n",
      "(4080, 173)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8232.7307\n",
      "Validation Loss: 8106.4456\n",
      "Epoch [21/3000], Loss: 7416.0262\n",
      "Validation Loss: 7218.3532\n",
      "Epoch [41/3000], Loss: 7104.4398\n",
      "Validation Loss: 6916.6213\n",
      "Epoch [61/3000], Loss: 6959.8041\n",
      "Validation Loss: 6779.9167\n",
      "Epoch [81/3000], Loss: 6913.4288\n",
      "Validation Loss: 6672.9551\n",
      "Epoch [101/3000], Loss: 6749.6088\n",
      "Validation Loss: 6574.4106\n",
      "Epoch [121/3000], Loss: 6664.6862\n",
      "Validation Loss: 6483.3686\n",
      "Epoch [141/3000], Loss: 6597.1419\n",
      "Validation Loss: 6395.8097\n",
      "Epoch [161/3000], Loss: 6493.9664\n",
      "Validation Loss: 6310.0430\n",
      "Epoch [181/3000], Loss: 6392.7988\n",
      "Validation Loss: 6226.9920\n",
      "Epoch [201/3000], Loss: 6352.1410\n",
      "Validation Loss: 6146.3366\n",
      "Epoch [221/3000], Loss: 6148.4223\n",
      "Validation Loss: 6067.4352\n",
      "Epoch [241/3000], Loss: 6143.0550\n",
      "Validation Loss: 5990.2792\n",
      "Epoch [261/3000], Loss: 6107.9666\n",
      "Validation Loss: 5914.2283\n",
      "Epoch [281/3000], Loss: 6010.5160\n",
      "Validation Loss: 5838.5475\n",
      "Epoch [301/3000], Loss: 5966.0836\n",
      "Validation Loss: 5764.9538\n",
      "Epoch [321/3000], Loss: 5879.0672\n",
      "Validation Loss: 5692.5511\n",
      "Epoch [341/3000], Loss: 5803.5182\n",
      "Validation Loss: 5621.5111\n",
      "Epoch [361/3000], Loss: 5734.0390\n",
      "Validation Loss: 5551.6409\n",
      "Epoch [381/3000], Loss: 5624.5571\n",
      "Validation Loss: 5483.0785\n",
      "Epoch [401/3000], Loss: 5581.8748\n",
      "Validation Loss: 5415.5005\n",
      "Epoch [421/3000], Loss: 5526.0076\n",
      "Validation Loss: 5349.1831\n",
      "Epoch [441/3000], Loss: 5406.2386\n",
      "Validation Loss: 5284.0420\n",
      "Epoch [461/3000], Loss: 5371.5018\n",
      "Validation Loss: 5219.9679\n",
      "Epoch [481/3000], Loss: 5273.0046\n",
      "Validation Loss: 5156.9364\n",
      "Epoch [501/3000], Loss: 5205.8156\n",
      "Validation Loss: 5095.0254\n",
      "Epoch [521/3000], Loss: 5205.9323\n",
      "Validation Loss: 5032.6838\n",
      "Epoch [541/3000], Loss: 5101.2292\n",
      "Validation Loss: 4972.5465\n",
      "Epoch [561/3000], Loss: 5072.9462\n",
      "Validation Loss: 4913.8267\n",
      "Epoch [581/3000], Loss: 4991.0564\n",
      "Validation Loss: 4856.1957\n",
      "Epoch [601/3000], Loss: 4929.4228\n",
      "Validation Loss: 4799.6009\n",
      "Epoch [621/3000], Loss: 4872.2379\n",
      "Validation Loss: 4744.0688\n",
      "Epoch [641/3000], Loss: 4796.1328\n",
      "Validation Loss: 4689.7755\n",
      "Epoch [661/3000], Loss: 4795.1864\n",
      "Validation Loss: 4636.5277\n",
      "Epoch [681/3000], Loss: 4709.4052\n",
      "Validation Loss: 4584.3260\n",
      "Epoch [701/3000], Loss: 4652.0097\n",
      "Validation Loss: 4533.1892\n",
      "Epoch [721/3000], Loss: 4618.5643\n",
      "Validation Loss: 4483.2475\n",
      "Epoch [741/3000], Loss: 4574.4479\n",
      "Validation Loss: 4434.2601\n",
      "Epoch [761/3000], Loss: 4525.9656\n",
      "Validation Loss: 4386.2893\n",
      "Epoch [781/3000], Loss: 4477.1608\n",
      "Validation Loss: 4339.4432\n",
      "Epoch [801/3000], Loss: 4398.0009\n",
      "Validation Loss: 4293.7698\n",
      "Epoch [821/3000], Loss: 4395.9643\n",
      "Validation Loss: 4249.0778\n",
      "Epoch [841/3000], Loss: 4301.3173\n",
      "Validation Loss: 4205.4736\n",
      "Epoch [861/3000], Loss: 4314.3957\n",
      "Validation Loss: 4162.9641\n",
      "Epoch [881/3000], Loss: 4210.5953\n",
      "Validation Loss: 4121.5554\n",
      "Epoch [901/3000], Loss: 4210.3474\n",
      "Validation Loss: 4081.1112\n",
      "Epoch [921/3000], Loss: 4146.5444\n",
      "Validation Loss: 4041.7442\n",
      "Epoch [941/3000], Loss: 4109.4740\n",
      "Validation Loss: 4003.5282\n",
      "Epoch [961/3000], Loss: 4045.9132\n",
      "Validation Loss: 3966.4325\n",
      "Epoch [981/3000], Loss: 4046.3506\n",
      "Validation Loss: 3930.3120\n",
      "Epoch [1001/3000], Loss: 4031.5435\n",
      "Validation Loss: 3895.1663\n",
      "Epoch [1021/3000], Loss: 3954.6011\n",
      "Validation Loss: 3861.0181\n",
      "Epoch [1041/3000], Loss: 3940.3844\n",
      "Validation Loss: 3827.8971\n",
      "Epoch [1061/3000], Loss: 3928.9465\n",
      "Validation Loss: 3795.1736\n",
      "Epoch [1081/3000], Loss: 3890.8785\n",
      "Validation Loss: 3763.9596\n",
      "Epoch [1101/3000], Loss: 3874.6360\n",
      "Validation Loss: 3733.9403\n",
      "Epoch [1121/3000], Loss: 3830.6452\n",
      "Validation Loss: 3704.9456\n",
      "Epoch [1141/3000], Loss: 3779.9292\n",
      "Validation Loss: 3676.9558\n",
      "Epoch [1161/3000], Loss: 3760.5869\n",
      "Validation Loss: 3650.1660\n",
      "Epoch [1181/3000], Loss: 3754.6325\n",
      "Validation Loss: 3624.3138\n",
      "Epoch [1201/3000], Loss: 3699.6522\n",
      "Validation Loss: 3599.4264\n",
      "Epoch [1221/3000], Loss: 3671.5907\n",
      "Validation Loss: 3575.5457\n",
      "Epoch [1241/3000], Loss: 3629.5344\n",
      "Validation Loss: 3552.7966\n",
      "Epoch [1261/3000], Loss: 3643.7400\n",
      "Validation Loss: 3531.0511\n",
      "Epoch [1281/3000], Loss: 3633.2431\n",
      "Validation Loss: 3510.1732\n",
      "Epoch [1301/3000], Loss: 3593.2044\n",
      "Validation Loss: 3490.3336\n",
      "Epoch [1321/3000], Loss: 3580.3109\n",
      "Validation Loss: 3471.4643\n",
      "Epoch [1341/3000], Loss: 3538.9948\n",
      "Validation Loss: 3453.5777\n",
      "Epoch [1361/3000], Loss: 3514.9799\n",
      "Validation Loss: 3436.1099\n",
      "Epoch [1381/3000], Loss: 2795.8188\n",
      "Validation Loss: 2521.6402\n",
      "Epoch [1401/3000], Loss: 2550.3524\n",
      "Validation Loss: 2428.0889\n",
      "Epoch [1421/3000], Loss: 2494.8525\n",
      "Validation Loss: 2399.9136\n",
      "Epoch [1441/3000], Loss: 2416.9916\n",
      "Validation Loss: 2351.3587\n",
      "Epoch [1461/3000], Loss: 2328.9382\n",
      "Validation Loss: 2324.0234\n",
      "Epoch [1481/3000], Loss: 2262.6731\n",
      "Validation Loss: 2301.4277\n",
      "Epoch [1501/3000], Loss: 2278.5647\n",
      "Validation Loss: 2264.8103\n",
      "Epoch [1521/3000], Loss: 2178.3392\n",
      "Validation Loss: 2206.3266\n",
      "Epoch [1541/3000], Loss: 2143.5727\n",
      "Validation Loss: 2158.6019\n",
      "Epoch [1561/3000], Loss: 2089.5775\n",
      "Validation Loss: 2108.3285\n",
      "Epoch [1581/3000], Loss: 2065.9018\n",
      "Validation Loss: 2102.1889\n",
      "Epoch [1601/3000], Loss: 2027.3690\n",
      "Validation Loss: 2072.1880\n",
      "Epoch [1621/3000], Loss: 1980.3466\n",
      "Validation Loss: 2046.3311\n",
      "Epoch [1641/3000], Loss: 1924.8698\n",
      "Validation Loss: 1997.1387\n",
      "Epoch [1661/3000], Loss: 1892.8999\n",
      "Validation Loss: 1972.0002\n",
      "Epoch [1681/3000], Loss: 1859.5588\n",
      "Validation Loss: 1930.5840\n",
      "Epoch [1701/3000], Loss: 1819.7624\n",
      "Validation Loss: 1885.9256\n",
      "Epoch [1721/3000], Loss: 1794.6586\n",
      "Validation Loss: 1852.4150\n",
      "Epoch [1741/3000], Loss: 1770.6269\n",
      "Validation Loss: 1846.2706\n",
      "Epoch [1761/3000], Loss: 1728.9497\n",
      "Validation Loss: 1781.2022\n",
      "Epoch [1781/3000], Loss: 1668.1497\n",
      "Validation Loss: 1810.2572\n",
      "Epoch [1801/3000], Loss: 1639.9379\n",
      "Validation Loss: 1711.9359\n",
      "Epoch [1821/3000], Loss: 1599.1609\n",
      "Validation Loss: 1676.3718\n",
      "Epoch [1841/3000], Loss: 1578.2788\n",
      "Validation Loss: 1625.4364\n",
      "Epoch [1861/3000], Loss: 1532.4092\n",
      "Validation Loss: 1655.6214\n",
      "Epoch [1881/3000], Loss: 1498.0232\n",
      "Validation Loss: 1601.6137\n",
      "Epoch [1901/3000], Loss: 1468.6910\n",
      "Validation Loss: 1589.9308\n",
      "Epoch [1921/3000], Loss: 1434.2478\n",
      "Validation Loss: 1527.7205\n",
      "Epoch [1941/3000], Loss: 1396.1823\n",
      "Validation Loss: 1514.2477\n",
      "Epoch [1961/3000], Loss: 1385.8036\n",
      "Validation Loss: 1497.2241\n",
      "Epoch [1981/3000], Loss: 1326.5476\n",
      "Validation Loss: 1469.3896\n",
      "Epoch [2001/3000], Loss: 1312.5750\n",
      "Validation Loss: 1445.1583\n",
      "Epoch [2021/3000], Loss: 1272.0019\n",
      "Validation Loss: 1430.6654\n",
      "Epoch [2041/3000], Loss: 1242.0180\n",
      "Validation Loss: 1400.6376\n",
      "Epoch [2061/3000], Loss: 1205.2505\n",
      "Validation Loss: 1354.7669\n",
      "Epoch [2081/3000], Loss: 1188.6400\n",
      "Validation Loss: 1363.2593\n",
      "Epoch [2101/3000], Loss: 1157.4179\n",
      "Validation Loss: 1327.9842\n",
      "Epoch [2121/3000], Loss: 1118.7775\n",
      "Validation Loss: 1313.1655\n",
      "Epoch [2141/3000], Loss: 1105.8302\n",
      "Validation Loss: 1294.8975\n",
      "Epoch [2161/3000], Loss: 1075.0317\n",
      "Validation Loss: 1283.1629\n",
      "Epoch [2181/3000], Loss: 1043.6747\n",
      "Validation Loss: 1258.5323\n",
      "Epoch [2201/3000], Loss: 1033.6535\n",
      "Validation Loss: 1242.4565\n",
      "Epoch [2221/3000], Loss: 999.5481\n",
      "Validation Loss: 1220.5734\n",
      "Epoch [2241/3000], Loss: 994.4885\n",
      "Validation Loss: 1200.6874\n",
      "Epoch [2261/3000], Loss: 954.1751\n",
      "Validation Loss: 1177.3440\n",
      "Epoch [2281/3000], Loss: 925.1662\n",
      "Validation Loss: 1161.3209\n",
      "Epoch [2301/3000], Loss: 908.2815\n",
      "Validation Loss: 1138.4530\n",
      "Epoch [2321/3000], Loss: 867.0204\n",
      "Validation Loss: 1126.4549\n",
      "Epoch [2341/3000], Loss: 851.0273\n",
      "Validation Loss: 1104.6922\n",
      "Epoch [2361/3000], Loss: 824.4210\n",
      "Validation Loss: 1090.0251\n",
      "Epoch [2381/3000], Loss: 807.8040\n",
      "Validation Loss: 1075.1605\n",
      "Epoch [2401/3000], Loss: 792.2940\n",
      "Validation Loss: 1052.1855\n",
      "Epoch [2421/3000], Loss: 757.9601\n",
      "Validation Loss: 1028.8896\n",
      "Epoch [2441/3000], Loss: 755.3652\n",
      "Validation Loss: 1014.2092\n",
      "Epoch [2461/3000], Loss: 734.7830\n",
      "Validation Loss: 994.4482\n",
      "Epoch [2481/3000], Loss: 719.2842\n",
      "Validation Loss: 976.7960\n",
      "Epoch [2501/3000], Loss: 693.9238\n",
      "Validation Loss: 964.2430\n",
      "Epoch [2521/3000], Loss: 678.8783\n",
      "Validation Loss: 951.0734\n",
      "Epoch [2541/3000], Loss: 642.8045\n",
      "Validation Loss: 938.6226\n",
      "Epoch [2561/3000], Loss: 628.8222\n",
      "Validation Loss: 929.9453\n",
      "Epoch [2581/3000], Loss: 628.0123\n",
      "Validation Loss: 914.2385\n",
      "Epoch [2601/3000], Loss: 600.3023\n",
      "Validation Loss: 901.0852\n",
      "Epoch [2621/3000], Loss: 585.2694\n",
      "Validation Loss: 892.2573\n",
      "Epoch [2641/3000], Loss: 561.5451\n",
      "Validation Loss: 876.3716\n",
      "Epoch [2661/3000], Loss: 553.3968\n",
      "Validation Loss: 863.3523\n",
      "Epoch [2681/3000], Loss: 533.4544\n",
      "Validation Loss: 848.4883\n",
      "Epoch [2701/3000], Loss: 519.8363\n",
      "Validation Loss: 834.5332\n",
      "Epoch [2721/3000], Loss: 500.2689\n",
      "Validation Loss: 817.0658\n",
      "Epoch [2741/3000], Loss: 490.0371\n",
      "Validation Loss: 819.6859\n",
      "Epoch [2761/3000], Loss: 523.7721\n",
      "Validation Loss: 774.2008\n",
      "Epoch [2781/3000], Loss: 467.2112\n",
      "Validation Loss: 806.5700\n",
      "Epoch [2801/3000], Loss: 449.5682\n",
      "Validation Loss: 794.7092\n",
      "Epoch [2821/3000], Loss: 420.7661\n",
      "Validation Loss: 783.1389\n",
      "Epoch [2841/3000], Loss: 427.5009\n",
      "Validation Loss: 774.2743\n",
      "Epoch [2861/3000], Loss: 404.7933\n",
      "Validation Loss: 766.3166\n",
      "Epoch [2881/3000], Loss: 396.6994\n",
      "Validation Loss: 756.7902\n",
      "Epoch [2901/3000], Loss: 380.7552\n",
      "Validation Loss: 746.9721\n",
      "Epoch [2921/3000], Loss: 376.8924\n",
      "Validation Loss: 738.0980\n",
      "Epoch [2941/3000], Loss: 363.8147\n",
      "Validation Loss: 730.2738\n",
      "Epoch [2961/3000], Loss: 348.4030\n",
      "Validation Loss: 714.5487\n",
      "Epoch [2981/3000], Loss: 338.6228\n",
      "Validation Loss: 708.9970\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day034_plane0_Fall.mat\n",
      "(4373, 159)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8297.7801\n",
      "Validation Loss: 7582.0391\n",
      "Epoch [21/3000], Loss: 7257.8913\n",
      "Validation Loss: 6605.4250\n",
      "Epoch [41/3000], Loss: 6960.1706\n",
      "Validation Loss: 6336.8447\n",
      "Epoch [61/3000], Loss: 6818.4764\n",
      "Validation Loss: 6206.9343\n",
      "Epoch [81/3000], Loss: 6687.2900\n",
      "Validation Loss: 6095.8345\n",
      "Epoch [101/3000], Loss: 6581.3256\n",
      "Validation Loss: 5994.4822\n",
      "Epoch [121/3000], Loss: 6474.2489\n",
      "Validation Loss: 5899.2998\n",
      "Epoch [141/3000], Loss: 6375.6387\n",
      "Validation Loss: 5807.2451\n",
      "Epoch [161/3000], Loss: 6279.5177\n",
      "Validation Loss: 5718.8167\n",
      "Epoch [181/3000], Loss: 6181.1995\n",
      "Validation Loss: 5633.0862\n",
      "Epoch [201/3000], Loss: 6090.8087\n",
      "Validation Loss: 5548.8730\n",
      "Epoch [221/3000], Loss: 6007.4676\n",
      "Validation Loss: 5466.3477\n",
      "Epoch [241/3000], Loss: 5907.9852\n",
      "Validation Loss: 5386.0876\n",
      "Epoch [261/3000], Loss: 5822.7630\n",
      "Validation Loss: 5307.6697\n",
      "Epoch [281/3000], Loss: 5736.8944\n",
      "Validation Loss: 5230.9355\n",
      "Epoch [301/3000], Loss: 5661.2746\n",
      "Validation Loss: 5155.8472\n",
      "Epoch [321/3000], Loss: 5574.2020\n",
      "Validation Loss: 5082.3120\n",
      "Epoch [341/3000], Loss: 5499.8458\n",
      "Validation Loss: 5010.3096\n",
      "Epoch [361/3000], Loss: 5408.1697\n",
      "Validation Loss: 4939.7573\n",
      "Epoch [381/3000], Loss: 5340.7563\n",
      "Validation Loss: 4870.7417\n",
      "Epoch [401/3000], Loss: 5267.8844\n",
      "Validation Loss: 4803.1099\n",
      "Epoch [421/3000], Loss: 5192.1139\n",
      "Validation Loss: 4737.0034\n",
      "Epoch [441/3000], Loss: 5115.4053\n",
      "Validation Loss: 4672.3184\n",
      "Epoch [461/3000], Loss: 5040.8377\n",
      "Validation Loss: 4609.0742\n",
      "Epoch [481/3000], Loss: 4975.6272\n",
      "Validation Loss: 4547.2649\n",
      "Epoch [501/3000], Loss: 4916.5077\n",
      "Validation Loss: 4486.8618\n",
      "Epoch [521/3000], Loss: 4847.4034\n",
      "Validation Loss: 4427.8718\n",
      "Epoch [541/3000], Loss: 4776.1329\n",
      "Validation Loss: 4370.4045\n",
      "Epoch [561/3000], Loss: 4717.4077\n",
      "Validation Loss: 4314.2639\n",
      "Epoch [581/3000], Loss: 4651.3438\n",
      "Validation Loss: 4259.5535\n",
      "Epoch [601/3000], Loss: 4591.1847\n",
      "Validation Loss: 4205.7126\n",
      "Epoch [621/3000], Loss: 4532.9736\n",
      "Validation Loss: 4153.2468\n",
      "Epoch [641/3000], Loss: 4465.2320\n",
      "Validation Loss: 4102.4441\n",
      "Epoch [661/3000], Loss: 4411.6606\n",
      "Validation Loss: 4053.1624\n",
      "Epoch [681/3000], Loss: 4352.0219\n",
      "Validation Loss: 4005.2467\n",
      "Epoch [701/3000], Loss: 4301.9582\n",
      "Validation Loss: 3958.7754\n",
      "Epoch [721/3000], Loss: 4250.9021\n",
      "Validation Loss: 3913.7463\n",
      "Epoch [741/3000], Loss: 4200.4474\n",
      "Validation Loss: 3870.0841\n",
      "Epoch [761/3000], Loss: 4148.9763\n",
      "Validation Loss: 3827.7985\n",
      "Epoch [781/3000], Loss: 4099.6873\n",
      "Validation Loss: 3786.9076\n",
      "Epoch [801/3000], Loss: 4049.5473\n",
      "Validation Loss: 3747.4318\n",
      "Epoch [821/3000], Loss: 4010.5960\n",
      "Validation Loss: 3709.2605\n",
      "Epoch [841/3000], Loss: 3967.5697\n",
      "Validation Loss: 3672.5094\n",
      "Epoch [861/3000], Loss: 3923.3231\n",
      "Validation Loss: 3637.1213\n",
      "Epoch [881/3000], Loss: 3875.0304\n",
      "Validation Loss: 3603.0730\n",
      "Epoch [901/3000], Loss: 3837.0478\n",
      "Validation Loss: 3570.4104\n",
      "Epoch [921/3000], Loss: 3799.3768\n",
      "Validation Loss: 3539.0836\n",
      "Epoch [941/3000], Loss: 3766.7017\n",
      "Validation Loss: 3509.0828\n",
      "Epoch [961/3000], Loss: 3721.3233\n",
      "Validation Loss: 3480.4404\n",
      "Epoch [981/3000], Loss: 3692.6879\n",
      "Validation Loss: 3453.1443\n",
      "Epoch [1001/3000], Loss: 3654.1028\n",
      "Validation Loss: 3427.1425\n",
      "Epoch [1021/3000], Loss: 3626.3410\n",
      "Validation Loss: 3402.4723\n",
      "Epoch [1041/3000], Loss: 3593.2192\n",
      "Validation Loss: 3379.0990\n",
      "Epoch [1061/3000], Loss: 3565.2944\n",
      "Validation Loss: 3356.9878\n",
      "Epoch [1081/3000], Loss: 3533.0934\n",
      "Validation Loss: 3336.2148\n",
      "Epoch [1101/3000], Loss: 3511.8266\n",
      "Validation Loss: 3316.6772\n",
      "Epoch [1121/3000], Loss: 3486.1828\n",
      "Validation Loss: 3298.4033\n",
      "Epoch [1141/3000], Loss: 3461.0516\n",
      "Validation Loss: 3281.4150\n",
      "Epoch [1161/3000], Loss: 3433.9750\n",
      "Validation Loss: 3265.6523\n",
      "Epoch [1181/3000], Loss: 3411.9134\n",
      "Validation Loss: 3251.0911\n",
      "Epoch [1201/3000], Loss: 3394.0178\n",
      "Validation Loss: 3237.7428\n",
      "Epoch [1221/3000], Loss: 3373.6034\n",
      "Validation Loss: 3225.5549\n",
      "Epoch [1241/3000], Loss: 3359.2850\n",
      "Validation Loss: 3214.5399\n",
      "Epoch [1261/3000], Loss: 3336.1209\n",
      "Validation Loss: 3204.6279\n",
      "Epoch [1281/3000], Loss: 3325.1669\n",
      "Validation Loss: 3195.8577\n",
      "Epoch [1301/3000], Loss: 3310.7692\n",
      "Validation Loss: 3188.1440\n",
      "Epoch [1321/3000], Loss: 3299.9804\n",
      "Validation Loss: 3181.5222\n",
      "Epoch [1341/3000], Loss: 3275.5865\n",
      "Validation Loss: 3161.3530\n",
      "Epoch [1361/3000], Loss: 2281.7594\n",
      "Validation Loss: 2268.7908\n",
      "Epoch [1381/3000], Loss: 2147.9979\n",
      "Validation Loss: 2156.3429\n",
      "Epoch [1401/3000], Loss: 2068.3049\n",
      "Validation Loss: 2027.7705\n",
      "Epoch [1421/3000], Loss: 2000.3749\n",
      "Validation Loss: 1993.4119\n",
      "Epoch [1441/3000], Loss: 1939.6820\n",
      "Validation Loss: 1980.7811\n",
      "Epoch [1461/3000], Loss: 1883.7661\n",
      "Validation Loss: 1938.3026\n",
      "Epoch [1481/3000], Loss: 1832.6171\n",
      "Validation Loss: 1875.6407\n",
      "Epoch [1501/3000], Loss: 1785.3172\n",
      "Validation Loss: 1867.0022\n",
      "Epoch [1521/3000], Loss: 1739.0155\n",
      "Validation Loss: 1888.7552\n",
      "Epoch [1541/3000], Loss: 1692.6786\n",
      "Validation Loss: 1844.3182\n",
      "Epoch [1561/3000], Loss: 1648.1986\n",
      "Validation Loss: 1822.7969\n",
      "Epoch [1581/3000], Loss: 1601.9595\n",
      "Validation Loss: 1763.6548\n",
      "Epoch [1601/3000], Loss: 1556.6187\n",
      "Validation Loss: 1755.9052\n",
      "Epoch [1621/3000], Loss: 1517.2620\n",
      "Validation Loss: 1738.0551\n",
      "Epoch [1641/3000], Loss: 1471.3207\n",
      "Validation Loss: 1704.5193\n",
      "Epoch [1661/3000], Loss: 1434.9323\n",
      "Validation Loss: 1633.9590\n",
      "Epoch [1681/3000], Loss: 1399.9370\n",
      "Validation Loss: 1622.7511\n",
      "Epoch [1701/3000], Loss: 1364.8070\n",
      "Validation Loss: 1556.5745\n",
      "Epoch [1721/3000], Loss: 1325.7381\n",
      "Validation Loss: 1526.8894\n",
      "Epoch [1741/3000], Loss: 1292.4173\n",
      "Validation Loss: 1507.9128\n",
      "Epoch [1761/3000], Loss: 1263.6650\n",
      "Validation Loss: 1503.7703\n",
      "Epoch [1781/3000], Loss: 1230.1832\n",
      "Validation Loss: 1437.6595\n",
      "Epoch [1801/3000], Loss: 1185.4244\n",
      "Validation Loss: 1373.1590\n",
      "Epoch [1821/3000], Loss: 1152.8252\n",
      "Validation Loss: 1369.5804\n",
      "Epoch [1841/3000], Loss: 1124.0207\n",
      "Validation Loss: 1348.3076\n",
      "Epoch [1861/3000], Loss: 1093.0998\n",
      "Validation Loss: 1313.9430\n",
      "Epoch [1881/3000], Loss: 1063.9201\n",
      "Validation Loss: 1282.2654\n",
      "Epoch [1901/3000], Loss: 1034.6163\n",
      "Validation Loss: 1261.9011\n",
      "Epoch [1921/3000], Loss: 1009.6286\n",
      "Validation Loss: 1231.6680\n",
      "Epoch [1941/3000], Loss: 980.5459\n",
      "Validation Loss: 1204.2445\n",
      "Epoch [1961/3000], Loss: 954.0297\n",
      "Validation Loss: 1189.5464\n",
      "Epoch [1981/3000], Loss: 930.9000\n",
      "Validation Loss: 1166.4720\n",
      "Epoch [2001/3000], Loss: 907.2605\n",
      "Validation Loss: 1126.2640\n",
      "Epoch [2021/3000], Loss: 881.0304\n",
      "Validation Loss: 1134.7447\n",
      "Epoch [2041/3000], Loss: 856.3309\n",
      "Validation Loss: 1134.7308\n",
      "Epoch [2061/3000], Loss: 828.1066\n",
      "Validation Loss: 1111.3217\n",
      "Epoch [2081/3000], Loss: 804.8773\n",
      "Validation Loss: 1079.0011\n",
      "Epoch [2101/3000], Loss: 781.6417\n",
      "Validation Loss: 1055.2772\n",
      "Epoch [2121/3000], Loss: 758.2920\n",
      "Validation Loss: 1040.5334\n",
      "Epoch [2141/3000], Loss: 737.2449\n",
      "Validation Loss: 1040.0848\n",
      "Epoch [2161/3000], Loss: 717.1702\n",
      "Validation Loss: 1030.9631\n",
      "Epoch [2181/3000], Loss: 694.4149\n",
      "Validation Loss: 1008.2847\n",
      "Epoch [2201/3000], Loss: 674.1706\n",
      "Validation Loss: 999.9691\n",
      "Epoch [2221/3000], Loss: 654.7382\n",
      "Validation Loss: 959.1966\n",
      "Epoch [2241/3000], Loss: 636.6379\n",
      "Validation Loss: 972.3622\n",
      "Epoch [2261/3000], Loss: 617.0737\n",
      "Validation Loss: 932.3835\n",
      "Epoch [2281/3000], Loss: 599.5223\n",
      "Validation Loss: 952.6000\n",
      "Epoch [2301/3000], Loss: 581.5509\n",
      "Validation Loss: 958.9947\n",
      "Epoch [2321/3000], Loss: 563.2295\n",
      "Validation Loss: 942.9535\n",
      "Epoch [2341/3000], Loss: 547.4476\n",
      "Validation Loss: 959.3194\n",
      "Epoch [2361/3000], Loss: 529.1800\n",
      "Validation Loss: 938.1491\n",
      "Epoch [2381/3000], Loss: 515.4089\n",
      "Validation Loss: 936.7962\n",
      "Epoch [2401/3000], Loss: 497.9203\n",
      "Validation Loss: 919.0216\n",
      "Epoch [2421/3000], Loss: 484.3028\n",
      "Validation Loss: 918.8564\n",
      "Epoch [2441/3000], Loss: 470.1023\n",
      "Validation Loss: 896.1986\n",
      "Epoch [2461/3000], Loss: 454.6520\n",
      "Validation Loss: 885.4373\n",
      "Epoch [2481/3000], Loss: 441.7517\n",
      "Validation Loss: 864.2581\n",
      "Epoch [2501/3000], Loss: 428.0611\n",
      "Validation Loss: 862.2929\n",
      "Epoch [2521/3000], Loss: 414.9524\n",
      "Validation Loss: 877.9322\n",
      "Epoch [2541/3000], Loss: 401.1825\n",
      "Validation Loss: 848.0409\n",
      "Epoch [2561/3000], Loss: 389.0866\n",
      "Validation Loss: 834.5541\n",
      "Epoch [2581/3000], Loss: 376.2878\n",
      "Validation Loss: 839.9903\n",
      "Epoch [2601/3000], Loss: 364.3655\n",
      "Validation Loss: 810.3516\n",
      "Epoch [2621/3000], Loss: 351.8240\n",
      "Validation Loss: 809.7958\n",
      "Epoch [2641/3000], Loss: 340.6540\n",
      "Validation Loss: 783.5363\n",
      "Epoch [2661/3000], Loss: 329.3788\n",
      "Validation Loss: 786.0220\n",
      "Epoch [2681/3000], Loss: 318.4551\n",
      "Validation Loss: 789.4924\n",
      "Epoch [2701/3000], Loss: 306.9726\n",
      "Validation Loss: 799.2053\n",
      "Epoch [2721/3000], Loss: 296.2985\n",
      "Validation Loss: 825.5630\n",
      "Epoch [2741/3000], Loss: 285.4818\n",
      "Validation Loss: 803.5210\n",
      "Epoch [2761/3000], Loss: 276.6209\n",
      "Validation Loss: 772.8323\n",
      "Epoch [2781/3000], Loss: 266.2887\n",
      "Validation Loss: 785.9702\n",
      "Epoch [2801/3000], Loss: 257.5347\n",
      "Validation Loss: 767.3886\n",
      "Epoch [2821/3000], Loss: 249.2595\n",
      "Validation Loss: 761.2130\n",
      "Epoch [2841/3000], Loss: 240.4435\n",
      "Validation Loss: 768.2167\n",
      "Epoch [2861/3000], Loss: 231.2989\n",
      "Validation Loss: 757.8492\n",
      "Epoch [2881/3000], Loss: 222.2290\n",
      "Validation Loss: 772.3270\n",
      "Epoch [2901/3000], Loss: 213.3382\n",
      "Validation Loss: 787.6002\n",
      "Epoch [2921/3000], Loss: 205.8752\n",
      "Validation Loss: 743.5863\n",
      "Epoch [2941/3000], Loss: 197.9988\n",
      "Validation Loss: 749.6330\n",
      "Epoch [2961/3000], Loss: 190.6564\n",
      "Validation Loss: 709.1891\n",
      "Epoch [2981/3000], Loss: 183.2088\n",
      "Validation Loss: 750.6313\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day035_plane0_Fall.mat\n",
      "(4196, 156)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9237.3037\n",
      "Validation Loss: 6605.1369\n",
      "Epoch [21/3000], Loss: 8281.2464\n",
      "Validation Loss: 5859.0076\n",
      "Epoch [41/3000], Loss: 7976.4102\n",
      "Validation Loss: 5624.2357\n",
      "Epoch [61/3000], Loss: 7817.4165\n",
      "Validation Loss: 5515.3786\n",
      "Epoch [81/3000], Loss: 7689.2232\n",
      "Validation Loss: 5425.3211\n",
      "Epoch [101/3000], Loss: 7578.5169\n",
      "Validation Loss: 5344.3490\n",
      "Epoch [121/3000], Loss: 7476.6666\n",
      "Validation Loss: 5268.4271\n",
      "Epoch [141/3000], Loss: 7374.4241\n",
      "Validation Loss: 5195.9789\n",
      "Epoch [161/3000], Loss: 7286.6484\n",
      "Validation Loss: 5126.1968\n",
      "Epoch [181/3000], Loss: 7207.8235\n",
      "Validation Loss: 5058.5806\n",
      "Epoch [201/3000], Loss: 7106.7911\n",
      "Validation Loss: 4992.8328\n",
      "Epoch [221/3000], Loss: 7028.3568\n",
      "Validation Loss: 4928.8415\n",
      "Epoch [241/3000], Loss: 6922.4343\n",
      "Validation Loss: 4866.3984\n",
      "Epoch [261/3000], Loss: 6843.4749\n",
      "Validation Loss: 4805.4302\n",
      "Epoch [281/3000], Loss: 6754.7566\n",
      "Validation Loss: 4745.8372\n",
      "Epoch [301/3000], Loss: 6666.3295\n",
      "Validation Loss: 4687.5950\n",
      "Epoch [321/3000], Loss: 6593.2355\n",
      "Validation Loss: 4630.7422\n",
      "Epoch [341/3000], Loss: 6515.5681\n",
      "Validation Loss: 4575.2392\n",
      "Epoch [361/3000], Loss: 6455.1920\n",
      "Validation Loss: 4520.9408\n",
      "Epoch [381/3000], Loss: 6379.4521\n",
      "Validation Loss: 4467.9320\n",
      "Epoch [401/3000], Loss: 6256.4909\n",
      "Validation Loss: 4416.2061\n",
      "Epoch [421/3000], Loss: 6219.2269\n",
      "Validation Loss: 4365.7458\n",
      "Epoch [441/3000], Loss: 6149.1669\n",
      "Validation Loss: 4316.4998\n",
      "Epoch [461/3000], Loss: 6064.3813\n",
      "Validation Loss: 4268.5486\n",
      "Epoch [481/3000], Loss: 5962.0225\n",
      "Validation Loss: 4221.7661\n",
      "Epoch [501/3000], Loss: 5886.7394\n",
      "Validation Loss: 4175.6817\n",
      "Epoch [521/3000], Loss: 5863.0078\n",
      "Validation Loss: 4130.9424\n",
      "Epoch [541/3000], Loss: 5767.5383\n",
      "Validation Loss: 4087.5923\n",
      "Epoch [561/3000], Loss: 5684.6499\n",
      "Validation Loss: 4045.5645\n",
      "Epoch [581/3000], Loss: 5664.2195\n",
      "Validation Loss: 4004.6989\n",
      "Epoch [601/3000], Loss: 5618.6109\n",
      "Validation Loss: 3965.1618\n",
      "Epoch [621/3000], Loss: 5543.4492\n",
      "Validation Loss: 3926.8562\n",
      "Epoch [641/3000], Loss: 5470.9182\n",
      "Validation Loss: 3889.6463\n",
      "Epoch [661/3000], Loss: 5405.4485\n",
      "Validation Loss: 3853.3136\n",
      "Epoch [681/3000], Loss: 5344.2940\n",
      "Validation Loss: 3818.0700\n",
      "Epoch [701/3000], Loss: 5275.3088\n",
      "Validation Loss: 3784.3621\n",
      "Epoch [721/3000], Loss: 5221.2821\n",
      "Validation Loss: 3751.9609\n",
      "Epoch [741/3000], Loss: 5175.3593\n",
      "Validation Loss: 3720.7063\n",
      "Epoch [761/3000], Loss: 5146.0150\n",
      "Validation Loss: 3690.6896\n",
      "Epoch [781/3000], Loss: 5056.7729\n",
      "Validation Loss: 3661.8837\n",
      "Epoch [801/3000], Loss: 5023.6156\n",
      "Validation Loss: 3634.3105\n",
      "Epoch [821/3000], Loss: 4953.3681\n",
      "Validation Loss: 3607.9474\n",
      "Epoch [841/3000], Loss: 4897.6633\n",
      "Validation Loss: 3582.7454\n",
      "Epoch [861/3000], Loss: 4888.8406\n",
      "Validation Loss: 3558.7965\n",
      "Epoch [881/3000], Loss: 4819.9787\n",
      "Validation Loss: 3535.9312\n",
      "Epoch [901/3000], Loss: 4752.0859\n",
      "Validation Loss: 3514.2594\n",
      "Epoch [921/3000], Loss: 4731.1279\n",
      "Validation Loss: 3493.7752\n",
      "Epoch [941/3000], Loss: 4675.0347\n",
      "Validation Loss: 3474.4552\n",
      "Epoch [961/3000], Loss: 4651.3907\n",
      "Validation Loss: 3456.2750\n",
      "Epoch [981/3000], Loss: 4601.3503\n",
      "Validation Loss: 3439.2503\n",
      "Epoch [1001/3000], Loss: 4566.3078\n",
      "Validation Loss: 3423.1482\n",
      "Epoch [1021/3000], Loss: 4523.9690\n",
      "Validation Loss: 3408.2237\n",
      "Epoch [1041/3000], Loss: 4505.3868\n",
      "Validation Loss: 3394.5448\n",
      "Epoch [1061/3000], Loss: 4438.9351\n",
      "Validation Loss: 3382.0474\n",
      "Epoch [1081/3000], Loss: 4410.1785\n",
      "Validation Loss: 3370.6855\n",
      "Epoch [1101/3000], Loss: 4385.2698\n",
      "Validation Loss: 3360.4634\n",
      "Epoch [1121/3000], Loss: 4346.1423\n",
      "Validation Loss: 3351.3399\n",
      "Epoch [1141/3000], Loss: 4331.7869\n",
      "Validation Loss: 3343.3148\n",
      "Epoch [1161/3000], Loss: 4293.3636\n",
      "Validation Loss: 3336.3716\n",
      "Epoch [1181/3000], Loss: 4166.6438\n",
      "Validation Loss: 3163.0405\n",
      "Epoch [1201/3000], Loss: 3388.3031\n",
      "Validation Loss: 2372.0950\n",
      "Epoch [1221/3000], Loss: 3268.3935\n",
      "Validation Loss: 2322.3063\n",
      "Epoch [1241/3000], Loss: 3199.2328\n",
      "Validation Loss: 2259.1995\n",
      "Epoch [1261/3000], Loss: 3126.9668\n",
      "Validation Loss: 2227.6418\n",
      "Epoch [1281/3000], Loss: 3060.2318\n",
      "Validation Loss: 2202.1271\n",
      "Epoch [1301/3000], Loss: 2997.5410\n",
      "Validation Loss: 2144.2161\n",
      "Epoch [1321/3000], Loss: 2941.6962\n",
      "Validation Loss: 2116.6101\n",
      "Epoch [1341/3000], Loss: 2869.9776\n",
      "Validation Loss: 2097.8323\n",
      "Epoch [1361/3000], Loss: 2808.9223\n",
      "Validation Loss: 2063.6070\n",
      "Epoch [1381/3000], Loss: 2768.6490\n",
      "Validation Loss: 2025.7298\n",
      "Epoch [1401/3000], Loss: 2698.1405\n",
      "Validation Loss: 1992.2232\n",
      "Epoch [1421/3000], Loss: 2650.8346\n",
      "Validation Loss: 1949.2411\n",
      "Epoch [1441/3000], Loss: 2592.5650\n",
      "Validation Loss: 1920.3682\n",
      "Epoch [1461/3000], Loss: 2552.7156\n",
      "Validation Loss: 1897.4075\n",
      "Epoch [1481/3000], Loss: 2507.7854\n",
      "Validation Loss: 1882.5589\n",
      "Epoch [1501/3000], Loss: 2447.0132\n",
      "Validation Loss: 1821.2083\n",
      "Epoch [1521/3000], Loss: 2412.5147\n",
      "Validation Loss: 1801.4308\n",
      "Epoch [1541/3000], Loss: 2350.9834\n",
      "Validation Loss: 1770.6745\n",
      "Epoch [1561/3000], Loss: 2295.3752\n",
      "Validation Loss: 1754.9647\n",
      "Epoch [1581/3000], Loss: 2254.5384\n",
      "Validation Loss: 1739.2592\n",
      "Epoch [1601/3000], Loss: 2225.3543\n",
      "Validation Loss: 1672.9011\n",
      "Epoch [1621/3000], Loss: 2170.7628\n",
      "Validation Loss: 1668.5309\n",
      "Epoch [1641/3000], Loss: 2137.1787\n",
      "Validation Loss: 1616.0408\n",
      "Epoch [1661/3000], Loss: 2078.3275\n",
      "Validation Loss: 1618.9952\n",
      "Epoch [1681/3000], Loss: 2025.8682\n",
      "Validation Loss: 1595.8102\n",
      "Epoch [1701/3000], Loss: 1994.7113\n",
      "Validation Loss: 1564.8395\n",
      "Epoch [1721/3000], Loss: 1952.3356\n",
      "Validation Loss: 1542.8550\n",
      "Epoch [1741/3000], Loss: 1897.9683\n",
      "Validation Loss: 1514.4267\n",
      "Epoch [1761/3000], Loss: 1867.9903\n",
      "Validation Loss: 1483.0133\n",
      "Epoch [1781/3000], Loss: 1812.9153\n",
      "Validation Loss: 1456.3062\n",
      "Epoch [1801/3000], Loss: 1782.3481\n",
      "Validation Loss: 1434.9233\n",
      "Epoch [1821/3000], Loss: 1739.4175\n",
      "Validation Loss: 1384.0810\n",
      "Epoch [1841/3000], Loss: 1697.1389\n",
      "Validation Loss: 1370.1928\n",
      "Epoch [1861/3000], Loss: 1647.1391\n",
      "Validation Loss: 1352.7201\n",
      "Epoch [1881/3000], Loss: 1608.4419\n",
      "Validation Loss: 1330.4136\n",
      "Epoch [1901/3000], Loss: 1575.9201\n",
      "Validation Loss: 1310.7723\n",
      "Epoch [1921/3000], Loss: 1546.1556\n",
      "Validation Loss: 1285.9675\n",
      "Epoch [1941/3000], Loss: 1509.6941\n",
      "Validation Loss: 1267.2511\n",
      "Epoch [1961/3000], Loss: 1469.5222\n",
      "Validation Loss: 1247.1407\n",
      "Epoch [1981/3000], Loss: 1420.9929\n",
      "Validation Loss: 1203.2327\n",
      "Epoch [2001/3000], Loss: 1397.3879\n",
      "Validation Loss: 1183.9712\n",
      "Epoch [2021/3000], Loss: 1357.7707\n",
      "Validation Loss: 1166.1432\n",
      "Epoch [2041/3000], Loss: 1332.5862\n",
      "Validation Loss: 1150.1948\n",
      "Epoch [2061/3000], Loss: 1280.8835\n",
      "Validation Loss: 1132.0143\n",
      "Epoch [2081/3000], Loss: 1250.9278\n",
      "Validation Loss: 1112.5542\n",
      "Epoch [2101/3000], Loss: 1222.4529\n",
      "Validation Loss: 1096.5219\n",
      "Epoch [2121/3000], Loss: 1191.1473\n",
      "Validation Loss: 1081.5938\n",
      "Epoch [2141/3000], Loss: 1162.8546\n",
      "Validation Loss: 1062.8919\n",
      "Epoch [2161/3000], Loss: 1137.0460\n",
      "Validation Loss: 1045.6810\n",
      "Epoch [2181/3000], Loss: 1095.1284\n",
      "Validation Loss: 1029.0941\n",
      "Epoch [2201/3000], Loss: 1069.3589\n",
      "Validation Loss: 1014.9909\n",
      "Epoch [2221/3000], Loss: 1042.2653\n",
      "Validation Loss: 996.9021\n",
      "Epoch [2241/3000], Loss: 1011.9219\n",
      "Validation Loss: 980.5834\n",
      "Epoch [2261/3000], Loss: 984.5810\n",
      "Validation Loss: 963.3687\n",
      "Epoch [2281/3000], Loss: 960.0208\n",
      "Validation Loss: 950.7011\n",
      "Epoch [2301/3000], Loss: 927.2924\n",
      "Validation Loss: 935.3977\n",
      "Epoch [2321/3000], Loss: 901.9236\n",
      "Validation Loss: 924.0239\n",
      "Epoch [2341/3000], Loss: 879.8066\n",
      "Validation Loss: 909.7445\n",
      "Epoch [2361/3000], Loss: 851.7974\n",
      "Validation Loss: 898.1833\n",
      "Epoch [2381/3000], Loss: 822.5431\n",
      "Validation Loss: 888.1643\n",
      "Epoch [2401/3000], Loss: 808.3186\n",
      "Validation Loss: 877.0785\n",
      "Epoch [2421/3000], Loss: 774.9338\n",
      "Validation Loss: 868.3291\n",
      "Epoch [2441/3000], Loss: 754.3395\n",
      "Validation Loss: 822.6912\n",
      "Epoch [2461/3000], Loss: 727.0692\n",
      "Validation Loss: 818.3493\n",
      "Epoch [2481/3000], Loss: 711.3001\n",
      "Validation Loss: 811.2075\n",
      "Epoch [2501/3000], Loss: 690.4590\n",
      "Validation Loss: 801.5931\n",
      "Epoch [2521/3000], Loss: 667.6288\n",
      "Validation Loss: 791.3284\n",
      "Epoch [2541/3000], Loss: 649.8457\n",
      "Validation Loss: 782.7246\n",
      "Epoch [2561/3000], Loss: 626.3468\n",
      "Validation Loss: 772.8729\n",
      "Epoch [2581/3000], Loss: 605.4865\n",
      "Validation Loss: 766.7392\n",
      "Epoch [2601/3000], Loss: 586.6208\n",
      "Validation Loss: 758.6742\n",
      "Epoch [2621/3000], Loss: 568.8761\n",
      "Validation Loss: 751.8634\n",
      "Epoch [2641/3000], Loss: 545.9806\n",
      "Validation Loss: 746.0779\n",
      "Epoch [2661/3000], Loss: 529.2794\n",
      "Validation Loss: 735.3195\n",
      "Epoch [2681/3000], Loss: 511.9845\n",
      "Validation Loss: 725.6364\n",
      "Epoch [2701/3000], Loss: 499.5809\n",
      "Validation Loss: 710.4611\n",
      "Epoch [2721/3000], Loss: 483.1631\n",
      "Validation Loss: 684.3667\n",
      "Epoch [2741/3000], Loss: 463.8752\n",
      "Validation Loss: 682.9824\n",
      "Epoch [2761/3000], Loss: 444.3354\n",
      "Validation Loss: 677.5250\n",
      "Epoch [2781/3000], Loss: 463.7236\n",
      "Validation Loss: 677.2448\n",
      "Epoch [2801/3000], Loss: 418.6775\n",
      "Validation Loss: 599.4950\n",
      "Epoch [2821/3000], Loss: 404.2197\n",
      "Validation Loss: 600.1058\n",
      "Epoch [2841/3000], Loss: 387.0267\n",
      "Validation Loss: 598.4005\n",
      "Epoch [2861/3000], Loss: 374.1296\n",
      "Validation Loss: 597.1681\n",
      "Epoch [2881/3000], Loss: 359.5001\n",
      "Validation Loss: 595.0083\n",
      "Epoch [2901/3000], Loss: 348.4937\n",
      "Validation Loss: 591.8194\n",
      "Epoch [2921/3000], Loss: 334.5762\n",
      "Validation Loss: 591.1829\n",
      "Epoch [2941/3000], Loss: 320.9923\n",
      "Validation Loss: 584.6286\n",
      "Epoch [2961/3000], Loss: 307.8487\n",
      "Validation Loss: 579.0115\n",
      "Epoch [2981/3000], Loss: 295.7406\n",
      "Validation Loss: 572.5949\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day040_plane0_Fall.mat\n",
      "(3075, 177)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8290.0336\n",
      "Validation Loss: 7572.4678\n",
      "Epoch [21/3000], Loss: 7650.2301\n",
      "Validation Loss: 6924.2347\n",
      "Epoch [41/3000], Loss: 7147.6618\n",
      "Validation Loss: 6507.2312\n",
      "Epoch [61/3000], Loss: 7077.3522\n",
      "Validation Loss: 6371.1702\n",
      "Epoch [81/3000], Loss: 6926.6023\n",
      "Validation Loss: 6275.6953\n",
      "Epoch [101/3000], Loss: 6807.9162\n",
      "Validation Loss: 6193.6802\n",
      "Epoch [121/3000], Loss: 6663.6967\n",
      "Validation Loss: 6119.9147\n",
      "Epoch [141/3000], Loss: 6668.2999\n",
      "Validation Loss: 6050.2465\n",
      "Epoch [161/3000], Loss: 6597.4631\n",
      "Validation Loss: 5981.9225\n",
      "Epoch [181/3000], Loss: 6576.2825\n",
      "Validation Loss: 5916.2542\n",
      "Epoch [201/3000], Loss: 6501.6584\n",
      "Validation Loss: 5852.7855\n",
      "Epoch [221/3000], Loss: 6336.3067\n",
      "Validation Loss: 5790.8204\n",
      "Epoch [241/3000], Loss: 6347.9208\n",
      "Validation Loss: 5730.0723\n",
      "Epoch [261/3000], Loss: 6279.2231\n",
      "Validation Loss: 5670.4684\n",
      "Epoch [281/3000], Loss: 6204.7248\n",
      "Validation Loss: 5611.7561\n",
      "Epoch [301/3000], Loss: 6139.9751\n",
      "Validation Loss: 5553.9375\n",
      "Epoch [321/3000], Loss: 6056.8624\n",
      "Validation Loss: 5497.0991\n",
      "Epoch [341/3000], Loss: 5990.7178\n",
      "Validation Loss: 5440.9329\n",
      "Epoch [361/3000], Loss: 5911.7042\n",
      "Validation Loss: 5385.7643\n",
      "Epoch [381/3000], Loss: 5876.8784\n",
      "Validation Loss: 5331.1814\n",
      "Epoch [401/3000], Loss: 5789.1411\n",
      "Validation Loss: 5277.3238\n",
      "Epoch [421/3000], Loss: 5789.4931\n",
      "Validation Loss: 5224.1694\n",
      "Epoch [441/3000], Loss: 5707.4589\n",
      "Validation Loss: 5171.6934\n",
      "Epoch [461/3000], Loss: 5666.3596\n",
      "Validation Loss: 5119.8397\n",
      "Epoch [481/3000], Loss: 5569.8726\n",
      "Validation Loss: 5068.6752\n",
      "Epoch [501/3000], Loss: 5597.5868\n",
      "Validation Loss: 5018.0978\n",
      "Epoch [521/3000], Loss: 5566.1617\n",
      "Validation Loss: 4968.0596\n",
      "Epoch [541/3000], Loss: 5472.7528\n",
      "Validation Loss: 4918.8523\n",
      "Epoch [561/3000], Loss: 5412.5613\n",
      "Validation Loss: 4870.2656\n",
      "Epoch [581/3000], Loss: 5295.4149\n",
      "Validation Loss: 4822.2506\n",
      "Epoch [601/3000], Loss: 5251.4563\n",
      "Validation Loss: 4774.8300\n",
      "Epoch [621/3000], Loss: 5247.3944\n",
      "Validation Loss: 4728.0638\n",
      "Epoch [641/3000], Loss: 5149.0712\n",
      "Validation Loss: 4681.8732\n",
      "Epoch [661/3000], Loss: 5146.9164\n",
      "Validation Loss: 4636.2924\n",
      "Epoch [681/3000], Loss: 5100.4069\n",
      "Validation Loss: 4591.3491\n",
      "Epoch [701/3000], Loss: 5009.8539\n",
      "Validation Loss: 4546.9965\n",
      "Epoch [721/3000], Loss: 4946.2956\n",
      "Validation Loss: 4503.2120\n",
      "Epoch [741/3000], Loss: 4894.8721\n",
      "Validation Loss: 4459.9091\n",
      "Epoch [761/3000], Loss: 4936.7016\n",
      "Validation Loss: 4417.3141\n",
      "Epoch [781/3000], Loss: 4905.8474\n",
      "Validation Loss: 4375.2810\n",
      "Epoch [801/3000], Loss: 4836.9192\n",
      "Validation Loss: 4333.8500\n",
      "Epoch [821/3000], Loss: 4783.2284\n",
      "Validation Loss: 4292.9861\n",
      "Epoch [841/3000], Loss: 4702.6239\n",
      "Validation Loss: 4252.8508\n",
      "Epoch [861/3000], Loss: 4721.9172\n",
      "Validation Loss: 4213.3083\n",
      "Epoch [881/3000], Loss: 4631.3932\n",
      "Validation Loss: 4174.2765\n",
      "Epoch [901/3000], Loss: 4665.0551\n",
      "Validation Loss: 4135.8764\n",
      "Epoch [921/3000], Loss: 4574.5439\n",
      "Validation Loss: 4098.0223\n",
      "Epoch [941/3000], Loss: 4559.2038\n",
      "Validation Loss: 4060.9214\n",
      "Epoch [961/3000], Loss: 4489.3868\n",
      "Validation Loss: 4024.2664\n",
      "Epoch [981/3000], Loss: 4415.2978\n",
      "Validation Loss: 3988.2662\n",
      "Epoch [1001/3000], Loss: 4376.0427\n",
      "Validation Loss: 3952.8220\n",
      "Epoch [1021/3000], Loss: 4375.3702\n",
      "Validation Loss: 3918.0624\n",
      "Epoch [1041/3000], Loss: 4303.2334\n",
      "Validation Loss: 3883.7811\n",
      "Epoch [1061/3000], Loss: 4321.4539\n",
      "Validation Loss: 3850.0200\n",
      "Epoch [1081/3000], Loss: 4282.0444\n",
      "Validation Loss: 3816.8204\n",
      "Epoch [1101/3000], Loss: 4208.4187\n",
      "Validation Loss: 3784.3539\n",
      "Epoch [1121/3000], Loss: 4131.7243\n",
      "Validation Loss: 3752.4218\n",
      "Epoch [1141/3000], Loss: 4123.1967\n",
      "Validation Loss: 3721.1309\n",
      "Epoch [1161/3000], Loss: 4131.3825\n",
      "Validation Loss: 3690.3379\n",
      "Epoch [1181/3000], Loss: 4079.9411\n",
      "Validation Loss: 3660.1072\n",
      "Epoch [1201/3000], Loss: 4045.5122\n",
      "Validation Loss: 3630.5302\n",
      "Epoch [1221/3000], Loss: 3985.2193\n",
      "Validation Loss: 3601.4863\n",
      "Epoch [1241/3000], Loss: 3961.4684\n",
      "Validation Loss: 3572.9252\n",
      "Epoch [1261/3000], Loss: 3905.7369\n",
      "Validation Loss: 3545.0640\n",
      "Epoch [1281/3000], Loss: 3893.4466\n",
      "Validation Loss: 3517.7813\n",
      "Epoch [1301/3000], Loss: 3836.2475\n",
      "Validation Loss: 3491.0408\n",
      "Epoch [1321/3000], Loss: 3821.0933\n",
      "Validation Loss: 3464.9052\n",
      "Epoch [1341/3000], Loss: 3837.0870\n",
      "Validation Loss: 3439.2880\n",
      "Epoch [1361/3000], Loss: 3784.5254\n",
      "Validation Loss: 3414.1985\n",
      "Epoch [1381/3000], Loss: 3715.7476\n",
      "Validation Loss: 3389.8722\n",
      "Epoch [1401/3000], Loss: 3707.1475\n",
      "Validation Loss: 3366.0368\n",
      "Epoch [1421/3000], Loss: 3731.9881\n",
      "Validation Loss: 3342.7448\n",
      "Epoch [1441/3000], Loss: 3663.0959\n",
      "Validation Loss: 3320.0427\n",
      "Epoch [1461/3000], Loss: 3610.0409\n",
      "Validation Loss: 3297.8978\n",
      "Epoch [1481/3000], Loss: 3615.1705\n",
      "Validation Loss: 3276.3729\n",
      "Epoch [1501/3000], Loss: 3598.3289\n",
      "Validation Loss: 3255.1976\n",
      "Epoch [1521/3000], Loss: 3581.3361\n",
      "Validation Loss: 3234.6557\n",
      "Epoch [1541/3000], Loss: 3522.7837\n",
      "Validation Loss: 3214.7439\n",
      "Epoch [1561/3000], Loss: 3519.1146\n",
      "Validation Loss: 3195.4434\n",
      "Epoch [1581/3000], Loss: 3510.9125\n",
      "Validation Loss: 3176.6903\n",
      "Epoch [1601/3000], Loss: 3457.3292\n",
      "Validation Loss: 3158.4153\n",
      "Epoch [1621/3000], Loss: 3468.5925\n",
      "Validation Loss: 3140.6905\n",
      "Epoch [1641/3000], Loss: 3446.5429\n",
      "Validation Loss: 3123.5297\n",
      "Epoch [1661/3000], Loss: 3385.8305\n",
      "Validation Loss: 3106.9338\n",
      "Epoch [1681/3000], Loss: 3372.0103\n",
      "Validation Loss: 3090.8867\n",
      "Epoch [1701/3000], Loss: 3381.2031\n",
      "Validation Loss: 3075.3629\n",
      "Epoch [1721/3000], Loss: 3362.3266\n",
      "Validation Loss: 3060.5026\n",
      "Epoch [1741/3000], Loss: 3325.6050\n",
      "Validation Loss: 3046.0291\n",
      "Epoch [1761/3000], Loss: 3311.9995\n",
      "Validation Loss: 3032.1062\n",
      "Epoch [1781/3000], Loss: 3287.9114\n",
      "Validation Loss: 3018.7818\n",
      "Epoch [1801/3000], Loss: 3300.7131\n",
      "Validation Loss: 3005.9434\n",
      "Epoch [1821/3000], Loss: 3242.2114\n",
      "Validation Loss: 2993.5812\n",
      "Epoch [1841/3000], Loss: 3232.0113\n",
      "Validation Loss: 2981.7936\n",
      "Epoch [1861/3000], Loss: 3204.8083\n",
      "Validation Loss: 2970.4977\n",
      "Epoch [1881/3000], Loss: 3239.9284\n",
      "Validation Loss: 2959.7227\n",
      "Epoch [1901/3000], Loss: 3161.6370\n",
      "Validation Loss: 2949.4246\n",
      "Epoch [1921/3000], Loss: 3159.0396\n",
      "Validation Loss: 2939.6599\n",
      "Epoch [1941/3000], Loss: 3190.5209\n",
      "Validation Loss: 2930.3901\n",
      "Epoch [1961/3000], Loss: 3134.5348\n",
      "Validation Loss: 2921.5549\n",
      "Epoch [1981/3000], Loss: 3156.9969\n",
      "Validation Loss: 2913.2559\n",
      "Epoch [2001/3000], Loss: 3140.6607\n",
      "Validation Loss: 2905.5023\n",
      "Epoch [2021/3000], Loss: 3126.4482\n",
      "Validation Loss: 2898.1949\n",
      "Epoch [2041/3000], Loss: 3096.4397\n",
      "Validation Loss: 2891.4244\n",
      "Epoch [2061/3000], Loss: 3106.4513\n",
      "Validation Loss: 2885.0691\n",
      "Epoch [2081/3000], Loss: 2293.2491\n",
      "Validation Loss: 2020.4090\n",
      "Epoch [2101/3000], Loss: 2125.5518\n",
      "Validation Loss: 1921.4275\n",
      "Epoch [2121/3000], Loss: 2060.3414\n",
      "Validation Loss: 1885.1799\n",
      "Epoch [2141/3000], Loss: 2017.9391\n",
      "Validation Loss: 1847.3232\n",
      "Epoch [2161/3000], Loss: 2003.4436\n",
      "Validation Loss: 1823.1195\n",
      "Epoch [2181/3000], Loss: 1950.4520\n",
      "Validation Loss: 1795.8219\n",
      "Epoch [2201/3000], Loss: 1899.2265\n",
      "Validation Loss: 1769.6396\n",
      "Epoch [2221/3000], Loss: 1868.7035\n",
      "Validation Loss: 1741.0359\n",
      "Epoch [2241/3000], Loss: 1827.7323\n",
      "Validation Loss: 1718.1665\n",
      "Epoch [2261/3000], Loss: 1831.7125\n",
      "Validation Loss: 1695.9974\n",
      "Epoch [2281/3000], Loss: 1776.1430\n",
      "Validation Loss: 1668.2704\n",
      "Epoch [2301/3000], Loss: 1745.7655\n",
      "Validation Loss: 1647.6023\n",
      "Epoch [2321/3000], Loss: 1721.2445\n",
      "Validation Loss: 1626.4309\n",
      "Epoch [2341/3000], Loss: 1715.1615\n",
      "Validation Loss: 1603.1209\n",
      "Epoch [2361/3000], Loss: 1668.8838\n",
      "Validation Loss: 1582.7925\n",
      "Epoch [2381/3000], Loss: 1644.5976\n",
      "Validation Loss: 1562.3087\n",
      "Epoch [2401/3000], Loss: 1658.8928\n",
      "Validation Loss: 1540.8101\n",
      "Epoch [2421/3000], Loss: 1597.3470\n",
      "Validation Loss: 1521.8864\n",
      "Epoch [2441/3000], Loss: 1556.3187\n",
      "Validation Loss: 1499.1989\n",
      "Epoch [2461/3000], Loss: 1531.6809\n",
      "Validation Loss: 1477.7908\n",
      "Epoch [2481/3000], Loss: 1521.4687\n",
      "Validation Loss: 1460.0431\n",
      "Epoch [2501/3000], Loss: 1504.1951\n",
      "Validation Loss: 1441.8708\n",
      "Epoch [2521/3000], Loss: 1479.7616\n",
      "Validation Loss: 1424.5885\n",
      "Epoch [2541/3000], Loss: 1440.1686\n",
      "Validation Loss: 1409.5340\n",
      "Epoch [2561/3000], Loss: 1434.9824\n",
      "Validation Loss: 1396.0900\n",
      "Epoch [2581/3000], Loss: 1395.6981\n",
      "Validation Loss: 1384.6345\n",
      "Epoch [2601/3000], Loss: 1378.0622\n",
      "Validation Loss: 1371.9538\n",
      "Epoch [2621/3000], Loss: 1384.9815\n",
      "Validation Loss: 1365.3920\n",
      "Epoch [2641/3000], Loss: 1356.9333\n",
      "Validation Loss: 1352.3661\n",
      "Epoch [2661/3000], Loss: 1317.7679\n",
      "Validation Loss: 1338.9456\n",
      "Epoch [2681/3000], Loss: 1310.2943\n",
      "Validation Loss: 1323.5795\n",
      "Epoch [2701/3000], Loss: 1274.0236\n",
      "Validation Loss: 1308.2748\n",
      "Epoch [2721/3000], Loss: 1257.3440\n",
      "Validation Loss: 1292.5916\n",
      "Epoch [2741/3000], Loss: 1223.0086\n",
      "Validation Loss: 1279.4444\n",
      "Epoch [2761/3000], Loss: 1233.9681\n",
      "Validation Loss: 1265.2593\n",
      "Epoch [2781/3000], Loss: 1219.9088\n",
      "Validation Loss: 1250.5114\n",
      "Epoch [2801/3000], Loss: 1177.5439\n",
      "Validation Loss: 1237.8308\n",
      "Epoch [2821/3000], Loss: 1172.0540\n",
      "Validation Loss: 1223.0988\n",
      "Epoch [2841/3000], Loss: 1143.5584\n",
      "Validation Loss: 1209.8552\n",
      "Epoch [2861/3000], Loss: 1134.4886\n",
      "Validation Loss: 1195.9119\n",
      "Epoch [2881/3000], Loss: 1110.8779\n",
      "Validation Loss: 1183.9674\n",
      "Epoch [2901/3000], Loss: 1119.0894\n",
      "Validation Loss: 1172.0139\n",
      "Epoch [2921/3000], Loss: 1085.9843\n",
      "Validation Loss: 1158.5619\n",
      "Epoch [2941/3000], Loss: 1053.6046\n",
      "Validation Loss: 1149.3224\n",
      "Epoch [2961/3000], Loss: 1042.0715\n",
      "Validation Loss: 1136.5522\n",
      "Epoch [2981/3000], Loss: 1008.7211\n",
      "Validation Loss: 1128.0874\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day041_plane0_Fall.mat\n",
      "(2537, 111)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8114.4352\n",
      "Validation Loss: 8188.5885\n",
      "Epoch [21/3000], Loss: 7948.6979\n",
      "Validation Loss: 7964.6794\n",
      "Epoch [41/3000], Loss: 7133.0269\n",
      "Validation Loss: 7137.0091\n",
      "Epoch [61/3000], Loss: 6916.0289\n",
      "Validation Loss: 6957.2528\n",
      "Epoch [81/3000], Loss: 6806.6436\n",
      "Validation Loss: 6860.2378\n",
      "Epoch [101/3000], Loss: 6875.2755\n",
      "Validation Loss: 6782.9894\n",
      "Epoch [121/3000], Loss: 6649.2151\n",
      "Validation Loss: 6714.5099\n",
      "Epoch [141/3000], Loss: 6678.9454\n",
      "Validation Loss: 6650.7078\n",
      "Epoch [161/3000], Loss: 6582.4175\n",
      "Validation Loss: 6586.8460\n",
      "Epoch [181/3000], Loss: 6561.7608\n",
      "Validation Loss: 6526.4574\n",
      "Epoch [201/3000], Loss: 6408.3337\n",
      "Validation Loss: 6469.1217\n",
      "Epoch [221/3000], Loss: 6382.8149\n",
      "Validation Loss: 6413.3825\n",
      "Epoch [241/3000], Loss: 6310.2074\n",
      "Validation Loss: 6358.8517\n",
      "Epoch [261/3000], Loss: 6224.3945\n",
      "Validation Loss: 6305.1629\n",
      "Epoch [281/3000], Loss: 6185.3534\n",
      "Validation Loss: 6252.2827\n",
      "Epoch [301/3000], Loss: 6246.8954\n",
      "Validation Loss: 6199.5864\n",
      "Epoch [321/3000], Loss: 6277.5988\n",
      "Validation Loss: 6147.3926\n",
      "Epoch [341/3000], Loss: 6102.6571\n",
      "Validation Loss: 6095.7762\n",
      "Epoch [361/3000], Loss: 6098.5331\n",
      "Validation Loss: 6044.8521\n",
      "Epoch [381/3000], Loss: 6012.1140\n",
      "Validation Loss: 5994.8089\n",
      "Epoch [401/3000], Loss: 6006.4340\n",
      "Validation Loss: 5945.3553\n",
      "Epoch [421/3000], Loss: 5935.6104\n",
      "Validation Loss: 5896.5378\n",
      "Epoch [441/3000], Loss: 5836.3946\n",
      "Validation Loss: 5848.1317\n",
      "Epoch [461/3000], Loss: 5755.3746\n",
      "Validation Loss: 5800.2617\n",
      "Epoch [481/3000], Loss: 5789.1660\n",
      "Validation Loss: 5752.2816\n",
      "Epoch [501/3000], Loss: 5800.0541\n",
      "Validation Loss: 5704.9076\n",
      "Epoch [521/3000], Loss: 5764.3118\n",
      "Validation Loss: 5658.1951\n",
      "Epoch [541/3000], Loss: 5605.0584\n",
      "Validation Loss: 5612.0928\n",
      "Epoch [561/3000], Loss: 5633.8549\n",
      "Validation Loss: 5566.4009\n",
      "Epoch [581/3000], Loss: 5543.7919\n",
      "Validation Loss: 5521.1912\n",
      "Epoch [601/3000], Loss: 5460.9163\n",
      "Validation Loss: 5476.5177\n",
      "Epoch [621/3000], Loss: 5450.5257\n",
      "Validation Loss: 5432.2463\n",
      "Epoch [641/3000], Loss: 5524.1227\n",
      "Validation Loss: 5388.3730\n",
      "Epoch [661/3000], Loss: 5428.4622\n",
      "Validation Loss: 5344.9077\n",
      "Epoch [681/3000], Loss: 5364.6580\n",
      "Validation Loss: 5301.9661\n",
      "Epoch [701/3000], Loss: 5335.7046\n",
      "Validation Loss: 5259.3953\n",
      "Epoch [721/3000], Loss: 5347.8508\n",
      "Validation Loss: 5217.2463\n",
      "Epoch [741/3000], Loss: 5223.1318\n",
      "Validation Loss: 5175.4536\n",
      "Epoch [761/3000], Loss: 5188.7565\n",
      "Validation Loss: 5134.0744\n",
      "Epoch [781/3000], Loss: 5108.5084\n",
      "Validation Loss: 5093.0972\n",
      "Epoch [801/3000], Loss: 5103.6368\n",
      "Validation Loss: 5052.5941\n",
      "Epoch [821/3000], Loss: 5020.1481\n",
      "Validation Loss: 5012.4434\n",
      "Epoch [841/3000], Loss: 5049.4250\n",
      "Validation Loss: 4972.7635\n",
      "Epoch [861/3000], Loss: 4992.8602\n",
      "Validation Loss: 4933.4144\n",
      "Epoch [881/3000], Loss: 5046.6187\n",
      "Validation Loss: 4894.5723\n",
      "Epoch [901/3000], Loss: 4931.2221\n",
      "Validation Loss: 4856.0539\n",
      "Epoch [921/3000], Loss: 4869.1817\n",
      "Validation Loss: 4817.8997\n",
      "Epoch [941/3000], Loss: 4907.9406\n",
      "Validation Loss: 4780.2137\n",
      "Epoch [961/3000], Loss: 4855.2056\n",
      "Validation Loss: 4742.9521\n",
      "Epoch [981/3000], Loss: 4747.9739\n",
      "Validation Loss: 4705.9383\n",
      "Epoch [1001/3000], Loss: 4788.1412\n",
      "Validation Loss: 4669.4608\n",
      "Epoch [1021/3000], Loss: 4708.1755\n",
      "Validation Loss: 4633.2705\n",
      "Epoch [1041/3000], Loss: 4732.3234\n",
      "Validation Loss: 4597.5635\n",
      "Epoch [1061/3000], Loss: 4672.7983\n",
      "Validation Loss: 4562.1746\n",
      "Epoch [1081/3000], Loss: 4576.1783\n",
      "Validation Loss: 4527.1483\n",
      "Epoch [1101/3000], Loss: 4563.5192\n",
      "Validation Loss: 4492.6699\n",
      "Epoch [1121/3000], Loss: 4540.1573\n",
      "Validation Loss: 4458.4917\n",
      "Epoch [1141/3000], Loss: 4523.7933\n",
      "Validation Loss: 4424.7498\n",
      "Epoch [1161/3000], Loss: 4493.2961\n",
      "Validation Loss: 4391.3953\n",
      "Epoch [1181/3000], Loss: 4396.6448\n",
      "Validation Loss: 4358.3977\n",
      "Epoch [1201/3000], Loss: 4354.5260\n",
      "Validation Loss: 4325.8521\n",
      "Epoch [1221/3000], Loss: 4410.3900\n",
      "Validation Loss: 4293.6000\n",
      "Epoch [1241/3000], Loss: 4345.5434\n",
      "Validation Loss: 4261.8228\n",
      "Epoch [1261/3000], Loss: 4246.2428\n",
      "Validation Loss: 4230.4709\n",
      "Epoch [1281/3000], Loss: 4288.7402\n",
      "Validation Loss: 4199.5790\n",
      "Epoch [1301/3000], Loss: 4368.5126\n",
      "Validation Loss: 4168.9933\n",
      "Epoch [1321/3000], Loss: 4287.3197\n",
      "Validation Loss: 4138.7466\n",
      "Epoch [1341/3000], Loss: 4203.1134\n",
      "Validation Loss: 4108.9805\n",
      "Epoch [1361/3000], Loss: 4168.5223\n",
      "Validation Loss: 4079.5462\n",
      "Epoch [1381/3000], Loss: 4150.2303\n",
      "Validation Loss: 4050.4702\n",
      "Epoch [1401/3000], Loss: 4101.9449\n",
      "Validation Loss: 4021.6211\n",
      "Epoch [1421/3000], Loss: 4124.0935\n",
      "Validation Loss: 3993.2861\n",
      "Epoch [1441/3000], Loss: 4086.3679\n",
      "Validation Loss: 3965.3693\n",
      "Epoch [1461/3000], Loss: 4028.0077\n",
      "Validation Loss: 3937.8584\n",
      "Epoch [1481/3000], Loss: 4026.8342\n",
      "Validation Loss: 3910.8548\n",
      "Epoch [1501/3000], Loss: 3989.3776\n",
      "Validation Loss: 3884.0491\n",
      "Epoch [1521/3000], Loss: 4016.2256\n",
      "Validation Loss: 3857.7510\n",
      "Epoch [1541/3000], Loss: 3931.2461\n",
      "Validation Loss: 3831.8684\n",
      "Epoch [1561/3000], Loss: 3915.7450\n",
      "Validation Loss: 3806.4129\n",
      "Epoch [1581/3000], Loss: 3970.0978\n",
      "Validation Loss: 3781.2795\n",
      "Epoch [1601/3000], Loss: 3866.3958\n",
      "Validation Loss: 3756.4718\n",
      "Epoch [1621/3000], Loss: 3852.7888\n",
      "Validation Loss: 3732.1153\n",
      "Epoch [1641/3000], Loss: 3847.1023\n",
      "Validation Loss: 3708.1252\n",
      "Epoch [1661/3000], Loss: 3811.0631\n",
      "Validation Loss: 3684.4762\n",
      "Epoch [1681/3000], Loss: 3835.6519\n",
      "Validation Loss: 3661.2025\n",
      "Epoch [1701/3000], Loss: 3797.4614\n",
      "Validation Loss: 3637.5297\n",
      "Epoch [1721/3000], Loss: 3757.1802\n",
      "Validation Loss: 3614.8065\n",
      "Epoch [1741/3000], Loss: 3685.9849\n",
      "Validation Loss: 3592.5988\n",
      "Epoch [1761/3000], Loss: 3734.1902\n",
      "Validation Loss: 3570.8630\n",
      "Epoch [1781/3000], Loss: 3704.4351\n",
      "Validation Loss: 3549.4945\n",
      "Epoch [1801/3000], Loss: 3670.4052\n",
      "Validation Loss: 3528.3947\n",
      "Epoch [1821/3000], Loss: 3628.6972\n",
      "Validation Loss: 3507.7402\n",
      "Epoch [1841/3000], Loss: 3631.5364\n",
      "Validation Loss: 3487.5487\n",
      "Epoch [1861/3000], Loss: 3620.5406\n",
      "Validation Loss: 3467.7126\n",
      "Epoch [1881/3000], Loss: 3591.6065\n",
      "Validation Loss: 3448.2747\n",
      "Epoch [1901/3000], Loss: 3542.6938\n",
      "Validation Loss: 3429.2817\n",
      "Epoch [1921/3000], Loss: 3553.6436\n",
      "Validation Loss: 3410.5614\n",
      "Epoch [1941/3000], Loss: 3542.9925\n",
      "Validation Loss: 3392.2077\n",
      "Epoch [1961/3000], Loss: 3507.0536\n",
      "Validation Loss: 3374.2121\n",
      "Epoch [1981/3000], Loss: 3460.0617\n",
      "Validation Loss: 3356.6448\n",
      "Epoch [2001/3000], Loss: 3506.0969\n",
      "Validation Loss: 3339.4040\n",
      "Epoch [2021/3000], Loss: 3491.3581\n",
      "Validation Loss: 3322.4412\n",
      "Epoch [2041/3000], Loss: 3439.9071\n",
      "Validation Loss: 3306.0122\n",
      "Epoch [2061/3000], Loss: 3466.9879\n",
      "Validation Loss: 3289.8989\n",
      "Epoch [2081/3000], Loss: 3451.0275\n",
      "Validation Loss: 3274.2035\n",
      "Epoch [2101/3000], Loss: 3421.2261\n",
      "Validation Loss: 3258.8742\n",
      "Epoch [2121/3000], Loss: 3397.6628\n",
      "Validation Loss: 3243.8366\n",
      "Epoch [2141/3000], Loss: 3406.2154\n",
      "Validation Loss: 3229.2878\n",
      "Epoch [2161/3000], Loss: 3435.0148\n",
      "Validation Loss: 3215.0067\n",
      "Epoch [2181/3000], Loss: 3399.3163\n",
      "Validation Loss: 3201.1153\n",
      "Epoch [2201/3000], Loss: 3397.2793\n",
      "Validation Loss: 3187.6324\n",
      "Epoch [2221/3000], Loss: 3387.6006\n",
      "Validation Loss: 3174.4567\n",
      "Epoch [2241/3000], Loss: 3316.8304\n",
      "Validation Loss: 3161.5734\n",
      "Epoch [2261/3000], Loss: 3329.4912\n",
      "Validation Loss: 3149.0577\n",
      "Epoch [2281/3000], Loss: 3314.6682\n",
      "Validation Loss: 3136.9930\n",
      "Epoch [2301/3000], Loss: 3316.1684\n",
      "Validation Loss: 3125.2345\n",
      "Epoch [2321/3000], Loss: 3277.9037\n",
      "Validation Loss: 3113.7715\n",
      "Epoch [2341/3000], Loss: 3301.6937\n",
      "Validation Loss: 3102.7812\n",
      "Epoch [2361/3000], Loss: 3255.9549\n",
      "Validation Loss: 3092.0147\n",
      "Epoch [2381/3000], Loss: 3278.7382\n",
      "Validation Loss: 3081.7521\n",
      "Epoch [2401/3000], Loss: 3299.9772\n",
      "Validation Loss: 3071.7533\n",
      "Epoch [2421/3000], Loss: 3270.4744\n",
      "Validation Loss: 3062.1063\n",
      "Epoch [2441/3000], Loss: 3269.8131\n",
      "Validation Loss: 3052.7707\n",
      "Epoch [2461/3000], Loss: 3272.8323\n",
      "Validation Loss: 3043.2699\n",
      "Epoch [2481/3000], Loss: 3212.9788\n",
      "Validation Loss: 3034.4333\n",
      "Epoch [2501/3000], Loss: 3243.4594\n",
      "Validation Loss: 3025.3441\n",
      "Epoch [2521/3000], Loss: 3237.9453\n",
      "Validation Loss: 3017.1289\n",
      "Epoch [2541/3000], Loss: 3212.1619\n",
      "Validation Loss: 3009.3883\n",
      "Epoch [2561/3000], Loss: 3154.6111\n",
      "Validation Loss: 3001.9062\n",
      "Epoch [2581/3000], Loss: 3170.2528\n",
      "Validation Loss: 2994.7690\n",
      "Epoch [2601/3000], Loss: 3178.1791\n",
      "Validation Loss: 2987.9830\n",
      "Epoch [2621/3000], Loss: 3173.1999\n",
      "Validation Loss: 2981.6458\n",
      "Epoch [2641/3000], Loss: 3181.7681\n",
      "Validation Loss: 2975.5412\n",
      "Epoch [2661/3000], Loss: 3168.5656\n",
      "Validation Loss: 2969.5881\n",
      "Epoch [2681/3000], Loss: 3182.1985\n",
      "Validation Loss: 2964.0180\n",
      "Epoch [2701/3000], Loss: 3144.6015\n",
      "Validation Loss: 2958.8235\n",
      "Epoch [2721/3000], Loss: 3184.5812\n",
      "Validation Loss: 2953.9105\n",
      "Epoch [2741/3000], Loss: 3175.1291\n",
      "Validation Loss: 2949.2202\n",
      "Epoch [2761/3000], Loss: 3170.7470\n",
      "Validation Loss: 2944.9142\n",
      "Epoch [2781/3000], Loss: 3129.4502\n",
      "Validation Loss: 2940.9145\n",
      "Epoch [2801/3000], Loss: 3125.9016\n",
      "Validation Loss: 2937.0522\n",
      "Epoch [2821/3000], Loss: 3169.7892\n",
      "Validation Loss: 2933.4202\n",
      "Epoch [2841/3000], Loss: 3156.6041\n",
      "Validation Loss: 2929.9969\n",
      "Epoch [2861/3000], Loss: 3140.8235\n",
      "Validation Loss: 2926.8762\n",
      "Epoch [2881/3000], Loss: 3135.8249\n",
      "Validation Loss: 2923.9795\n",
      "Epoch [2901/3000], Loss: 3115.1982\n",
      "Validation Loss: 2921.3580\n",
      "Epoch [2921/3000], Loss: 3175.6412\n",
      "Validation Loss: 2919.0245\n",
      "Epoch [2941/3000], Loss: 3123.8120\n",
      "Validation Loss: 2916.7839\n",
      "Epoch [2961/3000], Loss: 3146.3074\n",
      "Validation Loss: 2914.7660\n",
      "Epoch [2981/3000], Loss: 3139.3015\n",
      "Validation Loss: 2912.8514\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day042_plane0_Fall.mat\n",
      "(3477, 59)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9782.6416\n",
      "Validation Loss: 8478.4241\n",
      "Epoch [21/3000], Loss: 8959.0050\n",
      "Validation Loss: 7720.0172\n",
      "Epoch [41/3000], Loss: 8445.2040\n",
      "Validation Loss: 7244.3330\n",
      "Epoch [61/3000], Loss: 8301.0683\n",
      "Validation Loss: 7092.4563\n",
      "Epoch [81/3000], Loss: 8166.6959\n",
      "Validation Loss: 6982.8929\n",
      "Epoch [101/3000], Loss: 8003.1739\n",
      "Validation Loss: 6886.5593\n",
      "Epoch [121/3000], Loss: 7950.2262\n",
      "Validation Loss: 6793.7101\n",
      "Epoch [141/3000], Loss: 7856.9148\n",
      "Validation Loss: 6702.1786\n",
      "Epoch [161/3000], Loss: 7761.1182\n",
      "Validation Loss: 6618.3092\n",
      "Epoch [181/3000], Loss: 7708.8862\n",
      "Validation Loss: 6537.2671\n",
      "Epoch [201/3000], Loss: 7627.1183\n",
      "Validation Loss: 6458.1273\n",
      "Epoch [221/3000], Loss: 7498.1396\n",
      "Validation Loss: 6380.7139\n",
      "Epoch [241/3000], Loss: 7445.8912\n",
      "Validation Loss: 6301.6854\n",
      "Epoch [261/3000], Loss: 7303.2686\n",
      "Validation Loss: 6225.7360\n",
      "Epoch [281/3000], Loss: 7286.5825\n",
      "Validation Loss: 6151.6332\n",
      "Epoch [301/3000], Loss: 7202.6739\n",
      "Validation Loss: 6078.7887\n",
      "Epoch [321/3000], Loss: 7116.0537\n",
      "Validation Loss: 6007.0063\n",
      "Epoch [341/3000], Loss: 7059.5457\n",
      "Validation Loss: 5936.2837\n",
      "Epoch [361/3000], Loss: 6992.6511\n",
      "Validation Loss: 5866.4397\n",
      "Epoch [381/3000], Loss: 6925.6522\n",
      "Validation Loss: 5797.5249\n",
      "Epoch [401/3000], Loss: 6801.9793\n",
      "Validation Loss: 5729.5969\n",
      "Epoch [421/3000], Loss: 6770.9460\n",
      "Validation Loss: 5662.5107\n",
      "Epoch [441/3000], Loss: 6673.2285\n",
      "Validation Loss: 5596.1870\n",
      "Epoch [461/3000], Loss: 6579.7102\n",
      "Validation Loss: 5530.6805\n",
      "Epoch [481/3000], Loss: 6538.2225\n",
      "Validation Loss: 5464.7870\n",
      "Epoch [501/3000], Loss: 6459.4268\n",
      "Validation Loss: 5399.3756\n",
      "Epoch [521/3000], Loss: 6386.5641\n",
      "Validation Loss: 5335.6187\n",
      "Epoch [541/3000], Loss: 6346.1707\n",
      "Validation Loss: 5272.9044\n",
      "Epoch [561/3000], Loss: 6270.3508\n",
      "Validation Loss: 5211.0029\n",
      "Epoch [581/3000], Loss: 6244.4255\n",
      "Validation Loss: 5150.0698\n",
      "Epoch [601/3000], Loss: 6132.8890\n",
      "Validation Loss: 5090.0085\n",
      "Epoch [621/3000], Loss: 6057.8264\n",
      "Validation Loss: 5030.8272\n",
      "Epoch [641/3000], Loss: 6025.2129\n",
      "Validation Loss: 4972.3485\n",
      "Epoch [661/3000], Loss: 5934.0928\n",
      "Validation Loss: 4914.7996\n",
      "Epoch [681/3000], Loss: 5854.8548\n",
      "Validation Loss: 4858.0455\n",
      "Epoch [701/3000], Loss: 5807.0029\n",
      "Validation Loss: 4802.2453\n",
      "Epoch [721/3000], Loss: 5752.2572\n",
      "Validation Loss: 4747.1971\n",
      "Epoch [741/3000], Loss: 5689.0606\n",
      "Validation Loss: 4692.9728\n",
      "Epoch [761/3000], Loss: 5592.3085\n",
      "Validation Loss: 4639.6078\n",
      "Epoch [781/3000], Loss: 5583.4684\n",
      "Validation Loss: 4586.9053\n",
      "Epoch [801/3000], Loss: 5517.1296\n",
      "Validation Loss: 4535.0674\n",
      "Epoch [821/3000], Loss: 5438.1143\n",
      "Validation Loss: 4484.0309\n",
      "Epoch [841/3000], Loss: 5392.7853\n",
      "Validation Loss: 4433.7038\n",
      "Epoch [861/3000], Loss: 5331.9450\n",
      "Validation Loss: 4384.2753\n",
      "Epoch [881/3000], Loss: 5301.8334\n",
      "Validation Loss: 4335.7103\n",
      "Epoch [901/3000], Loss: 5244.0777\n",
      "Validation Loss: 4287.8945\n",
      "Epoch [921/3000], Loss: 5190.2665\n",
      "Validation Loss: 4240.9517\n",
      "Epoch [941/3000], Loss: 5121.9961\n",
      "Validation Loss: 4193.7369\n",
      "Epoch [961/3000], Loss: 5104.6988\n",
      "Validation Loss: 4146.3816\n",
      "Epoch [981/3000], Loss: 5056.5430\n",
      "Validation Loss: 4101.4611\n",
      "Epoch [1001/3000], Loss: 5003.5688\n",
      "Validation Loss: 4057.4712\n",
      "Epoch [1021/3000], Loss: 4949.6173\n",
      "Validation Loss: 4014.3085\n",
      "Epoch [1041/3000], Loss: 4898.5046\n",
      "Validation Loss: 3972.0251\n",
      "Epoch [1061/3000], Loss: 4864.3614\n",
      "Validation Loss: 3930.5925\n",
      "Epoch [1081/3000], Loss: 4807.8962\n",
      "Validation Loss: 3889.8792\n",
      "Epoch [1101/3000], Loss: 4756.6788\n",
      "Validation Loss: 3849.9534\n",
      "Epoch [1121/3000], Loss: 4713.8878\n",
      "Validation Loss: 3810.9083\n",
      "Epoch [1141/3000], Loss: 4677.5711\n",
      "Validation Loss: 3772.7009\n",
      "Epoch [1161/3000], Loss: 4612.5241\n",
      "Validation Loss: 3735.2123\n",
      "Epoch [1181/3000], Loss: 4595.2641\n",
      "Validation Loss: 3698.6099\n",
      "Epoch [1201/3000], Loss: 4512.2651\n",
      "Validation Loss: 3662.6646\n",
      "Epoch [1221/3000], Loss: 4503.3851\n",
      "Validation Loss: 3627.5986\n",
      "Epoch [1241/3000], Loss: 4458.2935\n",
      "Validation Loss: 3593.3297\n",
      "Epoch [1261/3000], Loss: 4439.9439\n",
      "Validation Loss: 3559.8167\n",
      "Epoch [1281/3000], Loss: 4406.4057\n",
      "Validation Loss: 3527.1356\n",
      "Epoch [1301/3000], Loss: 4328.6378\n",
      "Validation Loss: 3495.1604\n",
      "Epoch [1321/3000], Loss: 4336.8416\n",
      "Validation Loss: 3464.0825\n",
      "Epoch [1341/3000], Loss: 4284.8942\n",
      "Validation Loss: 3433.7651\n",
      "Epoch [1361/3000], Loss: 4219.7263\n",
      "Validation Loss: 3404.2545\n",
      "Epoch [1381/3000], Loss: 4211.7989\n",
      "Validation Loss: 3375.4891\n",
      "Epoch [1401/3000], Loss: 4189.8805\n",
      "Validation Loss: 3347.4179\n",
      "Epoch [1421/3000], Loss: 4153.9556\n",
      "Validation Loss: 3320.1099\n",
      "Epoch [1441/3000], Loss: 4107.4250\n",
      "Validation Loss: 3293.6609\n",
      "Epoch [1461/3000], Loss: 4098.7226\n",
      "Validation Loss: 3268.0272\n",
      "Epoch [1481/3000], Loss: 4044.4100\n",
      "Validation Loss: 3243.0811\n",
      "Epoch [1501/3000], Loss: 4024.3547\n",
      "Validation Loss: 3218.9490\n",
      "Epoch [1521/3000], Loss: 4001.3995\n",
      "Validation Loss: 3195.5965\n",
      "Epoch [1541/3000], Loss: 3993.9689\n",
      "Validation Loss: 3173.0169\n",
      "Epoch [1561/3000], Loss: 3915.2235\n",
      "Validation Loss: 3151.1312\n",
      "Epoch [1581/3000], Loss: 3933.7910\n",
      "Validation Loss: 3130.0216\n",
      "Epoch [1601/3000], Loss: 3898.1384\n",
      "Validation Loss: 3109.6144\n",
      "Epoch [1621/3000], Loss: 3897.0328\n",
      "Validation Loss: 3089.9565\n",
      "Epoch [1641/3000], Loss: 3856.1280\n",
      "Validation Loss: 3071.0971\n",
      "Epoch [1661/3000], Loss: 3810.1221\n",
      "Validation Loss: 3052.8957\n",
      "Epoch [1681/3000], Loss: 3808.4581\n",
      "Validation Loss: 3035.4861\n",
      "Epoch [1701/3000], Loss: 3789.7209\n",
      "Validation Loss: 3018.8166\n",
      "Epoch [1721/3000], Loss: 3771.7504\n",
      "Validation Loss: 3002.8528\n",
      "Epoch [1741/3000], Loss: 3728.9859\n",
      "Validation Loss: 2987.6423\n",
      "Epoch [1761/3000], Loss: 3728.9399\n",
      "Validation Loss: 2973.1829\n",
      "Epoch [1781/3000], Loss: 3697.9622\n",
      "Validation Loss: 2959.3910\n",
      "Epoch [1801/3000], Loss: 3702.0993\n",
      "Validation Loss: 2946.2874\n",
      "Epoch [1821/3000], Loss: 3650.6902\n",
      "Validation Loss: 2933.9456\n",
      "Epoch [1841/3000], Loss: 3651.8678\n",
      "Validation Loss: 2922.2562\n",
      "Epoch [1861/3000], Loss: 3658.1321\n",
      "Validation Loss: 2911.2522\n",
      "Epoch [1881/3000], Loss: 3606.3936\n",
      "Validation Loss: 2900.9783\n",
      "Epoch [1901/3000], Loss: 3574.9083\n",
      "Validation Loss: 2891.3806\n",
      "Epoch [1921/3000], Loss: 3583.5406\n",
      "Validation Loss: 2882.3979\n",
      "Epoch [1941/3000], Loss: 3570.5799\n",
      "Validation Loss: 2874.0538\n",
      "Epoch [1961/3000], Loss: 3562.2685\n",
      "Validation Loss: 2866.3925\n",
      "Epoch [1981/3000], Loss: 3544.5225\n",
      "Validation Loss: 2859.3377\n",
      "Epoch [2001/3000], Loss: 3539.4393\n",
      "Validation Loss: 2852.9406\n",
      "Epoch [2021/3000], Loss: 3518.5020\n",
      "Validation Loss: 2846.9560\n",
      "Epoch [2041/3000], Loss: 3524.6130\n",
      "Validation Loss: 2841.6666\n",
      "Epoch [2061/3000], Loss: 3522.8919\n",
      "Validation Loss: 2835.7122\n",
      "Epoch [2081/3000], Loss: 3490.2338\n",
      "Validation Loss: 2813.4453\n",
      "Epoch [2101/3000], Loss: 3458.7022\n",
      "Validation Loss: 2791.8053\n",
      "Epoch [2121/3000], Loss: 3437.2854\n",
      "Validation Loss: 2772.1570\n",
      "Epoch [2141/3000], Loss: 3425.5334\n",
      "Validation Loss: 2767.9507\n",
      "Epoch [2161/3000], Loss: 3414.3839\n",
      "Validation Loss: 2763.9110\n",
      "Epoch [2181/3000], Loss: 3400.6746\n",
      "Validation Loss: 2760.4290\n",
      "Epoch [2201/3000], Loss: 3381.6528\n",
      "Validation Loss: 2743.4769\n",
      "Epoch [2221/3000], Loss: 3358.7968\n",
      "Validation Loss: 2738.1700\n",
      "Epoch [2241/3000], Loss: 3349.9541\n",
      "Validation Loss: 2732.4687\n",
      "Epoch [2261/3000], Loss: 3343.2567\n",
      "Validation Loss: 2728.9808\n",
      "Epoch [2281/3000], Loss: 3350.3708\n",
      "Validation Loss: 2726.3622\n",
      "Epoch [2301/3000], Loss: 3330.7882\n",
      "Validation Loss: 2724.1967\n",
      "Epoch [2321/3000], Loss: 3352.6370\n",
      "Validation Loss: 2723.2932\n",
      "Epoch [2341/3000], Loss: 3304.1159\n",
      "Validation Loss: 2722.4318\n",
      "Epoch [2361/3000], Loss: 3328.1270\n",
      "Validation Loss: 2720.6428\n",
      "Epoch [2381/3000], Loss: 3280.7201\n",
      "Validation Loss: 2700.5790\n",
      "Epoch [2401/3000], Loss: 3287.0035\n",
      "Validation Loss: 2700.5959\n",
      "Epoch [2421/3000], Loss: 3279.4103\n",
      "Validation Loss: 2691.1161\n",
      "Epoch [2441/3000], Loss: 3268.9890\n",
      "Validation Loss: 2668.8372\n",
      "Epoch [2461/3000], Loss: 3240.0881\n",
      "Validation Loss: 2671.0503\n",
      "Epoch [2481/3000], Loss: 3244.0574\n",
      "Validation Loss: 2672.7507\n",
      "Epoch [2501/3000], Loss: 3229.4806\n",
      "Validation Loss: 2654.3679\n",
      "Epoch [2521/3000], Loss: 3186.8964\n",
      "Validation Loss: 2611.0865\n",
      "Epoch [2541/3000], Loss: 3086.7828\n",
      "Validation Loss: 2566.6543\n",
      "Epoch [2561/3000], Loss: 3104.8016\n",
      "Validation Loss: 2566.1076\n",
      "Epoch [2581/3000], Loss: 3037.4680\n",
      "Validation Loss: 2521.6564\n",
      "Epoch [2601/3000], Loss: 2954.6757\n",
      "Validation Loss: 2465.1542\n",
      "Epoch [2621/3000], Loss: 2949.6893\n",
      "Validation Loss: 2460.9711\n",
      "Epoch [2641/3000], Loss: 2940.2488\n",
      "Validation Loss: 2466.2917\n",
      "Epoch [2661/3000], Loss: 2882.6051\n",
      "Validation Loss: 2433.1285\n",
      "Epoch [2681/3000], Loss: 2815.8381\n",
      "Validation Loss: 2372.1622\n",
      "Epoch [2701/3000], Loss: 2771.2859\n",
      "Validation Loss: 2352.5348\n",
      "Epoch [2721/3000], Loss: 2435.0930\n",
      "Validation Loss: 2103.8802\n",
      "Epoch [2741/3000], Loss: 2039.2151\n",
      "Validation Loss: 2042.6751\n",
      "Epoch [2761/3000], Loss: 1846.3221\n",
      "Validation Loss: 2088.1104\n",
      "Epoch [2781/3000], Loss: 1729.1099\n",
      "Validation Loss: 1970.1183\n",
      "Epoch [2801/3000], Loss: 1658.2418\n",
      "Validation Loss: 1919.8694\n",
      "Epoch [2821/3000], Loss: 1597.4012\n",
      "Validation Loss: 2010.1813\n",
      "Epoch [2841/3000], Loss: 1549.8084\n",
      "Validation Loss: 1834.8145\n",
      "Epoch [2861/3000], Loss: 1496.3896\n",
      "Validation Loss: 1807.1220\n",
      "Epoch [2881/3000], Loss: 1440.0458\n",
      "Validation Loss: 1846.9810\n",
      "Epoch [2901/3000], Loss: 1413.0194\n",
      "Validation Loss: 1861.8327\n",
      "Epoch [2921/3000], Loss: 1404.4633\n",
      "Validation Loss: 1958.1024\n",
      "Epoch [2941/3000], Loss: 1339.2552\n",
      "Validation Loss: 1958.8531\n",
      "Epoch [2961/3000], Loss: 1311.7986\n",
      "Validation Loss: 1824.0447\n",
      "Epoch [2981/3000], Loss: 1287.6433\n",
      "Validation Loss: 2003.4984\n",
      "Y:\\analysis\\fmats\\e190\\days\\e190_day045_plane0_Fall.mat\n",
      "(3324, 49)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9197.0846\n",
      "Validation Loss: 9294.2598\n",
      "Epoch [21/3000], Loss: 8656.4864\n",
      "Validation Loss: 8714.5750\n",
      "Epoch [41/3000], Loss: 8061.5249\n",
      "Validation Loss: 7993.9176\n",
      "Epoch [61/3000], Loss: 7824.7350\n",
      "Validation Loss: 7816.1803\n",
      "Epoch [81/3000], Loss: 7737.2527\n",
      "Validation Loss: 7693.4214\n",
      "Epoch [101/3000], Loss: 7636.1470\n",
      "Validation Loss: 7592.2094\n",
      "Epoch [121/3000], Loss: 7590.1954\n",
      "Validation Loss: 7499.8953\n",
      "Epoch [141/3000], Loss: 7432.8969\n",
      "Validation Loss: 7412.3635\n",
      "Epoch [161/3000], Loss: 7341.9614\n",
      "Validation Loss: 7328.2495\n",
      "Epoch [181/3000], Loss: 7273.8443\n",
      "Validation Loss: 7246.5403\n",
      "Epoch [201/3000], Loss: 7256.1343\n",
      "Validation Loss: 7165.1631\n",
      "Epoch [221/3000], Loss: 7112.6938\n",
      "Validation Loss: 7085.4623\n",
      "Epoch [241/3000], Loss: 7047.4369\n",
      "Validation Loss: 7008.0358\n",
      "Epoch [261/3000], Loss: 6988.1602\n",
      "Validation Loss: 6932.0450\n",
      "Epoch [281/3000], Loss: 6899.2234\n",
      "Validation Loss: 6857.2698\n",
      "Epoch [301/3000], Loss: 6909.7965\n",
      "Validation Loss: 6783.4963\n",
      "Epoch [321/3000], Loss: 6767.2191\n",
      "Validation Loss: 6710.5195\n",
      "Epoch [341/3000], Loss: 6705.7997\n",
      "Validation Loss: 6637.8336\n",
      "Epoch [361/3000], Loss: 6592.0286\n",
      "Validation Loss: 6566.1714\n",
      "Epoch [381/3000], Loss: 6499.4416\n",
      "Validation Loss: 6494.5425\n",
      "Epoch [401/3000], Loss: 6452.3882\n",
      "Validation Loss: 6424.2214\n",
      "Epoch [421/3000], Loss: 6454.1950\n",
      "Validation Loss: 6355.0062\n",
      "Epoch [441/3000], Loss: 6356.2022\n",
      "Validation Loss: 6286.7687\n",
      "Epoch [461/3000], Loss: 6256.0927\n",
      "Validation Loss: 6219.3896\n",
      "Epoch [481/3000], Loss: 6226.2988\n",
      "Validation Loss: 6152.6533\n",
      "Epoch [501/3000], Loss: 6214.3050\n",
      "Validation Loss: 6086.7876\n",
      "Epoch [521/3000], Loss: 6104.6417\n",
      "Validation Loss: 6021.5859\n",
      "Epoch [541/3000], Loss: 6020.6934\n",
      "Validation Loss: 5957.2681\n",
      "Epoch [561/3000], Loss: 5991.4486\n",
      "Validation Loss: 5893.4541\n",
      "Epoch [581/3000], Loss: 5981.4889\n",
      "Validation Loss: 5830.4952\n",
      "Epoch [601/3000], Loss: 5891.7084\n",
      "Validation Loss: 5768.4790\n",
      "Epoch [621/3000], Loss: 5791.5796\n",
      "Validation Loss: 5706.9381\n",
      "Epoch [641/3000], Loss: 5754.5201\n",
      "Validation Loss: 5646.1212\n",
      "Epoch [661/3000], Loss: 5696.6619\n",
      "Validation Loss: 5586.1198\n",
      "Epoch [681/3000], Loss: 5652.4218\n",
      "Validation Loss: 5526.8850\n",
      "Epoch [701/3000], Loss: 5610.2013\n",
      "Validation Loss: 5468.3376\n",
      "Epoch [721/3000], Loss: 5552.2335\n",
      "Validation Loss: 5410.4355\n",
      "Epoch [741/3000], Loss: 5454.7385\n",
      "Validation Loss: 5353.2058\n",
      "Epoch [761/3000], Loss: 5452.2265\n",
      "Validation Loss: 5296.8970\n",
      "Epoch [781/3000], Loss: 5351.3174\n",
      "Validation Loss: 5241.2815\n",
      "Epoch [801/3000], Loss: 5291.6421\n",
      "Validation Loss: 5186.3173\n",
      "Epoch [821/3000], Loss: 5253.9373\n",
      "Validation Loss: 5132.0393\n",
      "Epoch [841/3000], Loss: 5213.3899\n",
      "Validation Loss: 5078.3007\n",
      "Epoch [861/3000], Loss: 5158.9637\n",
      "Validation Loss: 5023.9050\n",
      "Epoch [881/3000], Loss: 5142.2992\n",
      "Validation Loss: 4971.3711\n",
      "Epoch [901/3000], Loss: 5054.9558\n",
      "Validation Loss: 4919.6774\n",
      "Epoch [921/3000], Loss: 5037.3087\n",
      "Validation Loss: 4868.7202\n",
      "Epoch [941/3000], Loss: 4993.8350\n",
      "Validation Loss: 4818.4504\n",
      "Epoch [961/3000], Loss: 4938.1967\n",
      "Validation Loss: 4768.8844\n",
      "Epoch [981/3000], Loss: 4860.3138\n",
      "Validation Loss: 4720.0453\n",
      "Epoch [1001/3000], Loss: 4855.7878\n",
      "Validation Loss: 4671.9233\n",
      "Epoch [1021/3000], Loss: 4756.6351\n",
      "Validation Loss: 4624.6107\n",
      "Epoch [1041/3000], Loss: 4750.9897\n",
      "Validation Loss: 4577.9971\n",
      "Epoch [1061/3000], Loss: 4732.7577\n",
      "Validation Loss: 4532.0391\n",
      "Epoch [1081/3000], Loss: 4665.8239\n",
      "Validation Loss: 4486.8190\n",
      "Epoch [1101/3000], Loss: 4599.3483\n",
      "Validation Loss: 4442.3487\n",
      "Epoch [1121/3000], Loss: 4556.0609\n",
      "Validation Loss: 4398.5447\n",
      "Epoch [1141/3000], Loss: 4587.0468\n",
      "Validation Loss: 4355.5277\n",
      "Epoch [1161/3000], Loss: 4524.8532\n",
      "Validation Loss: 4313.0251\n",
      "Epoch [1181/3000], Loss: 4495.7922\n",
      "Validation Loss: 4271.3294\n",
      "Epoch [1201/3000], Loss: 4441.8057\n",
      "Validation Loss: 4230.3397\n",
      "Epoch [1221/3000], Loss: 4409.2344\n",
      "Validation Loss: 4189.9644\n",
      "Epoch [1241/3000], Loss: 4357.7413\n",
      "Validation Loss: 4150.2644\n",
      "Epoch [1261/3000], Loss: 4325.8610\n",
      "Validation Loss: 4111.5486\n",
      "Epoch [1281/3000], Loss: 4320.4027\n",
      "Validation Loss: 4073.3058\n",
      "Epoch [1301/3000], Loss: 4252.7951\n",
      "Validation Loss: 4035.9322\n",
      "Epoch [1321/3000], Loss: 4212.5806\n",
      "Validation Loss: 3999.1687\n",
      "Epoch [1341/3000], Loss: 4209.8007\n",
      "Validation Loss: 3963.1228\n",
      "Epoch [1361/3000], Loss: 4147.4960\n",
      "Validation Loss: 3927.7612\n",
      "Epoch [1381/3000], Loss: 4103.7154\n",
      "Validation Loss: 3893.0511\n",
      "Epoch [1401/3000], Loss: 4088.7182\n",
      "Validation Loss: 3858.9944\n",
      "Epoch [1421/3000], Loss: 4051.1544\n",
      "Validation Loss: 3825.8073\n",
      "Epoch [1441/3000], Loss: 4031.8738\n",
      "Validation Loss: 3793.1938\n",
      "Epoch [1461/3000], Loss: 4005.6142\n",
      "Validation Loss: 3761.1234\n",
      "Epoch [1481/3000], Loss: 3969.1165\n",
      "Validation Loss: 3729.8240\n",
      "Epoch [1501/3000], Loss: 3929.2808\n",
      "Validation Loss: 3699.2994\n",
      "Epoch [1521/3000], Loss: 3928.4839\n",
      "Validation Loss: 3669.4631\n",
      "Epoch [1541/3000], Loss: 3917.7883\n",
      "Validation Loss: 3640.2967\n",
      "Epoch [1561/3000], Loss: 3916.6109\n",
      "Validation Loss: 3611.6372\n",
      "Epoch [1581/3000], Loss: 3859.1458\n",
      "Validation Loss: 3583.8947\n",
      "Epoch [1601/3000], Loss: 3821.2053\n",
      "Validation Loss: 3556.8034\n",
      "Epoch [1621/3000], Loss: 3812.0365\n",
      "Validation Loss: 3530.3975\n",
      "Epoch [1641/3000], Loss: 3768.5198\n",
      "Validation Loss: 3504.5087\n",
      "Epoch [1661/3000], Loss: 3779.9062\n",
      "Validation Loss: 3479.3046\n",
      "Epoch [1681/3000], Loss: 3708.6284\n",
      "Validation Loss: 3454.8297\n",
      "Epoch [1701/3000], Loss: 3688.1090\n",
      "Validation Loss: 3431.0119\n",
      "Epoch [1721/3000], Loss: 3698.2591\n",
      "Validation Loss: 3407.9279\n",
      "Epoch [1741/3000], Loss: 3677.6719\n",
      "Validation Loss: 3385.4276\n",
      "Epoch [1761/3000], Loss: 3659.1330\n",
      "Validation Loss: 3363.7346\n",
      "Epoch [1781/3000], Loss: 3623.1063\n",
      "Validation Loss: 3342.5953\n",
      "Epoch [1801/3000], Loss: 3629.2080\n",
      "Validation Loss: 3322.2073\n",
      "Epoch [1821/3000], Loss: 3605.4030\n",
      "Validation Loss: 3302.3536\n",
      "Epoch [1841/3000], Loss: 3586.6544\n",
      "Validation Loss: 3283.2233\n",
      "Epoch [1861/3000], Loss: 3548.3192\n",
      "Validation Loss: 3264.6833\n",
      "Epoch [1881/3000], Loss: 3545.2312\n",
      "Validation Loss: 3246.7842\n",
      "Epoch [1901/3000], Loss: 3537.7413\n",
      "Validation Loss: 3229.3300\n",
      "Epoch [1921/3000], Loss: 3533.4565\n",
      "Validation Loss: 3212.7792\n",
      "Epoch [1941/3000], Loss: 3521.9037\n",
      "Validation Loss: 3196.7519\n",
      "Epoch [1961/3000], Loss: 3507.5903\n",
      "Validation Loss: 3181.4617\n",
      "Epoch [1981/3000], Loss: 3483.0739\n",
      "Validation Loss: 3166.8111\n",
      "Epoch [2001/3000], Loss: 3463.8361\n",
      "Validation Loss: 3152.5023\n",
      "Epoch [2021/3000], Loss: 3453.3736\n",
      "Validation Loss: 3138.9420\n",
      "Epoch [2041/3000], Loss: 3472.3913\n",
      "Validation Loss: 3126.1145\n",
      "Epoch [2061/3000], Loss: 3440.1670\n",
      "Validation Loss: 3113.9386\n",
      "Epoch [2081/3000], Loss: 3446.0077\n",
      "Validation Loss: 3102.2398\n",
      "Epoch [2101/3000], Loss: 3444.8895\n",
      "Validation Loss: 3091.0378\n",
      "Epoch [2121/3000], Loss: 3419.5788\n",
      "Validation Loss: 3080.4818\n",
      "Epoch [2141/3000], Loss: 3393.3958\n",
      "Validation Loss: 3070.3937\n",
      "Epoch [2161/3000], Loss: 3388.9293\n",
      "Validation Loss: 3061.0333\n",
      "Epoch [2181/3000], Loss: 3407.4917\n",
      "Validation Loss: 3052.1461\n",
      "Epoch [2201/3000], Loss: 3384.5890\n",
      "Validation Loss: 3043.8162\n",
      "Epoch [2221/3000], Loss: 3413.3291\n",
      "Validation Loss: 3036.1624\n",
      "Epoch [2241/3000], Loss: 3379.2215\n",
      "Validation Loss: 3028.8513\n",
      "Epoch [2261/3000], Loss: 3362.9990\n",
      "Validation Loss: 3022.1612\n",
      "Epoch [2281/3000], Loss: 3387.7484\n",
      "Validation Loss: 3015.9348\n",
      "Epoch [2301/3000], Loss: 3363.5895\n",
      "Validation Loss: 3010.2800\n",
      "Epoch [2321/3000], Loss: 3352.3682\n",
      "Validation Loss: 3004.9349\n",
      "Epoch [2341/3000], Loss: 3383.9078\n",
      "Validation Loss: 3000.0291\n",
      "Epoch [2361/3000], Loss: 3385.9006\n",
      "Validation Loss: 2995.5992\n",
      "Epoch [2381/3000], Loss: 3339.4744\n",
      "Validation Loss: 2991.6681\n",
      "Epoch [2401/3000], Loss: 3367.8077\n",
      "Validation Loss: 2988.1365\n",
      "Epoch [2421/3000], Loss: 3386.4047\n",
      "Validation Loss: 2985.1947\n",
      "Epoch [2441/3000], Loss: 3354.2120\n",
      "Validation Loss: 2982.5347\n",
      "Epoch [2461/3000], Loss: 3369.6348\n",
      "Validation Loss: 2980.0208\n",
      "Epoch [2481/3000], Loss: 3322.2693\n",
      "Validation Loss: 2977.7068\n",
      "Epoch [2501/3000], Loss: 3355.2539\n",
      "Validation Loss: 2975.7838\n",
      "Epoch [2521/3000], Loss: 3360.9992\n",
      "Validation Loss: 2974.1693\n",
      "Epoch [2541/3000], Loss: 3341.7369\n",
      "Validation Loss: 2972.7089\n",
      "Epoch [2561/3000], Loss: 3357.3043\n",
      "Validation Loss: 2971.4795\n",
      "Epoch [2581/3000], Loss: 3340.9228\n",
      "Validation Loss: 2970.4282\n",
      "Epoch [2601/3000], Loss: 3367.7723\n",
      "Validation Loss: 2969.5868\n",
      "Epoch [2621/3000], Loss: 3352.2505\n",
      "Validation Loss: 2968.7645\n",
      "Epoch [2641/3000], Loss: 3379.4183\n",
      "Validation Loss: 2967.9560\n",
      "Epoch [2661/3000], Loss: 3340.1470\n",
      "Validation Loss: 2967.4321\n",
      "Epoch [2681/3000], Loss: 3371.6087\n",
      "Validation Loss: 2966.9391\n",
      "Epoch [2701/3000], Loss: 3337.0151\n",
      "Validation Loss: 2966.5504\n",
      "Epoch [2721/3000], Loss: 3348.3753\n",
      "Validation Loss: 2966.2706\n",
      "Epoch [2741/3000], Loss: 3347.9340\n",
      "Validation Loss: 2966.1096\n",
      "Epoch [2761/3000], Loss: 3368.7508\n",
      "Validation Loss: 2965.8438\n",
      "Epoch [2781/3000], Loss: 3352.4430\n",
      "Validation Loss: 2965.6097\n",
      "Epoch [2801/3000], Loss: 3346.6777\n",
      "Validation Loss: 2965.4210\n",
      "Epoch [2821/3000], Loss: 3348.6066\n",
      "Validation Loss: 2965.2316\n",
      "Epoch [2841/3000], Loss: 3350.2347\n",
      "Validation Loss: 2965.1515\n",
      "Epoch [2861/3000], Loss: 3348.6342\n",
      "Validation Loss: 2965.1509\n",
      "Epoch [2881/3000], Loss: 3350.3644\n",
      "Validation Loss: 2965.0965\n",
      "Epoch [2901/3000], Loss: 3355.3342\n",
      "Validation Loss: 2965.1138\n",
      "Epoch [2921/3000], Loss: 3364.9060\n",
      "Validation Loss: 2964.9738\n",
      "Epoch [2941/3000], Loss: 3350.7921\n",
      "Validation Loss: 2964.8914\n",
      "Epoch [2961/3000], Loss: 3337.8658\n",
      "Validation Loss: 2964.9047\n",
      "Epoch [2981/3000], Loss: 3362.1320\n",
      "Validation Loss: 2964.8389\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day035_plane0_Fall.mat\n",
      "(4135, 77)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8135.3190\n",
      "Validation Loss: 7075.3500\n",
      "Epoch [21/3000], Loss: 7266.7383\n",
      "Validation Loss: 6216.8042\n",
      "Epoch [41/3000], Loss: 6921.4034\n",
      "Validation Loss: 5914.8423\n",
      "Epoch [61/3000], Loss: 6772.6435\n",
      "Validation Loss: 5789.9720\n",
      "Epoch [81/3000], Loss: 6646.7160\n",
      "Validation Loss: 5688.5848\n",
      "Epoch [101/3000], Loss: 6564.4016\n",
      "Validation Loss: 5597.6675\n",
      "Epoch [121/3000], Loss: 6463.3830\n",
      "Validation Loss: 5512.3916\n",
      "Epoch [141/3000], Loss: 6391.8170\n",
      "Validation Loss: 5430.8554\n",
      "Epoch [161/3000], Loss: 6287.5391\n",
      "Validation Loss: 5352.1727\n",
      "Epoch [181/3000], Loss: 6219.5347\n",
      "Validation Loss: 5275.7601\n",
      "Epoch [201/3000], Loss: 6130.2066\n",
      "Validation Loss: 5201.3031\n",
      "Epoch [221/3000], Loss: 6041.0222\n",
      "Validation Loss: 5128.6371\n",
      "Epoch [241/3000], Loss: 5967.4094\n",
      "Validation Loss: 5057.5907\n",
      "Epoch [261/3000], Loss: 5882.9054\n",
      "Validation Loss: 4988.0670\n",
      "Epoch [281/3000], Loss: 5811.4151\n",
      "Validation Loss: 4920.0697\n",
      "Epoch [301/3000], Loss: 5736.8682\n",
      "Validation Loss: 4853.4989\n",
      "Epoch [321/3000], Loss: 5649.4569\n",
      "Validation Loss: 4788.2030\n",
      "Epoch [341/3000], Loss: 5601.1450\n",
      "Validation Loss: 4724.3363\n",
      "Epoch [361/3000], Loss: 5508.3458\n",
      "Validation Loss: 4661.7456\n",
      "Epoch [381/3000], Loss: 5458.8727\n",
      "Validation Loss: 4600.4548\n",
      "Epoch [401/3000], Loss: 5393.7966\n",
      "Validation Loss: 4540.4390\n",
      "Epoch [421/3000], Loss: 5308.4900\n",
      "Validation Loss: 4481.6707\n",
      "Epoch [441/3000], Loss: 5269.7651\n",
      "Validation Loss: 4424.1992\n",
      "Epoch [461/3000], Loss: 5186.2622\n",
      "Validation Loss: 4367.9552\n",
      "Epoch [481/3000], Loss: 5135.4267\n",
      "Validation Loss: 4312.9170\n",
      "Epoch [501/3000], Loss: 5063.1624\n",
      "Validation Loss: 4259.1750\n",
      "Epoch [521/3000], Loss: 5000.3666\n",
      "Validation Loss: 4206.7050\n",
      "Epoch [541/3000], Loss: 4957.8849\n",
      "Validation Loss: 4155.4482\n",
      "Epoch [561/3000], Loss: 4901.5382\n",
      "Validation Loss: 4104.6523\n",
      "Epoch [581/3000], Loss: 4842.6891\n",
      "Validation Loss: 4055.2088\n",
      "Epoch [601/3000], Loss: 4772.8847\n",
      "Validation Loss: 4007.3323\n",
      "Epoch [621/3000], Loss: 4732.8656\n",
      "Validation Loss: 3960.7834\n",
      "Epoch [641/3000], Loss: 4679.5197\n",
      "Validation Loss: 3915.4915\n",
      "Epoch [661/3000], Loss: 4620.1998\n",
      "Validation Loss: 3871.4105\n",
      "Epoch [681/3000], Loss: 4574.7482\n",
      "Validation Loss: 3828.5597\n",
      "Epoch [701/3000], Loss: 4514.7112\n",
      "Validation Loss: 3786.9417\n",
      "Epoch [721/3000], Loss: 4475.1871\n",
      "Validation Loss: 3746.5786\n",
      "Epoch [741/3000], Loss: 4428.5318\n",
      "Validation Loss: 3707.4106\n",
      "Epoch [761/3000], Loss: 4370.1872\n",
      "Validation Loss: 3669.4696\n",
      "Epoch [781/3000], Loss: 4328.4821\n",
      "Validation Loss: 3632.6759\n",
      "Epoch [801/3000], Loss: 4302.2142\n",
      "Validation Loss: 3597.1598\n",
      "Epoch [821/3000], Loss: 4252.2979\n",
      "Validation Loss: 3562.7655\n",
      "Epoch [841/3000], Loss: 4204.4745\n",
      "Validation Loss: 3529.6320\n",
      "Epoch [861/3000], Loss: 4166.7564\n",
      "Validation Loss: 3496.8529\n",
      "Epoch [881/3000], Loss: 4119.3970\n",
      "Validation Loss: 3465.7946\n",
      "Epoch [901/3000], Loss: 4096.4511\n",
      "Validation Loss: 3436.0721\n",
      "Epoch [921/3000], Loss: 4058.1183\n",
      "Validation Loss: 3407.5280\n",
      "Epoch [941/3000], Loss: 4023.5191\n",
      "Validation Loss: 3380.1585\n",
      "Epoch [961/3000], Loss: 3998.4162\n",
      "Validation Loss: 3354.0261\n",
      "Epoch [981/3000], Loss: 3958.7677\n",
      "Validation Loss: 3328.9727\n",
      "Epoch [1001/3000], Loss: 3930.9867\n",
      "Validation Loss: 3305.1530\n",
      "Epoch [1021/3000], Loss: 3887.9347\n",
      "Validation Loss: 3282.4979\n",
      "Epoch [1041/3000], Loss: 3873.5219\n",
      "Validation Loss: 3260.9532\n",
      "Epoch [1061/3000], Loss: 3848.9675\n",
      "Validation Loss: 3240.5169\n",
      "Epoch [1081/3000], Loss: 3825.0643\n",
      "Validation Loss: 3221.2424\n",
      "Epoch [1101/3000], Loss: 3787.7014\n",
      "Validation Loss: 3203.0744\n",
      "Epoch [1121/3000], Loss: 3764.5252\n",
      "Validation Loss: 3186.0503\n",
      "Epoch [1141/3000], Loss: 3734.5007\n",
      "Validation Loss: 3170.0782\n",
      "Epoch [1161/3000], Loss: 3720.2794\n",
      "Validation Loss: 3155.2190\n",
      "Epoch [1181/3000], Loss: 3700.0973\n",
      "Validation Loss: 3141.4363\n",
      "Epoch [1201/3000], Loss: 3683.4217\n",
      "Validation Loss: 3128.6973\n",
      "Epoch [1221/3000], Loss: 3663.4821\n",
      "Validation Loss: 3116.9680\n",
      "Epoch [1241/3000], Loss: 3647.9240\n",
      "Validation Loss: 3106.2939\n",
      "Epoch [1261/3000], Loss: 3628.8433\n",
      "Validation Loss: 3096.6264\n",
      "Epoch [1281/3000], Loss: 3608.8163\n",
      "Validation Loss: 3087.9464\n",
      "Epoch [1301/3000], Loss: 3602.0593\n",
      "Validation Loss: 3080.2115\n",
      "Epoch [1321/3000], Loss: 3581.6816\n",
      "Validation Loss: 3073.4655\n",
      "Epoch [1341/3000], Loss: 3572.8657\n",
      "Validation Loss: 3067.6035\n",
      "Epoch [1361/3000], Loss: 3557.6983\n",
      "Validation Loss: 3062.6545\n",
      "Epoch [1381/3000], Loss: 3552.4496\n",
      "Validation Loss: 3058.5433\n",
      "Epoch [1401/3000], Loss: 3542.6471\n",
      "Validation Loss: 3055.2421\n",
      "Epoch [1421/3000], Loss: 3530.5557\n",
      "Validation Loss: 3052.7154\n",
      "Epoch [1441/3000], Loss: 3525.0524\n",
      "Validation Loss: 3050.9054\n",
      "Epoch [1461/3000], Loss: 3520.8561\n",
      "Validation Loss: 3049.7826\n",
      "Epoch [1481/3000], Loss: 3522.5999\n",
      "Validation Loss: 3049.2788\n",
      "Epoch [1501/3000], Loss: 3511.7275\n",
      "Validation Loss: 3049.3397\n",
      "Epoch [1521/3000], Loss: 3495.8205\n",
      "Validation Loss: 3048.9318\n",
      "Epoch [1541/3000], Loss: 2713.4078\n",
      "Validation Loss: 2141.0755\n",
      "Epoch [1561/3000], Loss: 2554.6631\n",
      "Validation Loss: 2027.4456\n",
      "Epoch [1581/3000], Loss: 2410.6003\n",
      "Validation Loss: 2031.8036\n",
      "Epoch [1601/3000], Loss: 2240.0681\n",
      "Validation Loss: 2032.0322\n",
      "Epoch [1621/3000], Loss: 2116.7008\n",
      "Validation Loss: 1967.2000\n",
      "Epoch [1641/3000], Loss: 2037.2124\n",
      "Validation Loss: 1913.5938\n",
      "Epoch [1661/3000], Loss: 1965.2989\n",
      "Validation Loss: 1906.0839\n",
      "Epoch [1681/3000], Loss: 1873.4383\n",
      "Validation Loss: 1868.1910\n",
      "Epoch [1701/3000], Loss: 1814.0290\n",
      "Validation Loss: 1799.5258\n",
      "Epoch [1721/3000], Loss: 1766.1444\n",
      "Validation Loss: 1774.6999\n",
      "Epoch [1741/3000], Loss: 1714.2962\n",
      "Validation Loss: 1728.2799\n",
      "Epoch [1761/3000], Loss: 1668.9358\n",
      "Validation Loss: 1695.1197\n",
      "Epoch [1781/3000], Loss: 1625.2649\n",
      "Validation Loss: 1698.8183\n",
      "Epoch [1801/3000], Loss: 1586.6846\n",
      "Validation Loss: 1686.4790\n",
      "Epoch [1821/3000], Loss: 1542.6580\n",
      "Validation Loss: 1697.6508\n",
      "Epoch [1841/3000], Loss: 1498.9037\n",
      "Validation Loss: 1677.5579\n",
      "Epoch [1861/3000], Loss: 1467.0820\n",
      "Validation Loss: 1667.7658\n",
      "Epoch [1881/3000], Loss: 1427.5876\n",
      "Validation Loss: 1666.2760\n",
      "Epoch [1901/3000], Loss: 1398.7304\n",
      "Validation Loss: 1656.7385\n",
      "Epoch [1921/3000], Loss: 1364.5679\n",
      "Validation Loss: 1643.1311\n",
      "Epoch [1941/3000], Loss: 1327.2979\n",
      "Validation Loss: 1646.3495\n",
      "Epoch [1961/3000], Loss: 1299.5198\n",
      "Validation Loss: 1632.0193\n",
      "Epoch [1981/3000], Loss: 1265.1821\n",
      "Validation Loss: 1608.9044\n",
      "Epoch [2001/3000], Loss: 1233.1710\n",
      "Validation Loss: 1594.3439\n",
      "Epoch [2021/3000], Loss: 1208.8487\n",
      "Validation Loss: 1597.3093\n",
      "Epoch [2041/3000], Loss: 1178.8516\n",
      "Validation Loss: 1558.3129\n",
      "Epoch [2061/3000], Loss: 1153.0411\n",
      "Validation Loss: 1566.3607\n",
      "Epoch [2081/3000], Loss: 1121.9259\n",
      "Validation Loss: 1572.1166\n",
      "Epoch [2101/3000], Loss: 1093.7499\n",
      "Validation Loss: 1543.0767\n",
      "Epoch [2121/3000], Loss: 1070.9563\n",
      "Validation Loss: 1543.8493\n",
      "Epoch [2141/3000], Loss: 1050.2618\n",
      "Validation Loss: 1527.5124\n",
      "Epoch [2161/3000], Loss: 1017.0321\n",
      "Validation Loss: 1525.7358\n",
      "Epoch [2181/3000], Loss: 993.5074\n",
      "Validation Loss: 1493.3756\n",
      "Epoch [2201/3000], Loss: 964.2715\n",
      "Validation Loss: 1476.7986\n",
      "Epoch [2221/3000], Loss: 936.3526\n",
      "Validation Loss: 1463.7769\n",
      "Epoch [2241/3000], Loss: 913.1226\n",
      "Validation Loss: 1452.1930\n",
      "Epoch [2261/3000], Loss: 887.3355\n",
      "Validation Loss: 1443.1094\n",
      "Epoch [2281/3000], Loss: 864.5044\n",
      "Validation Loss: 1431.1870\n",
      "Epoch [2301/3000], Loss: 839.3890\n",
      "Validation Loss: 1422.5984\n",
      "Epoch [2321/3000], Loss: 816.9096\n",
      "Validation Loss: 1408.8759\n",
      "Epoch [2341/3000], Loss: 797.6905\n",
      "Validation Loss: 1401.1740\n",
      "Epoch [2361/3000], Loss: 775.3713\n",
      "Validation Loss: 1391.8956\n",
      "Epoch [2381/3000], Loss: 754.7679\n",
      "Validation Loss: 1396.8606\n",
      "Epoch [2401/3000], Loss: 734.4710\n",
      "Validation Loss: 1359.6138\n",
      "Epoch [2421/3000], Loss: 712.2005\n",
      "Validation Loss: 1340.1708\n",
      "Epoch [2441/3000], Loss: 693.7626\n",
      "Validation Loss: 1342.0366\n",
      "Epoch [2461/3000], Loss: 676.0145\n",
      "Validation Loss: 1342.5786\n",
      "Epoch [2481/3000], Loss: 656.5152\n",
      "Validation Loss: 1339.2999\n",
      "Epoch [2501/3000], Loss: 632.8481\n",
      "Validation Loss: 1333.7038\n",
      "Epoch [2521/3000], Loss: 618.3032\n",
      "Validation Loss: 1336.8948\n",
      "Epoch [2541/3000], Loss: 597.1371\n",
      "Validation Loss: 1343.0376\n",
      "Epoch [2561/3000], Loss: 584.7819\n",
      "Validation Loss: 1343.7567\n",
      "Epoch [2581/3000], Loss: 566.9887\n",
      "Validation Loss: 1336.8519\n",
      "Epoch [2601/3000], Loss: 550.8778\n",
      "Validation Loss: 1331.7390\n",
      "Epoch [2621/3000], Loss: 534.3259\n",
      "Validation Loss: 1326.3166\n",
      "Epoch [2641/3000], Loss: 517.5737\n",
      "Validation Loss: 1325.7472\n",
      "Epoch [2661/3000], Loss: 499.7608\n",
      "Validation Loss: 1329.2750\n",
      "Epoch [2681/3000], Loss: 485.9384\n",
      "Validation Loss: 1334.4921\n",
      "Epoch [2701/3000], Loss: 468.3646\n",
      "Validation Loss: 1331.4868\n",
      "Epoch [2721/3000], Loss: 454.5534\n",
      "Validation Loss: 1321.5375\n",
      "Epoch [2741/3000], Loss: 435.8004\n",
      "Validation Loss: 1324.6341\n",
      "Epoch [2761/3000], Loss: 434.6346\n",
      "Validation Loss: 1294.3495\n",
      "Epoch [2781/3000], Loss: 406.8354\n",
      "Validation Loss: 1322.2012\n",
      "Epoch [2801/3000], Loss: 393.0257\n",
      "Validation Loss: 1316.0307\n",
      "Epoch [2821/3000], Loss: 380.0460\n",
      "Validation Loss: 1319.7953\n",
      "Epoch [2841/3000], Loss: 363.3476\n",
      "Validation Loss: 1324.0815\n",
      "Epoch [2861/3000], Loss: 355.5526\n",
      "Validation Loss: 1325.8726\n",
      "Epoch [2881/3000], Loss: 373.9092\n",
      "Validation Loss: 1287.4441\n",
      "Epoch [2901/3000], Loss: 330.8911\n",
      "Validation Loss: 1332.6618\n",
      "Epoch [2921/3000], Loss: 318.5495\n",
      "Validation Loss: 1331.8465\n",
      "Epoch [2941/3000], Loss: 308.5068\n",
      "Validation Loss: 1332.1037\n",
      "Epoch [2961/3000], Loss: 295.6865\n",
      "Validation Loss: 1334.1545\n",
      "Epoch [2981/3000], Loss: 286.0941\n",
      "Validation Loss: 1338.2667\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day036_plane0_Fall.mat\n",
      "(8016, 140)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7696.7999\n",
      "Validation Loss: 7759.8009\n",
      "Epoch [21/3000], Loss: 6539.9943\n",
      "Validation Loss: 6566.3204\n",
      "Epoch [41/3000], Loss: 6297.3696\n",
      "Validation Loss: 6322.5386\n",
      "Epoch [61/3000], Loss: 6105.8167\n",
      "Validation Loss: 6129.9337\n",
      "Epoch [81/3000], Loss: 5941.2531\n",
      "Validation Loss: 5951.4291\n",
      "Epoch [101/3000], Loss: 5755.6670\n",
      "Validation Loss: 5784.1885\n",
      "Epoch [121/3000], Loss: 5607.3304\n",
      "Validation Loss: 5624.2490\n",
      "Epoch [141/3000], Loss: 5460.3224\n",
      "Validation Loss: 5467.4111\n",
      "Epoch [161/3000], Loss: 5315.5448\n",
      "Validation Loss: 5317.2023\n",
      "Epoch [181/3000], Loss: 5162.0768\n",
      "Validation Loss: 5173.3049\n",
      "Epoch [201/3000], Loss: 5028.7585\n",
      "Validation Loss: 5034.5892\n",
      "Epoch [221/3000], Loss: 4911.6319\n",
      "Validation Loss: 4900.6588\n",
      "Epoch [241/3000], Loss: 4783.0081\n",
      "Validation Loss: 4771.5771\n",
      "Epoch [261/3000], Loss: 4668.4946\n",
      "Validation Loss: 4647.2313\n",
      "Epoch [281/3000], Loss: 4549.2223\n",
      "Validation Loss: 4527.5618\n",
      "Epoch [301/3000], Loss: 4438.9357\n",
      "Validation Loss: 4412.5161\n",
      "Epoch [321/3000], Loss: 4325.0903\n",
      "Validation Loss: 4302.2151\n",
      "Epoch [341/3000], Loss: 4234.2324\n",
      "Validation Loss: 4196.5539\n",
      "Epoch [361/3000], Loss: 4130.5215\n",
      "Validation Loss: 4095.4417\n",
      "Epoch [381/3000], Loss: 4034.8520\n",
      "Validation Loss: 3998.9663\n",
      "Epoch [401/3000], Loss: 3951.9949\n",
      "Validation Loss: 3907.0404\n",
      "Epoch [421/3000], Loss: 3867.7671\n",
      "Validation Loss: 3819.6222\n",
      "Epoch [441/3000], Loss: 3785.9394\n",
      "Validation Loss: 3736.8231\n",
      "Epoch [461/3000], Loss: 3718.1227\n",
      "Validation Loss: 3658.4097\n",
      "Epoch [481/3000], Loss: 3647.1667\n",
      "Validation Loss: 3584.5969\n",
      "Epoch [501/3000], Loss: 3576.7677\n",
      "Validation Loss: 3515.2832\n",
      "Epoch [521/3000], Loss: 3514.7130\n",
      "Validation Loss: 3450.4037\n",
      "Epoch [541/3000], Loss: 3466.9875\n",
      "Validation Loss: 3389.8254\n",
      "Epoch [561/3000], Loss: 3409.5956\n",
      "Validation Loss: 3333.6972\n",
      "Epoch [581/3000], Loss: 3355.6978\n",
      "Validation Loss: 3281.9121\n",
      "Epoch [601/3000], Loss: 3319.9662\n",
      "Validation Loss: 3234.3457\n",
      "Epoch [621/3000], Loss: 3277.8634\n",
      "Validation Loss: 3190.9352\n",
      "Epoch [641/3000], Loss: 3243.2376\n",
      "Validation Loss: 3151.7212\n",
      "Epoch [661/3000], Loss: 3208.9553\n",
      "Validation Loss: 3116.6291\n",
      "Epoch [681/3000], Loss: 3184.2147\n",
      "Validation Loss: 3085.4758\n",
      "Epoch [701/3000], Loss: 3155.4393\n",
      "Validation Loss: 3058.1723\n",
      "Epoch [721/3000], Loss: 3140.0564\n",
      "Validation Loss: 3034.6848\n",
      "Epoch [741/3000], Loss: 3122.3594\n",
      "Validation Loss: 3014.7065\n",
      "Epoch [761/3000], Loss: 3110.1989\n",
      "Validation Loss: 2998.2276\n",
      "Epoch [781/3000], Loss: 3099.6016\n",
      "Validation Loss: 2984.9461\n",
      "Epoch [801/3000], Loss: 3089.1583\n",
      "Validation Loss: 2974.6027\n",
      "Epoch [821/3000], Loss: 3078.9642\n",
      "Validation Loss: 2965.6116\n",
      "Epoch [841/3000], Loss: 2092.6978\n",
      "Validation Loss: 2120.3249\n",
      "Epoch [861/3000], Loss: 1684.3254\n",
      "Validation Loss: 1781.2265\n",
      "Epoch [881/3000], Loss: 1564.9374\n",
      "Validation Loss: 1722.3668\n",
      "Epoch [901/3000], Loss: 1466.4385\n",
      "Validation Loss: 1719.8792\n",
      "Epoch [921/3000], Loss: 1384.4140\n",
      "Validation Loss: 1673.9470\n",
      "Epoch [941/3000], Loss: 1311.9305\n",
      "Validation Loss: 1622.3945\n",
      "Epoch [961/3000], Loss: 1256.4559\n",
      "Validation Loss: 1569.4769\n",
      "Epoch [981/3000], Loss: 1192.0267\n",
      "Validation Loss: 1551.6178\n",
      "Epoch [1001/3000], Loss: 1140.6616\n",
      "Validation Loss: 1472.8221\n",
      "Epoch [1021/3000], Loss: 1092.6382\n",
      "Validation Loss: 1447.7591\n",
      "Epoch [1041/3000], Loss: 1032.4860\n",
      "Validation Loss: 1387.1283\n",
      "Epoch [1061/3000], Loss: 986.0852\n",
      "Validation Loss: 1290.6274\n",
      "Epoch [1081/3000], Loss: 937.5896\n",
      "Validation Loss: 1249.3352\n",
      "Epoch [1101/3000], Loss: 897.2871\n",
      "Validation Loss: 1187.8502\n",
      "Epoch [1121/3000], Loss: 851.9865\n",
      "Validation Loss: 1191.3031\n",
      "Epoch [1141/3000], Loss: 811.1947\n",
      "Validation Loss: 1109.8408\n",
      "Epoch [1161/3000], Loss: 770.6175\n",
      "Validation Loss: 1097.4292\n",
      "Epoch [1181/3000], Loss: 732.9234\n",
      "Validation Loss: 976.8014\n",
      "Epoch [1201/3000], Loss: 696.5887\n",
      "Validation Loss: 1043.1217\n",
      "Epoch [1221/3000], Loss: 662.4321\n",
      "Validation Loss: 1008.9918\n",
      "Epoch [1241/3000], Loss: 627.3683\n",
      "Validation Loss: 1001.9597\n",
      "Epoch [1261/3000], Loss: 598.5564\n",
      "Validation Loss: 946.2714\n",
      "Epoch [1281/3000], Loss: 564.3015\n",
      "Validation Loss: 946.0764\n",
      "Epoch [1301/3000], Loss: 533.2300\n",
      "Validation Loss: 937.0119\n",
      "Epoch [1321/3000], Loss: 504.6916\n",
      "Validation Loss: 935.3176\n",
      "Epoch [1341/3000], Loss: 496.2441\n",
      "Validation Loss: 866.8934\n",
      "Epoch [1361/3000], Loss: 454.8272\n",
      "Validation Loss: 894.4442\n",
      "Epoch [1381/3000], Loss: 430.1921\n",
      "Validation Loss: 887.5929\n",
      "Epoch [1401/3000], Loss: 409.2114\n",
      "Validation Loss: 895.3206\n",
      "Epoch [1421/3000], Loss: 385.8228\n",
      "Validation Loss: 881.5860\n",
      "Epoch [1441/3000], Loss: 367.6617\n",
      "Validation Loss: 962.6045\n",
      "Epoch [1461/3000], Loss: 346.3685\n",
      "Validation Loss: 880.1652\n",
      "Epoch [1481/3000], Loss: 329.7687\n",
      "Validation Loss: 879.3387\n",
      "Epoch [1501/3000], Loss: 310.2917\n",
      "Validation Loss: 866.1132\n",
      "Epoch [1521/3000], Loss: 292.4195\n",
      "Validation Loss: 865.8261\n",
      "Epoch [1541/3000], Loss: 277.7747\n",
      "Validation Loss: 873.6141\n",
      "Epoch [1561/3000], Loss: 266.5808\n",
      "Validation Loss: 898.6467\n",
      "Epoch [1581/3000], Loss: 245.9422\n",
      "Validation Loss: 851.3399\n",
      "Epoch [1601/3000], Loss: 232.6490\n",
      "Validation Loss: 855.9839\n",
      "Epoch [1621/3000], Loss: 218.5239\n",
      "Validation Loss: 849.7118\n",
      "Epoch [1641/3000], Loss: 204.9546\n",
      "Validation Loss: 860.5940\n",
      "Epoch [1661/3000], Loss: 190.6322\n",
      "Validation Loss: 864.0494\n",
      "Epoch [1681/3000], Loss: 178.6922\n",
      "Validation Loss: 859.2057\n",
      "Epoch [1701/3000], Loss: 166.6088\n",
      "Validation Loss: 864.9951\n",
      "Epoch [1721/3000], Loss: 155.6989\n",
      "Validation Loss: 875.0239\n",
      "Epoch [1741/3000], Loss: 144.1649\n",
      "Validation Loss: 889.0159\n",
      "Epoch [1761/3000], Loss: 133.1318\n",
      "Validation Loss: 813.8088\n",
      "Epoch [1781/3000], Loss: 123.4443\n",
      "Validation Loss: 819.7678\n",
      "Epoch [1801/3000], Loss: 114.1021\n",
      "Validation Loss: 823.2095\n",
      "Epoch [1821/3000], Loss: 104.7221\n",
      "Validation Loss: 825.2246\n",
      "Epoch [1841/3000], Loss: 95.5864\n",
      "Validation Loss: 832.9755\n",
      "Epoch [1861/3000], Loss: 87.6636\n",
      "Validation Loss: 834.1844\n",
      "Epoch [1881/3000], Loss: 79.3644\n",
      "Validation Loss: 840.9106\n",
      "Epoch [1901/3000], Loss: 72.0681\n",
      "Validation Loss: 867.4375\n",
      "Epoch [1921/3000], Loss: 70.5841\n",
      "Validation Loss: 1055.5929\n",
      "Epoch [1941/3000], Loss: 54.5074\n",
      "Validation Loss: 900.6714\n",
      "Epoch [1961/3000], Loss: 47.6098\n",
      "Validation Loss: 873.3656\n",
      "Epoch [1981/3000], Loss: 42.1523\n",
      "Validation Loss: 875.7531\n",
      "Epoch [2001/3000], Loss: 36.8247\n",
      "Validation Loss: 878.3435\n",
      "Epoch [2021/3000], Loss: 31.9130\n",
      "Validation Loss: 879.9946\n",
      "Epoch [2041/3000], Loss: 27.6850\n",
      "Validation Loss: 874.1435\n",
      "Epoch [2061/3000], Loss: 23.4531\n",
      "Validation Loss: 883.3516\n",
      "Epoch [2081/3000], Loss: 20.0367\n",
      "Validation Loss: 880.9792\n",
      "Epoch [2101/3000], Loss: 16.9728\n",
      "Validation Loss: 872.8783\n",
      "Epoch [2121/3000], Loss: 14.5389\n",
      "Validation Loss: 876.3555\n",
      "Epoch [2141/3000], Loss: 12.1004\n",
      "Validation Loss: 867.6169\n",
      "Epoch [2161/3000], Loss: 23.7236\n",
      "Validation Loss: 757.3452\n",
      "Epoch [2181/3000], Loss: 9.0061\n",
      "Validation Loss: 860.8410\n",
      "Epoch [2201/3000], Loss: 7.7667\n",
      "Validation Loss: 861.9864\n",
      "Epoch [2221/3000], Loss: 6.7967\n",
      "Validation Loss: 859.7086\n",
      "Epoch [2241/3000], Loss: 5.8874\n",
      "Validation Loss: 857.5517\n",
      "Epoch [2261/3000], Loss: 4.7168\n",
      "Validation Loss: 865.6047\n",
      "Epoch [2281/3000], Loss: 3.8290\n",
      "Validation Loss: 872.1753\n",
      "Epoch [2301/3000], Loss: 3.1238\n",
      "Validation Loss: 871.9947\n",
      "Epoch [2321/3000], Loss: 3.0423\n",
      "Validation Loss: 867.3440\n",
      "Epoch [2341/3000], Loss: 2.0429\n",
      "Validation Loss: 862.4457\n",
      "Epoch [2361/3000], Loss: 1.6983\n",
      "Validation Loss: 857.8257\n",
      "Epoch [2381/3000], Loss: 1.4176\n",
      "Validation Loss: 862.7118\n",
      "Epoch [2401/3000], Loss: 1.2462\n",
      "Validation Loss: 837.9184\n",
      "Epoch [2421/3000], Loss: 1.1082\n",
      "Validation Loss: 842.7214\n",
      "Epoch [2441/3000], Loss: 1.0050\n",
      "Validation Loss: 839.2007\n",
      "Epoch [2461/3000], Loss: 0.9547\n",
      "Validation Loss: 839.4027\n",
      "Epoch [2481/3000], Loss: 0.8814\n",
      "Validation Loss: 830.9687\n",
      "Epoch [2501/3000], Loss: 0.7455\n",
      "Validation Loss: 837.8665\n",
      "Epoch [2521/3000], Loss: 0.6853\n",
      "Validation Loss: 834.0756\n",
      "Epoch [2541/3000], Loss: 0.6449\n",
      "Validation Loss: 839.9559\n",
      "Epoch [2561/3000], Loss: 0.5563\n",
      "Validation Loss: 833.7454\n",
      "Epoch [2581/3000], Loss: 0.4994\n",
      "Validation Loss: 834.1494\n",
      "Epoch [2601/3000], Loss: 0.4473\n",
      "Validation Loss: 830.8417\n",
      "Epoch [2621/3000], Loss: 0.7116\n",
      "Validation Loss: 809.6053\n",
      "Epoch [2641/3000], Loss: 0.5005\n",
      "Validation Loss: 819.1251\n",
      "Epoch [2661/3000], Loss: 0.4510\n",
      "Validation Loss: 815.7436\n",
      "Epoch [2681/3000], Loss: 0.4234\n",
      "Validation Loss: 816.8644\n",
      "Epoch [2701/3000], Loss: 0.4041\n",
      "Validation Loss: 813.9975\n",
      "Epoch [2721/3000], Loss: 0.3909\n",
      "Validation Loss: 813.5326\n",
      "Epoch [2741/3000], Loss: 0.3769\n",
      "Validation Loss: 816.2563\n",
      "Epoch [2761/3000], Loss: 0.3512\n",
      "Validation Loss: 811.0102\n",
      "Epoch [2781/3000], Loss: 0.3462\n",
      "Validation Loss: 816.9057\n",
      "Epoch [2801/3000], Loss: 1.5113\n",
      "Validation Loss: 793.6178\n",
      "Epoch [2821/3000], Loss: 0.3535\n",
      "Validation Loss: 819.8086\n",
      "Epoch [2841/3000], Loss: 0.3228\n",
      "Validation Loss: 818.4442\n",
      "Epoch [2861/3000], Loss: 0.3098\n",
      "Validation Loss: 819.7899\n",
      "Epoch [2881/3000], Loss: 0.2969\n",
      "Validation Loss: 814.5688\n",
      "Epoch [2901/3000], Loss: 0.2866\n",
      "Validation Loss: 809.9833\n",
      "Epoch [2921/3000], Loss: 0.2788\n",
      "Validation Loss: 809.8422\n",
      "Epoch [2941/3000], Loss: 0.2729\n",
      "Validation Loss: 810.9922\n",
      "Epoch [2961/3000], Loss: 0.2860\n",
      "Validation Loss: 811.9965\n",
      "Epoch [2981/3000], Loss: 0.2550\n",
      "Validation Loss: 805.7686\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day037_plane0_Fall.mat\n",
      "(5324, 98)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8621.7292\n",
      "Validation Loss: 9346.5250\n",
      "Epoch [21/3000], Loss: 7475.9687\n",
      "Validation Loss: 8171.1408\n",
      "Epoch [41/3000], Loss: 7165.8878\n",
      "Validation Loss: 7868.2808\n",
      "Epoch [61/3000], Loss: 6984.6359\n",
      "Validation Loss: 7698.4796\n",
      "Epoch [81/3000], Loss: 6874.4986\n",
      "Validation Loss: 7551.2657\n",
      "Epoch [101/3000], Loss: 6708.5317\n",
      "Validation Loss: 7414.3740\n",
      "Epoch [121/3000], Loss: 6625.0030\n",
      "Validation Loss: 7283.8160\n",
      "Epoch [141/3000], Loss: 6490.5712\n",
      "Validation Loss: 7157.6273\n",
      "Epoch [161/3000], Loss: 6347.0350\n",
      "Validation Loss: 7034.8285\n",
      "Epoch [181/3000], Loss: 6302.6694\n",
      "Validation Loss: 6914.8862\n",
      "Epoch [201/3000], Loss: 6163.5565\n",
      "Validation Loss: 6796.4906\n",
      "Epoch [221/3000], Loss: 5999.4557\n",
      "Validation Loss: 6681.0805\n",
      "Epoch [241/3000], Loss: 5922.4400\n",
      "Validation Loss: 6568.1038\n",
      "Epoch [261/3000], Loss: 5829.7564\n",
      "Validation Loss: 6457.3929\n",
      "Epoch [281/3000], Loss: 5747.7335\n",
      "Validation Loss: 6348.7811\n",
      "Epoch [301/3000], Loss: 5620.4211\n",
      "Validation Loss: 6242.3998\n",
      "Epoch [321/3000], Loss: 5522.7826\n",
      "Validation Loss: 6137.9152\n",
      "Epoch [341/3000], Loss: 5444.6778\n",
      "Validation Loss: 6035.4701\n",
      "Epoch [361/3000], Loss: 5323.9684\n",
      "Validation Loss: 5931.8316\n",
      "Epoch [381/3000], Loss: 5246.5602\n",
      "Validation Loss: 5832.4912\n",
      "Epoch [401/3000], Loss: 5161.9508\n",
      "Validation Loss: 5735.5152\n",
      "Epoch [421/3000], Loss: 5079.2314\n",
      "Validation Loss: 5640.5390\n",
      "Epoch [441/3000], Loss: 4996.5288\n",
      "Validation Loss: 5547.6350\n",
      "Epoch [461/3000], Loss: 4877.7792\n",
      "Validation Loss: 5456.6010\n",
      "Epoch [481/3000], Loss: 4804.4716\n",
      "Validation Loss: 5367.5643\n",
      "Epoch [501/3000], Loss: 4739.5798\n",
      "Validation Loss: 5280.4947\n",
      "Epoch [521/3000], Loss: 4653.1851\n",
      "Validation Loss: 5195.3841\n",
      "Epoch [541/3000], Loss: 4564.9467\n",
      "Validation Loss: 5112.2736\n",
      "Epoch [561/3000], Loss: 4496.4495\n",
      "Validation Loss: 5031.1214\n",
      "Epoch [581/3000], Loss: 4405.8214\n",
      "Validation Loss: 4951.6789\n",
      "Epoch [601/3000], Loss: 4370.8326\n",
      "Validation Loss: 4874.2756\n",
      "Epoch [621/3000], Loss: 4286.8854\n",
      "Validation Loss: 4798.8172\n",
      "Epoch [641/3000], Loss: 4252.0682\n",
      "Validation Loss: 4725.3214\n",
      "Epoch [661/3000], Loss: 4145.6363\n",
      "Validation Loss: 4653.6080\n",
      "Epoch [681/3000], Loss: 4078.7943\n",
      "Validation Loss: 4583.9880\n",
      "Epoch [701/3000], Loss: 4030.8371\n",
      "Validation Loss: 4516.2336\n",
      "Epoch [721/3000], Loss: 3978.7347\n",
      "Validation Loss: 4450.3445\n",
      "Epoch [741/3000], Loss: 3911.2804\n",
      "Validation Loss: 4386.2234\n",
      "Epoch [761/3000], Loss: 3848.4302\n",
      "Validation Loss: 4324.1588\n",
      "Epoch [781/3000], Loss: 3810.0206\n",
      "Validation Loss: 4263.9786\n",
      "Epoch [801/3000], Loss: 3762.6343\n",
      "Validation Loss: 4204.2717\n",
      "Epoch [821/3000], Loss: 3693.0382\n",
      "Validation Loss: 4147.4764\n",
      "Epoch [841/3000], Loss: 3647.2443\n",
      "Validation Loss: 4092.7656\n",
      "Epoch [861/3000], Loss: 3611.4370\n",
      "Validation Loss: 4039.8895\n",
      "Epoch [881/3000], Loss: 3539.0789\n",
      "Validation Loss: 3988.9138\n",
      "Epoch [901/3000], Loss: 3531.8766\n",
      "Validation Loss: 3939.7811\n",
      "Epoch [921/3000], Loss: 3469.6582\n",
      "Validation Loss: 3892.6646\n",
      "Epoch [941/3000], Loss: 3427.2206\n",
      "Validation Loss: 3847.3911\n",
      "Epoch [961/3000], Loss: 3409.8255\n",
      "Validation Loss: 3803.8215\n",
      "Epoch [981/3000], Loss: 3358.7286\n",
      "Validation Loss: 3762.2153\n",
      "Epoch [1001/3000], Loss: 3347.8648\n",
      "Validation Loss: 3722.4000\n",
      "Epoch [1021/3000], Loss: 3314.1749\n",
      "Validation Loss: 3684.4879\n",
      "Epoch [1041/3000], Loss: 3283.5114\n",
      "Validation Loss: 3648.2768\n",
      "Epoch [1061/3000], Loss: 3240.8938\n",
      "Validation Loss: 3613.8143\n",
      "Epoch [1081/3000], Loss: 3193.5250\n",
      "Validation Loss: 3581.1793\n",
      "Epoch [1101/3000], Loss: 3196.2204\n",
      "Validation Loss: 3550.4305\n",
      "Epoch [1121/3000], Loss: 3177.8558\n",
      "Validation Loss: 3521.4992\n",
      "Epoch [1141/3000], Loss: 3142.6401\n",
      "Validation Loss: 3494.2700\n",
      "Epoch [1161/3000], Loss: 3127.9367\n",
      "Validation Loss: 3468.6844\n",
      "Epoch [1181/3000], Loss: 3105.7920\n",
      "Validation Loss: 3444.9895\n",
      "Epoch [1201/3000], Loss: 3088.3954\n",
      "Validation Loss: 3422.7724\n",
      "Epoch [1221/3000], Loss: 3074.6747\n",
      "Validation Loss: 3402.1642\n",
      "Epoch [1241/3000], Loss: 3067.0647\n",
      "Validation Loss: 3383.3293\n",
      "Epoch [1261/3000], Loss: 3036.1417\n",
      "Validation Loss: 3366.0005\n",
      "Epoch [1281/3000], Loss: 3056.3869\n",
      "Validation Loss: 3350.4249\n",
      "Epoch [1301/3000], Loss: 3043.6677\n",
      "Validation Loss: 3336.1090\n",
      "Epoch [1321/3000], Loss: 3029.3781\n",
      "Validation Loss: 3323.3670\n",
      "Epoch [1341/3000], Loss: 3022.4490\n",
      "Validation Loss: 3312.0852\n",
      "Epoch [1361/3000], Loss: 2982.0024\n",
      "Validation Loss: 3259.8698\n",
      "Epoch [1381/3000], Loss: 2920.8618\n",
      "Validation Loss: 3194.8628\n",
      "Epoch [1401/3000], Loss: 2825.6653\n",
      "Validation Loss: 3090.4010\n",
      "Epoch [1421/3000], Loss: 2718.8688\n",
      "Validation Loss: 2967.7506\n",
      "Epoch [1441/3000], Loss: 2619.4383\n",
      "Validation Loss: 2861.5212\n",
      "Epoch [1461/3000], Loss: 1875.3710\n",
      "Validation Loss: 2038.1876\n",
      "Epoch [1481/3000], Loss: 1613.8919\n",
      "Validation Loss: 1743.3560\n",
      "Epoch [1501/3000], Loss: 1505.8618\n",
      "Validation Loss: 1623.0312\n",
      "Epoch [1521/3000], Loss: 1454.5740\n",
      "Validation Loss: 1549.2318\n",
      "Epoch [1541/3000], Loss: 1410.8276\n",
      "Validation Loss: 1500.7643\n",
      "Epoch [1561/3000], Loss: 1369.0289\n",
      "Validation Loss: 1458.5836\n",
      "Epoch [1581/3000], Loss: 1303.8375\n",
      "Validation Loss: 1408.3221\n",
      "Epoch [1601/3000], Loss: 1271.0500\n",
      "Validation Loss: 1384.3289\n",
      "Epoch [1621/3000], Loss: 1233.1739\n",
      "Validation Loss: 1348.4685\n",
      "Epoch [1641/3000], Loss: 1196.6284\n",
      "Validation Loss: 1298.9343\n",
      "Epoch [1661/3000], Loss: 1162.6793\n",
      "Validation Loss: 1268.8845\n",
      "Epoch [1681/3000], Loss: 1128.0701\n",
      "Validation Loss: 1224.5284\n",
      "Epoch [1701/3000], Loss: 1099.6852\n",
      "Validation Loss: 1204.4351\n",
      "Epoch [1721/3000], Loss: 1063.4018\n",
      "Validation Loss: 1185.4930\n",
      "Epoch [1741/3000], Loss: 1033.6063\n",
      "Validation Loss: 1142.2557\n",
      "Epoch [1761/3000], Loss: 998.3241\n",
      "Validation Loss: 1101.1223\n",
      "Epoch [1781/3000], Loss: 970.4880\n",
      "Validation Loss: 1057.3304\n",
      "Epoch [1801/3000], Loss: 939.9599\n",
      "Validation Loss: 1022.5868\n",
      "Epoch [1821/3000], Loss: 906.6727\n",
      "Validation Loss: 996.7954\n",
      "Epoch [1841/3000], Loss: 871.0917\n",
      "Validation Loss: 969.2526\n",
      "Epoch [1861/3000], Loss: 830.0817\n",
      "Validation Loss: 938.0157\n",
      "Epoch [1881/3000], Loss: 800.4962\n",
      "Validation Loss: 907.4558\n",
      "Epoch [1901/3000], Loss: 771.9172\n",
      "Validation Loss: 896.6637\n",
      "Epoch [1921/3000], Loss: 745.2010\n",
      "Validation Loss: 866.0514\n",
      "Epoch [1941/3000], Loss: 725.0936\n",
      "Validation Loss: 844.3513\n",
      "Epoch [1961/3000], Loss: 697.1668\n",
      "Validation Loss: 828.1240\n",
      "Epoch [1981/3000], Loss: 664.9635\n",
      "Validation Loss: 800.9175\n",
      "Epoch [2001/3000], Loss: 637.2767\n",
      "Validation Loss: 789.8659\n",
      "Epoch [2021/3000], Loss: 614.5561\n",
      "Validation Loss: 758.3071\n",
      "Epoch [2041/3000], Loss: 597.0342\n",
      "Validation Loss: 755.0619\n",
      "Epoch [2061/3000], Loss: 574.8475\n",
      "Validation Loss: 754.9281\n",
      "Epoch [2081/3000], Loss: 548.4559\n",
      "Validation Loss: 747.2602\n",
      "Epoch [2101/3000], Loss: 533.0281\n",
      "Validation Loss: 708.3235\n",
      "Epoch [2121/3000], Loss: 497.8102\n",
      "Validation Loss: 711.7063\n",
      "Epoch [2141/3000], Loss: 485.5661\n",
      "Validation Loss: 711.5167\n",
      "Epoch [2161/3000], Loss: 464.6138\n",
      "Validation Loss: 682.4646\n",
      "Epoch [2181/3000], Loss: 446.6043\n",
      "Validation Loss: 679.5445\n",
      "Epoch [2201/3000], Loss: 430.0399\n",
      "Validation Loss: 672.7238\n",
      "Epoch [2221/3000], Loss: 405.8979\n",
      "Validation Loss: 638.3970\n",
      "Epoch [2241/3000], Loss: 388.3272\n",
      "Validation Loss: 639.0745\n",
      "Epoch [2261/3000], Loss: 373.3128\n",
      "Validation Loss: 641.7115\n",
      "Epoch [2281/3000], Loss: 357.9183\n",
      "Validation Loss: 619.4964\n",
      "Epoch [2301/3000], Loss: 344.7600\n",
      "Validation Loss: 604.1034\n",
      "Epoch [2321/3000], Loss: 326.1664\n",
      "Validation Loss: 595.5440\n",
      "Epoch [2341/3000], Loss: 313.5237\n",
      "Validation Loss: 574.3180\n",
      "Epoch [2361/3000], Loss: 300.5466\n",
      "Validation Loss: 568.5671\n",
      "Epoch [2381/3000], Loss: 285.3808\n",
      "Validation Loss: 548.7945\n",
      "Epoch [2401/3000], Loss: 283.4979\n",
      "Validation Loss: 569.7359\n",
      "Epoch [2421/3000], Loss: 256.0160\n",
      "Validation Loss: 514.2955\n",
      "Epoch [2441/3000], Loss: 246.2709\n",
      "Validation Loss: 512.1666\n",
      "Epoch [2461/3000], Loss: 235.8781\n",
      "Validation Loss: 514.1303\n",
      "Epoch [2481/3000], Loss: 222.5132\n",
      "Validation Loss: 504.7025\n",
      "Epoch [2501/3000], Loss: 210.8017\n",
      "Validation Loss: 495.9162\n",
      "Epoch [2521/3000], Loss: 203.1171\n",
      "Validation Loss: 488.3429\n",
      "Epoch [2541/3000], Loss: 193.9913\n",
      "Validation Loss: 487.2315\n",
      "Epoch [2561/3000], Loss: 183.0729\n",
      "Validation Loss: 470.6696\n",
      "Epoch [2581/3000], Loss: 171.9780\n",
      "Validation Loss: 459.2962\n",
      "Epoch [2601/3000], Loss: 165.7598\n",
      "Validation Loss: 466.6437\n",
      "Epoch [2621/3000], Loss: 158.8227\n",
      "Validation Loss: 512.6593\n",
      "Epoch [2641/3000], Loss: 149.2798\n",
      "Validation Loss: 464.1369\n",
      "Epoch [2661/3000], Loss: 142.3594\n",
      "Validation Loss: 474.1373\n",
      "Epoch [2681/3000], Loss: 133.8312\n",
      "Validation Loss: 451.1526\n",
      "Epoch [2701/3000], Loss: 125.8493\n",
      "Validation Loss: 433.8147\n",
      "Epoch [2721/3000], Loss: 123.4324\n",
      "Validation Loss: 479.8375\n",
      "Epoch [2741/3000], Loss: 113.0238\n",
      "Validation Loss: 439.8537\n",
      "Epoch [2761/3000], Loss: 107.0278\n",
      "Validation Loss: 435.3735\n",
      "Epoch [2781/3000], Loss: 102.7126\n",
      "Validation Loss: 428.7276\n",
      "Epoch [2801/3000], Loss: 96.3227\n",
      "Validation Loss: 430.6126\n",
      "Epoch [2821/3000], Loss: 90.4420\n",
      "Validation Loss: 422.1196\n",
      "Epoch [2841/3000], Loss: 85.5946\n",
      "Validation Loss: 413.4131\n",
      "Epoch [2861/3000], Loss: 81.9427\n",
      "Validation Loss: 409.9098\n",
      "Epoch [2881/3000], Loss: 75.9330\n",
      "Validation Loss: 400.8226\n",
      "Epoch [2901/3000], Loss: 71.0325\n",
      "Validation Loss: 399.9387\n",
      "Epoch [2921/3000], Loss: 66.8387\n",
      "Validation Loss: 397.2941\n",
      "Epoch [2941/3000], Loss: 63.1472\n",
      "Validation Loss: 380.2207\n",
      "Epoch [2961/3000], Loss: 58.7083\n",
      "Validation Loss: 391.4288\n",
      "Epoch [2981/3000], Loss: 54.7239\n",
      "Validation Loss: 383.6992\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day038_plane0_Fall.mat\n",
      "(3454, 147)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7408.2195\n",
      "Validation Loss: 8697.3218\n",
      "Epoch [21/3000], Loss: 6630.3265\n",
      "Validation Loss: 7850.8051\n",
      "Epoch [41/3000], Loss: 6278.4693\n",
      "Validation Loss: 7465.6989\n",
      "Epoch [61/3000], Loss: 6191.2280\n",
      "Validation Loss: 7318.6558\n",
      "Epoch [81/3000], Loss: 6043.8205\n",
      "Validation Loss: 7210.9814\n",
      "Epoch [101/3000], Loss: 5986.9017\n",
      "Validation Loss: 7116.6515\n",
      "Epoch [121/3000], Loss: 5912.8570\n",
      "Validation Loss: 7025.2370\n",
      "Epoch [141/3000], Loss: 5847.9895\n",
      "Validation Loss: 6941.2100\n",
      "Epoch [161/3000], Loss: 5741.9032\n",
      "Validation Loss: 6860.4449\n",
      "Epoch [181/3000], Loss: 5681.2624\n",
      "Validation Loss: 6782.0689\n",
      "Epoch [201/3000], Loss: 5632.0653\n",
      "Validation Loss: 6705.3862\n",
      "Epoch [221/3000], Loss: 5512.2066\n",
      "Validation Loss: 6626.5640\n",
      "Epoch [241/3000], Loss: 5545.1430\n",
      "Validation Loss: 6552.4474\n",
      "Epoch [261/3000], Loss: 5476.1815\n",
      "Validation Loss: 6479.8135\n",
      "Epoch [281/3000], Loss: 5411.6732\n",
      "Validation Loss: 6408.4284\n",
      "Epoch [301/3000], Loss: 5301.4657\n",
      "Validation Loss: 6334.0076\n",
      "Epoch [321/3000], Loss: 5241.9053\n",
      "Validation Loss: 6262.2475\n",
      "Epoch [341/3000], Loss: 5158.2170\n",
      "Validation Loss: 6193.4771\n",
      "Epoch [361/3000], Loss: 5112.9318\n",
      "Validation Loss: 6126.0592\n",
      "Epoch [381/3000], Loss: 5077.1229\n",
      "Validation Loss: 6059.5790\n",
      "Epoch [401/3000], Loss: 5025.7964\n",
      "Validation Loss: 5994.0491\n",
      "Epoch [421/3000], Loss: 4932.3700\n",
      "Validation Loss: 5929.5095\n",
      "Epoch [441/3000], Loss: 4900.8659\n",
      "Validation Loss: 5865.8145\n",
      "Epoch [461/3000], Loss: 4809.3752\n",
      "Validation Loss: 5803.0190\n",
      "Epoch [481/3000], Loss: 4735.3313\n",
      "Validation Loss: 5741.1356\n",
      "Epoch [501/3000], Loss: 4717.5975\n",
      "Validation Loss: 5680.2084\n",
      "Epoch [521/3000], Loss: 4660.9857\n",
      "Validation Loss: 5620.1119\n",
      "Epoch [541/3000], Loss: 4610.7764\n",
      "Validation Loss: 5560.7814\n",
      "Epoch [561/3000], Loss: 4561.4966\n",
      "Validation Loss: 5502.3826\n",
      "Epoch [581/3000], Loss: 4560.1571\n",
      "Validation Loss: 5444.8052\n",
      "Epoch [601/3000], Loss: 4527.9291\n",
      "Validation Loss: 5388.0888\n",
      "Epoch [621/3000], Loss: 4430.7792\n",
      "Validation Loss: 5332.2608\n",
      "Epoch [641/3000], Loss: 4414.2523\n",
      "Validation Loss: 5277.2966\n",
      "Epoch [661/3000], Loss: 4345.0984\n",
      "Validation Loss: 5223.1580\n",
      "Epoch [681/3000], Loss: 4298.4093\n",
      "Validation Loss: 5169.8363\n",
      "Epoch [701/3000], Loss: 4265.4216\n",
      "Validation Loss: 5117.2755\n",
      "Epoch [721/3000], Loss: 4241.8954\n",
      "Validation Loss: 5065.5728\n",
      "Epoch [741/3000], Loss: 4190.0856\n",
      "Validation Loss: 5014.6619\n",
      "Epoch [761/3000], Loss: 4127.5408\n",
      "Validation Loss: 4964.7381\n",
      "Epoch [781/3000], Loss: 4108.8579\n",
      "Validation Loss: 4915.6147\n",
      "Epoch [801/3000], Loss: 4023.3452\n",
      "Validation Loss: 4867.2975\n",
      "Epoch [821/3000], Loss: 4039.9268\n",
      "Validation Loss: 4819.7319\n",
      "Epoch [841/3000], Loss: 3984.1227\n",
      "Validation Loss: 4773.0087\n",
      "Epoch [861/3000], Loss: 3949.6279\n",
      "Validation Loss: 4727.2116\n",
      "Epoch [881/3000], Loss: 3902.6027\n",
      "Validation Loss: 4682.1681\n",
      "Epoch [901/3000], Loss: 3890.2392\n",
      "Validation Loss: 4637.9619\n",
      "Epoch [921/3000], Loss: 3841.5520\n",
      "Validation Loss: 4594.4857\n",
      "Epoch [941/3000], Loss: 3782.9787\n",
      "Validation Loss: 4551.8982\n",
      "Epoch [961/3000], Loss: 3781.8626\n",
      "Validation Loss: 4510.0961\n",
      "Epoch [981/3000], Loss: 3759.7397\n",
      "Validation Loss: 4469.2526\n",
      "Epoch [1001/3000], Loss: 3708.1260\n",
      "Validation Loss: 4429.1860\n",
      "Epoch [1021/3000], Loss: 3697.9268\n",
      "Validation Loss: 4390.0305\n",
      "Epoch [1041/3000], Loss: 3656.5862\n",
      "Validation Loss: 4351.5504\n",
      "Epoch [1061/3000], Loss: 3623.4191\n",
      "Validation Loss: 4313.9533\n",
      "Epoch [1081/3000], Loss: 3577.6796\n",
      "Validation Loss: 4277.2370\n",
      "Epoch [1101/3000], Loss: 3577.9637\n",
      "Validation Loss: 4241.1933\n",
      "Epoch [1121/3000], Loss: 3559.9495\n",
      "Validation Loss: 4206.1736\n",
      "Epoch [1141/3000], Loss: 3519.3570\n",
      "Validation Loss: 4171.7571\n",
      "Epoch [1161/3000], Loss: 3502.7191\n",
      "Validation Loss: 4138.2177\n",
      "Epoch [1181/3000], Loss: 3450.6419\n",
      "Validation Loss: 4105.4685\n",
      "Epoch [1201/3000], Loss: 3461.5113\n",
      "Validation Loss: 4073.5122\n",
      "Epoch [1221/3000], Loss: 3410.7435\n",
      "Validation Loss: 4042.3792\n",
      "Epoch [1241/3000], Loss: 3414.4691\n",
      "Validation Loss: 4012.0308\n",
      "Epoch [1261/3000], Loss: 3372.7338\n",
      "Validation Loss: 3982.4705\n",
      "Epoch [1281/3000], Loss: 3366.1614\n",
      "Validation Loss: 3953.6422\n",
      "Epoch [1301/3000], Loss: 3358.1335\n",
      "Validation Loss: 3925.7081\n",
      "Epoch [1321/3000], Loss: 3302.3596\n",
      "Validation Loss: 3898.5656\n",
      "Epoch [1341/3000], Loss: 3287.5890\n",
      "Validation Loss: 3872.2021\n",
      "Epoch [1361/3000], Loss: 3282.2431\n",
      "Validation Loss: 3846.5670\n",
      "Epoch [1381/3000], Loss: 3276.9572\n",
      "Validation Loss: 3821.8643\n",
      "Epoch [1401/3000], Loss: 3247.6903\n",
      "Validation Loss: 3797.1534\n",
      "Epoch [1421/3000], Loss: 3240.4073\n",
      "Validation Loss: 3773.4732\n",
      "Epoch [1441/3000], Loss: 3226.2261\n",
      "Validation Loss: 3751.0684\n",
      "Epoch [1461/3000], Loss: 3183.9117\n",
      "Validation Loss: 3719.7571\n",
      "Epoch [1481/3000], Loss: 3032.1424\n",
      "Validation Loss: 3580.4089\n",
      "Epoch [1501/3000], Loss: 2284.9376\n",
      "Validation Loss: 3210.8259\n",
      "Epoch [1521/3000], Loss: 2253.8970\n",
      "Validation Loss: 3069.9671\n",
      "Epoch [1541/3000], Loss: 2198.6135\n",
      "Validation Loss: 3020.8994\n",
      "Epoch [1561/3000], Loss: 2131.8254\n",
      "Validation Loss: 2986.4645\n",
      "Epoch [1581/3000], Loss: 2076.7333\n",
      "Validation Loss: 2939.5725\n",
      "Epoch [1601/3000], Loss: 2034.8262\n",
      "Validation Loss: 2919.2365\n",
      "Epoch [1621/3000], Loss: 2012.6827\n",
      "Validation Loss: 2838.1010\n",
      "Epoch [1641/3000], Loss: 1964.2178\n",
      "Validation Loss: 2751.5441\n",
      "Epoch [1661/3000], Loss: 1941.2591\n",
      "Validation Loss: 2707.1060\n",
      "Epoch [1681/3000], Loss: 1886.1837\n",
      "Validation Loss: 2674.9371\n",
      "Epoch [1701/3000], Loss: 1876.6343\n",
      "Validation Loss: 2656.3439\n",
      "Epoch [1721/3000], Loss: 1821.0765\n",
      "Validation Loss: 2537.4917\n",
      "Epoch [1741/3000], Loss: 1800.9432\n",
      "Validation Loss: 2538.0580\n",
      "Epoch [1761/3000], Loss: 1768.9866\n",
      "Validation Loss: 2515.0269\n",
      "Epoch [1781/3000], Loss: 1745.6851\n",
      "Validation Loss: 2453.2509\n",
      "Epoch [1801/3000], Loss: 1685.1812\n",
      "Validation Loss: 2422.5176\n",
      "Epoch [1821/3000], Loss: 1654.4323\n",
      "Validation Loss: 2356.9117\n",
      "Epoch [1841/3000], Loss: 1649.0461\n",
      "Validation Loss: 2317.1245\n",
      "Epoch [1861/3000], Loss: 1608.7414\n",
      "Validation Loss: 2281.7677\n",
      "Epoch [1881/3000], Loss: 1587.7496\n",
      "Validation Loss: 2239.3153\n",
      "Epoch [1901/3000], Loss: 1560.7995\n",
      "Validation Loss: 2197.2795\n",
      "Epoch [1921/3000], Loss: 1518.9426\n",
      "Validation Loss: 2130.6620\n",
      "Epoch [1941/3000], Loss: 1491.1463\n",
      "Validation Loss: 2083.2192\n",
      "Epoch [1961/3000], Loss: 1464.5934\n",
      "Validation Loss: 2047.5395\n",
      "Epoch [1981/3000], Loss: 1441.4674\n",
      "Validation Loss: 2013.7035\n",
      "Epoch [2001/3000], Loss: 1424.8439\n",
      "Validation Loss: 1982.2433\n",
      "Epoch [2021/3000], Loss: 1387.9029\n",
      "Validation Loss: 1947.4096\n",
      "Epoch [2041/3000], Loss: 1361.3789\n",
      "Validation Loss: 1921.5955\n",
      "Epoch [2061/3000], Loss: 1342.7546\n",
      "Validation Loss: 1886.7385\n",
      "Epoch [2081/3000], Loss: 1312.3431\n",
      "Validation Loss: 1856.2731\n",
      "Epoch [2101/3000], Loss: 1285.1305\n",
      "Validation Loss: 1828.6080\n",
      "Epoch [2121/3000], Loss: 1273.5367\n",
      "Validation Loss: 1795.9840\n",
      "Epoch [2141/3000], Loss: 1231.7233\n",
      "Validation Loss: 1766.1769\n",
      "Epoch [2161/3000], Loss: 1221.4288\n",
      "Validation Loss: 1736.7033\n",
      "Epoch [2181/3000], Loss: 1182.6080\n",
      "Validation Loss: 1709.3325\n",
      "Epoch [2201/3000], Loss: 1185.5601\n",
      "Validation Loss: 1692.0404\n",
      "Epoch [2221/3000], Loss: 1161.8671\n",
      "Validation Loss: 1663.3894\n",
      "Epoch [2241/3000], Loss: 1135.0450\n",
      "Validation Loss: 1633.2497\n",
      "Epoch [2261/3000], Loss: 1126.8373\n",
      "Validation Loss: 1606.9134\n",
      "Epoch [2281/3000], Loss: 1086.4695\n",
      "Validation Loss: 1583.3576\n",
      "Epoch [2301/3000], Loss: 1074.4600\n",
      "Validation Loss: 1548.3221\n",
      "Epoch [2321/3000], Loss: 1044.1446\n",
      "Validation Loss: 1531.3236\n",
      "Epoch [2341/3000], Loss: 1030.6025\n",
      "Validation Loss: 1499.6844\n",
      "Epoch [2361/3000], Loss: 1010.0142\n",
      "Validation Loss: 1475.5047\n",
      "Epoch [2381/3000], Loss: 989.8601\n",
      "Validation Loss: 1461.6093\n",
      "Epoch [2401/3000], Loss: 977.8150\n",
      "Validation Loss: 1422.0962\n",
      "Epoch [2421/3000], Loss: 942.5375\n",
      "Validation Loss: 1397.2215\n",
      "Epoch [2441/3000], Loss: 937.2152\n",
      "Validation Loss: 1368.0409\n",
      "Epoch [2461/3000], Loss: 926.3356\n",
      "Validation Loss: 1344.5655\n",
      "Epoch [2481/3000], Loss: 902.7100\n",
      "Validation Loss: 1319.3071\n",
      "Epoch [2501/3000], Loss: 873.8495\n",
      "Validation Loss: 1365.9610\n",
      "Epoch [2521/3000], Loss: 875.4791\n",
      "Validation Loss: 1321.8277\n",
      "Epoch [2541/3000], Loss: 856.1226\n",
      "Validation Loss: 1291.8555\n",
      "Epoch [2561/3000], Loss: 836.3998\n",
      "Validation Loss: 1266.6605\n",
      "Epoch [2581/3000], Loss: 816.4206\n",
      "Validation Loss: 1250.0617\n",
      "Epoch [2601/3000], Loss: 804.8358\n",
      "Validation Loss: 1230.3896\n",
      "Epoch [2621/3000], Loss: 787.7274\n",
      "Validation Loss: 1203.6274\n",
      "Epoch [2641/3000], Loss: 773.2011\n",
      "Validation Loss: 1182.6861\n",
      "Epoch [2661/3000], Loss: 757.0201\n",
      "Validation Loss: 1157.3030\n",
      "Epoch [2681/3000], Loss: 741.2019\n",
      "Validation Loss: 1133.6605\n",
      "Epoch [2701/3000], Loss: 729.6769\n",
      "Validation Loss: 1118.8377\n",
      "Epoch [2721/3000], Loss: 693.5838\n",
      "Validation Loss: 1105.0267\n",
      "Epoch [2741/3000], Loss: 695.2673\n",
      "Validation Loss: 1092.2741\n",
      "Epoch [2761/3000], Loss: 686.5474\n",
      "Validation Loss: 1074.8860\n",
      "Epoch [2781/3000], Loss: 657.5015\n",
      "Validation Loss: 1060.9853\n",
      "Epoch [2801/3000], Loss: 651.6271\n",
      "Validation Loss: 1043.7119\n",
      "Epoch [2821/3000], Loss: 639.1322\n",
      "Validation Loss: 1026.7683\n",
      "Epoch [2841/3000], Loss: 629.9355\n",
      "Validation Loss: 1008.8302\n",
      "Epoch [2861/3000], Loss: 611.0991\n",
      "Validation Loss: 992.0866\n",
      "Epoch [2881/3000], Loss: 602.1875\n",
      "Validation Loss: 975.5808\n",
      "Epoch [2901/3000], Loss: 600.0976\n",
      "Validation Loss: 960.0450\n",
      "Epoch [2921/3000], Loss: 565.6747\n",
      "Validation Loss: 949.2670\n",
      "Epoch [2941/3000], Loss: 568.3656\n",
      "Validation Loss: 939.3214\n",
      "Epoch [2961/3000], Loss: 553.1820\n",
      "Validation Loss: 931.5930\n",
      "Epoch [2981/3000], Loss: 534.9517\n",
      "Validation Loss: 922.0988\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day039_plane0_Fall.mat\n",
      "(6693, 193)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8809.6504\n",
      "Validation Loss: 6802.1905\n",
      "Epoch [21/3000], Loss: 7612.8213\n",
      "Validation Loss: 5827.8466\n",
      "Epoch [41/3000], Loss: 7347.6659\n",
      "Validation Loss: 5630.6951\n",
      "Epoch [61/3000], Loss: 7165.7830\n",
      "Validation Loss: 5487.3936\n",
      "Epoch [81/3000], Loss: 7007.4838\n",
      "Validation Loss: 5359.4935\n",
      "Epoch [101/3000], Loss: 6853.7326\n",
      "Validation Loss: 5239.8931\n",
      "Epoch [121/3000], Loss: 6687.6092\n",
      "Validation Loss: 5126.0509\n",
      "Epoch [141/3000], Loss: 6567.0285\n",
      "Validation Loss: 5016.8541\n",
      "Epoch [161/3000], Loss: 6420.2703\n",
      "Validation Loss: 4909.7637\n",
      "Epoch [181/3000], Loss: 6284.0067\n",
      "Validation Loss: 4807.8542\n",
      "Epoch [201/3000], Loss: 6151.2299\n",
      "Validation Loss: 4709.7523\n",
      "Epoch [221/3000], Loss: 6030.4881\n",
      "Validation Loss: 4615.1814\n",
      "Epoch [241/3000], Loss: 5895.8363\n",
      "Validation Loss: 4524.1536\n",
      "Epoch [261/3000], Loss: 5774.1088\n",
      "Validation Loss: 4436.3785\n",
      "Epoch [281/3000], Loss: 5655.1190\n",
      "Validation Loss: 4352.0029\n",
      "Epoch [301/3000], Loss: 5538.1366\n",
      "Validation Loss: 4270.8976\n",
      "Epoch [321/3000], Loss: 5432.2967\n",
      "Validation Loss: 4193.0261\n",
      "Epoch [341/3000], Loss: 5323.4015\n",
      "Validation Loss: 4118.4164\n",
      "Epoch [361/3000], Loss: 5217.5741\n",
      "Validation Loss: 4047.0597\n",
      "Epoch [381/3000], Loss: 5114.0044\n",
      "Validation Loss: 3978.9538\n",
      "Epoch [401/3000], Loss: 5017.5789\n",
      "Validation Loss: 3914.0459\n",
      "Epoch [421/3000], Loss: 4926.7304\n",
      "Validation Loss: 3852.3754\n",
      "Epoch [441/3000], Loss: 4834.1037\n",
      "Validation Loss: 3793.8306\n",
      "Epoch [461/3000], Loss: 4742.9122\n",
      "Validation Loss: 3738.5211\n",
      "Epoch [481/3000], Loss: 4654.9759\n",
      "Validation Loss: 3686.2785\n",
      "Epoch [501/3000], Loss: 4576.1943\n",
      "Validation Loss: 3637.2358\n",
      "Epoch [521/3000], Loss: 4500.9663\n",
      "Validation Loss: 3591.3022\n",
      "Epoch [541/3000], Loss: 4423.1433\n",
      "Validation Loss: 3548.5171\n",
      "Epoch [561/3000], Loss: 4348.1783\n",
      "Validation Loss: 3508.8063\n",
      "Epoch [581/3000], Loss: 4281.4482\n",
      "Validation Loss: 3472.1653\n",
      "Epoch [601/3000], Loss: 4216.4234\n",
      "Validation Loss: 3438.0713\n",
      "Epoch [621/3000], Loss: 4151.9826\n",
      "Validation Loss: 3407.2948\n",
      "Epoch [641/3000], Loss: 4090.6327\n",
      "Validation Loss: 3379.7030\n",
      "Epoch [661/3000], Loss: 4040.1456\n",
      "Validation Loss: 3355.0880\n",
      "Epoch [681/3000], Loss: 3982.6786\n",
      "Validation Loss: 3333.4626\n",
      "Epoch [701/3000], Loss: 3931.1617\n",
      "Validation Loss: 3314.7579\n",
      "Epoch [721/3000], Loss: 3883.9095\n",
      "Validation Loss: 3298.9290\n",
      "Epoch [741/3000], Loss: 3838.2577\n",
      "Validation Loss: 3285.9316\n",
      "Epoch [761/3000], Loss: 3796.5884\n",
      "Validation Loss: 3275.7134\n",
      "Epoch [781/3000], Loss: 3759.0492\n",
      "Validation Loss: 3268.2128\n",
      "Epoch [801/3000], Loss: 3724.0991\n",
      "Validation Loss: 3263.2771\n",
      "Epoch [821/3000], Loss: 3690.7596\n",
      "Validation Loss: 3261.0532\n",
      "Epoch [841/3000], Loss: 3661.8683\n",
      "Validation Loss: 3259.6435\n",
      "Epoch [861/3000], Loss: 3583.1944\n",
      "Validation Loss: 3194.3606\n",
      "Epoch [881/3000], Loss: 3550.3183\n",
      "Validation Loss: 3192.8997\n",
      "Epoch [901/3000], Loss: 3523.5153\n",
      "Validation Loss: 3196.3089\n",
      "Epoch [921/3000], Loss: 3502.1967\n",
      "Validation Loss: 3201.1585\n",
      "Epoch [941/3000], Loss: 3463.1437\n",
      "Validation Loss: 3181.2394\n",
      "Epoch [961/3000], Loss: 3440.3891\n",
      "Validation Loss: 3188.2435\n",
      "Epoch [981/3000], Loss: 3267.1541\n",
      "Validation Loss: 3006.4089\n",
      "Epoch [1001/3000], Loss: 3163.1701\n",
      "Validation Loss: 2906.1652\n",
      "Epoch [1021/3000], Loss: 2953.8527\n",
      "Validation Loss: 2679.4143\n",
      "Epoch [1041/3000], Loss: 2269.9205\n",
      "Validation Loss: 1882.9557\n",
      "Epoch [1061/3000], Loss: 1878.1609\n",
      "Validation Loss: 1423.9732\n",
      "Epoch [1081/3000], Loss: 1787.2755\n",
      "Validation Loss: 1353.9883\n",
      "Epoch [1101/3000], Loss: 1704.6174\n",
      "Validation Loss: 1343.5341\n",
      "Epoch [1121/3000], Loss: 1629.6436\n",
      "Validation Loss: 1293.4556\n",
      "Epoch [1141/3000], Loss: 1569.4567\n",
      "Validation Loss: 1276.3855\n",
      "Epoch [1161/3000], Loss: 1495.5253\n",
      "Validation Loss: 1233.9280\n",
      "Epoch [1181/3000], Loss: 1430.2059\n",
      "Validation Loss: 1197.8297\n",
      "Epoch [1201/3000], Loss: 1371.9576\n",
      "Validation Loss: 1163.8902\n",
      "Epoch [1221/3000], Loss: 1313.8000\n",
      "Validation Loss: 1133.3336\n",
      "Epoch [1241/3000], Loss: 1261.2880\n",
      "Validation Loss: 1092.4864\n",
      "Epoch [1261/3000], Loss: 1210.5620\n",
      "Validation Loss: 1060.1863\n",
      "Epoch [1281/3000], Loss: 1156.5071\n",
      "Validation Loss: 1019.1546\n",
      "Epoch [1301/3000], Loss: 1110.6992\n",
      "Validation Loss: 982.7840\n",
      "Epoch [1321/3000], Loss: 1063.0746\n",
      "Validation Loss: 953.1656\n",
      "Epoch [1341/3000], Loss: 1018.9573\n",
      "Validation Loss: 925.3677\n",
      "Epoch [1361/3000], Loss: 972.2491\n",
      "Validation Loss: 894.3827\n",
      "Epoch [1381/3000], Loss: 932.0523\n",
      "Validation Loss: 853.8102\n",
      "Epoch [1401/3000], Loss: 886.4288\n",
      "Validation Loss: 838.4216\n",
      "Epoch [1421/3000], Loss: 847.6714\n",
      "Validation Loss: 807.2805\n",
      "Epoch [1441/3000], Loss: 823.3043\n",
      "Validation Loss: 769.3029\n",
      "Epoch [1461/3000], Loss: 771.9364\n",
      "Validation Loss: 759.1320\n",
      "Epoch [1481/3000], Loss: 735.1997\n",
      "Validation Loss: 729.4669\n",
      "Epoch [1501/3000], Loss: 698.3814\n",
      "Validation Loss: 704.3820\n",
      "Epoch [1521/3000], Loss: 665.7124\n",
      "Validation Loss: 686.3448\n",
      "Epoch [1541/3000], Loss: 629.1786\n",
      "Validation Loss: 659.4161\n",
      "Epoch [1561/3000], Loss: 598.3175\n",
      "Validation Loss: 639.9368\n",
      "Epoch [1581/3000], Loss: 567.9924\n",
      "Validation Loss: 625.5018\n",
      "Epoch [1601/3000], Loss: 537.5996\n",
      "Validation Loss: 602.3111\n",
      "Epoch [1621/3000], Loss: 507.6208\n",
      "Validation Loss: 584.6905\n",
      "Epoch [1641/3000], Loss: 479.7535\n",
      "Validation Loss: 567.1134\n",
      "Epoch [1661/3000], Loss: 452.8829\n",
      "Validation Loss: 541.9610\n",
      "Epoch [1681/3000], Loss: 426.4230\n",
      "Validation Loss: 521.8951\n",
      "Epoch [1701/3000], Loss: 402.2276\n",
      "Validation Loss: 506.1310\n",
      "Epoch [1721/3000], Loss: 380.2949\n",
      "Validation Loss: 500.6904\n",
      "Epoch [1741/3000], Loss: 357.1713\n",
      "Validation Loss: 484.8127\n",
      "Epoch [1761/3000], Loss: 336.4953\n",
      "Validation Loss: 468.8607\n",
      "Epoch [1781/3000], Loss: 315.9929\n",
      "Validation Loss: 452.0161\n",
      "Epoch [1801/3000], Loss: 297.8111\n",
      "Validation Loss: 429.0879\n",
      "Epoch [1821/3000], Loss: 279.2761\n",
      "Validation Loss: 432.8736\n",
      "Epoch [1841/3000], Loss: 262.5687\n",
      "Validation Loss: 420.6716\n",
      "Epoch [1861/3000], Loss: 246.4885\n",
      "Validation Loss: 406.1221\n",
      "Epoch [1881/3000], Loss: 229.4603\n",
      "Validation Loss: 402.4496\n",
      "Epoch [1901/3000], Loss: 213.7941\n",
      "Validation Loss: 407.3547\n",
      "Epoch [1921/3000], Loss: 199.2521\n",
      "Validation Loss: 393.3727\n",
      "Epoch [1941/3000], Loss: 185.1759\n",
      "Validation Loss: 380.7489\n",
      "Epoch [1961/3000], Loss: 172.6296\n",
      "Validation Loss: 376.2968\n",
      "Epoch [1981/3000], Loss: 161.1728\n",
      "Validation Loss: 368.6016\n",
      "Epoch [2001/3000], Loss: 150.0189\n",
      "Validation Loss: 370.2705\n",
      "Epoch [2021/3000], Loss: 138.8009\n",
      "Validation Loss: 367.0094\n",
      "Epoch [2041/3000], Loss: 128.6966\n",
      "Validation Loss: 376.3659\n",
      "Epoch [2061/3000], Loss: 119.4853\n",
      "Validation Loss: 365.8114\n",
      "Epoch [2081/3000], Loss: 109.6290\n",
      "Validation Loss: 364.9602\n",
      "Epoch [2101/3000], Loss: 101.3157\n",
      "Validation Loss: 358.1945\n",
      "Epoch [2121/3000], Loss: 93.2700\n",
      "Validation Loss: 336.1167\n",
      "Epoch [2141/3000], Loss: 85.4501\n",
      "Validation Loss: 329.9579\n",
      "Epoch [2161/3000], Loss: 78.2647\n",
      "Validation Loss: 316.3705\n",
      "Epoch [2181/3000], Loss: 72.2575\n",
      "Validation Loss: 313.2227\n",
      "Epoch [2201/3000], Loss: 66.4404\n",
      "Validation Loss: 307.9387\n",
      "Epoch [2221/3000], Loss: 87.0297\n",
      "Validation Loss: 337.7577\n",
      "Epoch [2241/3000], Loss: 55.8450\n",
      "Validation Loss: 303.8188\n",
      "Epoch [2261/3000], Loss: 50.9563\n",
      "Validation Loss: 295.8636\n",
      "Epoch [2281/3000], Loss: 46.7771\n",
      "Validation Loss: 291.4902\n",
      "Epoch [2301/3000], Loss: 42.3183\n",
      "Validation Loss: 291.5724\n",
      "Epoch [2321/3000], Loss: 38.2622\n",
      "Validation Loss: 285.3641\n",
      "Epoch [2341/3000], Loss: 34.9793\n",
      "Validation Loss: 283.5320\n",
      "Epoch [2361/3000], Loss: 31.5933\n",
      "Validation Loss: 280.7824\n",
      "Epoch [2381/3000], Loss: 28.2825\n",
      "Validation Loss: 278.8037\n",
      "Epoch [2401/3000], Loss: 25.3222\n",
      "Validation Loss: 284.9685\n",
      "Epoch [2421/3000], Loss: 22.0786\n",
      "Validation Loss: 331.2350\n",
      "Epoch [2441/3000], Loss: 19.4826\n",
      "Validation Loss: 323.4005\n",
      "Epoch [2461/3000], Loss: 17.0007\n",
      "Validation Loss: 324.1779\n",
      "Epoch [2481/3000], Loss: 15.1209\n",
      "Validation Loss: 334.5496\n",
      "Epoch [2501/3000], Loss: 13.0408\n",
      "Validation Loss: 334.2997\n",
      "Epoch [2521/3000], Loss: 11.3658\n",
      "Validation Loss: 323.2688\n",
      "Epoch [2541/3000], Loss: 70.4647\n",
      "Validation Loss: 650.3117\n",
      "Epoch [2561/3000], Loss: 8.5369\n",
      "Validation Loss: 296.5360\n",
      "Epoch [2581/3000], Loss: 7.4732\n",
      "Validation Loss: 292.8479\n",
      "Epoch [2601/3000], Loss: 6.4662\n",
      "Validation Loss: 290.6718\n",
      "Epoch [2621/3000], Loss: 5.5354\n",
      "Validation Loss: 286.2615\n",
      "Epoch [2641/3000], Loss: 4.6913\n",
      "Validation Loss: 282.7792\n",
      "Epoch [2661/3000], Loss: 3.8882\n",
      "Validation Loss: 283.8806\n",
      "Epoch [2681/3000], Loss: 3.2453\n",
      "Validation Loss: 284.1741\n",
      "Epoch [2701/3000], Loss: 2.6350\n",
      "Validation Loss: 281.8849\n",
      "Epoch [2721/3000], Loss: 2.1565\n",
      "Validation Loss: 282.8122\n",
      "Epoch [2741/3000], Loss: 1.7298\n",
      "Validation Loss: 282.4927\n",
      "Epoch [2761/3000], Loss: 1.4300\n",
      "Validation Loss: 283.2355\n",
      "Epoch [2781/3000], Loss: 1.1489\n",
      "Validation Loss: 288.8922\n",
      "Epoch [2801/3000], Loss: 0.9164\n",
      "Validation Loss: 291.1795\n",
      "Epoch [2821/3000], Loss: 0.7268\n",
      "Validation Loss: 290.3856\n",
      "Epoch [2841/3000], Loss: 0.6379\n",
      "Validation Loss: 273.0257\n",
      "Epoch [2861/3000], Loss: 0.4673\n",
      "Validation Loss: 284.2337\n",
      "Epoch [2881/3000], Loss: 0.3897\n",
      "Validation Loss: 276.8415\n",
      "Epoch [2901/3000], Loss: 0.4997\n",
      "Validation Loss: 284.4339\n",
      "Epoch [2921/3000], Loss: 0.2860\n",
      "Validation Loss: 283.4957\n",
      "Epoch [2941/3000], Loss: 0.2307\n",
      "Validation Loss: 277.5249\n",
      "Epoch [2961/3000], Loss: 0.4232\n",
      "Validation Loss: 278.0844\n",
      "Epoch [2981/3000], Loss: 0.2144\n",
      "Validation Loss: 283.8231\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day040_plane0_Fall.mat\n",
      "(5404, 79)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7202.7969\n",
      "Validation Loss: 7029.1129\n",
      "Epoch [21/3000], Loss: 6121.9490\n",
      "Validation Loss: 6032.2543\n",
      "Epoch [41/3000], Loss: 5870.2799\n",
      "Validation Loss: 5818.4297\n",
      "Epoch [61/3000], Loss: 5721.5436\n",
      "Validation Loss: 5682.2311\n",
      "Epoch [81/3000], Loss: 5592.6497\n",
      "Validation Loss: 5562.4354\n",
      "Epoch [101/3000], Loss: 5468.5951\n",
      "Validation Loss: 5450.5035\n",
      "Epoch [121/3000], Loss: 5357.1581\n",
      "Validation Loss: 5342.0962\n",
      "Epoch [141/3000], Loss: 5226.0955\n",
      "Validation Loss: 5238.1155\n",
      "Epoch [161/3000], Loss: 5123.4462\n",
      "Validation Loss: 5137.1730\n",
      "Epoch [181/3000], Loss: 5005.9670\n",
      "Validation Loss: 5039.7654\n",
      "Epoch [201/3000], Loss: 4901.3555\n",
      "Validation Loss: 4945.0446\n",
      "Epoch [221/3000], Loss: 4799.7009\n",
      "Validation Loss: 4852.9072\n",
      "Epoch [241/3000], Loss: 4695.4949\n",
      "Validation Loss: 4763.1264\n",
      "Epoch [261/3000], Loss: 4597.2896\n",
      "Validation Loss: 4675.6766\n",
      "Epoch [281/3000], Loss: 4492.9290\n",
      "Validation Loss: 4590.5093\n",
      "Epoch [301/3000], Loss: 4407.5770\n",
      "Validation Loss: 4507.4921\n",
      "Epoch [321/3000], Loss: 4315.1476\n",
      "Validation Loss: 4425.4266\n",
      "Epoch [341/3000], Loss: 4213.4251\n",
      "Validation Loss: 4346.2724\n",
      "Epoch [361/3000], Loss: 4123.7929\n",
      "Validation Loss: 4269.3819\n",
      "Epoch [381/3000], Loss: 4040.1504\n",
      "Validation Loss: 4194.7008\n",
      "Epoch [401/3000], Loss: 3961.9412\n",
      "Validation Loss: 4122.1564\n",
      "Epoch [421/3000], Loss: 3872.3845\n",
      "Validation Loss: 4051.7239\n",
      "Epoch [441/3000], Loss: 3796.8549\n",
      "Validation Loss: 3983.4678\n",
      "Epoch [461/3000], Loss: 3720.6550\n",
      "Validation Loss: 3917.2695\n",
      "Epoch [481/3000], Loss: 3640.0851\n",
      "Validation Loss: 3853.1971\n",
      "Epoch [501/3000], Loss: 3571.7484\n",
      "Validation Loss: 3791.1922\n",
      "Epoch [521/3000], Loss: 3496.3370\n",
      "Validation Loss: 3731.3231\n",
      "Epoch [541/3000], Loss: 3431.4474\n",
      "Validation Loss: 3673.4853\n",
      "Epoch [561/3000], Loss: 3362.9756\n",
      "Validation Loss: 3617.7173\n",
      "Epoch [581/3000], Loss: 3293.4170\n",
      "Validation Loss: 3564.0385\n",
      "Epoch [601/3000], Loss: 3237.5346\n",
      "Validation Loss: 3511.5664\n",
      "Epoch [621/3000], Loss: 3168.9468\n",
      "Validation Loss: 3461.6887\n",
      "Epoch [641/3000], Loss: 3113.0801\n",
      "Validation Loss: 3413.0793\n",
      "Epoch [661/3000], Loss: 3058.2049\n",
      "Validation Loss: 3367.1140\n",
      "Epoch [681/3000], Loss: 3001.2799\n",
      "Validation Loss: 3323.4097\n",
      "Epoch [701/3000], Loss: 2948.7828\n",
      "Validation Loss: 3281.7605\n",
      "Epoch [721/3000], Loss: 2892.6022\n",
      "Validation Loss: 3242.2262\n",
      "Epoch [741/3000], Loss: 2849.3712\n",
      "Validation Loss: 3204.6588\n",
      "Epoch [761/3000], Loss: 2799.1721\n",
      "Validation Loss: 3169.1861\n",
      "Epoch [781/3000], Loss: 2755.7646\n",
      "Validation Loss: 3135.7254\n",
      "Epoch [801/3000], Loss: 2712.7930\n",
      "Validation Loss: 3104.2303\n",
      "Epoch [821/3000], Loss: 2670.7330\n",
      "Validation Loss: 3074.4185\n",
      "Epoch [841/3000], Loss: 2630.6501\n",
      "Validation Loss: 3046.3783\n",
      "Epoch [861/3000], Loss: 2589.8660\n",
      "Validation Loss: 3020.7010\n",
      "Epoch [881/3000], Loss: 2560.3822\n",
      "Validation Loss: 2996.3656\n",
      "Epoch [901/3000], Loss: 2520.1472\n",
      "Validation Loss: 2974.5330\n",
      "Epoch [921/3000], Loss: 2493.5425\n",
      "Validation Loss: 2954.6391\n",
      "Epoch [941/3000], Loss: 2465.6263\n",
      "Validation Loss: 2936.6747\n",
      "Epoch [961/3000], Loss: 2437.0310\n",
      "Validation Loss: 2920.5470\n",
      "Epoch [981/3000], Loss: 2416.9178\n",
      "Validation Loss: 2906.2510\n",
      "Epoch [1001/3000], Loss: 2392.7997\n",
      "Validation Loss: 2893.7179\n",
      "Epoch [1021/3000], Loss: 2374.7502\n",
      "Validation Loss: 2882.9179\n",
      "Epoch [1041/3000], Loss: 2351.6650\n",
      "Validation Loss: 2873.8294\n",
      "Epoch [1061/3000], Loss: 2333.6625\n",
      "Validation Loss: 2866.3702\n",
      "Epoch [1081/3000], Loss: 2317.0913\n",
      "Validation Loss: 2860.4818\n",
      "Epoch [1101/3000], Loss: 2303.8360\n",
      "Validation Loss: 2856.1087\n",
      "Epoch [1121/3000], Loss: 2293.3023\n",
      "Validation Loss: 2853.1433\n",
      "Epoch [1141/3000], Loss: 2283.2601\n",
      "Validation Loss: 2851.5050\n",
      "Epoch [1161/3000], Loss: 2272.0435\n",
      "Validation Loss: 2851.0789\n",
      "Epoch [1181/3000], Loss: 2264.3646\n",
      "Validation Loss: 2851.7387\n",
      "Epoch [1201/3000], Loss: 2255.1461\n",
      "Validation Loss: 2853.3384\n",
      "Epoch [1221/3000], Loss: 2247.5072\n",
      "Validation Loss: 2853.5850\n",
      "Epoch [1241/3000], Loss: 1800.0625\n",
      "Validation Loss: 2250.2848\n",
      "Epoch [1261/3000], Loss: 1412.9557\n",
      "Validation Loss: 1725.5437\n",
      "Epoch [1281/3000], Loss: 1215.9010\n",
      "Validation Loss: 1502.6330\n",
      "Epoch [1301/3000], Loss: 1154.0301\n",
      "Validation Loss: 1479.8889\n",
      "Epoch [1321/3000], Loss: 1108.7323\n",
      "Validation Loss: 1395.9576\n",
      "Epoch [1341/3000], Loss: 1070.1151\n",
      "Validation Loss: 1363.5144\n",
      "Epoch [1361/3000], Loss: 1033.7162\n",
      "Validation Loss: 1328.0686\n",
      "Epoch [1381/3000], Loss: 997.4925\n",
      "Validation Loss: 1304.3114\n",
      "Epoch [1401/3000], Loss: 964.4577\n",
      "Validation Loss: 1296.6386\n",
      "Epoch [1421/3000], Loss: 938.0004\n",
      "Validation Loss: 1276.7551\n",
      "Epoch [1441/3000], Loss: 907.8926\n",
      "Validation Loss: 1261.7861\n",
      "Epoch [1461/3000], Loss: 882.0220\n",
      "Validation Loss: 1222.9004\n",
      "Epoch [1481/3000], Loss: 855.2435\n",
      "Validation Loss: 1202.7042\n",
      "Epoch [1501/3000], Loss: 819.9284\n",
      "Validation Loss: 1196.4328\n",
      "Epoch [1521/3000], Loss: 788.9881\n",
      "Validation Loss: 1168.0396\n",
      "Epoch [1541/3000], Loss: 764.7435\n",
      "Validation Loss: 1076.6019\n",
      "Epoch [1561/3000], Loss: 732.4205\n",
      "Validation Loss: 1095.3901\n",
      "Epoch [1581/3000], Loss: 706.0292\n",
      "Validation Loss: 1091.2570\n",
      "Epoch [1601/3000], Loss: 682.1208\n",
      "Validation Loss: 1061.1826\n",
      "Epoch [1621/3000], Loss: 659.0414\n",
      "Validation Loss: 1042.0765\n",
      "Epoch [1641/3000], Loss: 639.7159\n",
      "Validation Loss: 1020.7780\n",
      "Epoch [1661/3000], Loss: 617.9362\n",
      "Validation Loss: 1003.1075\n",
      "Epoch [1681/3000], Loss: 598.5283\n",
      "Validation Loss: 981.9727\n",
      "Epoch [1701/3000], Loss: 578.1047\n",
      "Validation Loss: 957.9885\n",
      "Epoch [1721/3000], Loss: 560.8884\n",
      "Validation Loss: 948.6931\n",
      "Epoch [1741/3000], Loss: 544.7254\n",
      "Validation Loss: 935.1960\n",
      "Epoch [1761/3000], Loss: 523.5026\n",
      "Validation Loss: 912.7182\n",
      "Epoch [1781/3000], Loss: 510.1359\n",
      "Validation Loss: 902.2026\n",
      "Epoch [1801/3000], Loss: 492.6652\n",
      "Validation Loss: 878.3521\n",
      "Epoch [1821/3000], Loss: 473.3813\n",
      "Validation Loss: 869.3030\n",
      "Epoch [1841/3000], Loss: 461.6022\n",
      "Validation Loss: 855.7032\n",
      "Epoch [1861/3000], Loss: 446.8266\n",
      "Validation Loss: 834.9093\n",
      "Epoch [1881/3000], Loss: 432.2043\n",
      "Validation Loss: 825.3722\n",
      "Epoch [1901/3000], Loss: 415.0524\n",
      "Validation Loss: 806.5024\n",
      "Epoch [1921/3000], Loss: 403.4947\n",
      "Validation Loss: 793.7641\n",
      "Epoch [1941/3000], Loss: 388.8543\n",
      "Validation Loss: 779.8249\n",
      "Epoch [1961/3000], Loss: 374.2529\n",
      "Validation Loss: 766.2760\n",
      "Epoch [1981/3000], Loss: 361.9232\n",
      "Validation Loss: 750.0575\n",
      "Epoch [2001/3000], Loss: 348.5666\n",
      "Validation Loss: 742.9610\n",
      "Epoch [2021/3000], Loss: 335.4912\n",
      "Validation Loss: 730.3017\n",
      "Epoch [2041/3000], Loss: 322.1208\n",
      "Validation Loss: 727.6879\n",
      "Epoch [2061/3000], Loss: 309.6109\n",
      "Validation Loss: 714.1140\n",
      "Epoch [2081/3000], Loss: 290.9458\n",
      "Validation Loss: 732.3907\n",
      "Epoch [2101/3000], Loss: 279.7768\n",
      "Validation Loss: 715.2988\n",
      "Epoch [2121/3000], Loss: 268.0368\n",
      "Validation Loss: 704.0391\n",
      "Epoch [2141/3000], Loss: 255.7237\n",
      "Validation Loss: 705.6063\n",
      "Epoch [2161/3000], Loss: 247.3209\n",
      "Validation Loss: 671.9914\n",
      "Epoch [2181/3000], Loss: 236.1224\n",
      "Validation Loss: 682.4297\n",
      "Epoch [2201/3000], Loss: 223.0123\n",
      "Validation Loss: 635.5426\n",
      "Epoch [2221/3000], Loss: 213.3919\n",
      "Validation Loss: 655.6073\n",
      "Epoch [2241/3000], Loss: 203.2888\n",
      "Validation Loss: 645.1550\n",
      "Epoch [2261/3000], Loss: 195.0798\n",
      "Validation Loss: 616.9016\n",
      "Epoch [2281/3000], Loss: 185.4593\n",
      "Validation Loss: 605.5757\n",
      "Epoch [2301/3000], Loss: 177.2748\n",
      "Validation Loss: 590.1960\n",
      "Epoch [2321/3000], Loss: 168.2586\n",
      "Validation Loss: 601.5687\n",
      "Epoch [2341/3000], Loss: 160.6203\n",
      "Validation Loss: 582.2321\n",
      "Epoch [2361/3000], Loss: 152.8495\n",
      "Validation Loss: 578.7460\n",
      "Epoch [2381/3000], Loss: 145.3170\n",
      "Validation Loss: 574.2621\n",
      "Epoch [2401/3000], Loss: 138.1909\n",
      "Validation Loss: 562.5954\n",
      "Epoch [2421/3000], Loss: 131.0752\n",
      "Validation Loss: 555.7235\n",
      "Epoch [2441/3000], Loss: 124.4453\n",
      "Validation Loss: 546.0741\n",
      "Epoch [2461/3000], Loss: 118.3323\n",
      "Validation Loss: 544.3312\n",
      "Epoch [2481/3000], Loss: 112.5900\n",
      "Validation Loss: 538.5973\n",
      "Epoch [2501/3000], Loss: 106.7726\n",
      "Validation Loss: 526.8724\n",
      "Epoch [2521/3000], Loss: 101.2560\n",
      "Validation Loss: 525.7881\n",
      "Epoch [2541/3000], Loss: 95.7587\n",
      "Validation Loss: 522.1484\n",
      "Epoch [2561/3000], Loss: 90.7984\n",
      "Validation Loss: 529.8592\n",
      "Epoch [2581/3000], Loss: 85.7638\n",
      "Validation Loss: 519.8453\n",
      "Epoch [2601/3000], Loss: 81.0242\n",
      "Validation Loss: 511.6153\n",
      "Epoch [2621/3000], Loss: 76.4332\n",
      "Validation Loss: 509.3089\n",
      "Epoch [2641/3000], Loss: 71.3057\n",
      "Validation Loss: 506.4334\n",
      "Epoch [2661/3000], Loss: 67.7327\n",
      "Validation Loss: 511.0027\n",
      "Epoch [2681/3000], Loss: 63.6776\n",
      "Validation Loss: 503.3744\n",
      "Epoch [2701/3000], Loss: 60.1826\n",
      "Validation Loss: 507.4353\n",
      "Epoch [2721/3000], Loss: 56.3768\n",
      "Validation Loss: 504.3285\n",
      "Epoch [2741/3000], Loss: 53.2812\n",
      "Validation Loss: 498.8153\n",
      "Epoch [2761/3000], Loss: 50.1405\n",
      "Validation Loss: 492.7624\n",
      "Epoch [2781/3000], Loss: 47.0590\n",
      "Validation Loss: 487.6969\n",
      "Epoch [2801/3000], Loss: 43.8157\n",
      "Validation Loss: 498.8248\n",
      "Epoch [2821/3000], Loss: 40.8515\n",
      "Validation Loss: 491.5544\n",
      "Epoch [2841/3000], Loss: 38.0441\n",
      "Validation Loss: 500.6633\n",
      "Epoch [2861/3000], Loss: 35.3105\n",
      "Validation Loss: 488.8814\n",
      "Epoch [2881/3000], Loss: 32.9918\n",
      "Validation Loss: 497.4061\n",
      "Epoch [2901/3000], Loss: 30.8188\n",
      "Validation Loss: 479.3017\n",
      "Epoch [2921/3000], Loss: 28.6512\n",
      "Validation Loss: 481.8341\n",
      "Epoch [2941/3000], Loss: 26.6786\n",
      "Validation Loss: 489.1691\n",
      "Epoch [2961/3000], Loss: 24.7072\n",
      "Validation Loss: 484.4570\n",
      "Epoch [2981/3000], Loss: 23.1146\n",
      "Validation Loss: 480.8365\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day041_plane0_Fall.mat\n",
      "(7315, 207)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 7886.0241\n",
      "Validation Loss: 8081.6704\n",
      "Epoch [21/3000], Loss: 6660.9297\n",
      "Validation Loss: 6868.1020\n",
      "Epoch [41/3000], Loss: 6426.2953\n",
      "Validation Loss: 6623.3256\n",
      "Epoch [61/3000], Loss: 6240.2484\n",
      "Validation Loss: 6437.2101\n",
      "Epoch [81/3000], Loss: 6046.4156\n",
      "Validation Loss: 6267.2198\n",
      "Epoch [101/3000], Loss: 5889.5463\n",
      "Validation Loss: 6109.0715\n",
      "Epoch [121/3000], Loss: 5731.8296\n",
      "Validation Loss: 5957.5040\n",
      "Epoch [141/3000], Loss: 5613.8073\n",
      "Validation Loss: 5811.2058\n",
      "Epoch [161/3000], Loss: 5460.8090\n",
      "Validation Loss: 5670.0888\n",
      "Epoch [181/3000], Loss: 5323.9921\n",
      "Validation Loss: 5533.5701\n",
      "Epoch [201/3000], Loss: 5205.9173\n",
      "Validation Loss: 5401.3002\n",
      "Epoch [221/3000], Loss: 5061.4273\n",
      "Validation Loss: 5273.0765\n",
      "Epoch [241/3000], Loss: 4944.3313\n",
      "Validation Loss: 5148.9008\n",
      "Epoch [261/3000], Loss: 4800.3005\n",
      "Validation Loss: 5028.6781\n",
      "Epoch [281/3000], Loss: 4683.6862\n",
      "Validation Loss: 4912.3596\n",
      "Epoch [301/3000], Loss: 4585.1063\n",
      "Validation Loss: 4799.9235\n",
      "Epoch [321/3000], Loss: 4486.2423\n",
      "Validation Loss: 4691.3974\n",
      "Epoch [341/3000], Loss: 4374.1849\n",
      "Validation Loss: 4586.5744\n",
      "Epoch [361/3000], Loss: 4265.3628\n",
      "Validation Loss: 4485.6931\n",
      "Epoch [381/3000], Loss: 4161.9802\n",
      "Validation Loss: 4388.5254\n",
      "Epoch [401/3000], Loss: 4083.8261\n",
      "Validation Loss: 4295.2991\n",
      "Epoch [421/3000], Loss: 3996.8149\n",
      "Validation Loss: 4205.7309\n",
      "Epoch [441/3000], Loss: 3908.2206\n",
      "Validation Loss: 4120.0447\n",
      "Epoch [461/3000], Loss: 3825.8560\n",
      "Validation Loss: 4037.9946\n",
      "Epoch [481/3000], Loss: 3741.4505\n",
      "Validation Loss: 3959.7396\n",
      "Epoch [501/3000], Loss: 3649.7448\n",
      "Validation Loss: 3885.1893\n",
      "Epoch [521/3000], Loss: 3599.0702\n",
      "Validation Loss: 3814.3142\n",
      "Epoch [541/3000], Loss: 3522.4361\n",
      "Validation Loss: 3747.1905\n",
      "Epoch [561/3000], Loss: 3463.0609\n",
      "Validation Loss: 3683.8198\n",
      "Epoch [581/3000], Loss: 3413.6506\n",
      "Validation Loss: 3624.0299\n",
      "Epoch [601/3000], Loss: 3348.3189\n",
      "Validation Loss: 3566.7738\n",
      "Epoch [621/3000], Loss: 3293.1492\n",
      "Validation Loss: 3513.8945\n",
      "Epoch [641/3000], Loss: 3245.7769\n",
      "Validation Loss: 3464.7745\n",
      "Epoch [661/3000], Loss: 3190.6356\n",
      "Validation Loss: 3419.3159\n",
      "Epoch [681/3000], Loss: 3140.4072\n",
      "Validation Loss: 3377.2895\n",
      "Epoch [701/3000], Loss: 3102.5159\n",
      "Validation Loss: 3338.8051\n",
      "Epoch [721/3000], Loss: 3070.9547\n",
      "Validation Loss: 3303.7552\n",
      "Epoch [741/3000], Loss: 3047.1117\n",
      "Validation Loss: 3272.1036\n",
      "Epoch [761/3000], Loss: 3015.7003\n",
      "Validation Loss: 3243.7762\n",
      "Epoch [781/3000], Loss: 2641.5658\n",
      "Validation Loss: 2791.4205\n",
      "Epoch [801/3000], Loss: 2033.6603\n",
      "Validation Loss: 2148.8491\n",
      "Epoch [821/3000], Loss: 1895.3623\n",
      "Validation Loss: 2056.0403\n",
      "Epoch [841/3000], Loss: 1803.2559\n",
      "Validation Loss: 1974.7319\n",
      "Epoch [861/3000], Loss: 1727.6930\n",
      "Validation Loss: 1900.6853\n",
      "Epoch [881/3000], Loss: 1647.5427\n",
      "Validation Loss: 1836.3715\n",
      "Epoch [901/3000], Loss: 1590.8782\n",
      "Validation Loss: 1782.0350\n",
      "Epoch [921/3000], Loss: 1515.0531\n",
      "Validation Loss: 1713.4368\n",
      "Epoch [941/3000], Loss: 1465.6965\n",
      "Validation Loss: 1647.5761\n",
      "Epoch [961/3000], Loss: 1402.7796\n",
      "Validation Loss: 1587.4866\n",
      "Epoch [981/3000], Loss: 1328.4019\n",
      "Validation Loss: 1524.3789\n",
      "Epoch [1001/3000], Loss: 1266.2170\n",
      "Validation Loss: 1478.1350\n",
      "Epoch [1021/3000], Loss: 1206.7844\n",
      "Validation Loss: 1432.7251\n",
      "Epoch [1041/3000], Loss: 1155.6551\n",
      "Validation Loss: 1383.9141\n",
      "Epoch [1061/3000], Loss: 1109.0489\n",
      "Validation Loss: 1334.2063\n",
      "Epoch [1081/3000], Loss: 1059.9369\n",
      "Validation Loss: 1280.1371\n",
      "Epoch [1101/3000], Loss: 1007.7745\n",
      "Validation Loss: 1231.5332\n",
      "Epoch [1121/3000], Loss: 964.3476\n",
      "Validation Loss: 1183.8642\n",
      "Epoch [1141/3000], Loss: 922.0966\n",
      "Validation Loss: 1148.7299\n",
      "Epoch [1161/3000], Loss: 875.3322\n",
      "Validation Loss: 1110.1395\n",
      "Epoch [1181/3000], Loss: 839.4061\n",
      "Validation Loss: 1057.9224\n",
      "Epoch [1201/3000], Loss: 803.4011\n",
      "Validation Loss: 1024.8078\n",
      "Epoch [1221/3000], Loss: 755.7210\n",
      "Validation Loss: 988.4274\n",
      "Epoch [1241/3000], Loss: 729.4500\n",
      "Validation Loss: 949.7683\n",
      "Epoch [1261/3000], Loss: 692.0651\n",
      "Validation Loss: 917.0841\n",
      "Epoch [1281/3000], Loss: 660.2868\n",
      "Validation Loss: 881.9817\n",
      "Epoch [1301/3000], Loss: 625.2237\n",
      "Validation Loss: 857.2137\n",
      "Epoch [1321/3000], Loss: 591.0378\n",
      "Validation Loss: 816.6258\n",
      "Epoch [1341/3000], Loss: 562.3264\n",
      "Validation Loss: 795.6158\n",
      "Epoch [1361/3000], Loss: 531.3978\n",
      "Validation Loss: 771.4393\n",
      "Epoch [1381/3000], Loss: 509.1127\n",
      "Validation Loss: 749.5968\n",
      "Epoch [1401/3000], Loss: 485.9892\n",
      "Validation Loss: 725.5947\n",
      "Epoch [1421/3000], Loss: 458.9306\n",
      "Validation Loss: 706.4184\n",
      "Epoch [1441/3000], Loss: 437.3377\n",
      "Validation Loss: 687.2983\n",
      "Epoch [1461/3000], Loss: 407.9789\n",
      "Validation Loss: 678.5513\n",
      "Epoch [1481/3000], Loss: 386.5174\n",
      "Validation Loss: 668.4239\n",
      "Epoch [1501/3000], Loss: 366.7113\n",
      "Validation Loss: 656.9767\n",
      "Epoch [1521/3000], Loss: 343.1326\n",
      "Validation Loss: 645.9142\n",
      "Epoch [1541/3000], Loss: 323.7975\n",
      "Validation Loss: 633.1099\n",
      "Epoch [1561/3000], Loss: 305.1754\n",
      "Validation Loss: 621.4240\n",
      "Epoch [1581/3000], Loss: 286.8506\n",
      "Validation Loss: 603.2867\n",
      "Epoch [1601/3000], Loss: 269.1430\n",
      "Validation Loss: 590.3112\n",
      "Epoch [1621/3000], Loss: 256.0050\n",
      "Validation Loss: 575.3469\n",
      "Epoch [1641/3000], Loss: 239.2743\n",
      "Validation Loss: 556.5601\n",
      "Epoch [1661/3000], Loss: 225.0145\n",
      "Validation Loss: 548.4517\n",
      "Epoch [1681/3000], Loss: 212.3178\n",
      "Validation Loss: 519.3793\n",
      "Epoch [1701/3000], Loss: 198.0206\n",
      "Validation Loss: 508.4834\n",
      "Epoch [1721/3000], Loss: 187.7805\n",
      "Validation Loss: 501.6647\n",
      "Epoch [1741/3000], Loss: 177.8196\n",
      "Validation Loss: 492.2164\n",
      "Epoch [1761/3000], Loss: 166.9471\n",
      "Validation Loss: 480.7252\n",
      "Epoch [1781/3000], Loss: 156.0797\n",
      "Validation Loss: 472.5783\n",
      "Epoch [1801/3000], Loss: 145.8527\n",
      "Validation Loss: 467.0135\n",
      "Epoch [1821/3000], Loss: 136.4484\n",
      "Validation Loss: 465.4005\n",
      "Epoch [1841/3000], Loss: 128.9664\n",
      "Validation Loss: 464.0310\n",
      "Epoch [1861/3000], Loss: 120.0387\n",
      "Validation Loss: 464.1208\n",
      "Epoch [1881/3000], Loss: 110.4767\n",
      "Validation Loss: 448.5378\n",
      "Epoch [1901/3000], Loss: 104.7412\n",
      "Validation Loss: 439.3300\n",
      "Epoch [1921/3000], Loss: 97.3090\n",
      "Validation Loss: 436.3930\n",
      "Epoch [1941/3000], Loss: 90.5124\n",
      "Validation Loss: 433.9455\n",
      "Epoch [1961/3000], Loss: 83.9873\n",
      "Validation Loss: 430.9188\n",
      "Epoch [1981/3000], Loss: 76.9069\n",
      "Validation Loss: 430.2356\n",
      "Epoch [2001/3000], Loss: 70.5407\n",
      "Validation Loss: 427.6040\n",
      "Epoch [2021/3000], Loss: 64.0156\n",
      "Validation Loss: 430.2086\n",
      "Epoch [2041/3000], Loss: 58.4163\n",
      "Validation Loss: 436.2894\n",
      "Epoch [2061/3000], Loss: 53.1429\n",
      "Validation Loss: 430.1221\n",
      "Epoch [2081/3000], Loss: 47.9480\n",
      "Validation Loss: 431.6063\n",
      "Epoch [2101/3000], Loss: 72.6294\n",
      "Validation Loss: 435.6403\n",
      "Epoch [2121/3000], Loss: 38.8475\n",
      "Validation Loss: 417.9255\n",
      "Epoch [2141/3000], Loss: 34.6565\n",
      "Validation Loss: 420.1468\n",
      "Epoch [2161/3000], Loss: 30.7238\n",
      "Validation Loss: 420.9669\n",
      "Epoch [2181/3000], Loss: 27.3605\n",
      "Validation Loss: 421.8129\n",
      "Epoch [2201/3000], Loss: 24.2341\n",
      "Validation Loss: 419.9926\n",
      "Epoch [2221/3000], Loss: 21.1762\n",
      "Validation Loss: 421.5073\n",
      "Epoch [2241/3000], Loss: 18.3635\n",
      "Validation Loss: 425.4910\n",
      "Epoch [2261/3000], Loss: 15.9977\n",
      "Validation Loss: 429.5355\n",
      "Epoch [2281/3000], Loss: 13.6188\n",
      "Validation Loss: 424.9739\n",
      "Epoch [2301/3000], Loss: 11.8763\n",
      "Validation Loss: 427.3077\n",
      "Epoch [2321/3000], Loss: 10.1672\n",
      "Validation Loss: 427.2430\n",
      "Epoch [2341/3000], Loss: 8.5580\n",
      "Validation Loss: 424.8462\n",
      "Epoch [2361/3000], Loss: 7.3018\n",
      "Validation Loss: 430.8363\n",
      "Epoch [2381/3000], Loss: 6.2151\n",
      "Validation Loss: 424.3563\n",
      "Epoch [2401/3000], Loss: 5.2318\n",
      "Validation Loss: 419.9723\n",
      "Epoch [2421/3000], Loss: 4.3577\n",
      "Validation Loss: 422.8183\n",
      "Epoch [2441/3000], Loss: 3.6471\n",
      "Validation Loss: 424.5933\n",
      "Epoch [2461/3000], Loss: 2.9875\n",
      "Validation Loss: 424.1446\n",
      "Epoch [2481/3000], Loss: 2.5431\n",
      "Validation Loss: 423.8322\n",
      "Epoch [2501/3000], Loss: 2.1042\n",
      "Validation Loss: 422.0930\n",
      "Epoch [2521/3000], Loss: 1.6766\n",
      "Validation Loss: 425.6497\n",
      "Epoch [2541/3000], Loss: 1.3262\n",
      "Validation Loss: 433.5177\n",
      "Epoch [2561/3000], Loss: 1.0691\n",
      "Validation Loss: 425.5683\n",
      "Epoch [2581/3000], Loss: 0.8522\n",
      "Validation Loss: 425.3569\n",
      "Epoch [2601/3000], Loss: 0.6661\n",
      "Validation Loss: 425.8618\n",
      "Epoch [2621/3000], Loss: 0.5672\n",
      "Validation Loss: 429.4830\n",
      "Epoch [2641/3000], Loss: 0.4278\n",
      "Validation Loss: 430.5174\n",
      "Epoch [2661/3000], Loss: 0.3660\n",
      "Validation Loss: 433.1313\n",
      "Epoch [2681/3000], Loss: 0.2988\n",
      "Validation Loss: 435.0376\n",
      "Epoch [2701/3000], Loss: 0.2849\n",
      "Validation Loss: 434.5751\n",
      "Epoch [2721/3000], Loss: 0.2324\n",
      "Validation Loss: 438.5755\n",
      "Epoch [2741/3000], Loss: 0.2491\n",
      "Validation Loss: 440.9404\n",
      "Epoch [2761/3000], Loss: 0.1817\n",
      "Validation Loss: 441.0581\n",
      "Epoch [2781/3000], Loss: 0.1936\n",
      "Validation Loss: 443.1057\n",
      "Epoch [2801/3000], Loss: 0.1558\n",
      "Validation Loss: 441.4994\n",
      "Epoch [2821/3000], Loss: 0.1600\n",
      "Validation Loss: 442.5110\n",
      "Epoch [2841/3000], Loss: 0.1473\n",
      "Validation Loss: 442.7657\n",
      "Epoch [2861/3000], Loss: 0.1413\n",
      "Validation Loss: 444.4447\n",
      "Epoch [2881/3000], Loss: 0.1223\n",
      "Validation Loss: 445.5908\n",
      "Epoch [2901/3000], Loss: 0.1131\n",
      "Validation Loss: 446.9593\n",
      "Epoch [2921/3000], Loss: 0.1069\n",
      "Validation Loss: 447.9510\n",
      "Epoch [2941/3000], Loss: 0.1021\n",
      "Validation Loss: 447.7671\n",
      "Epoch [2961/3000], Loss: 0.1078\n",
      "Validation Loss: 448.5616\n",
      "Epoch [2981/3000], Loss: 0.1294\n",
      "Validation Loss: 450.9146\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day042_plane0_Fall.mat\n",
      "(5497, 140)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 8292.5012\n",
      "Validation Loss: 7054.5666\n",
      "Epoch [21/3000], Loss: 7165.9770\n",
      "Validation Loss: 6051.8728\n",
      "Epoch [41/3000], Loss: 6946.3041\n",
      "Validation Loss: 5827.2468\n",
      "Epoch [61/3000], Loss: 6766.2370\n",
      "Validation Loss: 5681.1161\n",
      "Epoch [81/3000], Loss: 6619.2887\n",
      "Validation Loss: 5553.4611\n",
      "Epoch [101/3000], Loss: 6488.1161\n",
      "Validation Loss: 5436.2947\n",
      "Epoch [121/3000], Loss: 6377.0031\n",
      "Validation Loss: 5324.9913\n",
      "Epoch [141/3000], Loss: 6249.7979\n",
      "Validation Loss: 5217.9871\n",
      "Epoch [161/3000], Loss: 6144.9642\n",
      "Validation Loss: 5114.4474\n",
      "Epoch [181/3000], Loss: 6011.3456\n",
      "Validation Loss: 5013.7137\n",
      "Epoch [201/3000], Loss: 5906.2480\n",
      "Validation Loss: 4915.9224\n",
      "Epoch [221/3000], Loss: 5784.0875\n",
      "Validation Loss: 4820.5495\n",
      "Epoch [241/3000], Loss: 5702.1682\n",
      "Validation Loss: 4727.6911\n",
      "Epoch [261/3000], Loss: 5574.8290\n",
      "Validation Loss: 4635.0836\n",
      "Epoch [281/3000], Loss: 5481.0908\n",
      "Validation Loss: 4546.2852\n",
      "Epoch [301/3000], Loss: 5367.7513\n",
      "Validation Loss: 4459.9189\n",
      "Epoch [321/3000], Loss: 5316.6651\n",
      "Validation Loss: 4375.8724\n",
      "Epoch [341/3000], Loss: 5206.0196\n",
      "Validation Loss: 4294.0444\n",
      "Epoch [361/3000], Loss: 5107.4751\n",
      "Validation Loss: 4214.3627\n",
      "Epoch [381/3000], Loss: 5027.2272\n",
      "Validation Loss: 4136.9254\n",
      "Epoch [401/3000], Loss: 4957.9069\n",
      "Validation Loss: 4061.6702\n",
      "Epoch [421/3000], Loss: 4851.4129\n",
      "Validation Loss: 3988.6635\n",
      "Epoch [441/3000], Loss: 4781.6364\n",
      "Validation Loss: 3917.7729\n",
      "Epoch [461/3000], Loss: 4694.3156\n",
      "Validation Loss: 3848.9947\n",
      "Epoch [481/3000], Loss: 4615.2990\n",
      "Validation Loss: 3782.4041\n",
      "Epoch [501/3000], Loss: 4550.2666\n",
      "Validation Loss: 3717.8835\n",
      "Epoch [521/3000], Loss: 4464.9159\n",
      "Validation Loss: 3655.5481\n",
      "Epoch [541/3000], Loss: 4396.0310\n",
      "Validation Loss: 3595.3932\n",
      "Epoch [561/3000], Loss: 4325.2270\n",
      "Validation Loss: 3537.3369\n",
      "Epoch [581/3000], Loss: 4261.2128\n",
      "Validation Loss: 3481.3779\n",
      "Epoch [601/3000], Loss: 4195.6401\n",
      "Validation Loss: 3427.6167\n",
      "Epoch [621/3000], Loss: 4092.5469\n",
      "Validation Loss: 3375.8881\n",
      "Epoch [641/3000], Loss: 4072.7297\n",
      "Validation Loss: 3326.2434\n",
      "Epoch [661/3000], Loss: 4020.0186\n",
      "Validation Loss: 3278.7839\n",
      "Epoch [681/3000], Loss: 3953.3321\n",
      "Validation Loss: 3233.2658\n",
      "Epoch [701/3000], Loss: 3908.7506\n",
      "Validation Loss: 3189.8040\n",
      "Epoch [721/3000], Loss: 3848.9329\n",
      "Validation Loss: 3148.5455\n",
      "Epoch [741/3000], Loss: 3807.2478\n",
      "Validation Loss: 3109.2749\n",
      "Epoch [761/3000], Loss: 3753.7476\n",
      "Validation Loss: 3071.9773\n",
      "Epoch [781/3000], Loss: 3709.0739\n",
      "Validation Loss: 3036.7460\n",
      "Epoch [801/3000], Loss: 3666.6679\n",
      "Validation Loss: 3003.5638\n",
      "Epoch [821/3000], Loss: 3631.9291\n",
      "Validation Loss: 2972.3419\n",
      "Epoch [841/3000], Loss: 3589.4564\n",
      "Validation Loss: 2943.1078\n",
      "Epoch [861/3000], Loss: 3534.8015\n",
      "Validation Loss: 2915.8586\n",
      "Epoch [881/3000], Loss: 3508.2058\n",
      "Validation Loss: 2890.6117\n",
      "Epoch [901/3000], Loss: 3489.9190\n",
      "Validation Loss: 2867.2292\n",
      "Epoch [921/3000], Loss: 3439.5044\n",
      "Validation Loss: 2845.7998\n",
      "Epoch [941/3000], Loss: 3418.3852\n",
      "Validation Loss: 2826.2258\n",
      "Epoch [961/3000], Loss: 3383.8317\n",
      "Validation Loss: 2808.4508\n",
      "Epoch [981/3000], Loss: 3366.0878\n",
      "Validation Loss: 2792.5588\n",
      "Epoch [1001/3000], Loss: 3336.3310\n",
      "Validation Loss: 2778.4678\n",
      "Epoch [1021/3000], Loss: 3324.6112\n",
      "Validation Loss: 2766.1385\n",
      "Epoch [1041/3000], Loss: 3286.6138\n",
      "Validation Loss: 2755.4348\n",
      "Epoch [1061/3000], Loss: 3282.2781\n",
      "Validation Loss: 2746.4700\n",
      "Epoch [1081/3000], Loss: 3261.8365\n",
      "Validation Loss: 2739.0422\n",
      "Epoch [1101/3000], Loss: 3246.8014\n",
      "Validation Loss: 2733.1307\n",
      "Epoch [1121/3000], Loss: 3237.3890\n",
      "Validation Loss: 2728.6798\n",
      "Epoch [1141/3000], Loss: 3227.7556\n",
      "Validation Loss: 2725.5895\n",
      "Epoch [1161/3000], Loss: 3200.8002\n",
      "Validation Loss: 2723.7794\n",
      "Epoch [1181/3000], Loss: 3207.8108\n",
      "Validation Loss: 2723.1238\n",
      "Epoch [1201/3000], Loss: 3189.6570\n",
      "Validation Loss: 2723.4916\n",
      "Epoch [1221/3000], Loss: 3194.6707\n",
      "Validation Loss: 2724.7356\n",
      "Epoch [1241/3000], Loss: 3188.0533\n",
      "Validation Loss: 2726.6756\n",
      "Epoch [1261/3000], Loss: 3182.8337\n",
      "Validation Loss: 2729.0997\n",
      "Epoch [1281/3000], Loss: 3167.8106\n",
      "Validation Loss: 2731.8378\n",
      "Epoch [1301/3000], Loss: 3178.3899\n",
      "Validation Loss: 2734.7447\n",
      "Epoch [1321/3000], Loss: 3174.0195\n",
      "Validation Loss: 2737.6660\n",
      "Epoch [1341/3000], Loss: 3181.6936\n",
      "Validation Loss: 2740.3381\n",
      "Epoch [1361/3000], Loss: 3168.8360\n",
      "Validation Loss: 2742.8673\n",
      "Epoch [1381/3000], Loss: 3180.9124\n",
      "Validation Loss: 2745.0035\n",
      "Epoch [1401/3000], Loss: 3164.6173\n",
      "Validation Loss: 2746.8027\n",
      "Epoch [1421/3000], Loss: 3165.2409\n",
      "Validation Loss: 2748.2047\n",
      "Epoch [1441/3000], Loss: 3183.3729\n",
      "Validation Loss: 2749.3268\n",
      "Epoch [1461/3000], Loss: 3165.3402\n",
      "Validation Loss: 2750.1137\n",
      "Epoch [1481/3000], Loss: 3171.9585\n",
      "Validation Loss: 2750.8729\n",
      "Epoch [1501/3000], Loss: 3181.6875\n",
      "Validation Loss: 2751.2621\n",
      "Epoch [1521/3000], Loss: 3171.7673\n",
      "Validation Loss: 2751.6170\n",
      "Epoch [1541/3000], Loss: 3179.6825\n",
      "Validation Loss: 2751.9254\n",
      "Epoch [1561/3000], Loss: 3174.6948\n",
      "Validation Loss: 2752.0802\n",
      "Epoch [1581/3000], Loss: 3170.4188\n",
      "Validation Loss: 2752.1943\n",
      "Epoch [1601/3000], Loss: 3165.3173\n",
      "Validation Loss: 2752.4802\n",
      "Epoch [1621/3000], Loss: 3171.4393\n",
      "Validation Loss: 2752.5743\n",
      "Epoch [1641/3000], Loss: 3179.1553\n",
      "Validation Loss: 2752.5941\n",
      "Epoch [1661/3000], Loss: 3178.1436\n",
      "Validation Loss: 2752.6270\n",
      "Epoch [1681/3000], Loss: 3175.1277\n",
      "Validation Loss: 2752.6490\n",
      "Epoch [1701/3000], Loss: 3168.1471\n",
      "Validation Loss: 2752.5922\n",
      "Epoch [1721/3000], Loss: 3170.7004\n",
      "Validation Loss: 2752.6864\n",
      "Epoch [1741/3000], Loss: 3169.4822\n",
      "Validation Loss: 2752.6851\n",
      "Epoch [1761/3000], Loss: 3169.6352\n",
      "Validation Loss: 2752.7960\n",
      "Epoch [1781/3000], Loss: 3169.2763\n",
      "Validation Loss: 2752.6937\n",
      "Epoch [1801/3000], Loss: 3170.8488\n",
      "Validation Loss: 2752.6395\n",
      "Epoch [1821/3000], Loss: 3186.8216\n",
      "Validation Loss: 2752.7942\n",
      "Epoch [1841/3000], Loss: 3165.9966\n",
      "Validation Loss: 2752.6702\n",
      "Epoch [1861/3000], Loss: 3174.8817\n",
      "Validation Loss: 2752.6706\n",
      "Epoch [1881/3000], Loss: 3172.5730\n",
      "Validation Loss: 2752.6399\n",
      "Epoch [1901/3000], Loss: 3177.4442\n",
      "Validation Loss: 2752.6861\n",
      "Epoch [1921/3000], Loss: 3170.2728\n",
      "Validation Loss: 2752.5347\n",
      "Epoch [1941/3000], Loss: 3174.9160\n",
      "Validation Loss: 2752.4987\n",
      "Epoch [1961/3000], Loss: 3172.9960\n",
      "Validation Loss: 2752.4035\n",
      "Epoch [1981/3000], Loss: 3172.2576\n",
      "Validation Loss: 2752.5094\n",
      "Epoch [2001/3000], Loss: 3162.1886\n",
      "Validation Loss: 2752.4691\n",
      "Epoch [2021/3000], Loss: 3168.3440\n",
      "Validation Loss: 2752.5721\n",
      "Epoch [2041/3000], Loss: 3166.3229\n",
      "Validation Loss: 2752.5791\n",
      "Epoch [2061/3000], Loss: 3175.5075\n",
      "Validation Loss: 2752.7060\n",
      "Epoch [2081/3000], Loss: 3182.5734\n",
      "Validation Loss: 2752.6182\n",
      "Epoch [2101/3000], Loss: 3165.0060\n",
      "Validation Loss: 2752.6460\n",
      "Epoch [2121/3000], Loss: 3182.1978\n",
      "Validation Loss: 2752.5184\n",
      "Epoch [2141/3000], Loss: 3164.3660\n",
      "Validation Loss: 2752.4620\n",
      "Epoch [2161/3000], Loss: 3167.9904\n",
      "Validation Loss: 2752.4933\n",
      "Epoch [2181/3000], Loss: 3179.5839\n",
      "Validation Loss: 2752.4700\n",
      "Epoch [2201/3000], Loss: 3175.6900\n",
      "Validation Loss: 2752.5437\n",
      "Epoch [2221/3000], Loss: 3171.2016\n",
      "Validation Loss: 2752.5661\n",
      "Epoch [2241/3000], Loss: 3181.2707\n",
      "Validation Loss: 2752.5938\n",
      "Epoch [2261/3000], Loss: 3169.0265\n",
      "Validation Loss: 2752.6220\n",
      "Epoch [2281/3000], Loss: 3171.6872\n",
      "Validation Loss: 2752.6417\n",
      "Epoch [2301/3000], Loss: 3181.1802\n",
      "Validation Loss: 2752.7335\n",
      "Epoch [2321/3000], Loss: 3176.0118\n",
      "Validation Loss: 2752.7185\n",
      "Epoch [2341/3000], Loss: 3172.3861\n",
      "Validation Loss: 2752.7050\n",
      "Epoch [2361/3000], Loss: 3173.7109\n",
      "Validation Loss: 2752.6947\n",
      "Epoch [2381/3000], Loss: 3162.0341\n",
      "Validation Loss: 2752.6479\n",
      "Epoch [2401/3000], Loss: 3179.7645\n",
      "Validation Loss: 2752.5596\n",
      "Epoch [2421/3000], Loss: 3179.2169\n",
      "Validation Loss: 2752.5098\n",
      "Epoch [2441/3000], Loss: 3166.3450\n",
      "Validation Loss: 2752.4612\n",
      "Epoch [2461/3000], Loss: 3168.7869\n",
      "Validation Loss: 2752.5807\n",
      "Epoch [2481/3000], Loss: 3164.2576\n",
      "Validation Loss: 2752.6182\n",
      "Epoch [2501/3000], Loss: 3165.7180\n",
      "Validation Loss: 2752.6258\n",
      "Epoch [2521/3000], Loss: 3171.1041\n",
      "Validation Loss: 2752.6105\n",
      "Epoch [2541/3000], Loss: 3184.9208\n",
      "Validation Loss: 2752.5396\n",
      "Epoch [2561/3000], Loss: 3182.9751\n",
      "Validation Loss: 2752.6006\n",
      "Epoch [2581/3000], Loss: 3165.3580\n",
      "Validation Loss: 2752.5720\n",
      "Epoch [2601/3000], Loss: 3168.4188\n",
      "Validation Loss: 2752.3850\n",
      "Epoch [2621/3000], Loss: 3174.1596\n",
      "Validation Loss: 2752.3532\n",
      "Epoch [2641/3000], Loss: 3178.4207\n",
      "Validation Loss: 2752.4616\n",
      "Epoch [2661/3000], Loss: 3174.0355\n",
      "Validation Loss: 2752.4528\n",
      "Epoch [2681/3000], Loss: 3172.1110\n",
      "Validation Loss: 2752.5551\n",
      "Epoch [2701/3000], Loss: 3162.5556\n",
      "Validation Loss: 2752.3892\n",
      "Epoch [2721/3000], Loss: 3180.4907\n",
      "Validation Loss: 2752.4361\n",
      "Epoch [2741/3000], Loss: 3174.0400\n",
      "Validation Loss: 2752.6256\n",
      "Epoch [2761/3000], Loss: 3175.1775\n",
      "Validation Loss: 2752.6770\n",
      "Epoch [2781/3000], Loss: 3176.5884\n",
      "Validation Loss: 2752.5632\n",
      "Epoch [2801/3000], Loss: 3171.7721\n",
      "Validation Loss: 2752.6257\n",
      "Epoch [2821/3000], Loss: 3175.8343\n",
      "Validation Loss: 2752.5821\n",
      "Epoch [2841/3000], Loss: 3173.4035\n",
      "Validation Loss: 2752.6604\n",
      "Epoch [2861/3000], Loss: 3173.1615\n",
      "Validation Loss: 2752.6877\n",
      "Epoch [2881/3000], Loss: 3162.6720\n",
      "Validation Loss: 2752.6462\n",
      "Epoch [2901/3000], Loss: 3173.8245\n",
      "Validation Loss: 2752.5413\n",
      "Epoch [2921/3000], Loss: 3165.0455\n",
      "Validation Loss: 2752.5141\n",
      "Epoch [2941/3000], Loss: 3178.3870\n",
      "Validation Loss: 2752.6150\n",
      "Epoch [2961/3000], Loss: 3168.1528\n",
      "Validation Loss: 2752.6674\n",
      "Epoch [2981/3000], Loss: 3176.4448\n",
      "Validation Loss: 2752.5125\n",
      "Y:\\analysis\\fmats\\e189\\days\\e189_day044_plane0_Fall.mat\n",
      "(8471, 23)\n",
      "cuda:0\n",
      "Epoch [1/3000], Loss: 9163.7372\n",
      "Validation Loss: 8685.5481\n",
      "Epoch [21/3000], Loss: 7742.0316\n",
      "Validation Loss: 7316.1605\n",
      "Epoch [41/3000], Loss: 7448.0728\n",
      "Validation Loss: 7038.7653\n",
      "Epoch [61/3000], Loss: 7218.1752\n",
      "Validation Loss: 6816.9791\n",
      "Epoch [81/3000], Loss: 7002.5533\n",
      "Validation Loss: 6612.1704\n",
      "Epoch [101/3000], Loss: 6789.6264\n",
      "Validation Loss: 6417.5419\n",
      "Epoch [121/3000], Loss: 6595.8685\n",
      "Validation Loss: 6230.6749\n",
      "Epoch [141/3000], Loss: 6410.0481\n",
      "Validation Loss: 6049.9264\n",
      "Epoch [161/3000], Loss: 6218.9031\n",
      "Validation Loss: 5870.7084\n",
      "Epoch [181/3000], Loss: 6033.7705\n",
      "Validation Loss: 5700.2311\n",
      "Epoch [201/3000], Loss: 5863.9920\n",
      "Validation Loss: 5535.7924\n",
      "Epoch [221/3000], Loss: 5690.4284\n",
      "Validation Loss: 5376.9674\n",
      "Epoch [241/3000], Loss: 5528.2724\n",
      "Validation Loss: 5223.7614\n",
      "Epoch [261/3000], Loss: 5370.7901\n",
      "Validation Loss: 5075.7813\n",
      "Epoch [281/3000], Loss: 5223.8119\n",
      "Validation Loss: 4933.2285\n",
      "Epoch [301/3000], Loss: 5068.9894\n",
      "Validation Loss: 4796.0139\n",
      "Epoch [321/3000], Loss: 4929.2984\n",
      "Validation Loss: 4664.0915\n",
      "Epoch [341/3000], Loss: 4795.5515\n",
      "Validation Loss: 4537.4463\n",
      "Epoch [361/3000], Loss: 4661.1823\n",
      "Validation Loss: 4416.0769\n",
      "Epoch [381/3000], Loss: 4539.0554\n",
      "Validation Loss: 4300.0168\n",
      "Epoch [401/3000], Loss: 4415.6226\n",
      "Validation Loss: 4189.1231\n",
      "Epoch [421/3000], Loss: 4301.1937\n",
      "Validation Loss: 4083.4836\n",
      "Epoch [441/3000], Loss: 4190.3703\n",
      "Validation Loss: 3983.0348\n",
      "Epoch [461/3000], Loss: 4086.3188\n",
      "Validation Loss: 3887.8145\n",
      "Epoch [481/3000], Loss: 3987.5519\n",
      "Validation Loss: 3797.6726\n",
      "Epoch [501/3000], Loss: 3890.9959\n",
      "Validation Loss: 3712.7044\n",
      "Epoch [521/3000], Loss: 3803.4043\n",
      "Validation Loss: 3632.7939\n",
      "Epoch [541/3000], Loss: 3716.6041\n",
      "Validation Loss: 3557.9106\n",
      "Epoch [561/3000], Loss: 3636.1773\n",
      "Validation Loss: 3486.6755\n",
      "Epoch [581/3000], Loss: 3563.2508\n",
      "Validation Loss: 3421.7345\n",
      "Epoch [601/3000], Loss: 3494.0151\n",
      "Validation Loss: 3361.9052\n",
      "Epoch [621/3000], Loss: 3429.7801\n",
      "Validation Loss: 3306.9831\n",
      "Epoch [641/3000], Loss: 3369.2060\n",
      "Validation Loss: 3257.0011\n",
      "Epoch [661/3000], Loss: 3315.0389\n",
      "Validation Loss: 3211.8852\n",
      "Epoch [681/3000], Loss: 3267.2259\n",
      "Validation Loss: 3171.5119\n",
      "Epoch [701/3000], Loss: 3222.5354\n",
      "Validation Loss: 3135.7879\n",
      "Epoch [721/3000], Loss: 3180.8778\n",
      "Validation Loss: 3104.6908\n",
      "Epoch [741/3000], Loss: 3148.1470\n",
      "Validation Loss: 3077.9877\n",
      "Epoch [761/3000], Loss: 3116.7686\n",
      "Validation Loss: 3055.7055\n",
      "Epoch [781/3000], Loss: 3087.6468\n",
      "Validation Loss: 3037.5239\n",
      "Epoch [801/3000], Loss: 3068.3578\n",
      "Validation Loss: 3023.2165\n",
      "Epoch [821/3000], Loss: 3048.6134\n",
      "Validation Loss: 3012.5975\n",
      "Epoch [841/3000], Loss: 3033.2023\n",
      "Validation Loss: 3005.3028\n",
      "Epoch [861/3000], Loss: 2990.3956\n",
      "Validation Loss: 2978.9659\n",
      "Epoch [881/3000], Loss: 2900.7720\n",
      "Validation Loss: 2950.6588\n",
      "Epoch [901/3000], Loss: 2884.3851\n",
      "Validation Loss: 2940.2050\n",
      "Epoch [921/3000], Loss: 2815.8535\n",
      "Validation Loss: 2857.6259\n",
      "Epoch [941/3000], Loss: 2385.4126\n",
      "Validation Loss: 2351.2658\n",
      "Epoch [961/3000], Loss: 2217.1209\n",
      "Validation Loss: 2254.0156\n",
      "Epoch [981/3000], Loss: 2075.7718\n",
      "Validation Loss: 2184.6579\n",
      "Epoch [1001/3000], Loss: 1964.1339\n",
      "Validation Loss: 2121.2229\n",
      "Epoch [1021/3000], Loss: 1867.3750\n",
      "Validation Loss: 2075.3531\n",
      "Epoch [1041/3000], Loss: 1775.1735\n",
      "Validation Loss: 1996.2363\n",
      "Epoch [1061/3000], Loss: 1698.5234\n",
      "Validation Loss: 1964.7209\n",
      "Epoch [1081/3000], Loss: 1641.3638\n",
      "Validation Loss: 1923.3269\n",
      "Epoch [1101/3000], Loss: 1581.2264\n",
      "Validation Loss: 1919.2350\n",
      "Epoch [1121/3000], Loss: 1537.4192\n",
      "Validation Loss: 1897.2469\n",
      "Epoch [1141/3000], Loss: 1489.3740\n",
      "Validation Loss: 1866.7315\n",
      "Epoch [1161/3000], Loss: 1447.7360\n",
      "Validation Loss: 1860.0445\n",
      "Epoch [1181/3000], Loss: 1415.8306\n",
      "Validation Loss: 1839.3392\n",
      "Epoch [1201/3000], Loss: 1365.2720\n",
      "Validation Loss: 1821.6019\n",
      "Epoch [1221/3000], Loss: 1326.5989\n",
      "Validation Loss: 1835.5198\n",
      "Epoch [1241/3000], Loss: 1285.4656\n",
      "Validation Loss: 1797.2691\n",
      "Epoch [1261/3000], Loss: 1246.6629\n",
      "Validation Loss: 1813.2675\n",
      "Epoch [1281/3000], Loss: 1211.2647\n",
      "Validation Loss: 1798.8006\n",
      "Epoch [1301/3000], Loss: 1171.3234\n",
      "Validation Loss: 1798.4467\n",
      "Epoch [1321/3000], Loss: 1148.7735\n",
      "Validation Loss: 1828.0956\n",
      "Epoch [1341/3000], Loss: 1117.8894\n",
      "Validation Loss: 1783.5054\n",
      "Epoch [1361/3000], Loss: 1075.2523\n",
      "Validation Loss: 1796.7639\n",
      "Epoch [1381/3000], Loss: 1046.7969\n",
      "Validation Loss: 1806.5543\n",
      "Epoch [1401/3000], Loss: 1013.6924\n",
      "Validation Loss: 1824.3498\n",
      "Epoch [1421/3000], Loss: 985.3291\n",
      "Validation Loss: 1852.6695\n",
      "Epoch [1441/3000], Loss: 954.0571\n",
      "Validation Loss: 1858.5727\n",
      "Epoch [1461/3000], Loss: 932.4107\n",
      "Validation Loss: 1882.3859\n",
      "Epoch [1481/3000], Loss: 894.3036\n",
      "Validation Loss: 1950.0867\n",
      "Epoch [1501/3000], Loss: 862.6927\n",
      "Validation Loss: 1948.0326\n",
      "Epoch [1521/3000], Loss: 824.6884\n",
      "Validation Loss: 1952.5177\n",
      "Epoch [1541/3000], Loss: 793.2395\n",
      "Validation Loss: 1998.1288\n",
      "Epoch [1561/3000], Loss: 755.6378\n",
      "Validation Loss: 1977.7998\n",
      "Epoch [1581/3000], Loss: 733.9075\n",
      "Validation Loss: 1926.3093\n",
      "Epoch [1601/3000], Loss: 702.4753\n",
      "Validation Loss: 1977.8749\n",
      "Epoch [1621/3000], Loss: 665.1967\n",
      "Validation Loss: 1906.0837\n",
      "Epoch [1641/3000], Loss: 648.4516\n",
      "Validation Loss: 1951.5165\n",
      "Epoch [1661/3000], Loss: 618.5305\n",
      "Validation Loss: 1979.9321\n",
      "Epoch [1681/3000], Loss: 581.7242\n",
      "Validation Loss: 1967.1472\n",
      "Epoch [1701/3000], Loss: 572.8091\n",
      "Validation Loss: 1980.2392\n",
      "Epoch [1721/3000], Loss: 537.3449\n",
      "Validation Loss: 1935.0080\n",
      "Epoch [1741/3000], Loss: 512.0318\n",
      "Validation Loss: 1939.9306\n",
      "Epoch [1761/3000], Loss: 486.4334\n",
      "Validation Loss: 1985.5545\n",
      "Epoch [1781/3000], Loss: 473.6663\n",
      "Validation Loss: 1933.7329\n",
      "Epoch [1801/3000], Loss: 437.2749\n",
      "Validation Loss: 1994.6758\n",
      "Epoch [1821/3000], Loss: 424.0240\n",
      "Validation Loss: 1933.6343\n",
      "Epoch [1841/3000], Loss: 397.1861\n",
      "Validation Loss: 1979.1411\n",
      "Epoch [1861/3000], Loss: 375.4984\n",
      "Validation Loss: 1929.3671\n",
      "Epoch [1881/3000], Loss: 367.3202\n",
      "Validation Loss: 1978.0225\n",
      "Epoch [1901/3000], Loss: 338.4288\n",
      "Validation Loss: 1969.1362\n",
      "Epoch [1921/3000], Loss: 322.3249\n",
      "Validation Loss: 1980.9679\n",
      "Epoch [1941/3000], Loss: 316.0678\n",
      "Validation Loss: 1865.4164\n",
      "Epoch [1961/3000], Loss: 309.4545\n",
      "Validation Loss: 1932.8074\n",
      "Epoch [1981/3000], Loss: 283.4542\n",
      "Validation Loss: 1959.0354\n",
      "Epoch [2001/3000], Loss: 290.2935\n",
      "Validation Loss: 1902.9320\n",
      "Epoch [2021/3000], Loss: 252.2328\n",
      "Validation Loss: 1913.5840\n",
      "Epoch [2041/3000], Loss: 241.5300\n",
      "Validation Loss: 1928.5862\n",
      "Epoch [2061/3000], Loss: 231.1491\n",
      "Validation Loss: 1974.4207\n",
      "Epoch [2081/3000], Loss: 218.6501\n",
      "Validation Loss: 1881.3276\n",
      "Epoch [2101/3000], Loss: 212.9884\n",
      "Validation Loss: 1905.5893\n",
      "Epoch [2121/3000], Loss: 202.4877\n",
      "Validation Loss: 1945.5000\n",
      "Epoch [2141/3000], Loss: 191.8713\n",
      "Validation Loss: 1907.0859\n",
      "Epoch [2161/3000], Loss: 180.8505\n",
      "Validation Loss: 1833.1988\n",
      "Epoch [2181/3000], Loss: 189.0735\n",
      "Validation Loss: 1893.8006\n",
      "Epoch [2201/3000], Loss: 168.3151\n",
      "Validation Loss: 1923.6783\n",
      "Epoch [2221/3000], Loss: 160.2822\n",
      "Validation Loss: 1938.0626\n",
      "Epoch [2241/3000], Loss: 151.5556\n",
      "Validation Loss: 2009.0421\n",
      "Epoch [2261/3000], Loss: 150.7207\n",
      "Validation Loss: 1862.0942\n",
      "Epoch [2281/3000], Loss: 144.0926\n",
      "Validation Loss: 1929.6134\n",
      "Epoch [2301/3000], Loss: 133.1809\n",
      "Validation Loss: 1903.2588\n",
      "Epoch [2321/3000], Loss: 126.6621\n",
      "Validation Loss: 1859.7411\n",
      "Epoch [2341/3000], Loss: 127.4690\n",
      "Validation Loss: 1975.0263\n",
      "Epoch [2361/3000], Loss: 114.7174\n",
      "Validation Loss: 1940.8256\n",
      "Epoch [2381/3000], Loss: 108.7108\n",
      "Validation Loss: 1911.9493\n",
      "Epoch [2401/3000], Loss: 106.0218\n",
      "Validation Loss: 1936.2270\n",
      "Epoch [2421/3000], Loss: 100.9602\n",
      "Validation Loss: 1999.4527\n",
      "Epoch [2441/3000], Loss: 102.1943\n",
      "Validation Loss: 1981.8794\n",
      "Epoch [2461/3000], Loss: 92.6967\n",
      "Validation Loss: 1982.3745\n",
      "Epoch [2481/3000], Loss: 90.1413\n",
      "Validation Loss: 1953.9292\n",
      "Epoch [2501/3000], Loss: 85.0856\n",
      "Validation Loss: 2060.9395\n",
      "Epoch [2521/3000], Loss: 84.1685\n",
      "Validation Loss: 2004.1988\n",
      "Epoch [2541/3000], Loss: 76.8650\n",
      "Validation Loss: 2017.9142\n",
      "Epoch [2561/3000], Loss: 77.6643\n",
      "Validation Loss: 1998.5708\n",
      "Epoch [2581/3000], Loss: 82.1607\n",
      "Validation Loss: 2056.8883\n",
      "Epoch [2601/3000], Loss: 69.1688\n",
      "Validation Loss: 1977.1824\n",
      "Epoch [2621/3000], Loss: 65.6474\n",
      "Validation Loss: 2017.8391\n",
      "Epoch [2641/3000], Loss: 69.5677\n",
      "Validation Loss: 2079.0590\n",
      "Epoch [2661/3000], Loss: 62.5017\n",
      "Validation Loss: 2000.6812\n",
      "Epoch [2681/3000], Loss: 62.6328\n",
      "Validation Loss: 2089.5205\n",
      "Epoch [2701/3000], Loss: 57.7187\n",
      "Validation Loss: 1982.4290\n",
      "Epoch [2721/3000], Loss: 55.1240\n",
      "Validation Loss: 1988.4631\n",
      "Epoch [2741/3000], Loss: 131.5317\n",
      "Validation Loss: 2143.9659\n",
      "Epoch [2761/3000], Loss: 51.7507\n",
      "Validation Loss: 2026.7465\n",
      "Epoch [2781/3000], Loss: 50.8950\n",
      "Validation Loss: 2055.6492\n",
      "Epoch [2801/3000], Loss: 54.9083\n",
      "Validation Loss: 2066.8166\n",
      "Epoch [2821/3000], Loss: 49.9359\n",
      "Validation Loss: 1970.2427\n",
      "Epoch [2841/3000], Loss: 47.0788\n",
      "Validation Loss: 2047.0279\n",
      "Epoch [2861/3000], Loss: 50.7818\n",
      "Validation Loss: 2062.5053\n",
      "Epoch [2881/3000], Loss: 52.1534\n",
      "Validation Loss: 2110.5082\n",
      "Epoch [2901/3000], Loss: 41.4068\n",
      "Validation Loss: 2079.2589\n",
      "Epoch [2921/3000], Loss: 40.3848\n",
      "Validation Loss: 2054.1497\n",
      "Epoch [2941/3000], Loss: 38.1884\n",
      "Validation Loss: 2019.1497\n",
      "Epoch [2961/3000], Loss: 36.6905\n",
      "Validation Loss: 2052.9711\n",
      "Epoch [2981/3000], Loss: 63.9934\n",
      "Validation Loss: 2102.9181\n"
     ]
    }
   ],
   "source": [
    "# make models for all animals/days\n",
    "for dd in range(len(conddf)): \n",
    "    animal = conddf.animals.values[dd]\n",
    "    day = conddf.days.values[dd]\n",
    "    savepth = rf'Z:\\models_lstm_all_cells_no_rew'   \n",
    "    testpth = glob.glob(os.path.join(savepth, f'model_dd{dd:03d}*_{animal}_day{day}*'), recursive=True)\n",
    "    if len(testpth)==0:             \n",
    "        dct = dcts[dd]\n",
    "        params_pth = rf\"Y:\\analysis\\fmats\\{animal}\\days\\{animal}_day{day:03d}_plane0_Fall.mat\"\n",
    "        print(params_pth)\n",
    "        fall = scipy.io.loadmat(params_pth, variable_names=['dFF', 'forwardvel', 'ybinned', 'iscell',\n",
    "                                    'trialnum', 'bordercells', 'changeRewLoc', 'licks', 'VR'])\n",
    "        VR = fall['VR'][0][0]\n",
    "        try:\n",
    "            gainf = VR[14][0][0]\n",
    "            rewsize = VR[16][0][0][4][0][0]/gainf\n",
    "        except:\n",
    "            gainf = VR[15][0][0] # opto days have additional variables in vr\n",
    "            rewsize = VR[17][0][0][4][0][0]/gainf\n",
    "        inactive = dcts[dd]['inactive']\n",
    "        changeRewLoc = np.hstack(fall['changeRewLoc']) \n",
    "        eptest = conddf.optoep.values[dd]\n",
    "        eps = np.where(changeRewLoc>0)[0]\n",
    "        rewlocs = changeRewLoc[eps]\n",
    "        eps = np.append(eps, len(changeRewLoc)) \n",
    "        if conddf.optoep.values[dd]<2: \n",
    "            eptest = random.randint(2,3)   \n",
    "            if len(eps)<4: eptest = 2 # if no 3 epochs\n",
    "        trialnum = np.hstack(fall['trialnum'])\n",
    "        comp = [eptest-2,eptest-1] # eps to compare  \n",
    "        other_ep = [xx for xx in range(len(eps)-1) if xx not in comp]\n",
    "        # filter iscell        \n",
    "        dff = fall['dFF'][:,(fall['iscell'][:,0].astype(bool)) & (~fall['bordercells'][0].astype(bool))]\n",
    "        # position mask \n",
    "        # NOTE: excl reward location            \n",
    "        position = fall['ybinned'][0]\n",
    "        position_per_ep = [position[eps[xx]:eps[xx+1]] for xx in range(len(eps)-1)]       \n",
    "        # remove nans\n",
    "        dff[:, sum(np.isnan(dff))>0] = 0\n",
    "        # exclude rew zone\n",
    "        dff_per_ep = [dff[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "                (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))]\n",
    "            for xx in range(len(eps)-1)]        \n",
    "        trialnum_per_ep = [trialnum[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "                (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))] for xx in range(len(eps)-1)]\n",
    "        # get a subset of trials\n",
    "        dff_per_ep_trials = [dff_per_ep[ii][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "        dff_per_ep_trials_test = [dff_per_ep[ii][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "        # get a subset of trials\n",
    "        position_per_ep_trials = [position_per_ep[ii][(position_per_ep[ii]<rewlocs[ii]-(.5*rewsize)) |\n",
    "                (position_per_ep[ii]>rewlocs[ii]+(.5*rewsize))][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "        position_per_ep_trials_test = [position_per_ep[ii][(position_per_ep[ii]<rewlocs[ii]-(.5*rewsize)) |\n",
    "            (position_per_ep[ii]>rewlocs[ii]+(.5*rewsize))][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "        # licks\n",
    "        licks = fall['licks'][0]\n",
    "        licks_per_ep = [licks[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "            (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))] for xx in range(len(eps)-1)]\n",
    "        # get a subset of trials\n",
    "        licks_per_ep_trials = [licks_per_ep[ii][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "        licks_per_ep_trials_test = [licks_per_ep[ii][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "            #prepare variables \n",
    "        TimeInterval = 15 # frames\n",
    "        train = dff_per_ep_trials[comp[0]]\n",
    "        print(train.shape)\n",
    "        if train.shape[1]>0:\n",
    "            test = dff_per_ep_trials_test[comp[0]]\n",
    "            train_pos = position_per_ep_trials[comp[0]]\n",
    "            TrainingLabel = train_pos[TimeInterval-1:].reshape(-1,1)\n",
    "            test_pos = position_per_ep_trials_test[comp[0]]\n",
    "            TestLabel = test_pos[TimeInterval-1:].reshape(-1,1)\n",
    "\n",
    "            TrainingData = create_subsequences(train,TimeInterval)\n",
    "            batch_size = 256\n",
    "            input_size = TrainingData.shape[-1] # number of cells\n",
    "            output_size = 1\n",
    "            Train_dataset = CreateTimeSeriesData(TrainingData, TrainingLabel)\n",
    "            Train_loader = DataLoader(dataset=Train_dataset, batch_size=batch_size, \n",
    "                        shuffle=True, drop_last = True)\n",
    "            TestData = create_subsequences(test,TimeInterval)\n",
    "            Test_dataset = CreateTimeSeriesData(TestData, TestLabel)\n",
    "            Test_loader = DataLoader(dataset=Test_dataset, batch_size=batch_size,\n",
    "                        shuffle=False, drop_last = True)\n",
    "            \n",
    "            # define the model & train\n",
    "            # TODO: add transfer learning\n",
    "            model = LSTMModel(input_size, output_dim = output_size)\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            print(device)\n",
    "            model = model.to(device)\n",
    "            criterion = nn.MSELoss()  # For regression tasks\n",
    "            # criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(),\n",
    "                    lr=1e-5, weight_decay = 1e-9)\n",
    "            # Example training loop\n",
    "            l = []\n",
    "            val_l = []\n",
    "            num_epochs = 3000\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for inputs, targets in Train_loader:\n",
    "                    # Forward pass\n",
    "                    inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                l.append(train_loss/len(Train_loader))\n",
    "                if epoch % 20 == 0:\n",
    "                    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss/len(Train_loader)))\n",
    "                    val_loss = 0.0\n",
    "                    for inputs, targets in Test_loader:\n",
    "                        # Forward pass\n",
    "                        inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        val_loss += loss.item()\n",
    "                        val_l.append(val_loss/len(Test_loader))\n",
    "                    print('Validation Loss: {:.4f}'.format(val_loss/len(Test_loader)))\n",
    "            # save        \n",
    "            torch.save(model.state_dict(), os.path.join(savepth, f'model_dd{dd:03d}_epcompare{comp[0]}-{comp[1]}_{animal}_day{day}.pt'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d29c6cd7-d190-498e-8257-e9891d08fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTMModel:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 837]) from checkpoint, the shape in current model is torch.Size([1024, 23]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dd)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMModel(input_size, output_dim \u001b[38;5;241m=\u001b[39m output_size)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msavepth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n",
      "File \u001b[1;32mc:\\Users\\Han\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTMModel:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 837]) from checkpoint, the shape in current model is torch.Size([1024, 23])."
     ]
    }
   ],
   "source": [
    "# load existing model\n",
    "dd=4\n",
    "dct = dcts[dd]\n",
    "animal = conddf.animals.values[dd]\n",
    "day = conddf.days.values[dd]\n",
    "\n",
    "params_pth = rf\"Y:\\analysis\\fmats\\{animal}\\days\\{animal}_day{day:03d}_plane0_Fall.mat\"\n",
    "print(params_pth)\n",
    "fall = scipy.io.loadmat(params_pth, variable_names=['dFF', 'forwardvel', 'ybinned', 'iscell',\n",
    "                            'trialnum', 'bordercells', 'changeRewLoc', 'licks', 'VR'])\n",
    "VR = fall['VR'][0][0]\n",
    "try:\n",
    "    gainf = VR[14][0][0]\n",
    "    rewsize = VR[16][0][0][4][0][0]/gainf\n",
    "except:\n",
    "    gainf = VR[15][0][0] # opto days have additional variables in vr\n",
    "    rewsize = VR[17][0][0][4][0][0]/gainf\n",
    "inactive = dcts[dd]['inactive']\n",
    "changeRewLoc = np.hstack(fall['changeRewLoc']) \n",
    "eptest = conddf.optoep.values[dd]\n",
    "eps = np.where(changeRewLoc>0)[0]\n",
    "rewlocs = changeRewLoc[eps]\n",
    "eps = np.append(eps, len(changeRewLoc)) \n",
    "if conddf.optoep.values[dd]<2: \n",
    "    eptest = random.randint(2,3)   \n",
    "    if len(eps)<4: eptest = 2 # if no 3 epochs\n",
    "trialnum = np.hstack(fall['trialnum'])\n",
    "comp = [eptest-2,eptest-1] # eps to compare  \n",
    "other_ep = [xx for xx in range(len(eps)-1) if xx not in comp]\n",
    "# filter iscell        \n",
    "dff = fall['dFF'][:,(fall['iscell'][:,0].astype(bool)) & (~fall['bordercells'][0].astype(bool))]\n",
    "# position mask \n",
    "# NOTE: excl reward location            \n",
    "position = fall['ybinned'][0]\n",
    "position_per_ep = [position[eps[xx]:eps[xx+1]] for xx in range(len(eps)-1)]       \n",
    "# remove nans\n",
    "dff[:, sum(np.isnan(dff))>0] = 0\n",
    "# exclude rew zone\n",
    "dff_per_ep = [dff[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "        (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))]\n",
    "    for xx in range(len(eps)-1)]        \n",
    "trialnum_per_ep = [trialnum[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "        (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))] for xx in range(len(eps)-1)]\n",
    "# get a subset of trials\n",
    "dff_per_ep_trials = [dff_per_ep[ii][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "dff_per_ep_trials_test = [dff_per_ep[ii][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "# get a subset of trials\n",
    "position_per_ep_trials = [position_per_ep[ii][(position_per_ep[ii]<rewlocs[ii]-(.5*rewsize)) |\n",
    "        (position_per_ep[ii]>rewlocs[ii]+(.5*rewsize))][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "position_per_ep_trials_test = [position_per_ep[ii][(position_per_ep[ii]<rewlocs[ii]-(.5*rewsize)) |\n",
    "    (position_per_ep[ii]>rewlocs[ii]+(.5*rewsize))][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "# licks\n",
    "licks = fall['licks'][0]\n",
    "licks_per_ep = [licks[eps[xx]:eps[xx+1]][(position_per_ep[xx]<rewlocs[xx]-(.5*rewsize)) | \n",
    "    (position_per_ep[xx]>rewlocs[xx]+(.5*rewsize))] for xx in range(len(eps)-1)]\n",
    "# get a subset of trials\n",
    "licks_per_ep_trials = [licks_per_ep[ii][((trialnum_per_ep[ii]>2) & (trialnum_per_ep[ii]<=10)) | (trialnum_per_ep[ii]>15)] for ii in range(len(eps)-1)]\n",
    "licks_per_ep_trials_test = [licks_per_ep[ii][(trialnum_per_ep[ii]>10) & (trialnum_per_ep[ii]<16)] for ii in range(len(eps)-1)]\n",
    "    #prepare variables \n",
    "\n",
    "savepth = rf'\"Z:\\models_lstm_all_cells_no_rew\\model_dd004_epcompare1-2_e218_day35.pt\"'\n",
    "print(dd)\n",
    "model = LSTMModel(input_size, output_dim = output_size)\n",
    "model.load_state_dict(torch.load(savepth))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()  # For regression tasks\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, \n",
    "            weight_decay = 1e-9)\n",
    "\n",
    "# use model to predict position\n",
    "dff_test = dff_per_ep_trials_test[comp[1]]\n",
    "# TODO: use a couple trials from same ep as testing\n",
    "# use different epochs for further testing\n",
    "pos = position_per_ep_trials_test[comp[1]]\n",
    "pos = pos[TimeInterval-1:].reshape(-1,1)\n",
    "lick = licks_per_ep_trials_test[comp[1]]\n",
    "\n",
    "TestData = create_subsequences(dff_test,TimeInterval)\n",
    "input_size = TestData.shape[-1] # number of cells\n",
    "output_size = 1\n",
    "\n",
    "Test_dataset = CreateTimeSeriesData(TestData, pos)\n",
    "Test_loader = DataLoader(dataset=Test_dataset, batch_size=batch_size, \n",
    "                        shuffle=False, drop_last = True)\n",
    "predict = []\n",
    "val_loss = 0\n",
    "for inputs, targets in Test_loader:\n",
    "    # Forward pass\n",
    "    inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "    outputs = model(inputs)\n",
    "    predict.append(outputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    val_loss += loss.item()\n",
    "print('Validation Loss: {:.4f}'.format(val_loss/len(Test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "024bb556-2627-4cda-9916-0da92521e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c16c476d60>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict = np.concatenate([xx.cpu().detach().numpy() for xx in predict])\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,7))\n",
    "axes[0].plot(pos)\n",
    "axes[1].plot(predict)\n",
    "axes[2].plot(pos)\n",
    "axes[2].plot(predict)\n",
    "axes[0].scatter(np.where(lick>0)[0], pos[np.where(lick>0)[0]], s=5, color='k')\n",
    "axes[1].scatter(np.where(lick>0)[0], pos[np.where(lick>0)[0]], s=5, color='k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
